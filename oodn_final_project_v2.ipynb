    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "collapsed": true,
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "bhw8NPwVRbdT"
      },
      "outputs": [],
      "source": [
        "from os import listdir\n",
        "\n",
        "import time\n",
        "import json\n",
        "import copy\n",
        "\n",
        "import torch\n",
        "\n",
        "from torchvision.datasets import mnist, FashionMNIST\n",
        "from torch.utils.data import DataLoader\n",
        "from torchvision.transforms import ToTensor\n",
        "from torch.optim import SGD, Adam\n",
        "from torch.nn import Module\n",
        "from torch import nn\n",
        "from torch.nn import CrossEntropyLoss\n",
        "from torchvision.models.resnet import Bottleneck, ResNet\n",
        "from torchvision import datasets, models, transforms\n",
        "\n",
        "from wilds import get_dataset\n",
        "from wilds.common.data_loaders import get_train_loader\n",
        "import torchvision.transforms as transforms\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "from openood.evaluators import metrics"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "11.6\n"
          ]
        }
      ],
      "source": [
        "print(torch.version.cuda)"
      ],
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "11glohxERbdU",
        "outputId": "a412b2d2-d294-470d-b27a-abd3627aa087"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cuda:0\n"
          ]
        }
      ],
      "source": [
        "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
        "print(device)"
      ],
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1tHAXNmwRbdU",
        "outputId": "ae15afd4-3c31-4e5c-d557-178f188de89c"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pwd"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WtgqLe2SajQb",
        "outputId": "3961662e-2a97-4bb0-a56c-11d9e69e79a6"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive/oodn\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Supported Activation Functions\n",
        "\n",
        "For activation functions, we are considering ReLU, Softplus, Swish. *Note that we may conduct experiments for a subset based on the compute resources available*"
      ],
      "metadata": {
        "collapsed": false,
        "pycharm": {
          "name": "#%% md\n"
        },
        "id": "BWs4cttKRbdU"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "outputs": [],
      "source": [
        "def get_activation_fn(activation):\n",
        "    if activation == 'relu':\n",
        "        return nn.ReLU()\n",
        "    elif activation == 'softplus':\n",
        "        return nn.Softplus()\n",
        "    elif activation == 'swish':\n",
        "        return nn.Swish()\n",
        "    return None"
      ],
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "wFDrLIC4RbdV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "collapsed": false,
        "pycharm": {
          "name": "#%% md\n"
        },
        "id": "ORnYhf-1RbdV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### LeNet"
      ],
      "metadata": {
        "collapsed": false,
        "pycharm": {
          "name": "#%% md\n"
        },
        "id": "7vRFe847RbdV"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "outputs": [],
      "source": [
        "class LeNet(nn.Module):\n",
        "    def __init__(self, num_classes, num_channel=3, activation='relu'):\n",
        "        super(LeNet, self).__init__()\n",
        "        self.num_classes = num_classes\n",
        "        self.feature_size = 84\n",
        "        self.block1 = nn.Sequential(\n",
        "            nn.Conv2d(in_channels=num_channel,\n",
        "                      out_channels=6,\n",
        "                      kernel_size=5,\n",
        "                      stride=1,\n",
        "                      padding=2), get_activation_fn(activation), nn.MaxPool2d(kernel_size=2))\n",
        "\n",
        "        self.block2 = nn.Sequential(\n",
        "            nn.Conv2d(in_channels=6, out_channels=16, kernel_size=5, stride=1),\n",
        "             get_activation_fn(activation), nn.MaxPool2d(kernel_size=2))\n",
        "\n",
        "        self.block3 = nn.Sequential(\n",
        "            nn.Conv2d(in_channels=16,\n",
        "                      out_channels=120,\n",
        "                      kernel_size=5,\n",
        "                      stride=1), get_activation_fn(activation))\n",
        "\n",
        "        self.classifier1 = nn.Linear(in_features=120, out_features=84)\n",
        "        self.relu = get_activation_fn(activation)\n",
        "        self.fc = nn.Linear(in_features=84, out_features=num_classes)\n",
        "\n",
        "    def get_fc(self):\n",
        "        fc = self.fc\n",
        "        return fc.weight.cpu().detach().numpy(), fc.bias.cpu().detach().numpy()\n",
        "\n",
        "    def forward(self, x, return_feature=False, return_feature_list=False):\n",
        "        feature1 = self.block1(x)\n",
        "        feature2 = self.block2(feature1)\n",
        "        feature3 = self.block3(feature2)\n",
        "        feature3 = feature3.view(feature3.shape[0], -1)\n",
        "        feature = self.relu(self.classifier1(feature3))\n",
        "        logits_cls = self.fc(feature)\n",
        "        feature_list = [feature1, feature2, feature3, feature]\n",
        "        if return_feature:\n",
        "            return logits_cls, feature\n",
        "        elif return_feature_list:\n",
        "            return logits_cls, feature_list\n",
        "        else:\n",
        "            return logits_cls\n",
        "\n",
        "    def forward_threshold(self, x, threshold):\n",
        "        feature1 = self.block1(x)\n",
        "        feature2 = self.block2(feature1)\n",
        "        feature3 = self.block3(feature2)\n",
        "        feature3 = feature3.view(feature3.shape[0], -1)\n",
        "        feature = self.relu(self.classifier1(feature3))\n",
        "        feature = feature.clip(max=threshold)\n",
        "        logits_cls = self.fc(feature)\n",
        "\n",
        "        return logits_cls"
      ],
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "-H6TJweYRbdV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### ResNet50"
      ],
      "metadata": {
        "collapsed": false,
        "pycharm": {
          "name": "#%% md\n"
        },
        "id": "XYwc4beHRbdV"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "outputs": [],
      "source": [
        "def set_parameter_requires_grad(model, feature_extract):\n",
        "    if feature_extract:\n",
        "        for name,param in model.named_parameters():\n",
        "          if not (name.startswith('layer4') or name.startswith('fc')):\n",
        "            param.requires_grad = False\n",
        "\n",
        "def get_resnet_model(activation_function_type, n_classes,feature_extract=True, use_pretrained=True):\n",
        "    resnet_model = models.resnet50(pretrained=use_pretrained)\n",
        "    set_parameter_requires_grad(resnet_model, feature_extract)\n",
        "    set_activation_function(resnet_model,activation_function_type)\n",
        "    num_ftrs = resnet_model.fc.in_features\n",
        "    resnet_model.fc = nn.Linear(num_ftrs, n_classes)\n",
        "    resnet_model.to(device)\n",
        "    return resnet_model\n",
        "\n",
        "def set_activation_function(resnet_model, activation_function_type):\n",
        "    resnet_model.relu = get_activation_fn(activation_function_type)\n",
        "    resnet_model.layer1[0].relu = get_activation_fn(activation_function_type)\n",
        "    resnet_model.layer1[1].relu = get_activation_fn(activation_function_type)\n",
        "    resnet_model.layer1[2].relu = get_activation_fn(activation_function_type)\n",
        "\n",
        "    resnet_model.layer2[0].relu = get_activation_fn(activation_function_type)\n",
        "    resnet_model.layer2[1].relu = get_activation_fn(activation_function_type)\n",
        "    resnet_model.layer2[2].relu = get_activation_fn(activation_function_type)\n",
        "    resnet_model.layer2[3].relu = get_activation_fn(activation_function_type)\n",
        "\n",
        "    resnet_model.layer3[0].relu = get_activation_fn(activation_function_type)\n",
        "    resnet_model.layer3[1].relu = get_activation_fn(activation_function_type)\n",
        "    resnet_model.layer3[2].relu = get_activation_fn(activation_function_type)\n",
        "    resnet_model.layer3[3].relu = get_activation_fn(activation_function_type)\n",
        "    resnet_model.layer3[4].relu = get_activation_fn(activation_function_type)\n",
        "    resnet_model.layer3[5].relu = get_activation_fn(activation_function_type)\n",
        "\n",
        "\n",
        "    resnet_model.layer4[0].relu = get_activation_fn(activation_function_type)\n",
        "    resnet_model.layer4[1].relu = get_activation_fn(activation_function_type)\n",
        "    resnet_model.layer4[2].relu = get_activation_fn(activation_function_type)\n",
        "\n",
        "    return resnet_model"
      ],
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "4EaTD1nVRbdW"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "outputs": [],
      "source": [
        "def get_model(config):\n",
        "    activation_function_type = config[\"activation_function_type\"]\n",
        "    network_type = config[\"network\"]\n",
        "    n_classes = config[\"n_classes\"]\n",
        "\n",
        "    if network_type == \"lenet\":\n",
        "        model =  LeNet(num_classes=n_classes, num_channel=1, activation=activation_function_type)\n",
        "    elif network_type == \"resnet50\":\n",
        "        model = get_resnet_model(activation_function_type, n_classes)\n",
        "    else:\n",
        "        raise Exception(\"Currently we only support lenet or resnet50\")\n",
        "\n",
        "    return model"
      ],
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "Mm1fB4piRbdW"
      }
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "collapsed": false,
        "pycharm": {
          "name": "#%% md\n"
        },
        "id": "9veLq_LDRbdW"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Supported Post-Hoc OODN Processors"
      ],
      "metadata": {
        "collapsed": false,
        "pycharm": {
          "name": "#%% md\n"
        },
        "id": "OKbri3J-RbdW"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### The first post processor we consider is ODIN"
      ],
      "metadata": {
        "collapsed": false,
        "pycharm": {
          "name": "#%% md\n"
        },
        "id": "dPvVbPU4RbdW"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "outputs": [],
      "source": [
        "class ODINPostprocessor():\n",
        "    def __init__(self, temperature, noise):\n",
        "        self.temperature = temperature\n",
        "        self.noise = noise\n",
        "\n",
        "    def postprocess(self, net: nn.Module, data):\n",
        "        net.eval()\n",
        "        data.requires_grad = True\n",
        "        output = net(data)\n",
        "\n",
        "        # Calculating the perturbation we need to add, that is,\n",
        "        # the sign of gradient of cross entropy loss w.r.t. input\n",
        "        criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "        labels = output.detach().argmax(axis=1)\n",
        "\n",
        "        # Using temperature scaling\n",
        "        output = output / self.temperature\n",
        "\n",
        "        loss = criterion(output, labels)\n",
        "        loss.backward()\n",
        "\n",
        "        # Normalizing the gradient to binary in {0, 1}\n",
        "        gradient = torch.ge(data.grad.detach(), 0)\n",
        "        gradient = (gradient.float() - 0.5) * 2\n",
        "\n",
        "        # Scaling values taken from original code\n",
        "        gradient[:, 0] = (gradient[:, 0]) / (63.0 / 255.0)\n",
        "        if gradient.shape[1] == 3:\n",
        "            gradient[:, 1] = (gradient[:, 1]) / (62.1 / 255.0)\n",
        "            gradient[:, 2] = (gradient[:, 2]) / (66.7 / 255.0)\n",
        "\n",
        "        # Adding small perturbations to images\n",
        "        tempInputs = torch.add(data.detach(), gradient, alpha=-self.noise)\n",
        "        output = net(tempInputs)\n",
        "        output = output / self.temperature\n",
        "\n",
        "        # Calculating the confidence after adding perturbations\n",
        "        nnOutput = output.detach()\n",
        "        nnOutput = nnOutput - nnOutput.max(dim=1, keepdims=True).values\n",
        "        nnOutput = nnOutput.exp() / nnOutput.exp().sum(dim=1, keepdims=True)\n",
        "\n",
        "        conf, pred = nnOutput.max(dim=1)\n",
        "\n",
        "        return pred, conf\n",
        "\n",
        "    def inference(self, net: nn.Module, data_loader: DataLoader):\n",
        "        pred_list, conf_list, label_list = [], [], []\n",
        "        for idx, loaded_data in enumerate(data_loader):\n",
        "            data, label = loaded_data[0], loaded_data[1]\n",
        "            if idx % 50 == 0:\n",
        "                print(f'Performing inference on batch: {idx}')\n",
        "            pred, conf = self.postprocess(net, data.to(device))\n",
        "            for idx in range(len(data)):\n",
        "                pred_list.append(pred[idx].tolist())\n",
        "                conf_list.append(conf[idx].tolist())\n",
        "                label_list.append(label[idx].tolist())\n",
        "\n",
        "        # convert values into numpy array\n",
        "        pred_list = np.array(pred_list, dtype=int)\n",
        "        conf_list = np.array(conf_list)\n",
        "        label_list = np.array(label_list, dtype=int)\n",
        "\n",
        "        return pred_list, conf_list, label_list"
      ],
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "Am-I4gXqRbdW"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### We consider the Maximum Classifier Discrepancy Post OODN method\n",
        "\n",
        "https://arxiv.org/pdf/1712.02560.pdf"
      ],
      "metadata": {
        "collapsed": false,
        "pycharm": {
          "name": "#%% md\n"
        },
        "id": "Kz32VFq9RbdX"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "outputs": [],
      "source": [
        "class MCDPostprocessor():\n",
        "    @torch.no_grad()\n",
        "    def postprocess(self, net: nn.Module, data):\n",
        "        logits1, logits2 = net(data, return_double=True)\n",
        "        score1 = torch.softmax(logits1, dim=1)\n",
        "        score2 = torch.softmax(logits2, dim=1)\n",
        "        conf = -torch.sum(torch.abs(score1 - score2), dim=1)\n",
        "        _, pred = torch.max(score1, dim=1)\n",
        "        return pred, conf\n",
        "\n",
        "    def inference(self, net: nn.Module, data_loader: DataLoader):\n",
        "        pred_list, conf_list, label_list = [], [], []\n",
        "        for idx, loaded_data in enumerate(data_loader):\n",
        "            data, label = loaded_data[0], loaded_data[1]\n",
        "            if idx % 50 == 0:\n",
        "                print(f'Performing inference on batch: {idx}')\n",
        "            pred, conf = self.postprocess(net, data.to(device))\n",
        "            for idx in range(len(data)):\n",
        "                pred_list.append(pred[idx].tolist())\n",
        "                conf_list.append(conf[idx].tolist())\n",
        "                label_list.append(label[idx].tolist())\n",
        "\n",
        "        # convert values into numpy array\n",
        "        pred_list = np.array(pred_list, dtype=int)\n",
        "        conf_list = np.array(conf_list)\n",
        "        label_list = np.array(label_list, dtype=int)\n",
        "\n",
        "        return pred_list, conf_list, label_list"
      ],
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "7L45tl2cRbdX"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "outputs": [],
      "source": [
        "def get_postprocessor(postprocessor_type=\"odin\"):\n",
        "    if postprocessor_type == \"odin\":\n",
        "        postprocessor = ODINPostprocessor(1000, 0.0014)\n",
        "    elif postprocessor_type == \"mcd\":\n",
        "        postprocessor = MCDPostprocessor()\n",
        "    return postprocessor"
      ],
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "0NHU_CaCRbdX"
      }
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "collapsed": false,
        "pycharm": {
          "name": "#%% md\n"
        },
        "id": "IZfeGklQRbdX"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Supported Out of Distribution Detection Metrics\n",
        "\n",
        "What metrics do we specifically care about here?\n",
        "\n",
        "**FPR@95** measures the false positive rate (FPR) when the true positive rate (TPR) is\n",
        "equal to 95%. Lower scores indicate better performance.\n",
        "\n",
        "**AUROC** measures the area under the\n",
        "Receiver Operating Characteristic (ROC) curve, which displays the relationship between TPR and\n",
        "FPR. The area under the ROC curve can be interpreted as the probability that a positive ID example\n",
        "will have a higher detection score than a negative OOD example.\n",
        "\n",
        "**AUPR** measures the area under\n",
        "the Precision-Recall (PR) curve. The PR curve is created by plotting precision versus recall. Similar\n",
        "to AUROC, we consider ID samples as positive, so that the score corresponds to the AUPR-In metric\n",
        "in some works"
      ],
      "metadata": {
        "collapsed": false,
        "pycharm": {
          "name": "#%% md\n"
        },
        "id": "bGtatMpzRbdX"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "outputs": [],
      "source": [
        "def calculate_oodn_metrics(model, postprocessor_type, id_test_loader, ood_test_loader, ood_name):\n",
        "    postprocessor = get_postprocessor(postprocessor_type)\n",
        "    id_pred, id_conf, id_gt = postprocessor.inference(\n",
        "                model, id_test_loader)\n",
        "\n",
        "    ood_pred, ood_conf, ood_gt = postprocessor.inference(\n",
        "        model, ood_test_loader)\n",
        "\n",
        "    ood_gt = -1 * np.ones_like(ood_gt)  # hard set to -1 as ood\n",
        "    pred = np.concatenate([id_pred, ood_pred])\n",
        "    conf = np.concatenate([id_conf, ood_conf])\n",
        "    label = np.concatenate([id_gt, ood_gt])\n",
        "    ood_metrics = metrics.compute_all_metrics(conf, label, pred)\n",
        "\n",
        "    return print_and_get_formatted_metrics(ood_metrics, ood_name)\n",
        "\n",
        "def print_and_get_formatted_metrics(metrics, dataset_name):\n",
        "    [fpr, auroc, aupr_in, aupr_out,\n",
        "     ccr_4, ccr_3, ccr_2, ccr_1, accuracy] \\\n",
        "     = metrics\n",
        "\n",
        "    write_content = {\n",
        "        'dataset': dataset_name,\n",
        "        'FPR@95': '{:.2f}'.format(100 * fpr),\n",
        "        'AUROC': '{:.2f}'.format(100 * auroc),\n",
        "        'AUPR_IN': '{:.2f}'.format(100 * aupr_in),\n",
        "        'AUPR_OUT': '{:.2f}'.format(100 * aupr_out),\n",
        "        'CCR_4': '{:.2f}'.format(100 * ccr_4),\n",
        "        'CCR_3': '{:.2f}'.format(100 * ccr_3),\n",
        "        'CCR_2': '{:.2f}'.format(100 * ccr_2),\n",
        "        'CCR_1': '{:.2f}'.format(100 * ccr_1),\n",
        "        'ACC': '{:.2f}'.format(100 * accuracy)\n",
        "    }\n",
        "\n",
        "    fieldnames = list(write_content.keys())\n",
        "\n",
        "    # print ood metric results\n",
        "    print('FPR@95: {:.2f}, AUROC: {:.2f}'.format(100 * fpr, 100 * auroc),\n",
        "          end=' ',\n",
        "          flush=True)\n",
        "    print('AUPR_IN: {:.2f}, AUPR_OUT: {:.2f}'.format(\n",
        "        100 * aupr_in, 100 * aupr_out),\n",
        "          flush=True)\n",
        "    print('CCR: {:.2f}, {:.2f}, {:.2f}, {:.2f},'.format(\n",
        "        ccr_4 * 100, ccr_3 * 100, ccr_2 * 100, ccr_1 * 100),\n",
        "          end=' ',\n",
        "          flush=True)\n",
        "    print('ACC: {:.2f}'.format(accuracy * 100), flush=True)\n",
        "    print(u'\\u2500' * 70, flush=True)\n",
        "    return write_content\n",
        "\n",
        "def load_results_into_df(dir_path):\n",
        "    res_files = [dir_path+each for each in listdir(dir_path)]\n",
        "    all_results = []\n",
        "    columns = ['optimizer_type', 'activation_function_type', 'postprocessor_type', 'trial', 'AUROC']\n",
        "    for fp in res_files:\n",
        "        f = open(fp)\n",
        "        data = json.load(f)\n",
        "        for trial, results in data.items():\n",
        "            all_results.append([\n",
        "                    results['optimizer_type'],\n",
        "                    results['activation_function_type'],\n",
        "                    results['postprocessor_type'],\n",
        "                    trial,\n",
        "                    float(results['AUROC'])\n",
        "                ])\n",
        "    df = pd.DataFrame(all_results, columns=columns)\n",
        "    return df"
      ],
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "Xm89cB-XRbdX"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "outputs": [],
      "source": [
        "def get_optimizer(model, config):\n",
        "    params = model.parameters()\n",
        "    lr = config['lr']\n",
        "    momentum = config['momentum']\n",
        "    weight_decay = config['weight_decay']\n",
        "    optimizer_type = config['optimizer_type']\n",
        "\n",
        "    print(f'Getting optimizer for type: {optimizer_type}...')\n",
        "    if optimizer_type == 'SGD':\n",
        "        return SGD(params,\n",
        "              lr=lr,\n",
        "              momentum=momentum,\n",
        "              weight_decay=weight_decay)\n",
        "    elif optimizer_type == 'Adam':\n",
        "        return Adam(params,\n",
        "                    lr=lr,\n",
        "                    weight_decay=weight_decay)\n",
        "    else:\n",
        "        raise Exception(\"Invalid optimizer_type provided, only SGD and Adam are supported currently\")\n",
        "\n",
        "def get_wilds_loader(dataset, split, batch_size):\n",
        "    d = dataset.get_subset(\n",
        "        split,\n",
        "        # frac=0.1,\n",
        "        transform=transforms.Compose(\n",
        "            [transforms.Resize((448, 448)), transforms.ToTensor()]\n",
        "        ),\n",
        "    )\n",
        "    # Prepare the standard data loader\n",
        "    return get_train_loader(\"standard\", d, batch_size=batch_size)\n",
        "\n",
        "def get_data_loaders(config):\n",
        "    data_loaders = {}\n",
        "    dataset_name = config[\"dataset_name\"]\n",
        "    dataset_type = config[\"dataset_type\"]\n",
        "    batch_size = config['batch_size']\n",
        "\n",
        "    wilds_id_test_split = \"id_val\" if dataset_name == \"camelyon17\" else \"id_test\"\n",
        "    if dataset_type == \"wilds\":\n",
        "        # wilds dataset\n",
        "        dataset = get_dataset(dataset=dataset_name, download=True)\n",
        "        data_loaders[\"train\"] = get_wilds_loader(dataset, \"train\", batch_size)\n",
        "        data_loaders[\"ood_test\"] = get_wilds_loader(dataset, \"test\", batch_size)\n",
        "        data_loaders[\"id_test\"] = get_wilds_loader(dataset, wilds_id_test_split, batch_size)\n",
        "    elif dataset_name == \"mnist\":\n",
        "        # mnist dataset\n",
        "        train_dataset = mnist.MNIST(root='data', download=True, train=True, transform=ToTensor())\n",
        "        test_dataset = mnist.MNIST(root='data', download=True, train=False, transform=ToTensor())\n",
        "        fashion_test_dataset = mnist.FashionMNIST(root='data', download=True,train=False,transform=ToTensor())\n",
        "\n",
        "        data_loaders[\"train\"] = DataLoader(train_dataset, batch_size=batch_size)\n",
        "        data_loaders[\"id_test\"] = DataLoader(test_dataset, batch_size=batch_size)\n",
        "        data_loaders[\"ood_test\"] = DataLoader(fashion_test_dataset, batch_size=batch_size)\n",
        "\n",
        "    return data_loaders"
      ],
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "aEJLZ75aRbdX"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "outputs": [],
      "source": [
        "def train_resnet_model_given_opti_activation_fn(config):\n",
        "    # get the train loader\n",
        "    train_loader = config[\"data_loaders\"][\"train\"]\n",
        "\n",
        "    # get the resnet model with the replaced activation functions\n",
        "    model = get_model(config)\n",
        "    model.to(device)\n",
        "\n",
        "    # get the optimizer\n",
        "    sgd = get_optimizer(model, config)\n",
        "\n",
        "    loss_fn = CrossEntropyLoss()\n",
        "    for current_epoch in range(config['epochs']):\n",
        "      tic=time.time()\n",
        "      model.train()\n",
        "      print('Training epoch: {}'.format(current_epoch))\n",
        "      for idx, (loader_data) in enumerate(train_loader):\n",
        "        train_x, train_label = loader_data[0].to(device), loader_data[1].to(device)\n",
        "        sgd.zero_grad()\n",
        "        predict_y = model(train_x.float())\n",
        "        loss = loss_fn(predict_y, train_label.long())\n",
        "        if idx % 100 == 0:\n",
        "          print('idx: {}, loss: {}'.format(idx, loss.sum().item()))\n",
        "        loss.backward()\n",
        "        sgd.step()\n",
        "      print(f\"epoch {current_epoch} time taken: {time.time()-tic}s\")\n",
        "    torch.save(model, config['model_name'])\n",
        "\n",
        "    return model\n",
        "\n",
        "def run_full_oodn_pipeline(config):\n",
        "    metrics = {}\n",
        "    for i in range(config[\"trials\"]):\n",
        "        model_name = f\"models/{config['network']}_{config['dataset_name']}_{config['activation_function_type']}_{config['optimizer_type']}_{i}.pkl\"\n",
        "        print(f'Running model: {model_name}...')\n",
        "        config['model_name'] = model_name\n",
        "        # train model\n",
        "        model = train_resnet_model_given_opti_activation_fn(config)\n",
        "        # calculate oodn metrics\n",
        "        metrics[i] = calculate_oodn_metrics(model,\n",
        "                               \"odin\",\n",
        "                               config[\"data_loaders\"][\"id_test\"],\n",
        "                               config[\"data_loaders\"][\"ood_test\"],\n",
        "                               config[\"dataset_name\"])\n",
        "        metrics[i]['optimizer_type'] = config['optimizer_type']\n",
        "        metrics[i]['activation_function_type'] = config['activation_function_type']\n",
        "        metrics[i]['postprocessor_type'] = config['postprocessor_type']\n",
        "\n",
        "    experiment_name = f\"{config['results_dir']}/{config['dataset_name']}_{config['network']}_{config['postprocessor_type']}_{config['activation_function_type']}_{config['optimizer_type']}.json\"\n",
        "    with open(experiment_name, 'w') as fp:\n",
        "        json.dump(metrics, fp)\n",
        "    return metrics"
      ],
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "JfRfN2fNRbdX"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading dataset to data/camelyon17_v1.0...\n",
            "You can also download the dataset manually at https://wilds.stanford.edu/downloads.\n",
            "Using downloaded and verified file: data/camelyon17_v1.0/archive.tar.gz\n",
            "Extracting data/camelyon17_v1.0/archive.tar.gz to data/camelyon17_v1.0\n"
          ]
        }
      ],
      "source": [
        "config_2a = {\n",
        "    \"batch_size\": 16,\n",
        "    \"n_classes\": 2,\n",
        "    \"dataset_name\": \"camelyon17\",\n",
        "    \"epochs\": 10,\n",
        "    \"version\": time.time(),\n",
        "    \"lr\": 0.01,\n",
        "    \"momentum\": 0.9,\n",
        "    \"weight_decay\": 0.0005,\n",
        "    \"optimizer_type\": \"SGD\",\n",
        "    \"activation_function_type\": \"softplus\",\n",
        "    \"network\": \"resnet50\",\n",
        "    \"postprocessor_type\": \"odin\",\n",
        "    \"trials\": 1,\n",
        "    \"dataset_type\": \"wilds\",\n",
        "     \"results_dir\": \"camelyon17-study\"\n",
        "}\n",
        "config_2a[\"data_loaders\"] = get_data_loaders(config_2a)"
      ],
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Lzf8wgoTRbdY",
        "outputId": "b0d274c3-4075-4581-97dc-e3fce18f24d2"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Running model: models/resnet50_camelyon17_softplus_SGD_0.pkl...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "D:\\Anaconda3\\envs\\torch\\lib\\site-packages\\torchvision\\models\\_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
            "  warnings.warn(\n",
            "D:\\Anaconda3\\envs\\torch\\lib\\site-packages\\torchvision\\models\\_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet50_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet50_Weights.DEFAULT` to get the most up-to-date weights.\n",
            "  warnings.warn(msg)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Getting optimizer for type: SGD...\n",
            "Training epoch: 0\n",
            "idx: 0, loss: 0.8394182920455933\n",
            "idx: 100, loss: 7.229266166687012\n",
            "idx: 200, loss: 4.90431547164917\n",
            "idx: 300, loss: 5.418013095855713\n",
            "idx: 400, loss: 2.502758026123047\n",
            "idx: 500, loss: 6.383957862854004\n",
            "idx: 600, loss: 24.026390075683594\n",
            "idx: 700, loss: 18.57456398010254\n",
            "idx: 800, loss: 15.221599578857422\n",
            "idx: 900, loss: 1.505684733390808\n",
            "idx: 1000, loss: 0.08190107345581055\n",
            "idx: 1100, loss: 4.197094917297363\n",
            "idx: 1200, loss: 2.8323913284111768e-05\n",
            "idx: 1300, loss: 0.53661048412323\n",
            "idx: 1400, loss: 6.90887451171875\n",
            "idx: 1500, loss: 2.849867105484009\n",
            "idx: 1600, loss: 7.646994113922119\n",
            "idx: 1700, loss: 2.3749046325683594\n",
            "idx: 1800, loss: 0.00044331009848974645\n",
            "Training epoch: 1\n",
            "idx: 0, loss: 14.791077613830566\n",
            "idx: 100, loss: 18.964080810546875\n",
            "idx: 200, loss: 3.37542986869812\n",
            "idx: 300, loss: 13.885287284851074\n",
            "idx: 400, loss: 5.516000270843506\n",
            "idx: 500, loss: 10.746439933776855\n",
            "idx: 600, loss: 12.892280578613281\n",
            "idx: 700, loss: 3.3480584621429443\n",
            "idx: 800, loss: 13.87397289276123\n",
            "idx: 900, loss: 4.5218329429626465\n",
            "idx: 1000, loss: 4.24131441116333\n",
            "idx: 1100, loss: 2.2860958576202393\n",
            "idx: 1200, loss: 4.334759712219238\n",
            "idx: 1300, loss: 2.1023247241973877\n",
            "idx: 1400, loss: 4.214862823486328\n",
            "idx: 1500, loss: 5.357310771942139\n",
            "idx: 1600, loss: 10.319915771484375\n",
            "idx: 1700, loss: 0.20704612135887146\n",
            "idx: 1800, loss: 4.375713348388672\n",
            "Training epoch: 2\n",
            "idx: 0, loss: 6.342280864715576\n",
            "idx: 100, loss: 2.8830513954162598\n",
            "idx: 200, loss: 4.185488700866699\n",
            "idx: 300, loss: 2.056823253631592\n",
            "idx: 400, loss: 11.192858695983887\n",
            "idx: 500, loss: 8.669508934020996\n",
            "idx: 600, loss: 1.7106692790985107\n",
            "idx: 700, loss: 6.829305648803711\n",
            "idx: 800, loss: 5.812616348266602\n",
            "idx: 900, loss: 9.334757804870605\n",
            "idx: 1000, loss: 0.0\n",
            "idx: 1100, loss: 10.427053451538086\n",
            "idx: 1200, loss: 14.39255142211914\n",
            "idx: 1300, loss: 7.192540168762207\n",
            "idx: 1400, loss: 4.422722816467285\n",
            "idx: 1500, loss: 0.05223266780376434\n",
            "idx: 1600, loss: 3.7511627674102783\n",
            "idx: 1700, loss: 0.0075095719657838345\n",
            "idx: 1800, loss: 5.475547790527344\n",
            "Training epoch: 3\n",
            "idx: 0, loss: 4.379312515258789\n",
            "idx: 100, loss: 4.254211489751469e-06\n",
            "idx: 200, loss: 9.26268196105957\n",
            "idx: 300, loss: 5.374846458435059\n",
            "idx: 400, loss: 5.5295820236206055\n",
            "idx: 500, loss: 0.9654259085655212\n",
            "idx: 600, loss: 1.4016832113265991\n",
            "idx: 700, loss: 13.180137634277344\n",
            "idx: 800, loss: 4.4665961265563965\n",
            "idx: 900, loss: 1.6807119846343994\n",
            "idx: 1000, loss: 2.7852232456207275\n",
            "idx: 1100, loss: 1.385066270828247\n",
            "idx: 1200, loss: 16.29294204711914\n",
            "idx: 1300, loss: 0.40636351704597473\n",
            "idx: 1400, loss: 10.665979385375977\n",
            "idx: 1500, loss: 1.5946986675262451\n",
            "idx: 1600, loss: 1.336852788925171\n",
            "idx: 1700, loss: 1.8385173082351685\n",
            "idx: 1800, loss: 12.152692794799805\n",
            "Training epoch: 4\n",
            "idx: 0, loss: 5.561256408691406\n",
            "idx: 100, loss: 20.942296981811523\n",
            "idx: 200, loss: 6.202061176300049\n",
            "idx: 300, loss: 2.3713085651397705\n",
            "idx: 400, loss: 1.1757134199142456\n",
            "idx: 500, loss: 1.8170380592346191\n",
            "idx: 600, loss: 38.084896087646484\n",
            "idx: 700, loss: 23.06406593322754\n",
            "idx: 800, loss: 59.41804122924805\n",
            "idx: 900, loss: 4.624551773071289\n",
            "idx: 1000, loss: 6.687564373016357\n",
            "idx: 1100, loss: 3.269991874694824\n",
            "idx: 1200, loss: 8.946282386779785\n",
            "idx: 1300, loss: 0.0\n",
            "idx: 1400, loss: 2.1920905113220215\n",
            "idx: 1500, loss: 9.31972885131836\n",
            "idx: 1600, loss: 2.3921241760253906\n",
            "idx: 1700, loss: 3.1576881408691406\n",
            "idx: 1800, loss: 4.7955098152160645\n",
            "Training epoch: 5\n",
            "idx: 0, loss: 33.835506439208984\n",
            "idx: 100, loss: 10.284966468811035\n",
            "idx: 200, loss: 12.029923439025879\n",
            "idx: 300, loss: 3.680825710296631\n",
            "idx: 400, loss: 0.8987345695495605\n",
            "idx: 500, loss: 7.377917766571045\n",
            "idx: 600, loss: 0.6077181696891785\n",
            "idx: 700, loss: 15.571131706237793\n",
            "idx: 800, loss: 8.641231536865234\n",
            "idx: 900, loss: 9.84467551461421e-05\n",
            "idx: 1000, loss: 19.829803466796875\n",
            "idx: 1100, loss: 3.5636632442474365\n",
            "idx: 1200, loss: 15.53299617767334\n",
            "idx: 1300, loss: 2.9256839752197266\n",
            "idx: 1400, loss: 0.0978865996003151\n",
            "idx: 1500, loss: 1.8083405494689941\n",
            "idx: 1600, loss: 0.06899157911539078\n",
            "idx: 1700, loss: 0.0016008805250748992\n",
            "idx: 1800, loss: 1.2200820446014404\n",
            "Training epoch: 6\n",
            "idx: 0, loss: 20.03449249267578\n",
            "idx: 100, loss: 19.410308837890625\n",
            "idx: 200, loss: 2.6542177200317383\n",
            "idx: 300, loss: 4.597987174987793\n",
            "idx: 400, loss: 4.970605373382568\n",
            "idx: 500, loss: 12.2149076461792\n",
            "idx: 600, loss: 0.17739099264144897\n",
            "idx: 700, loss: 27.33542251586914\n",
            "idx: 800, loss: 2.8006818294525146\n",
            "idx: 900, loss: 8.273530006408691\n",
            "idx: 1000, loss: 4.268409729003906\n",
            "idx: 1100, loss: 23.038589477539062\n",
            "idx: 1200, loss: 5.794947624206543\n",
            "idx: 1300, loss: 0.8157685995101929\n",
            "idx: 1400, loss: 7.522960186004639\n",
            "idx: 1500, loss: 14.0994234085083\n",
            "idx: 1600, loss: 11.849184036254883\n",
            "idx: 1700, loss: 7.254415512084961\n",
            "idx: 1800, loss: 5.389585018157959\n",
            "Training epoch: 7\n",
            "idx: 0, loss: 25.06574821472168\n",
            "idx: 100, loss: 1.1425923109054565\n",
            "idx: 200, loss: 3.400986433029175\n",
            "idx: 300, loss: 5.011919021606445\n",
            "idx: 400, loss: 0.0006787878810428083\n",
            "idx: 500, loss: 1.6443593502044678\n",
            "idx: 600, loss: 0.0\n",
            "idx: 700, loss: 9.85629653930664\n",
            "idx: 800, loss: 3.1723265647888184\n",
            "idx: 900, loss: 10.337830543518066\n",
            "idx: 1000, loss: 0.8848350048065186\n",
            "idx: 1100, loss: 9.577593300491571e-05\n",
            "idx: 1200, loss: 1.619546310394071e-05\n",
            "idx: 1300, loss: 8.111943244934082\n",
            "idx: 1400, loss: 1.5585718154907227\n",
            "idx: 1500, loss: 8.968999862670898\n",
            "idx: 1600, loss: 0.6711656451225281\n",
            "idx: 1700, loss: 5.42578649520874\n",
            "idx: 1800, loss: 5.584263801574707\n",
            "Training epoch: 8\n",
            "idx: 0, loss: 3.1638283729553223\n",
            "idx: 100, loss: 1.1957036256790161\n",
            "idx: 200, loss: 6.583376407623291\n",
            "idx: 300, loss: 15.276423454284668\n",
            "idx: 400, loss: 3.859694004058838\n",
            "idx: 500, loss: 2.1192433834075928\n",
            "idx: 600, loss: 4.944895267486572\n",
            "idx: 700, loss: 19.99091148376465\n",
            "idx: 800, loss: 1.037564754486084\n",
            "idx: 900, loss: 0.5386591553688049\n",
            "idx: 1000, loss: 12.178611755371094\n",
            "idx: 1100, loss: 7.261570930480957\n",
            "idx: 1200, loss: 24.66884994506836\n",
            "idx: 1300, loss: 22.17237091064453\n",
            "idx: 1400, loss: 16.758846282958984\n",
            "idx: 1500, loss: 4.181355953216553\n",
            "idx: 1600, loss: 2.2357683181762695\n",
            "idx: 1700, loss: 2.246553897857666\n",
            "idx: 1800, loss: 5.183844089508057\n",
            "Training epoch: 9\n",
            "idx: 0, loss: 4.763650417327881\n",
            "idx: 100, loss: 0.7238193154335022\n",
            "idx: 200, loss: 0.07091531157493591\n",
            "idx: 300, loss: 0.07301214337348938\n",
            "idx: 400, loss: 15.480278015136719\n",
            "idx: 500, loss: 2.870816469192505\n",
            "idx: 600, loss: 0.8591330051422119\n",
            "idx: 700, loss: 0.00047241715947166085\n",
            "idx: 800, loss: 28.791637420654297\n",
            "idx: 900, loss: 1.3326151371002197\n",
            "idx: 1000, loss: 1.1227409839630127\n",
            "idx: 1100, loss: 1.4077048301696777\n",
            "idx: 1200, loss: 12.04030990600586\n",
            "idx: 1300, loss: 2.71122670173645\n",
            "idx: 1400, loss: 27.142614364624023\n",
            "idx: 1500, loss: 1.1648271083831787\n",
            "idx: 1600, loss: 13.328449249267578\n",
            "idx: 1700, loss: 7.788036346435547\n",
            "idx: 1800, loss: 2.97084641456604\n",
            "Performing inference on batch: 0\n"
          ]
        },
        {
          "ename": "OutOfMemoryError",
          "evalue": "CUDA out of memory. Tried to allocate 50.00 MiB (GPU 0; 8.00 GiB total capacity; 7.15 GiB already allocated; 0 bytes free; 7.28 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mOutOfMemoryError\u001b[0m                          Traceback (most recent call last)",
            "Cell \u001b[1;32mIn[28], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mrun_full_oodn_pipeline\u001b[49m\u001b[43m(\u001b[49m\u001b[43mconfig_2a\u001b[49m\u001b[43m)\u001b[49m\n",
            "Cell \u001b[1;32mIn[22], line 39\u001b[0m, in \u001b[0;36mrun_full_oodn_pipeline\u001b[1;34m(config)\u001b[0m\n\u001b[0;32m     37\u001b[0m model \u001b[38;5;241m=\u001b[39m train_resnet_model_given_opti_activation_fn(config)\n\u001b[0;32m     38\u001b[0m \u001b[38;5;66;03m# calculate oodn metrics\u001b[39;00m\n\u001b[1;32m---> 39\u001b[0m metrics[i] \u001b[38;5;241m=\u001b[39m \u001b[43mcalculate_oodn_metrics\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     40\u001b[0m \u001b[43m                       \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43modin\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m     41\u001b[0m \u001b[43m                       \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mdata_loaders\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mid_test\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     42\u001b[0m \u001b[43m                       \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mdata_loaders\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mood_test\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     43\u001b[0m \u001b[43m                       \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mdataset_name\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     44\u001b[0m metrics[i][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124moptimizer_type\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m config[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124moptimizer_type\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[0;32m     45\u001b[0m metrics[i][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mactivation_function_type\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m config[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mactivation_function_type\u001b[39m\u001b[38;5;124m'\u001b[39m]\n",
            "Cell \u001b[1;32mIn[20], line 3\u001b[0m, in \u001b[0;36mcalculate_oodn_metrics\u001b[1;34m(model, postprocessor_type, id_test_loader, ood_test_loader, ood_name)\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcalculate_oodn_metrics\u001b[39m(model, postprocessor_type, id_test_loader, ood_test_loader, ood_name):\n\u001b[0;32m      2\u001b[0m     postprocessor \u001b[38;5;241m=\u001b[39m get_postprocessor(postprocessor_type)\n\u001b[1;32m----> 3\u001b[0m     id_pred, id_conf, id_gt \u001b[38;5;241m=\u001b[39m \u001b[43mpostprocessor\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minference\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m      4\u001b[0m \u001b[43m                \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mid_test_loader\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      6\u001b[0m     ood_pred, ood_conf, ood_gt \u001b[38;5;241m=\u001b[39m postprocessor\u001b[38;5;241m.\u001b[39minference(\n\u001b[0;32m      7\u001b[0m         model, ood_test_loader)\n\u001b[0;32m      9\u001b[0m     ood_gt \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m \u001b[38;5;241m*\u001b[39m np\u001b[38;5;241m.\u001b[39mones_like(ood_gt)  \u001b[38;5;66;03m# hard set to -1 as ood\u001b[39;00m\n",
            "Cell \u001b[1;32mIn[17], line 53\u001b[0m, in \u001b[0;36mODINPostprocessor.inference\u001b[1;34m(self, net, data_loader)\u001b[0m\n\u001b[0;32m     51\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m idx \u001b[38;5;241m%\u001b[39m \u001b[38;5;241m50\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m     52\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mPerforming inference on batch: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00midx\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m---> 53\u001b[0m pred, conf \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpostprocess\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnet\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     54\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mlen\u001b[39m(data)):\n\u001b[0;32m     55\u001b[0m     pred_list\u001b[38;5;241m.\u001b[39mappend(pred[idx]\u001b[38;5;241m.\u001b[39mtolist())\n",
            "Cell \u001b[1;32mIn[17], line 9\u001b[0m, in \u001b[0;36mODINPostprocessor.postprocess\u001b[1;34m(self, net, data)\u001b[0m\n\u001b[0;32m      7\u001b[0m net\u001b[38;5;241m.\u001b[39meval()\n\u001b[0;32m      8\u001b[0m data\u001b[38;5;241m.\u001b[39mrequires_grad \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m----> 9\u001b[0m output \u001b[38;5;241m=\u001b[39m \u001b[43mnet\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     11\u001b[0m \u001b[38;5;66;03m# Calculating the perturbation we need to add, that is,\u001b[39;00m\n\u001b[0;32m     12\u001b[0m \u001b[38;5;66;03m# the sign of gradient of cross entropy loss w.r.t. input\u001b[39;00m\n\u001b[0;32m     13\u001b[0m criterion \u001b[38;5;241m=\u001b[39m nn\u001b[38;5;241m.\u001b[39mCrossEntropyLoss()\n",
            "File \u001b[1;32mD:\\Anaconda3\\envs\\torch\\lib\\site-packages\\torch\\nn\\modules\\module.py:1190\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1186\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1187\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1188\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1189\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1190\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39m\u001b[38;5;28minput\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1191\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1192\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
            "File \u001b[1;32mD:\\Anaconda3\\envs\\torch\\lib\\site-packages\\torchvision\\models\\resnet.py:285\u001b[0m, in \u001b[0;36mResNet.forward\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m    284\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[1;32m--> 285\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_forward_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[1;32mD:\\Anaconda3\\envs\\torch\\lib\\site-packages\\torchvision\\models\\resnet.py:275\u001b[0m, in \u001b[0;36mResNet._forward_impl\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m    273\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlayer1(x)\n\u001b[0;32m    274\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlayer2(x)\n\u001b[1;32m--> 275\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlayer3\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    276\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlayer4(x)\n\u001b[0;32m    278\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mavgpool(x)\n",
            "File \u001b[1;32mD:\\Anaconda3\\envs\\torch\\lib\\site-packages\\torch\\nn\\modules\\module.py:1190\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1186\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1187\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1188\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1189\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1190\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39m\u001b[38;5;28minput\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1191\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1192\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
            "File \u001b[1;32mD:\\Anaconda3\\envs\\torch\\lib\\site-packages\\torch\\nn\\modules\\container.py:204\u001b[0m, in \u001b[0;36mSequential.forward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    202\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m):\n\u001b[0;32m    203\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m:\n\u001b[1;32m--> 204\u001b[0m         \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[43mmodule\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m    205\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28minput\u001b[39m\n",
            "File \u001b[1;32mD:\\Anaconda3\\envs\\torch\\lib\\site-packages\\torch\\nn\\modules\\module.py:1190\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1186\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1187\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1188\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1189\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1190\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39m\u001b[38;5;28minput\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1191\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1192\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
            "File \u001b[1;32mD:\\Anaconda3\\envs\\torch\\lib\\site-packages\\torchvision\\models\\resnet.py:155\u001b[0m, in \u001b[0;36mBottleneck.forward\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m    152\u001b[0m out \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrelu(out)\n\u001b[0;32m    154\u001b[0m out \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconv3(out)\n\u001b[1;32m--> 155\u001b[0m out \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbn3\u001b[49m\u001b[43m(\u001b[49m\u001b[43mout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    157\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdownsample \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    158\u001b[0m     identity \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdownsample(x)\n",
            "File \u001b[1;32mD:\\Anaconda3\\envs\\torch\\lib\\site-packages\\torch\\nn\\modules\\module.py:1190\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1186\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1187\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1188\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1189\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1190\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39m\u001b[38;5;28minput\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1191\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1192\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
            "File \u001b[1;32mD:\\Anaconda3\\envs\\torch\\lib\\site-packages\\torch\\nn\\modules\\batchnorm.py:171\u001b[0m, in \u001b[0;36m_BatchNorm.forward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    164\u001b[0m     bn_training \u001b[38;5;241m=\u001b[39m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrunning_mean \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m) \u001b[38;5;129;01mand\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrunning_var \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[0;32m    166\u001b[0m \u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    167\u001b[0m \u001b[38;5;124;03mBuffers are only updated if they are to be tracked and we are in training mode. Thus they only need to be\u001b[39;00m\n\u001b[0;32m    168\u001b[0m \u001b[38;5;124;03mpassed when the update should occur (i.e. in training mode when they are tracked), or when buffer stats are\u001b[39;00m\n\u001b[0;32m    169\u001b[0m \u001b[38;5;124;03mused for normalization (i.e. in eval mode when buffers are not None).\u001b[39;00m\n\u001b[0;32m    170\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m--> 171\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbatch_norm\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    172\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m    173\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;66;43;03m# If buffers are not to be tracked, ensure that they won't be updated\u001b[39;49;00m\n\u001b[0;32m    174\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrunning_mean\u001b[49m\n\u001b[0;32m    175\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mnot\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtraining\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrack_running_stats\u001b[49m\n\u001b[0;32m    176\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    177\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrunning_var\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mnot\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtraining\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrack_running_stats\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    178\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    179\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbias\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    180\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbn_training\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    181\u001b[0m \u001b[43m    \u001b[49m\u001b[43mexponential_average_factor\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    182\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43meps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    183\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[1;32mD:\\Anaconda3\\envs\\torch\\lib\\site-packages\\torch\\nn\\functional.py:2450\u001b[0m, in \u001b[0;36mbatch_norm\u001b[1;34m(input, running_mean, running_var, weight, bias, training, momentum, eps)\u001b[0m\n\u001b[0;32m   2447\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m training:\n\u001b[0;32m   2448\u001b[0m     _verify_batch_size(\u001b[38;5;28minput\u001b[39m\u001b[38;5;241m.\u001b[39msize())\n\u001b[1;32m-> 2450\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbatch_norm\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   2451\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbias\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrunning_mean\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrunning_var\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtraining\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmomentum\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43meps\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackends\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcudnn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43menabled\u001b[49m\n\u001b[0;32m   2452\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
            "\u001b[1;31mOutOfMemoryError\u001b[0m: CUDA out of memory. Tried to allocate 50.00 MiB (GPU 0; 8.00 GiB total capacity; 7.15 GiB already allocated; 0 bytes free; 7.28 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF"
          ]
        }
      ],
      "source": [
        "run_full_oodn_pipeline(config_2a)"
      ],
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "PdtcNadxRbdY",
        "outputId": "aeabc371-b40c-47a7-9ff8-c180d51d680d"
      }
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 2
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython2",
      "version": "2.7.6"
    },
    "colab": {
      "provenance": [],
      "machine_shape": "hm"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
