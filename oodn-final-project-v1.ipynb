{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e9c08843",
   "metadata": {},
   "source": [
    "### Exploring The Impact of Optimizers and Activation Functions On OODN "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "9b10d253",
   "metadata": {},
   "outputs": [],
   "source": [
    "from os import listdir\n",
    "\n",
    "import time\n",
    "import json\n",
    "\n",
    "import torch\n",
    "\n",
    "from torchvision.datasets import mnist, FashionMNIST\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision.transforms import ToTensor\n",
    "from torch.optim import SGD, Adam\n",
    "from torch.nn import Module\n",
    "from torch import nn\n",
    "from torch.nn import CrossEntropyLoss\n",
    "from torchvision.models.resnet import Bottleneck, ResNet\n",
    "\n",
    "from wilds import get_dataset\n",
    "from wilds.common.data_loaders import get_train_loader\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from openood.evaluators import metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "656f1978",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0\n"
     ]
    }
   ],
   "source": [
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1560babc",
   "metadata": {},
   "source": [
    "### Supported Activation Functions\n",
    "\n",
    "For activation functions, we are considering ReLU, Softplus, Swish. *Note that we may conduct experiments for a subset based on the compute resources available*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3313226f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_activation_fn(activation):\n",
    "    if activation == 'relu':\n",
    "        return nn.ReLU()\n",
    "    elif activation == 'softplus':\n",
    "        return nn.Softplus()\n",
    "    elif activation == 'swish':\n",
    "        return nn.Swish()\n",
    "    return None"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45540f49",
   "metadata": {},
   "source": [
    "### Supported Networks\n",
    "\n",
    "Currently, we support LeNet and ResNet50."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf27a4d4",
   "metadata": {},
   "source": [
    "### LeNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0beec4a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LeNet(nn.Module):\n",
    "    def __init__(self, num_classes, num_channel=3, activation='relu'):\n",
    "        super(LeNet, self).__init__()\n",
    "        self.num_classes = num_classes\n",
    "        self.feature_size = 84\n",
    "        self.block1 = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=num_channel,\n",
    "                      out_channels=6,\n",
    "                      kernel_size=5,\n",
    "                      stride=1,\n",
    "                      padding=2), get_activation_fn(activation), nn.MaxPool2d(kernel_size=2))\n",
    "\n",
    "        self.block2 = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=6, out_channels=16, kernel_size=5, stride=1),\n",
    "             get_activation_fn(activation), nn.MaxPool2d(kernel_size=2))\n",
    "\n",
    "        self.block3 = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=16,\n",
    "                      out_channels=120,\n",
    "                      kernel_size=5,\n",
    "                      stride=1), get_activation_fn(activation))\n",
    "\n",
    "        self.classifier1 = nn.Linear(in_features=120, out_features=84)\n",
    "        self.relu = get_activation_fn(activation)\n",
    "        self.fc = nn.Linear(in_features=84, out_features=num_classes)\n",
    "\n",
    "    def get_fc(self):\n",
    "        fc = self.fc\n",
    "        return fc.weight.cpu().detach().numpy(), fc.bias.cpu().detach().numpy()\n",
    "\n",
    "    def forward(self, x, return_feature=False, return_feature_list=False):\n",
    "        feature1 = self.block1(x)\n",
    "        feature2 = self.block2(feature1)\n",
    "        feature3 = self.block3(feature2)\n",
    "        feature3 = feature3.view(feature3.shape[0], -1)\n",
    "        feature = self.relu(self.classifier1(feature3))\n",
    "        logits_cls = self.fc(feature)\n",
    "        feature_list = [feature1, feature2, feature3, feature]\n",
    "        if return_feature:\n",
    "            return logits_cls, feature\n",
    "        elif return_feature_list:\n",
    "            return logits_cls, feature_list\n",
    "        else:\n",
    "            return logits_cls\n",
    "\n",
    "    def forward_threshold(self, x, threshold):\n",
    "        feature1 = self.block1(x)\n",
    "        feature2 = self.block2(feature1)\n",
    "        feature3 = self.block3(feature2)\n",
    "        feature3 = feature3.view(feature3.shape[0], -1)\n",
    "        feature = self.relu(self.classifier1(feature3))\n",
    "        feature = feature.clip(max=threshold)\n",
    "        logits_cls = self.fc(feature)\n",
    "\n",
    "        return logits_cls"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09018e71",
   "metadata": {},
   "source": [
    "### ResNet50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fe9cc86f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResNet50(ResNet):\n",
    "    def __init__(self,\n",
    "                 block=Bottleneck,\n",
    "                 layers=[3, 4, 6, 3],\n",
    "                 num_classes=1000):\n",
    "        super(ResNet50, self).__init__(block=block,\n",
    "                                       layers=layers,\n",
    "                                       num_classes=num_classes)\n",
    "        self.feature_size = 2048\n",
    "\n",
    "\n",
    "    def forward(self, x, return_feature=False, return_feature_list=False):\n",
    "        feature1 = self.relu(self.bn1(self.conv1(x)))\n",
    "        feature1 = self.maxpool(feature1)\n",
    "        feature2 = self.layer1(feature1)\n",
    "        feature3 = self.layer2(feature2)\n",
    "        feature4 = self.layer3(feature3)\n",
    "        feature5 = self.layer4(feature4)\n",
    "        feature5 = self.avgpool(feature5)\n",
    "        feature = feature5.view(feature5.size(0), -1)\n",
    "        logits_cls = self.fc(feature)\n",
    "\n",
    "        feature_list = [feature1, feature2, feature3, feature4, feature5]\n",
    "        if return_feature:\n",
    "            return logits_cls, feature\n",
    "        elif return_feature_list:\n",
    "            return logits_cls, feature_list\n",
    "        else:\n",
    "            return logits_cls\n",
    "\n",
    "    def forward_threshold(self, x, threshold):\n",
    "        feature1 = self.relu(self.bn1(self.conv1(x)))\n",
    "        feature1 = self.maxpool(feature1)\n",
    "        feature2 = self.layer1(feature1)\n",
    "        feature3 = self.layer2(feature2)\n",
    "        feature4 = self.layer3(feature3)\n",
    "        feature5 = self.layer4(feature4)\n",
    "        feature5 = self.avgpool(feature5)\n",
    "        feature = feature5.clip(max=threshold)\n",
    "        feature = feature.view(feature.size(0), -1)\n",
    "        logits_cls = self.fc(feature)\n",
    "\n",
    "        return logits_cls\n",
    "\n",
    "    def get_fc(self):\n",
    "        fc = self.fc\n",
    "        return fc.weight.cpu().detach().numpy(), fc.bias.cpu().detach().numpy()\n",
    "    \n",
    "def get_resnet_model(activation_function_type, n_classes):\n",
    "    resnet_model = ResNet50(num_classes=n_classes)\n",
    "    resnet_model.to(device)    \n",
    "    return resnet_model\n",
    "\n",
    "def set_activation_function(resnet_model, activation_function_type):\n",
    "    resnet_model.relu = get_activation_fn(activation_function_type)\n",
    "    resnet_model.layer1[0].relu = get_activation_fn(activation_function_type)\n",
    "    resnet_model.layer1[1].relu = get_activation_fn(activation_function_type)\n",
    "    resnet_model.layer1[2].relu = get_activation_fn(activation_function_type)\n",
    "\n",
    "    resnet_model.layer2[0].relu = get_activation_fn(activation_function_type)\n",
    "    resnet_model.layer2[1].relu = get_activation_fn(activation_function_type)\n",
    "    resnet_model.layer2[2].relu = get_activation_fn(activation_function_type)\n",
    "    resnet_model.layer2[3].relu = get_activation_fn(activation_function_type)\n",
    "\n",
    "    resnet_model.layer3[0].relu = get_activation_fn(activation_function_type)\n",
    "    resnet_model.layer3[1].relu = get_activation_fn(activation_function_type)\n",
    "    resnet_model.layer3[2].relu = get_activation_fn(activation_function_type)\n",
    "    resnet_model.layer3[3].relu = get_activation_fn(activation_function_type)\n",
    "    resnet_model.layer3[4].relu = get_activation_fn(activation_function_type)\n",
    "    resnet_model.layer3[5].relu = get_activation_fn(activation_function_type)\n",
    "\n",
    "\n",
    "    resnet_model.layer4[0].relu = get_activation_fn(activation_function_type)\n",
    "    resnet_model.layer4[1].relu = get_activation_fn(activation_function_type)\n",
    "    resnet_model.layer4[2].relu = get_activation_fn(activation_function_type)\n",
    "    \n",
    "    return resnet_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ed366e10",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_model(config):\n",
    "    activation_function_type = config[\"activation_function_type\"]\n",
    "    network_type = config[\"network\"]\n",
    "    n_classes = config[\"n_classes\"]\n",
    "    \n",
    "    if network_type == \"lenet\":\n",
    "        model =  LeNet(num_classes=n_classes, num_channel=1, activation=activation_function_type)\n",
    "    elif network_type == \"resnet50\":\n",
    "        model = get_resnet_model(activation_function_type, n_classes)\n",
    "    else:\n",
    "        raise Exception(\"Currently we only support lenet or resnet50\")\n",
    "    \n",
    "    return model\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d03e75b",
   "metadata": {},
   "source": [
    "### Supported Post-Hoc OODN Processors"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7324715e",
   "metadata": {},
   "source": [
    "#### The first post processor we consider is ODIN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "52873040",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ODINPostprocessor():\n",
    "    def __init__(self, temperature, noise):\n",
    "        self.temperature = temperature\n",
    "        self.noise = noise\n",
    "        \n",
    "    def postprocess(self, net: nn.Module, data):\n",
    "        net.eval()\n",
    "        data.requires_grad = True\n",
    "        output = net(data)\n",
    "\n",
    "        # Calculating the perturbation we need to add, that is,\n",
    "        # the sign of gradient of cross entropy loss w.r.t. input\n",
    "        criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "        labels = output.detach().argmax(axis=1)\n",
    "\n",
    "        # Using temperature scaling\n",
    "        output = output / self.temperature\n",
    "\n",
    "        loss = criterion(output, labels)\n",
    "        loss.backward()\n",
    "\n",
    "        # Normalizing the gradient to binary in {0, 1}\n",
    "        gradient = torch.ge(data.grad.detach(), 0)\n",
    "        gradient = (gradient.float() - 0.5) * 2\n",
    "\n",
    "        # Scaling values taken from original code       \n",
    "        gradient[:, 0] = (gradient[:, 0]) / (63.0 / 255.0)\n",
    "        if gradient.shape[1] == 3:\n",
    "            gradient[:, 1] = (gradient[:, 1]) / (62.1 / 255.0)\n",
    "            gradient[:, 2] = (gradient[:, 2]) / (66.7 / 255.0)\n",
    "\n",
    "        # Adding small perturbations to images\n",
    "        tempInputs = torch.add(data.detach(), gradient, alpha=-self.noise)\n",
    "        output = net(tempInputs)\n",
    "        output = output / self.temperature\n",
    "\n",
    "        # Calculating the confidence after adding perturbations\n",
    "        nnOutput = output.detach()\n",
    "        nnOutput = nnOutput - nnOutput.max(dim=1, keepdims=True).values\n",
    "        nnOutput = nnOutput.exp() / nnOutput.exp().sum(dim=1, keepdims=True)\n",
    "\n",
    "        conf, pred = nnOutput.max(dim=1)\n",
    "\n",
    "        return pred, conf\n",
    "    \n",
    "    def inference(self, net: nn.Module, data_loader: DataLoader):\n",
    "        pred_list, conf_list, label_list = [], [], []\n",
    "        for idx, loaded_data in enumerate(data_loader):\n",
    "            data, label = loaded_data[0], loaded_data[1]\n",
    "            if idx % 50 == 0:\n",
    "                print(f'Performing inference on batch: {idx}')\n",
    "            pred, conf = self.postprocess(net, data.to(device))\n",
    "            for idx in range(len(data)):\n",
    "                pred_list.append(pred[idx].tolist())\n",
    "                conf_list.append(conf[idx].tolist())\n",
    "                label_list.append(label[idx].tolist())\n",
    "\n",
    "        # convert values into numpy array\n",
    "        pred_list = np.array(pred_list, dtype=int)\n",
    "        conf_list = np.array(conf_list)\n",
    "        label_list = np.array(label_list, dtype=int)\n",
    "\n",
    "        return pred_list, conf_list, label_list"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d1d6994",
   "metadata": {},
   "source": [
    "#### We consider the Maximum Classifier Discrepancy Post OODN method\n",
    "\n",
    "https://arxiv.org/pdf/1712.02560.pdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "3db5d740",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MCDPostprocessor():\n",
    "    @torch.no_grad()\n",
    "    def postprocess(self, net: nn.Module, data):\n",
    "        logits1, logits2 = net(data, return_double=True)\n",
    "        score1 = torch.softmax(logits1, dim=1)\n",
    "        score2 = torch.softmax(logits2, dim=1)\n",
    "        conf = -torch.sum(torch.abs(score1 - score2), dim=1)\n",
    "        _, pred = torch.max(score1, dim=1)\n",
    "        return pred, conf\n",
    "    \n",
    "    def inference(self, net: nn.Module, data_loader: DataLoader):\n",
    "        pred_list, conf_list, label_list = [], [], []\n",
    "        for idx, loaded_data in enumerate(data_loader):\n",
    "            data, label = loaded_data[0], loaded_data[1]\n",
    "            if idx % 50 == 0:\n",
    "                print(f'Performing inference on batch: {idx}')\n",
    "            pred, conf = self.postprocess(net, data.to(device))\n",
    "            for idx in range(len(data)):\n",
    "                pred_list.append(pred[idx].tolist())\n",
    "                conf_list.append(conf[idx].tolist())\n",
    "                label_list.append(label[idx].tolist())\n",
    "\n",
    "        # convert values into numpy array\n",
    "        pred_list = np.array(pred_list, dtype=int)\n",
    "        conf_list = np.array(conf_list)\n",
    "        label_list = np.array(label_list, dtype=int)\n",
    "\n",
    "        return pred_list, conf_list, label_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "eeec0aa1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_postprocessor(postprocessor_type=\"odin\"):\n",
    "    if postprocessor_type == \"odin\":\n",
    "        postprocessor = ODINPostprocessor(1000, 0.0014)\n",
    "    elif postprocessor_type == \"mcd\":\n",
    "        postprocessor = MCDPostprocessor()\n",
    "    return postprocessor"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "338742a6",
   "metadata": {},
   "source": [
    "### Supported Out of Distribution Detection Metrics\n",
    "\n",
    "What metrics do we specifically care about here?\n",
    "\n",
    "**FPR@95** measures the false positive rate (FPR) when the true positive rate (TPR) is\n",
    "equal to 95%. Lower scores indicate better performance. \n",
    "\n",
    "**AUROC** measures the area under the\n",
    "Receiver Operating Characteristic (ROC) curve, which displays the relationship between TPR and\n",
    "FPR. The area under the ROC curve can be interpreted as the probability that a positive ID example\n",
    "will have a higher detection score than a negative OOD example. \n",
    "\n",
    "**AUPR** measures the area under\n",
    "the Precision-Recall (PR) curve. The PR curve is created by plotting precision versus recall. Similar\n",
    "to AUROC, we consider ID samples as positive, so that the score corresponds to the AUPR-In metric\n",
    "in some works"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "c5d6c1d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_oodn_metrics(model, postprocessor_type, id_test_loader, ood_test_loader, ood_name):\n",
    "    postprocessor = get_postprocessor(postprocessor_type)\n",
    "    id_pred, id_conf, id_gt = postprocessor.inference(\n",
    "                model, id_test_loader)\n",
    "\n",
    "    ood_pred, ood_conf, ood_gt = postprocessor.inference(\n",
    "        model, ood_test_loader)\n",
    "\n",
    "    ood_gt = -1 * np.ones_like(ood_gt)  # hard set to -1 as ood\n",
    "    pred = np.concatenate([id_pred, ood_pred])\n",
    "    conf = np.concatenate([id_conf, ood_conf])\n",
    "    label = np.concatenate([id_gt, ood_gt])\n",
    "    ood_metrics = metrics.compute_all_metrics(conf, label, pred)\n",
    "\n",
    "    return print_and_get_formatted_metrics(ood_metrics, ood_name)\n",
    "\n",
    "def print_and_get_formatted_metrics(metrics, dataset_name):\n",
    "    [fpr, auroc, aupr_in, aupr_out,\n",
    "     ccr_4, ccr_3, ccr_2, ccr_1, accuracy] \\\n",
    "     = metrics\n",
    "\n",
    "    write_content = {\n",
    "        'dataset': dataset_name,\n",
    "        'FPR@95': '{:.2f}'.format(100 * fpr),\n",
    "        'AUROC': '{:.2f}'.format(100 * auroc),\n",
    "        'AUPR_IN': '{:.2f}'.format(100 * aupr_in),\n",
    "        'AUPR_OUT': '{:.2f}'.format(100 * aupr_out),\n",
    "        'CCR_4': '{:.2f}'.format(100 * ccr_4),\n",
    "        'CCR_3': '{:.2f}'.format(100 * ccr_3),\n",
    "        'CCR_2': '{:.2f}'.format(100 * ccr_2),\n",
    "        'CCR_1': '{:.2f}'.format(100 * ccr_1),\n",
    "        'ACC': '{:.2f}'.format(100 * accuracy)\n",
    "    }\n",
    "\n",
    "    fieldnames = list(write_content.keys())\n",
    "\n",
    "    # print ood metric results\n",
    "    print('FPR@95: {:.2f}, AUROC: {:.2f}'.format(100 * fpr, 100 * auroc),\n",
    "          end=' ',\n",
    "          flush=True)\n",
    "    print('AUPR_IN: {:.2f}, AUPR_OUT: {:.2f}'.format(\n",
    "        100 * aupr_in, 100 * aupr_out),\n",
    "          flush=True)\n",
    "    print('CCR: {:.2f}, {:.2f}, {:.2f}, {:.2f},'.format(\n",
    "        ccr_4 * 100, ccr_3 * 100, ccr_2 * 100, ccr_1 * 100),\n",
    "          end=' ',\n",
    "          flush=True)\n",
    "    print('ACC: {:.2f}'.format(accuracy * 100), flush=True)\n",
    "    print(u'\\u2500' * 70, flush=True)\n",
    "    return write_content\n",
    "\n",
    "def load_results_into_df(dir_path):\n",
    "    res_files = [dir_path+each for each in listdir(dir_path)]\n",
    "    all_results = []\n",
    "    columns = ['optimizer_type', 'activation_function_type', 'postprocessor_type', 'trial', 'AUROC']\n",
    "    for fp in res_files:\n",
    "        f = open(fp)\n",
    "        data = json.load(f)\n",
    "        for trial, results in data.items():\n",
    "            all_results.append([\n",
    "                    results['optimizer_type'],\n",
    "                    results['activation_function_type'],\n",
    "                    results['postprocessor_type'],\n",
    "                    trial,\n",
    "                    float(results['AUROC'])\n",
    "                ])\n",
    "    df = pd.DataFrame(all_results, columns=columns)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "f872ebda",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_optimizer(model, config):\n",
    "    params = model.parameters()\n",
    "    lr = config['lr']\n",
    "    momentum = config['momentum']\n",
    "    weight_decay = config['weight_decay']\n",
    "    optimizer_type = config['optimizer_type']\n",
    "    \n",
    "    print(f'Getting optimizer for type: {optimizer_type}...')\n",
    "    if optimizer_type == 'SGD':\n",
    "        return SGD(params, \n",
    "              lr=lr, \n",
    "              momentum=momentum,\n",
    "              weight_decay=weight_decay)\n",
    "    elif optimizer_type == 'Adam':\n",
    "        return Adam(params, \n",
    "                    lr=lr, \n",
    "                    weight_decay=weight_decay)\n",
    "    else:\n",
    "        raise Exception(\"Invalid optimizer_type provided, only SGD and Adam are supported currently\")\n",
    "\n",
    "def get_wilds_loader(dataset, split, batch_size):\n",
    "    d = dataset.get_subset(\n",
    "        \"train\",\n",
    "        transform=transforms.Compose(\n",
    "            [transforms.Resize((448, 448)), transforms.ToTensor()]\n",
    "        ),\n",
    "    )\n",
    "    # Prepare the standard data loader\n",
    "    return get_train_loader(\"standard\", d, batch_size=batch_size)\n",
    "\n",
    "def get_data_loaders(config):\n",
    "    data_loaders = {}\n",
    "    dataset_name = config[\"dataset_name\"]\n",
    "    dataset_type = config[\"dataset_type\"]\n",
    "    batch_size = config['batch_size']\n",
    "    \n",
    "    wilds_id_test_split = \"id_val\" if dataset_name == \"camelyon17\" else \"id_test\"\n",
    "    if dataset_type == \"wilds\":\n",
    "        # wilds dataset\n",
    "        dataset = get_dataset(dataset=dataset_name, download=True)\n",
    "        data_loaders[\"train\"] = get_wilds_loader(dataset, \"train\", batch_size)\n",
    "        data_loaders[\"ood_test\"] = get_wilds_loader(dataset, \"test\", batch_size)\n",
    "        data_loaders[\"id_test\"] = get_wilds_loader(dataset, wilds_id_test_split, batch_size)\n",
    "    elif dataset_name == \"mnist\":\n",
    "        # mnist dataset\n",
    "        train_dataset = mnist.MNIST(root='data', download=True, train=True, transform=ToTensor())\n",
    "        test_dataset = mnist.MNIST(root='data', download=True, train=False, transform=ToTensor())\n",
    "        fashion_test_dataset = mnist.FashionMNIST(root='data', download=True,train=False,transform=ToTensor())\n",
    "\n",
    "        data_loaders[\"train\"] = DataLoader(train_dataset, batch_size=batch_size)\n",
    "        data_loaders[\"id_test\"] = DataLoader(test_dataset, batch_size=batch_size)\n",
    "        data_loaders[\"ood_test\"] = DataLoader(fashion_test_dataset, batch_size=batch_size)\n",
    "    \n",
    "    return data_loaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "ee26224e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_resnet_model_given_opti_activation_fn(config):\n",
    "    # get the train loader\n",
    "    train_loader = config[\"data_loaders\"][\"train\"]\n",
    "    \n",
    "    # get the resnet model with the replaced activation functions\n",
    "    model = get_model(config)\n",
    "    model.to(device)\n",
    "    \n",
    "    # get the optimizer\n",
    "    sgd = get_optimizer(model, config)\n",
    "    \n",
    "    loss_fn = CrossEntropyLoss()\n",
    "\n",
    "    for current_epoch in range(config['epochs']):\n",
    "        model.train()\n",
    "        print('Training epoch: {}'.format(current_epoch))\n",
    "        for idx, (loader_data) in enumerate(train_loader):\n",
    "            train_x, train_label = loader_data[0].to(device), loader_data[1].to(device)\n",
    "            sgd.zero_grad()\n",
    "            predict_y = model(train_x.float())\n",
    "            loss = loss_fn(predict_y, train_label.long())\n",
    "            if idx % 100 == 0:\n",
    "                print('idx: {}, loss: {}'.format(idx, loss.sum().item()))\n",
    "            loss.backward()\n",
    "            sgd.step()\n",
    "    \n",
    "    torch.save(model, config['model_name'])\n",
    "    return model\n",
    "\n",
    "def run_full_oodn_pipeline(config):\n",
    "    metrics = {}\n",
    "    for i in range(config[\"trials\"]):\n",
    "        model_name = f\"models/{config['network']}_{config['dataset_name']}_{config['activation_function_type']}_{config['optimizer_type']}_{i}.pkl\"\n",
    "        print(f'Running model: {model_name}...')\n",
    "        config['model_name'] = model_name\n",
    "        # train model\n",
    "        model = train_resnet_model_given_opti_activation_fn(config)\n",
    "        # calculate oodn metrics\n",
    "        metrics[i] = calculate_oodn_metrics(model,\n",
    "                               \"odin\", \n",
    "                               config[\"data_loaders\"][\"id_test\"], \n",
    "                               config[\"data_loaders\"][\"ood_test\"], \n",
    "                               config[\"dataset_name\"])\n",
    "        metrics[i]['optimizer_type'] = config['optimizer_type']\n",
    "        metrics[i]['activation_function_type'] = config['activation_function_type']\n",
    "        metrics[i]['postprocessor_type'] = config['postprocessor_type']\n",
    "        \n",
    "    experiment_name = f\"{config['results_dir']}/{config['dataset_name']}_{config['network']}_{config['postprocessor_type']}_{config['activation_function_type']}_{config['optimizer_type']}.json\"\n",
    "    with open(experiment_name, 'w') as fp:\n",
    "        json.dump(metrics, fp)\n",
    "    return metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c992663",
   "metadata": {},
   "source": [
    "### Study 1: LeNet5, MNIST as the ID Dataset, FashionMNIST as the OOD Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae7e58bf",
   "metadata": {},
   "source": [
    "#### Study 1(a): Combination: SGD + ReLU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "de1880d7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running model: models/lenet_mnist_relu_SGD_0.pkl...\n",
      "Getting optimizer for type: SGD...\n",
      "Training epoch: 0\n",
      "idx: 0, loss: 2.300678014755249\n",
      "idx: 100, loss: 0.23158413171768188\n",
      "idx: 200, loss: 0.3385574519634247\n",
      "idx: 300, loss: 0.14093522727489471\n",
      "idx: 400, loss: 0.3233451247215271\n",
      "Training epoch: 1\n",
      "idx: 0, loss: 0.11926180869340897\n",
      "idx: 100, loss: 0.12861403822898865\n",
      "idx: 200, loss: 0.16344964504241943\n",
      "idx: 300, loss: 0.06893038004636765\n",
      "idx: 400, loss: 0.2226434201002121\n",
      "Training epoch: 2\n",
      "idx: 0, loss: 0.18933868408203125\n",
      "idx: 100, loss: 0.1398666501045227\n",
      "idx: 200, loss: 0.08190067112445831\n",
      "idx: 300, loss: 0.05670902132987976\n",
      "idx: 400, loss: 0.2548925280570984\n",
      "Training epoch: 3\n",
      "idx: 0, loss: 0.17106886208057404\n",
      "idx: 100, loss: 0.0651470348238945\n",
      "idx: 200, loss: 0.09267112612724304\n",
      "idx: 300, loss: 0.08352600038051605\n",
      "idx: 400, loss: 0.2009848803281784\n",
      "Training epoch: 4\n",
      "idx: 0, loss: 0.07830512523651123\n",
      "idx: 100, loss: 0.05214201658964157\n",
      "idx: 200, loss: 0.06437063962221146\n",
      "idx: 300, loss: 0.06984651833772659\n",
      "idx: 400, loss: 0.12151651084423065\n",
      "Training epoch: 5\n",
      "idx: 0, loss: 0.063811294734478\n",
      "idx: 100, loss: 0.051630206406116486\n",
      "idx: 200, loss: 0.07938621193170547\n",
      "idx: 300, loss: 0.06165458261966705\n",
      "idx: 400, loss: 0.1297258585691452\n",
      "Training epoch: 6\n",
      "idx: 0, loss: 0.06481128931045532\n",
      "idx: 100, loss: 0.043277814984321594\n",
      "idx: 200, loss: 0.07349785417318344\n",
      "idx: 300, loss: 0.06463441997766495\n",
      "idx: 400, loss: 0.14536185562610626\n",
      "Training epoch: 7\n",
      "idx: 0, loss: 0.10988715291023254\n",
      "idx: 100, loss: 0.04026467725634575\n",
      "idx: 200, loss: 0.06704201549291611\n",
      "idx: 300, loss: 0.038924530148506165\n",
      "idx: 400, loss: 0.33158257603645325\n",
      "Training epoch: 8\n",
      "idx: 0, loss: 0.04163479059934616\n",
      "idx: 100, loss: 0.07650937139987946\n",
      "idx: 200, loss: 0.0754041075706482\n",
      "idx: 300, loss: 0.040161747485399246\n",
      "idx: 400, loss: 0.08443257212638855\n",
      "Training epoch: 9\n",
      "idx: 0, loss: 0.052605193108320236\n",
      "idx: 100, loss: 0.0179137010127306\n",
      "idx: 200, loss: 0.02945999801158905\n",
      "idx: 300, loss: 0.04769270122051239\n",
      "idx: 400, loss: 0.10393639653921127\n",
      "Performing inference on batch: 0\n",
      "Performing inference on batch: 50\n",
      "Performing inference on batch: 0\n",
      "Performing inference on batch: 50\n",
      "FPR@95: 0.95, AUROC: 99.60 AUPR_IN: 99.64, AUPR_OUT: 99.56\n",
      "CCR: 58.68, 85.04, 94.07, 97.25, ACC: 97.89\n",
      "──────────────────────────────────────────────────────────────────────\n",
      "Running model: models/lenet_mnist_relu_SGD_1.pkl...\n",
      "Getting optimizer for type: SGD...\n",
      "Training epoch: 0\n",
      "idx: 0, loss: 2.2979631423950195\n",
      "idx: 100, loss: 2.305391788482666\n",
      "idx: 200, loss: 0.27267369627952576\n",
      "idx: 300, loss: 0.18561150133609772\n",
      "idx: 400, loss: 0.4328201115131378\n",
      "Training epoch: 1\n",
      "idx: 0, loss: 0.16348794102668762\n",
      "idx: 100, loss: 0.2112744003534317\n",
      "idx: 200, loss: 0.15512844920158386\n",
      "idx: 300, loss: 0.1485271006822586\n",
      "idx: 400, loss: 0.430167555809021\n",
      "Training epoch: 2\n",
      "idx: 0, loss: 0.07311089336872101\n",
      "idx: 100, loss: 0.2090502679347992\n",
      "idx: 200, loss: 0.149739608168602\n",
      "idx: 300, loss: 0.11472673714160919\n",
      "idx: 400, loss: 0.36608532071113586\n",
      "Training epoch: 3\n",
      "idx: 0, loss: 0.10443542897701263\n",
      "idx: 100, loss: 0.06452040374279022\n",
      "idx: 200, loss: 0.07750789076089859\n",
      "idx: 300, loss: 0.07280903309583664\n",
      "idx: 400, loss: 0.3029100000858307\n",
      "Training epoch: 4\n",
      "idx: 0, loss: 0.09004812687635422\n",
      "idx: 100, loss: 0.03718124330043793\n",
      "idx: 200, loss: 0.08279869705438614\n",
      "idx: 300, loss: 0.056891802698373795\n",
      "idx: 400, loss: 0.1670951247215271\n",
      "Training epoch: 5\n",
      "idx: 0, loss: 0.11733017861843109\n",
      "idx: 100, loss: 0.03639562427997589\n",
      "idx: 200, loss: 0.12119926512241364\n",
      "idx: 300, loss: 0.08221603184938431\n",
      "idx: 400, loss: 0.18877013027668\n",
      "Training epoch: 6\n",
      "idx: 0, loss: 0.06403425335884094\n",
      "idx: 100, loss: 0.05653488263487816\n",
      "idx: 200, loss: 0.14763812720775604\n",
      "idx: 300, loss: 0.06167050078511238\n",
      "idx: 400, loss: 0.10528603196144104\n",
      "Training epoch: 7\n",
      "idx: 0, loss: 0.062131043523550034\n",
      "idx: 100, loss: 0.062491949647665024\n",
      "idx: 200, loss: 0.11494124680757523\n",
      "idx: 300, loss: 0.0678940862417221\n",
      "idx: 400, loss: 0.17974241077899933\n",
      "Training epoch: 8\n",
      "idx: 0, loss: 0.038879960775375366\n",
      "idx: 100, loss: 0.06349044293165207\n",
      "idx: 200, loss: 0.0854370966553688\n",
      "idx: 300, loss: 0.051508866250514984\n",
      "idx: 400, loss: 0.16709943115711212\n",
      "Training epoch: 9\n",
      "idx: 0, loss: 0.042216815054416656\n",
      "idx: 100, loss: 0.03895144909620285\n",
      "idx: 200, loss: 0.1080065593123436\n",
      "idx: 300, loss: 0.037605464458465576\n",
      "idx: 400, loss: 0.10400994122028351\n",
      "Performing inference on batch: 0\n",
      "Performing inference on batch: 50\n",
      "Performing inference on batch: 0\n",
      "Performing inference on batch: 50\n",
      "FPR@95: 2.89, AUROC: 99.36 AUPR_IN: 99.40, AUPR_OUT: 99.35\n",
      "CCR: 53.81, 69.97, 89.37, 96.98, ACC: 97.97\n",
      "──────────────────────────────────────────────────────────────────────\n",
      "Running model: models/lenet_mnist_relu_SGD_2.pkl...\n",
      "Getting optimizer for type: SGD...\n",
      "Training epoch: 0\n",
      "idx: 0, loss: 2.3148486614227295\n",
      "idx: 100, loss: 0.29588180780410767\n",
      "idx: 200, loss: 0.29048952460289\n",
      "idx: 300, loss: 0.07895567268133163\n",
      "idx: 400, loss: 0.1914328783750534\n",
      "Training epoch: 1\n",
      "idx: 0, loss: 0.07823692262172699\n",
      "idx: 100, loss: 0.18198469281196594\n",
      "idx: 200, loss: 0.11282601952552795\n",
      "idx: 300, loss: 0.06061578169465065\n",
      "idx: 400, loss: 0.1756141632795334\n",
      "Training epoch: 2\n",
      "idx: 0, loss: 0.04061947390437126\n",
      "idx: 100, loss: 0.09604177623987198\n",
      "idx: 200, loss: 0.12270838767290115\n",
      "idx: 300, loss: 0.09370957314968109\n",
      "idx: 400, loss: 0.08664742857217789\n",
      "Training epoch: 3\n",
      "idx: 0, loss: 0.020608793944120407\n",
      "idx: 100, loss: 0.046492189168930054\n",
      "idx: 200, loss: 0.06588658690452576\n",
      "idx: 300, loss: 0.05406162142753601\n",
      "idx: 400, loss: 0.10225660353899002\n",
      "Training epoch: 4\n",
      "idx: 0, loss: 0.023084046319127083\n",
      "idx: 100, loss: 0.1183188408613205\n",
      "idx: 200, loss: 0.10977242141962051\n",
      "idx: 300, loss: 0.03947194293141365\n",
      "idx: 400, loss: 0.08025575429201126\n",
      "Training epoch: 5\n",
      "idx: 0, loss: 0.0101516367867589\n",
      "idx: 100, loss: 0.031293805688619614\n",
      "idx: 200, loss: 0.09723909199237823\n",
      "idx: 300, loss: 0.07466325163841248\n",
      "idx: 400, loss: 0.1149488240480423\n",
      "Training epoch: 6\n",
      "idx: 0, loss: 0.010120629332959652\n",
      "idx: 100, loss: 0.05794340744614601\n",
      "idx: 200, loss: 0.15966156125068665\n",
      "idx: 300, loss: 0.07212581485509872\n",
      "idx: 400, loss: 0.03787638992071152\n",
      "Training epoch: 7\n",
      "idx: 0, loss: 0.01140196155756712\n",
      "idx: 100, loss: 0.03902653977274895\n",
      "idx: 200, loss: 0.05972956120967865\n",
      "idx: 300, loss: 0.04763485863804817\n",
      "idx: 400, loss: 0.03504573181271553\n",
      "Training epoch: 8\n",
      "idx: 0, loss: 0.021831553429365158\n",
      "idx: 100, loss: 0.05264263600111008\n",
      "idx: 200, loss: 0.12575626373291016\n",
      "idx: 300, loss: 0.06649338454008102\n",
      "idx: 400, loss: 0.04992707818746567\n",
      "Training epoch: 9\n",
      "idx: 0, loss: 0.00995754823088646\n",
      "idx: 100, loss: 0.04670840874314308\n",
      "idx: 200, loss: 0.06155872717499733\n",
      "idx: 300, loss: 0.03608371317386627\n",
      "idx: 400, loss: 0.07056823372840881\n",
      "Performing inference on batch: 0\n",
      "Performing inference on batch: 50\n",
      "Performing inference on batch: 0\n",
      "Performing inference on batch: 50\n",
      "FPR@95: 0.22, AUROC: 99.81 AUPR_IN: 99.83, AUPR_OUT: 99.80\n",
      "CCR: 80.52, 92.84, 96.66, 98.34, ACC: 98.64\n",
      "──────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{0: {'dataset': 'mnist',\n",
       "  'FPR@95': '0.95',\n",
       "  'AUROC': '99.60',\n",
       "  'AUPR_IN': '99.64',\n",
       "  'AUPR_OUT': '99.56',\n",
       "  'CCR_4': '58.68',\n",
       "  'CCR_3': '85.04',\n",
       "  'CCR_2': '94.07',\n",
       "  'CCR_1': '97.25',\n",
       "  'ACC': '97.89',\n",
       "  'optimizer_type': 'SGD',\n",
       "  'activation_function_type': 'relu',\n",
       "  'postprocessor_type': 'odin'},\n",
       " 1: {'dataset': 'mnist',\n",
       "  'FPR@95': '2.89',\n",
       "  'AUROC': '99.36',\n",
       "  'AUPR_IN': '99.40',\n",
       "  'AUPR_OUT': '99.35',\n",
       "  'CCR_4': '53.81',\n",
       "  'CCR_3': '69.97',\n",
       "  'CCR_2': '89.37',\n",
       "  'CCR_1': '96.98',\n",
       "  'ACC': '97.97',\n",
       "  'optimizer_type': 'SGD',\n",
       "  'activation_function_type': 'relu',\n",
       "  'postprocessor_type': 'odin'},\n",
       " 2: {'dataset': 'mnist',\n",
       "  'FPR@95': '0.22',\n",
       "  'AUROC': '99.81',\n",
       "  'AUPR_IN': '99.83',\n",
       "  'AUPR_OUT': '99.80',\n",
       "  'CCR_4': '80.52',\n",
       "  'CCR_3': '92.84',\n",
       "  'CCR_2': '96.66',\n",
       "  'CCR_1': '98.34',\n",
       "  'ACC': '98.64',\n",
       "  'optimizer_type': 'SGD',\n",
       "  'activation_function_type': 'relu',\n",
       "  'postprocessor_type': 'odin'}}"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "config_1a = {\n",
    "    \"batch_size\": 128,\n",
    "    \"n_classes\": 10,\n",
    "    \"dataset_name\": \"mnist\",\n",
    "    \"epochs\": 10,\n",
    "    \"version\": time.time(),\n",
    "    \"lr\": 0.1,\n",
    "    \"momentum\": 0.9,\n",
    "    \"weight_decay\": 0.0005,\n",
    "    \"optimizer_type\": \"SGD\",\n",
    "    \"activation_function_type\": \"relu\",\n",
    "    \"network\": \"lenet\",\n",
    "    \"postprocessor_type\": \"odin\",\n",
    "    \"dataset_type\": \"mnist\",\n",
    "    \"trials\": 3,\n",
    "    \"results_dir\": \"mnist-study\"\n",
    "}\n",
    "config_1a[\"data_loaders\"] = get_data_loaders(config_1a)\n",
    "run_full_oodn_pipeline(config_1a)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2be2d7df",
   "metadata": {},
   "source": [
    "#### 1 (b) SGD + SoftPlus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "7a3ae7d8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running model: models/lenet_mnist_softplus_SGD_0.pkl...\n",
      "Getting optimizer for type: SGD...\n",
      "Training epoch: 0\n",
      "idx: 0, loss: 2.4468095302581787\n",
      "idx: 100, loss: 2.3068735599517822\n",
      "idx: 200, loss: 2.3037972450256348\n",
      "idx: 300, loss: 2.013766050338745\n",
      "idx: 400, loss: 0.9880338907241821\n",
      "Training epoch: 1\n",
      "idx: 0, loss: 0.47247204184532166\n",
      "idx: 100, loss: 0.4614843428134918\n",
      "idx: 200, loss: 0.4421844780445099\n",
      "idx: 300, loss: 0.2332533895969391\n",
      "idx: 400, loss: 0.5398097038269043\n",
      "Training epoch: 2\n",
      "idx: 0, loss: 0.12531839311122894\n",
      "idx: 100, loss: 0.1766596883535385\n",
      "idx: 200, loss: 0.19630563259124756\n",
      "idx: 300, loss: 0.14620856940746307\n",
      "idx: 400, loss: 0.2683812975883484\n",
      "Training epoch: 3\n",
      "idx: 0, loss: 0.10990933328866959\n",
      "idx: 100, loss: 0.12922294437885284\n",
      "idx: 200, loss: 0.12120915949344635\n",
      "idx: 300, loss: 0.08533128350973129\n",
      "idx: 400, loss: 0.23656682670116425\n",
      "Training epoch: 4\n",
      "idx: 0, loss: 0.09355681389570236\n",
      "idx: 100, loss: 0.1110059916973114\n",
      "idx: 200, loss: 0.1473049521446228\n",
      "idx: 300, loss: 0.09925108402967453\n",
      "idx: 400, loss: 0.17063066363334656\n",
      "Training epoch: 5\n",
      "idx: 0, loss: 0.06497308611869812\n",
      "idx: 100, loss: 0.03878457844257355\n",
      "idx: 200, loss: 0.1205115094780922\n",
      "idx: 300, loss: 0.09662658721208572\n",
      "idx: 400, loss: 0.17233319580554962\n",
      "Training epoch: 6\n",
      "idx: 0, loss: 0.060701724141836166\n",
      "idx: 100, loss: 0.05562351644039154\n",
      "idx: 200, loss: 0.09817349165678024\n",
      "idx: 300, loss: 0.06852012127637863\n",
      "idx: 400, loss: 0.2070307731628418\n",
      "Training epoch: 7\n",
      "idx: 0, loss: 0.05982840806245804\n",
      "idx: 100, loss: 0.041968055069446564\n",
      "idx: 200, loss: 0.09146915376186371\n",
      "idx: 300, loss: 0.06613045930862427\n",
      "idx: 400, loss: 0.2235732525587082\n",
      "Training epoch: 8\n",
      "idx: 0, loss: 0.05893777683377266\n",
      "idx: 100, loss: 0.04733992740511894\n",
      "idx: 200, loss: 0.135393887758255\n",
      "idx: 300, loss: 0.0440501794219017\n",
      "idx: 400, loss: 0.21958322823047638\n",
      "Training epoch: 9\n",
      "idx: 0, loss: 0.06410006433725357\n",
      "idx: 100, loss: 0.04827360808849335\n",
      "idx: 200, loss: 0.1063225045800209\n",
      "idx: 300, loss: 0.045183755457401276\n",
      "idx: 400, loss: 0.36780673265457153\n",
      "Performing inference on batch: 0\n",
      "Performing inference on batch: 50\n",
      "Performing inference on batch: 0\n",
      "Performing inference on batch: 50\n",
      "FPR@95: 3.61, AUROC: 98.99 AUPR_IN: 99.18, AUPR_OUT: 98.70\n",
      "CCR: 45.28, 81.40, 89.68, 96.18, ACC: 97.97\n",
      "──────────────────────────────────────────────────────────────────────\n",
      "Running model: models/lenet_mnist_softplus_SGD_1.pkl...\n",
      "Getting optimizer for type: SGD...\n",
      "Training epoch: 0\n",
      "idx: 0, loss: 2.4295883178710938\n",
      "idx: 100, loss: 2.3054468631744385\n",
      "idx: 200, loss: 2.409177303314209\n",
      "idx: 300, loss: 0.556250274181366\n",
      "idx: 400, loss: 0.730586051940918\n",
      "Training epoch: 1\n",
      "idx: 0, loss: 0.17931874096393585\n",
      "idx: 100, loss: 0.24305588006973267\n",
      "idx: 200, loss: 0.20324769616127014\n",
      "idx: 300, loss: 0.10194379836320877\n",
      "idx: 400, loss: 0.32297956943511963\n",
      "Training epoch: 2\n",
      "idx: 0, loss: 0.1013593077659607\n",
      "idx: 100, loss: 0.22296270728111267\n",
      "idx: 200, loss: 0.050150152295827866\n",
      "idx: 300, loss: 0.09565269947052002\n",
      "idx: 400, loss: 0.18905508518218994\n",
      "Training epoch: 3\n",
      "idx: 0, loss: 0.10094868391752243\n",
      "idx: 100, loss: 0.06860997527837753\n",
      "idx: 200, loss: 0.09684555977582932\n",
      "idx: 300, loss: 0.09496651589870453\n",
      "idx: 400, loss: 0.15098819136619568\n",
      "Training epoch: 4\n",
      "idx: 0, loss: 0.09433500468730927\n",
      "idx: 100, loss: 0.06457667797803879\n",
      "idx: 200, loss: 0.04859977215528488\n",
      "idx: 300, loss: 0.0733039602637291\n",
      "idx: 400, loss: 0.07306211441755295\n",
      "Training epoch: 5\n",
      "idx: 0, loss: 0.05245807394385338\n",
      "idx: 100, loss: 0.062286652624607086\n",
      "idx: 200, loss: 0.08584724366664886\n",
      "idx: 300, loss: 0.09682371467351913\n",
      "idx: 400, loss: 0.19771134853363037\n",
      "Training epoch: 6\n",
      "idx: 0, loss: 0.04379139468073845\n",
      "idx: 100, loss: 0.039061885327100754\n",
      "idx: 200, loss: 0.10921458154916763\n",
      "idx: 300, loss: 0.07018472254276276\n",
      "idx: 400, loss: 0.10600479692220688\n",
      "Training epoch: 7\n",
      "idx: 0, loss: 0.07188063114881516\n",
      "idx: 100, loss: 0.08392651379108429\n",
      "idx: 200, loss: 0.058363232761621475\n",
      "idx: 300, loss: 0.057823166251182556\n",
      "idx: 400, loss: 0.0434793122112751\n",
      "Training epoch: 8\n",
      "idx: 0, loss: 0.04575676470994949\n",
      "idx: 100, loss: 0.06038466840982437\n",
      "idx: 200, loss: 0.1530076414346695\n",
      "idx: 300, loss: 0.06497865170240402\n",
      "idx: 400, loss: 0.0952250212430954\n",
      "Training epoch: 9\n",
      "idx: 0, loss: 0.04663925990462303\n",
      "idx: 100, loss: 0.07029278576374054\n",
      "idx: 200, loss: 0.13268837332725525\n",
      "idx: 300, loss: 0.042225178331136703\n",
      "idx: 400, loss: 0.0975961983203888\n",
      "Performing inference on batch: 0\n",
      "Performing inference on batch: 50\n",
      "Performing inference on batch: 0\n",
      "Performing inference on batch: 50\n",
      "FPR@95: 3.05, AUROC: 99.07 AUPR_IN: 99.19, AUPR_OUT: 98.90\n",
      "CCR: 6.62, 72.95, 89.86, 96.13, ACC: 97.66\n",
      "──────────────────────────────────────────────────────────────────────\n",
      "Running model: models/lenet_mnist_softplus_SGD_2.pkl...\n",
      "Getting optimizer for type: SGD...\n",
      "Training epoch: 0\n",
      "idx: 0, loss: 2.347205877304077\n",
      "idx: 100, loss: 2.3059659004211426\n",
      "idx: 200, loss: 2.300297975540161\n",
      "idx: 300, loss: 1.383050799369812\n",
      "idx: 400, loss: 0.5673156976699829\n",
      "Training epoch: 1\n",
      "idx: 0, loss: 0.0949491634964943\n",
      "idx: 100, loss: 0.24765320122241974\n",
      "idx: 200, loss: 0.23510809242725372\n",
      "idx: 300, loss: 0.18788045644760132\n",
      "idx: 400, loss: 0.19607704877853394\n",
      "Training epoch: 2\n",
      "idx: 0, loss: 0.06842920184135437\n",
      "idx: 100, loss: 0.0683121383190155\n",
      "idx: 200, loss: 0.15141864120960236\n",
      "idx: 300, loss: 0.09907254576683044\n",
      "idx: 400, loss: 0.22054597735404968\n",
      "Training epoch: 3\n",
      "idx: 0, loss: 0.11562954634428024\n",
      "idx: 100, loss: 0.09666790813207626\n",
      "idx: 200, loss: 0.1283344328403473\n",
      "idx: 300, loss: 0.05510738864541054\n",
      "idx: 400, loss: 0.15779824554920197\n",
      "Training epoch: 4\n",
      "idx: 0, loss: 0.0626659095287323\n",
      "idx: 100, loss: 0.09467177838087082\n",
      "idx: 200, loss: 0.14338156580924988\n",
      "idx: 300, loss: 0.030973998829722404\n",
      "idx: 400, loss: 0.14152108132839203\n",
      "Training epoch: 5\n",
      "idx: 0, loss: 0.10121425241231918\n",
      "idx: 100, loss: 0.06996101886034012\n",
      "idx: 200, loss: 0.16786611080169678\n",
      "idx: 300, loss: 0.03930629789829254\n",
      "idx: 400, loss: 0.16494899988174438\n",
      "Training epoch: 6\n",
      "idx: 0, loss: 0.07385436445474625\n",
      "idx: 100, loss: 0.061707545071840286\n",
      "idx: 200, loss: 0.15967993438243866\n",
      "idx: 300, loss: 0.08543683588504791\n",
      "idx: 400, loss: 0.16265690326690674\n",
      "Training epoch: 7\n",
      "idx: 0, loss: 0.07048681378364563\n",
      "idx: 100, loss: 0.029770640656352043\n",
      "idx: 200, loss: 0.0888717919588089\n",
      "idx: 300, loss: 0.03788580745458603\n",
      "idx: 400, loss: 0.13767896592617035\n",
      "Training epoch: 8\n",
      "idx: 0, loss: 0.10089296102523804\n",
      "idx: 100, loss: 0.01691422052681446\n",
      "idx: 200, loss: 0.06939185410737991\n",
      "idx: 300, loss: 0.03127201646566391\n",
      "idx: 400, loss: 0.10214222222566605\n",
      "Training epoch: 9\n",
      "idx: 0, loss: 0.06836213916540146\n",
      "idx: 100, loss: 0.037621986120939255\n",
      "idx: 200, loss: 0.08796259760856628\n",
      "idx: 300, loss: 0.029758945107460022\n",
      "idx: 400, loss: 0.1351865828037262\n",
      "Performing inference on batch: 0\n",
      "Performing inference on batch: 50\n",
      "Performing inference on batch: 0\n",
      "Performing inference on batch: 50\n",
      "FPR@95: 4.31, AUROC: 98.80 AUPR_IN: 99.05, AUPR_OUT: 98.31\n",
      "CCR: 55.94, 78.45, 88.74, 95.57, ACC: 97.51\n",
      "──────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{0: {'dataset': 'mnist',\n",
       "  'FPR@95': '3.61',\n",
       "  'AUROC': '98.99',\n",
       "  'AUPR_IN': '99.18',\n",
       "  'AUPR_OUT': '98.70',\n",
       "  'CCR_4': '45.28',\n",
       "  'CCR_3': '81.40',\n",
       "  'CCR_2': '89.68',\n",
       "  'CCR_1': '96.18',\n",
       "  'ACC': '97.97',\n",
       "  'optimizer_type': 'SGD',\n",
       "  'activation_function_type': 'softplus',\n",
       "  'postprocessor_type': 'odin'},\n",
       " 1: {'dataset': 'mnist',\n",
       "  'FPR@95': '3.05',\n",
       "  'AUROC': '99.07',\n",
       "  'AUPR_IN': '99.19',\n",
       "  'AUPR_OUT': '98.90',\n",
       "  'CCR_4': '6.62',\n",
       "  'CCR_3': '72.95',\n",
       "  'CCR_2': '89.86',\n",
       "  'CCR_1': '96.13',\n",
       "  'ACC': '97.66',\n",
       "  'optimizer_type': 'SGD',\n",
       "  'activation_function_type': 'softplus',\n",
       "  'postprocessor_type': 'odin'},\n",
       " 2: {'dataset': 'mnist',\n",
       "  'FPR@95': '4.31',\n",
       "  'AUROC': '98.80',\n",
       "  'AUPR_IN': '99.05',\n",
       "  'AUPR_OUT': '98.31',\n",
       "  'CCR_4': '55.94',\n",
       "  'CCR_3': '78.45',\n",
       "  'CCR_2': '88.74',\n",
       "  'CCR_1': '95.57',\n",
       "  'ACC': '97.51',\n",
       "  'optimizer_type': 'SGD',\n",
       "  'activation_function_type': 'softplus',\n",
       "  'postprocessor_type': 'odin'}}"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "config_1b = {\n",
    "    \"batch_size\": 128,\n",
    "    \"dataset_name\": \"mnist\",\n",
    "    \"n_classes\": 10,\n",
    "    \"epochs\": 10,\n",
    "    \"version\": time.time(),\n",
    "    \"lr\": 0.1,\n",
    "    \"momentum\": 0.9,\n",
    "    \"weight_decay\": 0.0005,\n",
    "    \"optimizer_type\": \"SGD\",\n",
    "    \"activation_function_type\": \"softplus\",\n",
    "    \"network\": \"lenet\",\n",
    "    \"postprocessor_type\": \"odin\",\n",
    "    \"dataset_type\": \"mnist\",\n",
    "    \"trials\": 3,\n",
    "    \"results_dir\": \"mnist-study\"\n",
    "}\n",
    "config_1b[\"data_loaders\"] = get_data_loaders(config_1b)\n",
    "run_full_oodn_pipeline(config_1b)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "966af048",
   "metadata": {},
   "source": [
    "#### 1(c) Adam + ReLU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "38bf5903",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running model: models/lenet_mnist_relu_Adam_0.pkl...\n",
      "Getting optimizer for type: Adam...\n",
      "Training epoch: 0\n",
      "idx: 0, loss: 2.301894187927246\n",
      "idx: 100, loss: 0.11984912306070328\n",
      "idx: 200, loss: 0.15497374534606934\n",
      "idx: 300, loss: 0.06791342049837112\n",
      "idx: 400, loss: 0.22912515699863434\n",
      "Training epoch: 1\n",
      "idx: 0, loss: 0.07157646864652634\n",
      "idx: 100, loss: 0.05058322101831436\n",
      "idx: 200, loss: 0.09429037570953369\n",
      "idx: 300, loss: 0.08827465027570724\n",
      "idx: 400, loss: 0.1425236165523529\n",
      "Training epoch: 2\n",
      "idx: 0, loss: 0.08118437230587006\n",
      "idx: 100, loss: 0.029627040028572083\n",
      "idx: 200, loss: 0.11240573972463608\n",
      "idx: 300, loss: 0.049749165773391724\n",
      "idx: 400, loss: 0.10378781706094742\n",
      "Training epoch: 3\n",
      "idx: 0, loss: 0.05978626012802124\n",
      "idx: 100, loss: 0.04203808680176735\n",
      "idx: 200, loss: 0.12809190154075623\n",
      "idx: 300, loss: 0.072877898812294\n",
      "idx: 400, loss: 0.12331315875053406\n",
      "Training epoch: 4\n",
      "idx: 0, loss: 0.04495770111680031\n",
      "idx: 100, loss: 0.02584172785282135\n",
      "idx: 200, loss: 0.11872470378875732\n",
      "idx: 300, loss: 0.07828597724437714\n",
      "idx: 400, loss: 0.07598255574703217\n",
      "Training epoch: 5\n",
      "idx: 0, loss: 0.05495789647102356\n",
      "idx: 100, loss: 0.037266433238983154\n",
      "idx: 200, loss: 0.10434290766716003\n",
      "idx: 300, loss: 0.10311908274888992\n",
      "idx: 400, loss: 0.11808832734823227\n",
      "Training epoch: 6\n",
      "idx: 0, loss: 0.060246095061302185\n",
      "idx: 100, loss: 0.03131585195660591\n",
      "idx: 200, loss: 0.12608620524406433\n",
      "idx: 300, loss: 0.09490960836410522\n",
      "idx: 400, loss: 0.06511182337999344\n",
      "Training epoch: 7\n",
      "idx: 0, loss: 0.0499860905110836\n",
      "idx: 100, loss: 0.03962114080786705\n",
      "idx: 200, loss: 0.10502298176288605\n",
      "idx: 300, loss: 0.09349831193685532\n",
      "idx: 400, loss: 0.07813948392868042\n",
      "Training epoch: 8\n",
      "idx: 0, loss: 0.07985585182905197\n",
      "idx: 100, loss: 0.02391934208571911\n",
      "idx: 200, loss: 0.12107112258672714\n",
      "idx: 300, loss: 0.10891781747341156\n",
      "idx: 400, loss: 0.0778113380074501\n",
      "Training epoch: 9\n",
      "idx: 0, loss: 0.04968756064772606\n",
      "idx: 100, loss: 0.04941726103425026\n",
      "idx: 200, loss: 0.1538858562707901\n",
      "idx: 300, loss: 0.07793816924095154\n",
      "idx: 400, loss: 0.1059483215212822\n",
      "Performing inference on batch: 0\n",
      "Performing inference on batch: 50\n",
      "Performing inference on batch: 0\n",
      "Performing inference on batch: 50\n",
      "FPR@95: 2.70, AUROC: 99.40 AUPR_IN: 99.44, AUPR_OUT: 99.38\n",
      "CCR: 52.68, 74.63, 91.00, 97.29, ACC: 98.42\n",
      "──────────────────────────────────────────────────────────────────────\n",
      "Running model: models/lenet_mnist_relu_Adam_1.pkl...\n",
      "Getting optimizer for type: Adam...\n",
      "Training epoch: 0\n",
      "idx: 0, loss: 2.293492555618286\n",
      "idx: 100, loss: 0.1070859432220459\n",
      "idx: 200, loss: 0.18924188613891602\n",
      "idx: 300, loss: 0.09109842777252197\n",
      "idx: 400, loss: 0.2963612377643585\n",
      "Training epoch: 1\n",
      "idx: 0, loss: 0.09902137517929077\n",
      "idx: 100, loss: 0.0712750032544136\n",
      "idx: 200, loss: 0.1316186636686325\n",
      "idx: 300, loss: 0.08733689785003662\n",
      "idx: 400, loss: 0.11562913656234741\n",
      "Training epoch: 2\n",
      "idx: 0, loss: 0.12325657159090042\n",
      "idx: 100, loss: 0.10450296103954315\n",
      "idx: 200, loss: 0.11444566398859024\n",
      "idx: 300, loss: 0.06541197001934052\n",
      "idx: 400, loss: 0.16334471106529236\n",
      "Training epoch: 3\n",
      "idx: 0, loss: 0.06405773758888245\n",
      "idx: 100, loss: 0.09464186429977417\n",
      "idx: 200, loss: 0.08733242005109787\n",
      "idx: 300, loss: 0.07983353734016418\n",
      "idx: 400, loss: 0.13288548588752747\n",
      "Training epoch: 4\n",
      "idx: 0, loss: 0.041788797825574875\n",
      "idx: 100, loss: 0.11960559338331223\n",
      "idx: 200, loss: 0.06364922225475311\n",
      "idx: 300, loss: 0.0588051974773407\n",
      "idx: 400, loss: 0.08897693455219269\n",
      "Training epoch: 5\n",
      "idx: 0, loss: 0.07402198761701584\n",
      "idx: 100, loss: 0.027897847816348076\n",
      "idx: 200, loss: 0.0605357363820076\n",
      "idx: 300, loss: 0.07506825774908066\n",
      "idx: 400, loss: 0.09559640288352966\n",
      "Training epoch: 6\n",
      "idx: 0, loss: 0.025842729955911636\n",
      "idx: 100, loss: 0.020025210455060005\n",
      "idx: 200, loss: 0.07151507586240768\n",
      "idx: 300, loss: 0.06313208490610123\n",
      "idx: 400, loss: 0.09809078276157379\n",
      "Training epoch: 7\n",
      "idx: 0, loss: 0.07373160123825073\n",
      "idx: 100, loss: 0.05142107605934143\n",
      "idx: 200, loss: 0.09560370445251465\n",
      "idx: 300, loss: 0.08956504613161087\n",
      "idx: 400, loss: 0.1100311130285263\n",
      "Training epoch: 8\n",
      "idx: 0, loss: 0.03840656578540802\n",
      "idx: 100, loss: 0.08099064230918884\n",
      "idx: 200, loss: 0.07125180959701538\n",
      "idx: 300, loss: 0.06617546826601028\n",
      "idx: 400, loss: 0.1358678936958313\n",
      "Training epoch: 9\n",
      "idx: 0, loss: 0.030743299052119255\n",
      "idx: 100, loss: 0.02863333187997341\n",
      "idx: 200, loss: 0.0692383348941803\n",
      "idx: 300, loss: 0.06162397563457489\n",
      "idx: 400, loss: 0.07264650613069534\n",
      "Performing inference on batch: 0\n",
      "Performing inference on batch: 50\n",
      "Performing inference on batch: 0\n",
      "Performing inference on batch: 50\n",
      "FPR@95: 2.21, AUROC: 99.41 AUPR_IN: 99.47, AUPR_OUT: 99.36\n",
      "CCR: 73.34, 81.76, 91.29, 97.00, ACC: 97.89\n",
      "──────────────────────────────────────────────────────────────────────\n",
      "Running model: models/lenet_mnist_relu_Adam_2.pkl...\n",
      "Getting optimizer for type: Adam...\n",
      "Training epoch: 0\n",
      "idx: 0, loss: 2.3150246143341064\n",
      "idx: 100, loss: 0.09638706594705582\n",
      "idx: 200, loss: 0.0772596001625061\n",
      "idx: 300, loss: 0.06783361732959747\n",
      "idx: 400, loss: 0.28136304020881653\n",
      "Training epoch: 1\n",
      "idx: 0, loss: 0.10244044661521912\n",
      "idx: 100, loss: 0.07415791600942612\n",
      "idx: 200, loss: 0.12683618068695068\n",
      "idx: 300, loss: 0.05580576881766319\n",
      "idx: 400, loss: 0.12959930300712585\n",
      "Training epoch: 2\n",
      "idx: 0, loss: 0.15167661011219025\n",
      "idx: 100, loss: 0.05276137962937355\n",
      "idx: 200, loss: 0.07899244129657745\n",
      "idx: 300, loss: 0.0825977772474289\n",
      "idx: 400, loss: 0.14491266012191772\n",
      "Training epoch: 3\n",
      "idx: 0, loss: 0.04338781535625458\n",
      "idx: 100, loss: 0.039009105414152145\n",
      "idx: 200, loss: 0.050371427088975906\n",
      "idx: 300, loss: 0.0858735591173172\n",
      "idx: 400, loss: 0.11740030348300934\n",
      "Training epoch: 4\n",
      "idx: 0, loss: 0.0560772642493248\n",
      "idx: 100, loss: 0.04598218575119972\n",
      "idx: 200, loss: 0.04679730907082558\n",
      "idx: 300, loss: 0.06849267333745956\n",
      "idx: 400, loss: 0.17239250242710114\n",
      "Training epoch: 5\n",
      "idx: 0, loss: 0.0752267837524414\n",
      "idx: 100, loss: 0.0584476962685585\n",
      "idx: 200, loss: 0.0814000591635704\n",
      "idx: 300, loss: 0.08675199747085571\n",
      "idx: 400, loss: 0.13120029866695404\n",
      "Training epoch: 6\n",
      "idx: 0, loss: 0.06261128187179565\n",
      "idx: 100, loss: 0.040838275104761124\n",
      "idx: 200, loss: 0.0757877305150032\n",
      "idx: 300, loss: 0.08975743502378464\n",
      "idx: 400, loss: 0.09847201406955719\n",
      "Training epoch: 7\n",
      "idx: 0, loss: 0.052738580852746964\n",
      "idx: 100, loss: 0.07920383661985397\n",
      "idx: 200, loss: 0.13834163546562195\n",
      "idx: 300, loss: 0.08015734702348709\n",
      "idx: 400, loss: 0.08001728355884552\n",
      "Training epoch: 8\n",
      "idx: 0, loss: 0.0355585552752018\n",
      "idx: 100, loss: 0.03549942001700401\n",
      "idx: 200, loss: 0.09980328381061554\n",
      "idx: 300, loss: 0.06354200094938278\n",
      "idx: 400, loss: 0.17420224845409393\n",
      "Training epoch: 9\n",
      "idx: 0, loss: 0.02488134801387787\n",
      "idx: 100, loss: 0.01913141831755638\n",
      "idx: 200, loss: 0.07770228385925293\n",
      "idx: 300, loss: 0.06821347028017044\n",
      "idx: 400, loss: 0.050187814980745316\n",
      "Performing inference on batch: 0\n",
      "Performing inference on batch: 50\n",
      "Performing inference on batch: 0\n",
      "Performing inference on batch: 50\n",
      "FPR@95: 0.97, AUROC: 99.55 AUPR_IN: 99.61, AUPR_OUT: 99.51\n",
      "CCR: 73.59, 89.21, 94.54, 97.55, ACC: 98.29\n",
      "──────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{0: {'dataset': 'mnist',\n",
       "  'FPR@95': '2.70',\n",
       "  'AUROC': '99.40',\n",
       "  'AUPR_IN': '99.44',\n",
       "  'AUPR_OUT': '99.38',\n",
       "  'CCR_4': '52.68',\n",
       "  'CCR_3': '74.63',\n",
       "  'CCR_2': '91.00',\n",
       "  'CCR_1': '97.29',\n",
       "  'ACC': '98.42',\n",
       "  'optimizer_type': 'Adam',\n",
       "  'activation_function_type': 'relu',\n",
       "  'postprocessor_type': 'odin'},\n",
       " 1: {'dataset': 'mnist',\n",
       "  'FPR@95': '2.21',\n",
       "  'AUROC': '99.41',\n",
       "  'AUPR_IN': '99.47',\n",
       "  'AUPR_OUT': '99.36',\n",
       "  'CCR_4': '73.34',\n",
       "  'CCR_3': '81.76',\n",
       "  'CCR_2': '91.29',\n",
       "  'CCR_1': '97.00',\n",
       "  'ACC': '97.89',\n",
       "  'optimizer_type': 'Adam',\n",
       "  'activation_function_type': 'relu',\n",
       "  'postprocessor_type': 'odin'},\n",
       " 2: {'dataset': 'mnist',\n",
       "  'FPR@95': '0.97',\n",
       "  'AUROC': '99.55',\n",
       "  'AUPR_IN': '99.61',\n",
       "  'AUPR_OUT': '99.51',\n",
       "  'CCR_4': '73.59',\n",
       "  'CCR_3': '89.21',\n",
       "  'CCR_2': '94.54',\n",
       "  'CCR_1': '97.55',\n",
       "  'ACC': '98.29',\n",
       "  'optimizer_type': 'Adam',\n",
       "  'activation_function_type': 'relu',\n",
       "  'postprocessor_type': 'odin'}}"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "config_1c = {\n",
    "    \"batch_size\": 128,\n",
    "    \"dataset_name\": \"mnist\",\n",
    "    \"n_classes\": 10,\n",
    "    \"epochs\": 10,\n",
    "    \"version\": time.time(),\n",
    "    \"lr\": 0.01,\n",
    "    \"momentum\": 0.9,\n",
    "    \"weight_decay\": 0.0005,\n",
    "    \"optimizer_type\": \"Adam\",\n",
    "    \"activation_function_type\": \"relu\",\n",
    "    \"network\": \"lenet\",\n",
    "    \"postprocessor_type\": \"odin\",\n",
    "    \"dataset_type\": \"mnist\",\n",
    "    \"trials\": 3,\n",
    "    \"results_dir\": \"mnist-study\"\n",
    "}\n",
    "config_1c[\"data_loaders\"] = get_data_loaders(config_1c)\n",
    "run_full_oodn_pipeline(config_1c)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60a72681",
   "metadata": {},
   "source": [
    "#### 1(d) Adam + Softplus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "39e851fb",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running model: models/lenet_mnist_softplus_Adam_0.pkl...\n",
      "Getting optimizer for type: Adam...\n",
      "Training epoch: 0\n",
      "idx: 0, loss: 2.3255388736724854\n",
      "idx: 100, loss: 2.3116369247436523\n",
      "idx: 200, loss: 2.305769443511963\n",
      "idx: 300, loss: 2.2983803749084473\n",
      "idx: 400, loss: 2.307865619659424\n",
      "Training epoch: 1\n",
      "idx: 0, loss: 2.276770830154419\n",
      "idx: 100, loss: 0.8078237175941467\n",
      "idx: 200, loss: 0.25390756130218506\n",
      "idx: 300, loss: 0.32934701442718506\n",
      "idx: 400, loss: 0.3490292727947235\n",
      "Training epoch: 2\n",
      "idx: 0, loss: 0.1403365433216095\n",
      "idx: 100, loss: 0.2735982835292816\n",
      "idx: 200, loss: 0.14142420887947083\n",
      "idx: 300, loss: 0.18107478320598602\n",
      "idx: 400, loss: 0.2841825485229492\n",
      "Training epoch: 3\n",
      "idx: 0, loss: 0.10381539165973663\n",
      "idx: 100, loss: 0.18071672320365906\n",
      "idx: 200, loss: 0.11766538769006729\n",
      "idx: 300, loss: 0.14970530569553375\n",
      "idx: 400, loss: 0.25166428089141846\n",
      "Training epoch: 4\n",
      "idx: 0, loss: 0.13393616676330566\n",
      "idx: 100, loss: 0.14538753032684326\n",
      "idx: 200, loss: 0.12768563628196716\n",
      "idx: 300, loss: 0.1438809633255005\n",
      "idx: 400, loss: 0.23875348269939423\n",
      "Training epoch: 5\n",
      "idx: 0, loss: 0.1682489514350891\n",
      "idx: 100, loss: 0.125187948346138\n",
      "idx: 200, loss: 0.10146977007389069\n",
      "idx: 300, loss: 0.1371866911649704\n",
      "idx: 400, loss: 0.24889390170574188\n",
      "Training epoch: 6\n",
      "idx: 0, loss: 0.16242900490760803\n",
      "idx: 100, loss: 0.12314209342002869\n",
      "idx: 200, loss: 0.07206807285547256\n",
      "idx: 300, loss: 0.12145186960697174\n",
      "idx: 400, loss: 0.2527179419994354\n",
      "Training epoch: 7\n",
      "idx: 0, loss: 0.14371009171009064\n",
      "idx: 100, loss: 0.12553422152996063\n",
      "idx: 200, loss: 0.07212996482849121\n",
      "idx: 300, loss: 0.1133328229188919\n",
      "idx: 400, loss: 0.2411177158355713\n",
      "Training epoch: 8\n",
      "idx: 0, loss: 0.1492113322019577\n",
      "idx: 100, loss: 0.1270325928926468\n",
      "idx: 200, loss: 0.07622025161981583\n",
      "idx: 300, loss: 0.13347668945789337\n",
      "idx: 400, loss: 0.2641887366771698\n",
      "Training epoch: 9\n",
      "idx: 0, loss: 0.1303073763847351\n",
      "idx: 100, loss: 0.12316741049289703\n",
      "idx: 200, loss: 0.0875595360994339\n",
      "idx: 300, loss: 0.13701032102108002\n",
      "idx: 400, loss: 0.3080427050590515\n",
      "Performing inference on batch: 0\n",
      "Performing inference on batch: 50\n",
      "Performing inference on batch: 0\n",
      "Performing inference on batch: 50\n",
      "FPR@95: 30.70, AUROC: 93.93 AUPR_IN: 94.30, AUPR_OUT: 93.41\n",
      "CCR: 3.42, 20.72, 50.00, 81.76, ACC: 95.28\n",
      "──────────────────────────────────────────────────────────────────────\n",
      "Running model: models/lenet_mnist_softplus_Adam_1.pkl...\n",
      "Getting optimizer for type: Adam...\n",
      "Training epoch: 0\n",
      "idx: 0, loss: 2.3405096530914307\n",
      "idx: 100, loss: 1.1046229600906372\n",
      "idx: 200, loss: 0.2685489356517792\n",
      "idx: 300, loss: 0.1404259353876114\n",
      "idx: 400, loss: 0.4758177101612091\n",
      "Training epoch: 1\n",
      "idx: 0, loss: 0.11224426329135895\n",
      "idx: 100, loss: 0.13264623284339905\n",
      "idx: 200, loss: 0.1573409140110016\n",
      "idx: 300, loss: 0.05845817178487778\n",
      "idx: 400, loss: 0.14816255867481232\n",
      "Training epoch: 2\n",
      "idx: 0, loss: 0.11375203728675842\n",
      "idx: 100, loss: 0.08551232516765594\n",
      "idx: 200, loss: 0.118370421230793\n",
      "idx: 300, loss: 0.06918679922819138\n",
      "idx: 400, loss: 0.14604556560516357\n",
      "Training epoch: 3\n",
      "idx: 0, loss: 0.1344720721244812\n",
      "idx: 100, loss: 0.06814386695623398\n",
      "idx: 200, loss: 0.16939346492290497\n",
      "idx: 300, loss: 0.07554427534341812\n",
      "idx: 400, loss: 0.12440013885498047\n",
      "Training epoch: 4\n",
      "idx: 0, loss: 0.09729144722223282\n",
      "idx: 100, loss: 0.0858185887336731\n",
      "idx: 200, loss: 0.12555819749832153\n",
      "idx: 300, loss: 0.06559436768293381\n",
      "idx: 400, loss: 0.12955397367477417\n",
      "Training epoch: 5\n",
      "idx: 0, loss: 0.07271065562963486\n",
      "idx: 100, loss: 0.06363765150308609\n",
      "idx: 200, loss: 0.14262747764587402\n",
      "idx: 300, loss: 0.08564385026693344\n",
      "idx: 400, loss: 0.18204116821289062\n",
      "Training epoch: 6\n",
      "idx: 0, loss: 0.09751572459936142\n",
      "idx: 100, loss: 0.08811667561531067\n",
      "idx: 200, loss: 0.1450086236000061\n",
      "idx: 300, loss: 0.07871059328317642\n",
      "idx: 400, loss: 0.15326723456382751\n",
      "Training epoch: 7\n",
      "idx: 0, loss: 0.10136561840772629\n",
      "idx: 100, loss: 0.07258191704750061\n",
      "idx: 200, loss: 0.18079206347465515\n",
      "idx: 300, loss: 0.06459623575210571\n",
      "idx: 400, loss: 0.18128153681755066\n",
      "Training epoch: 8\n",
      "idx: 0, loss: 0.052126094698905945\n",
      "idx: 100, loss: 0.05263349413871765\n",
      "idx: 200, loss: 0.11266246438026428\n",
      "idx: 300, loss: 0.08637259900569916\n",
      "idx: 400, loss: 0.17438673973083496\n",
      "Training epoch: 9\n",
      "idx: 0, loss: 0.04394402354955673\n",
      "idx: 100, loss: 0.0485212542116642\n",
      "idx: 200, loss: 0.08750747889280319\n",
      "idx: 300, loss: 0.06150608882308006\n",
      "idx: 400, loss: 0.17633961141109467\n",
      "Performing inference on batch: 0\n",
      "Performing inference on batch: 50\n",
      "Performing inference on batch: 0\n",
      "Performing inference on batch: 50\n",
      "FPR@95: 5.51, AUROC: 98.81 AUPR_IN: 98.96, AUPR_OUT: 98.67\n",
      "CCR: 43.70, 68.11, 86.62, 95.13, ACC: 97.47\n",
      "──────────────────────────────────────────────────────────────────────\n",
      "Running model: models/lenet_mnist_softplus_Adam_2.pkl...\n",
      "Getting optimizer for type: Adam...\n",
      "Training epoch: 0\n",
      "idx: 0, loss: 2.4221198558807373\n",
      "idx: 100, loss: 2.312039613723755\n",
      "idx: 200, loss: 2.306194305419922\n",
      "idx: 300, loss: 2.299694061279297\n",
      "idx: 400, loss: 2.3050243854522705\n",
      "Training epoch: 1\n",
      "idx: 0, loss: 2.2877562046051025\n",
      "idx: 100, loss: 2.30895733833313\n",
      "idx: 200, loss: 1.5261534452438354\n",
      "idx: 300, loss: 0.8511296510696411\n",
      "idx: 400, loss: 0.7020911574363708\n",
      "Training epoch: 2\n",
      "idx: 0, loss: 0.20907029509544373\n",
      "idx: 100, loss: 0.3291794955730438\n",
      "idx: 200, loss: 0.2950512766838074\n",
      "idx: 300, loss: 0.23336149752140045\n",
      "idx: 400, loss: 0.3269370198249817\n",
      "Training epoch: 3\n",
      "idx: 0, loss: 0.16842445731163025\n",
      "idx: 100, loss: 0.2669447958469391\n",
      "idx: 200, loss: 0.19706901907920837\n",
      "idx: 300, loss: 0.1288926899433136\n",
      "idx: 400, loss: 0.2780193090438843\n",
      "Training epoch: 4\n",
      "idx: 0, loss: 0.1794627159833908\n",
      "idx: 100, loss: 0.22332549095153809\n",
      "idx: 200, loss: 0.15077124536037445\n",
      "idx: 300, loss: 0.11029205471277237\n",
      "idx: 400, loss: 0.2817866802215576\n",
      "Training epoch: 5\n",
      "idx: 0, loss: 0.18127259612083435\n",
      "idx: 100, loss: 0.16727091372013092\n",
      "idx: 200, loss: 0.13531199097633362\n",
      "idx: 300, loss: 0.11126790940761566\n",
      "idx: 400, loss: 0.2621843218803406\n",
      "Training epoch: 6\n",
      "idx: 0, loss: 0.1277046650648117\n",
      "idx: 100, loss: 0.1518840789794922\n",
      "idx: 200, loss: 0.1338602751493454\n",
      "idx: 300, loss: 0.09819823503494263\n",
      "idx: 400, loss: 0.23511849343776703\n",
      "Training epoch: 7\n",
      "idx: 0, loss: 0.15773755311965942\n",
      "idx: 100, loss: 0.1302693635225296\n",
      "idx: 200, loss: 0.11891195178031921\n",
      "idx: 300, loss: 0.11487491428852081\n",
      "idx: 400, loss: 0.22482170164585114\n",
      "Training epoch: 8\n",
      "idx: 0, loss: 0.14453186094760895\n",
      "idx: 100, loss: 0.1280101090669632\n",
      "idx: 200, loss: 0.13013525307178497\n",
      "idx: 300, loss: 0.1115909069776535\n",
      "idx: 400, loss: 0.19540278613567352\n",
      "Training epoch: 9\n",
      "idx: 0, loss: 0.16506829857826233\n",
      "idx: 100, loss: 0.11937467753887177\n",
      "idx: 200, loss: 0.15994501113891602\n",
      "idx: 300, loss: 0.10763005912303925\n",
      "idx: 400, loss: 0.16847139596939087\n",
      "Performing inference on batch: 0\n",
      "Performing inference on batch: 50\n",
      "Performing inference on batch: 0\n",
      "Performing inference on batch: 50\n",
      "FPR@95: 39.54, AUROC: 93.00 AUPR_IN: 93.58, AUPR_OUT: 92.81\n",
      "CCR: 2.51, 19.59, 49.86, 78.18, ACC: 94.28\n",
      "──────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{0: {'dataset': 'mnist',\n",
       "  'FPR@95': '30.70',\n",
       "  'AUROC': '93.93',\n",
       "  'AUPR_IN': '94.30',\n",
       "  'AUPR_OUT': '93.41',\n",
       "  'CCR_4': '3.42',\n",
       "  'CCR_3': '20.72',\n",
       "  'CCR_2': '50.00',\n",
       "  'CCR_1': '81.76',\n",
       "  'ACC': '95.28',\n",
       "  'optimizer_type': 'Adam',\n",
       "  'activation_function_type': 'softplus',\n",
       "  'postprocessor_type': 'odin'},\n",
       " 1: {'dataset': 'mnist',\n",
       "  'FPR@95': '5.51',\n",
       "  'AUROC': '98.81',\n",
       "  'AUPR_IN': '98.96',\n",
       "  'AUPR_OUT': '98.67',\n",
       "  'CCR_4': '43.70',\n",
       "  'CCR_3': '68.11',\n",
       "  'CCR_2': '86.62',\n",
       "  'CCR_1': '95.13',\n",
       "  'ACC': '97.47',\n",
       "  'optimizer_type': 'Adam',\n",
       "  'activation_function_type': 'softplus',\n",
       "  'postprocessor_type': 'odin'},\n",
       " 2: {'dataset': 'mnist',\n",
       "  'FPR@95': '39.54',\n",
       "  'AUROC': '93.00',\n",
       "  'AUPR_IN': '93.58',\n",
       "  'AUPR_OUT': '92.81',\n",
       "  'CCR_4': '2.51',\n",
       "  'CCR_3': '19.59',\n",
       "  'CCR_2': '49.86',\n",
       "  'CCR_1': '78.18',\n",
       "  'ACC': '94.28',\n",
       "  'optimizer_type': 'Adam',\n",
       "  'activation_function_type': 'softplus',\n",
       "  'postprocessor_type': 'odin'}}"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "config_1d = {\n",
    "    \"batch_size\": 128,\n",
    "    \"dataset_name\": \"mnist\",\n",
    "    \"n_classes\": 10,\n",
    "    \"epochs\": 10,\n",
    "    \"version\": time.time(),\n",
    "    \"lr\": 0.01,\n",
    "    \"momentum\": 0.9,\n",
    "    \"weight_decay\": 0.0005,\n",
    "    \"optimizer_type\": \"Adam\",\n",
    "    \"activation_function_type\": \"softplus\",\n",
    "    \"network\": \"lenet\",\n",
    "    \"postprocessor_type\": \"odin\",\n",
    "    \"dataset_type\": \"mnist\",\n",
    "    \"trials\": 3,\n",
    "    \"results_dir\": \"mnist-study\"\n",
    "}\n",
    "config_1d[\"data_loaders\"] = get_data_loaders(config_1d)\n",
    "run_full_oodn_pipeline(config_1d)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f12abb2",
   "metadata": {},
   "source": [
    "### Robustness Analysis For Study 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "ed57b8a4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>optimizer_type</th>\n",
       "      <th>activation_function_type</th>\n",
       "      <th>postprocessor_type</th>\n",
       "      <th>trial</th>\n",
       "      <th>AUROC</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>SGD</td>\n",
       "      <td>softplus</td>\n",
       "      <td>odin</td>\n",
       "      <td>0</td>\n",
       "      <td>98.99</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>SGD</td>\n",
       "      <td>softplus</td>\n",
       "      <td>odin</td>\n",
       "      <td>1</td>\n",
       "      <td>99.07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>SGD</td>\n",
       "      <td>softplus</td>\n",
       "      <td>odin</td>\n",
       "      <td>2</td>\n",
       "      <td>98.80</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Adam</td>\n",
       "      <td>softplus</td>\n",
       "      <td>odin</td>\n",
       "      <td>0</td>\n",
       "      <td>93.93</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Adam</td>\n",
       "      <td>softplus</td>\n",
       "      <td>odin</td>\n",
       "      <td>1</td>\n",
       "      <td>98.81</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Adam</td>\n",
       "      <td>softplus</td>\n",
       "      <td>odin</td>\n",
       "      <td>2</td>\n",
       "      <td>93.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>SGD</td>\n",
       "      <td>relu</td>\n",
       "      <td>odin</td>\n",
       "      <td>0</td>\n",
       "      <td>99.60</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>SGD</td>\n",
       "      <td>relu</td>\n",
       "      <td>odin</td>\n",
       "      <td>1</td>\n",
       "      <td>99.36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>SGD</td>\n",
       "      <td>relu</td>\n",
       "      <td>odin</td>\n",
       "      <td>2</td>\n",
       "      <td>99.81</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Adam</td>\n",
       "      <td>relu</td>\n",
       "      <td>odin</td>\n",
       "      <td>0</td>\n",
       "      <td>99.40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Adam</td>\n",
       "      <td>relu</td>\n",
       "      <td>odin</td>\n",
       "      <td>1</td>\n",
       "      <td>99.41</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Adam</td>\n",
       "      <td>relu</td>\n",
       "      <td>odin</td>\n",
       "      <td>2</td>\n",
       "      <td>99.55</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   optimizer_type activation_function_type postprocessor_type trial  AUROC\n",
       "0             SGD                 softplus               odin     0  98.99\n",
       "1             SGD                 softplus               odin     1  99.07\n",
       "2             SGD                 softplus               odin     2  98.80\n",
       "3            Adam                 softplus               odin     0  93.93\n",
       "4            Adam                 softplus               odin     1  98.81\n",
       "5            Adam                 softplus               odin     2  93.00\n",
       "6             SGD                     relu               odin     0  99.60\n",
       "7             SGD                     relu               odin     1  99.36\n",
       "8             SGD                     relu               odin     2  99.81\n",
       "9            Adam                     relu               odin     0  99.40\n",
       "10           Adam                     relu               odin     1  99.41\n",
       "11           Adam                     relu               odin     2  99.55"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_study_1 = load_results_into_df('mnist-study/')\n",
    "df_study_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "37b29ba6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>min</th>\n",
       "      <th>25%</th>\n",
       "      <th>50%</th>\n",
       "      <th>75%</th>\n",
       "      <th>max</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>optimizer_type</th>\n",
       "      <th>activation_function_type</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">Adam</th>\n",
       "      <th>relu</th>\n",
       "      <td>3.0</td>\n",
       "      <td>99.453333</td>\n",
       "      <td>0.083865</td>\n",
       "      <td>99.40</td>\n",
       "      <td>99.405</td>\n",
       "      <td>99.41</td>\n",
       "      <td>99.480</td>\n",
       "      <td>99.55</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>softplus</th>\n",
       "      <td>3.0</td>\n",
       "      <td>95.246667</td>\n",
       "      <td>3.120774</td>\n",
       "      <td>93.00</td>\n",
       "      <td>93.465</td>\n",
       "      <td>93.93</td>\n",
       "      <td>96.370</td>\n",
       "      <td>98.81</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">SGD</th>\n",
       "      <th>relu</th>\n",
       "      <td>3.0</td>\n",
       "      <td>99.590000</td>\n",
       "      <td>0.225167</td>\n",
       "      <td>99.36</td>\n",
       "      <td>99.480</td>\n",
       "      <td>99.60</td>\n",
       "      <td>99.705</td>\n",
       "      <td>99.81</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>softplus</th>\n",
       "      <td>3.0</td>\n",
       "      <td>98.953333</td>\n",
       "      <td>0.138684</td>\n",
       "      <td>98.80</td>\n",
       "      <td>98.895</td>\n",
       "      <td>98.99</td>\n",
       "      <td>99.030</td>\n",
       "      <td>99.07</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         count       mean       std    min  \\\n",
       "optimizer_type activation_function_type                                      \n",
       "Adam           relu                        3.0  99.453333  0.083865  99.40   \n",
       "               softplus                    3.0  95.246667  3.120774  93.00   \n",
       "SGD            relu                        3.0  99.590000  0.225167  99.36   \n",
       "               softplus                    3.0  98.953333  0.138684  98.80   \n",
       "\n",
       "                                            25%    50%     75%    max  \n",
       "optimizer_type activation_function_type                                \n",
       "Adam           relu                      99.405  99.41  99.480  99.55  \n",
       "               softplus                  93.465  93.93  96.370  98.81  \n",
       "SGD            relu                      99.480  99.60  99.705  99.81  \n",
       "               softplus                  98.895  98.99  99.030  99.07  "
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_study_1.groupby(['optimizer_type', 'activation_function_type'])['AUROC'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "999547f7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>min</th>\n",
       "      <th>25%</th>\n",
       "      <th>50%</th>\n",
       "      <th>75%</th>\n",
       "      <th>max</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>activation_function_type</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>relu</th>\n",
       "      <td>6.0</td>\n",
       "      <td>99.521667</td>\n",
       "      <td>0.169401</td>\n",
       "      <td>99.36</td>\n",
       "      <td>99.4025</td>\n",
       "      <td>99.480</td>\n",
       "      <td>99.5875</td>\n",
       "      <td>99.81</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>softplus</th>\n",
       "      <td>6.0</td>\n",
       "      <td>97.100000</td>\n",
       "      <td>2.832878</td>\n",
       "      <td>93.00</td>\n",
       "      <td>95.1475</td>\n",
       "      <td>98.805</td>\n",
       "      <td>98.9450</td>\n",
       "      <td>99.07</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                          count       mean       std    min      25%     50%  \\\n",
       "activation_function_type                                                       \n",
       "relu                        6.0  99.521667  0.169401  99.36  99.4025  99.480   \n",
       "softplus                    6.0  97.100000  2.832878  93.00  95.1475  98.805   \n",
       "\n",
       "                              75%    max  \n",
       "activation_function_type                  \n",
       "relu                      99.5875  99.81  \n",
       "softplus                  98.9450  99.07  "
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_study_1.groupby(['activation_function_type'])['AUROC'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "4784b707",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>min</th>\n",
       "      <th>25%</th>\n",
       "      <th>50%</th>\n",
       "      <th>75%</th>\n",
       "      <th>max</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>optimizer_type</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Adam</th>\n",
       "      <td>6.0</td>\n",
       "      <td>97.350000</td>\n",
       "      <td>3.034357</td>\n",
       "      <td>93.0</td>\n",
       "      <td>95.15</td>\n",
       "      <td>99.105</td>\n",
       "      <td>99.4075</td>\n",
       "      <td>99.55</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SGD</th>\n",
       "      <td>6.0</td>\n",
       "      <td>99.271667</td>\n",
       "      <td>0.386751</td>\n",
       "      <td>98.8</td>\n",
       "      <td>99.01</td>\n",
       "      <td>99.215</td>\n",
       "      <td>99.5400</td>\n",
       "      <td>99.81</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                count       mean       std   min    25%     50%      75%  \\\n",
       "optimizer_type                                                             \n",
       "Adam              6.0  97.350000  3.034357  93.0  95.15  99.105  99.4075   \n",
       "SGD               6.0  99.271667  0.386751  98.8  99.01  99.215  99.5400   \n",
       "\n",
       "                  max  \n",
       "optimizer_type         \n",
       "Adam            99.55  \n",
       "SGD             99.81  "
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_study_1.groupby(['optimizer_type'])['AUROC'].describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f0e9381",
   "metadata": {},
   "source": [
    "### Study 2: Resnet50, WILDS iwildcam as the Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "63f1f93d",
   "metadata": {},
   "outputs": [],
   "source": [
    "config_2a = {\n",
    "    \"batch_size\": 16,\n",
    "    \"n_classes\": 2,\n",
    "    \"dataset_name\": \"camelyon17\",\n",
    "    \"epochs\": 10,\n",
    "    \"version\": time.time(),\n",
    "    \"lr\": 0.01,\n",
    "    \"momentum\": 0.9,\n",
    "    \"weight_decay\": 0.0005,\n",
    "    \"optimizer_type\": \"SGD\",\n",
    "    \"activation_function_type\": \"softplus\",\n",
    "    \"network\": \"resnet50\",\n",
    "    \"postprocessor_type\": \"odin\",\n",
    "    \"dataset_type\": \"wilds\"\n",
    "}\n",
    "config_2a[\"data_loaders\"] = get_data_loaders(config_2a)\n",
    "# run_full_oodn_pipeline(config_1d)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
