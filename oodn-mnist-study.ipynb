{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e9c08843",
   "metadata": {},
   "source": [
    "### Exploring The Impact of Optimizers and Activation Functions On OODN "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9b10d253",
   "metadata": {},
   "outputs": [],
   "source": [
    "from os import listdir\n",
    "\n",
    "import time\n",
    "import json\n",
    "\n",
    "import torch\n",
    "\n",
    "from torchvision.datasets import mnist, FashionMNIST\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision.transforms import ToTensor\n",
    "from torch.optim import SGD, Adam\n",
    "from torch.nn import Module\n",
    "from torch import nn\n",
    "from torch.nn import CrossEntropyLoss\n",
    "from torchvision.models.resnet import Bottleneck, ResNet\n",
    "\n",
    "from wilds import get_dataset\n",
    "from wilds.common.data_loaders import get_train_loader\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from openood.evaluators import metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "656f1978",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0\n"
     ]
    }
   ],
   "source": [
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1560babc",
   "metadata": {},
   "source": [
    "### Supported Activation Functions\n",
    "\n",
    "For activation functions, we are considering ReLU, Softplus, Swish. *Note that we may conduct experiments for a subset based on the compute resources available*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3313226f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_activation_fn(activation):\n",
    "    if activation == 'relu':\n",
    "        return nn.ReLU()\n",
    "    elif activation == 'softplus':\n",
    "        return nn.Softplus()\n",
    "    elif activation == 'swish':\n",
    "        return nn.Swish()\n",
    "    return None"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45540f49",
   "metadata": {},
   "source": [
    "### Supported Networks\n",
    "\n",
    "Currently, we support LeNet and ResNet50."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf27a4d4",
   "metadata": {},
   "source": [
    "### LeNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0beec4a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LeNet(nn.Module):\n",
    "    def __init__(self, num_classes, num_channel=3, activation='relu'):\n",
    "        super(LeNet, self).__init__()\n",
    "        self.num_classes = num_classes\n",
    "        self.feature_size = 84\n",
    "        self.block1 = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=num_channel,\n",
    "                      out_channels=6,\n",
    "                      kernel_size=5,\n",
    "                      stride=1,\n",
    "                      padding=2), get_activation_fn(activation), nn.MaxPool2d(kernel_size=2))\n",
    "\n",
    "        self.block2 = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=6, out_channels=16, kernel_size=5, stride=1),\n",
    "             get_activation_fn(activation), nn.MaxPool2d(kernel_size=2))\n",
    "\n",
    "        self.block3 = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=16,\n",
    "                      out_channels=120,\n",
    "                      kernel_size=5,\n",
    "                      stride=1), get_activation_fn(activation))\n",
    "\n",
    "        self.classifier1 = nn.Linear(in_features=120, out_features=84)\n",
    "        self.relu = get_activation_fn(activation)\n",
    "        self.fc = nn.Linear(in_features=84, out_features=num_classes)\n",
    "\n",
    "    def get_fc(self):\n",
    "        fc = self.fc\n",
    "        return fc.weight.cpu().detach().numpy(), fc.bias.cpu().detach().numpy()\n",
    "\n",
    "    def forward(self, x, return_feature=False, return_feature_list=False):\n",
    "        feature1 = self.block1(x)\n",
    "        feature2 = self.block2(feature1)\n",
    "        feature3 = self.block3(feature2)\n",
    "        feature3 = feature3.view(feature3.shape[0], -1)\n",
    "        feature = self.relu(self.classifier1(feature3))\n",
    "        logits_cls = self.fc(feature)\n",
    "        feature_list = [feature1, feature2, feature3, feature]\n",
    "        if return_feature:\n",
    "            return logits_cls, feature\n",
    "        elif return_feature_list:\n",
    "            return logits_cls, feature_list\n",
    "        else:\n",
    "            return logits_cls\n",
    "\n",
    "    def forward_threshold(self, x, threshold):\n",
    "        feature1 = self.block1(x)\n",
    "        feature2 = self.block2(feature1)\n",
    "        feature3 = self.block3(feature2)\n",
    "        feature3 = feature3.view(feature3.shape[0], -1)\n",
    "        feature = self.relu(self.classifier1(feature3))\n",
    "        feature = feature.clip(max=threshold)\n",
    "        logits_cls = self.fc(feature)\n",
    "\n",
    "        return logits_cls"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09018e71",
   "metadata": {},
   "source": [
    "### ResNet50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fe9cc86f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResNet50(ResNet):\n",
    "    def __init__(self,\n",
    "                 block=Bottleneck,\n",
    "                 layers=[3, 4, 6, 3],\n",
    "                 num_classes=1000):\n",
    "        super(ResNet50, self).__init__(block=block,\n",
    "                                       layers=layers,\n",
    "                                       num_classes=num_classes)\n",
    "        self.feature_size = 2048\n",
    "\n",
    "\n",
    "    def forward(self, x, return_feature=False, return_feature_list=False):\n",
    "        feature1 = self.relu(self.bn1(self.conv1(x)))\n",
    "        feature1 = self.maxpool(feature1)\n",
    "        feature2 = self.layer1(feature1)\n",
    "        feature3 = self.layer2(feature2)\n",
    "        feature4 = self.layer3(feature3)\n",
    "        feature5 = self.layer4(feature4)\n",
    "        feature5 = self.avgpool(feature5)\n",
    "        feature = feature5.view(feature5.size(0), -1)\n",
    "        logits_cls = self.fc(feature)\n",
    "\n",
    "        feature_list = [feature1, feature2, feature3, feature4, feature5]\n",
    "        if return_feature:\n",
    "            return logits_cls, feature\n",
    "        elif return_feature_list:\n",
    "            return logits_cls, feature_list\n",
    "        else:\n",
    "            return logits_cls\n",
    "\n",
    "    def forward_threshold(self, x, threshold):\n",
    "        feature1 = self.relu(self.bn1(self.conv1(x)))\n",
    "        feature1 = self.maxpool(feature1)\n",
    "        feature2 = self.layer1(feature1)\n",
    "        feature3 = self.layer2(feature2)\n",
    "        feature4 = self.layer3(feature3)\n",
    "        feature5 = self.layer4(feature4)\n",
    "        feature5 = self.avgpool(feature5)\n",
    "        feature = feature5.clip(max=threshold)\n",
    "        feature = feature.view(feature.size(0), -1)\n",
    "        logits_cls = self.fc(feature)\n",
    "\n",
    "        return logits_cls\n",
    "\n",
    "    def get_fc(self):\n",
    "        fc = self.fc\n",
    "        return fc.weight.cpu().detach().numpy(), fc.bias.cpu().detach().numpy()\n",
    "    \n",
    "def get_resnet_model(activation_function_type, n_classes):\n",
    "    resnet_model = ResNet50(num_classes=n_classes)\n",
    "    resnet_model.to(device)    \n",
    "    return resnet_model\n",
    "\n",
    "def set_activation_function(resnet_model, activation_function_type):\n",
    "    resnet_model.relu = get_activation_fn(activation_function_type)\n",
    "    resnet_model.layer1[0].relu = get_activation_fn(activation_function_type)\n",
    "    resnet_model.layer1[1].relu = get_activation_fn(activation_function_type)\n",
    "    resnet_model.layer1[2].relu = get_activation_fn(activation_function_type)\n",
    "\n",
    "    resnet_model.layer2[0].relu = get_activation_fn(activation_function_type)\n",
    "    resnet_model.layer2[1].relu = get_activation_fn(activation_function_type)\n",
    "    resnet_model.layer2[2].relu = get_activation_fn(activation_function_type)\n",
    "    resnet_model.layer2[3].relu = get_activation_fn(activation_function_type)\n",
    "\n",
    "    resnet_model.layer3[0].relu = get_activation_fn(activation_function_type)\n",
    "    resnet_model.layer3[1].relu = get_activation_fn(activation_function_type)\n",
    "    resnet_model.layer3[2].relu = get_activation_fn(activation_function_type)\n",
    "    resnet_model.layer3[3].relu = get_activation_fn(activation_function_type)\n",
    "    resnet_model.layer3[4].relu = get_activation_fn(activation_function_type)\n",
    "    resnet_model.layer3[5].relu = get_activation_fn(activation_function_type)\n",
    "\n",
    "\n",
    "    resnet_model.layer4[0].relu = get_activation_fn(activation_function_type)\n",
    "    resnet_model.layer4[1].relu = get_activation_fn(activation_function_type)\n",
    "    resnet_model.layer4[2].relu = get_activation_fn(activation_function_type)\n",
    "    \n",
    "    return resnet_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ed366e10",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_model(config):\n",
    "    activation_function_type = config[\"activation_function_type\"]\n",
    "    network_type = config[\"network\"]\n",
    "    n_classes = config[\"n_classes\"]\n",
    "    \n",
    "    if network_type == \"lenet\":\n",
    "        model =  LeNet(num_classes=n_classes, num_channel=1, activation=activation_function_type)\n",
    "    elif network_type == \"resnet50\":\n",
    "        model = get_resnet_model(activation_function_type, n_classes)\n",
    "    else:\n",
    "        raise Exception(\"Currently we only support lenet or resnet50\")\n",
    "    \n",
    "    return model\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d03e75b",
   "metadata": {},
   "source": [
    "### Supported Post-Hoc OODN Processors"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7324715e",
   "metadata": {},
   "source": [
    "#### The first post processor we consider is ODIN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "98e8b33e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class OODPostprocessor():\n",
    "    \n",
    "    def inference(self, net: nn.Module, data_loader: DataLoader):\n",
    "        pred_list, conf_list, label_list = [], [], []\n",
    "        for idx, loaded_data in enumerate(data_loader):\n",
    "            data, label = loaded_data[0], loaded_data[1]\n",
    "            if idx % 50 == 0:\n",
    "                print(f'Performing inference on batch: {idx}')\n",
    "            pred, conf = self.postprocess(net, data.to(device))\n",
    "            for idx in range(len(data)):\n",
    "                pred_list.append(pred[idx].tolist())\n",
    "                conf_list.append(conf[idx].tolist())\n",
    "                label_list.append(label[idx].tolist())\n",
    "\n",
    "        # convert values into numpy array\n",
    "        pred_list = np.array(pred_list, dtype=int)\n",
    "        conf_list = np.array(conf_list)\n",
    "        label_list = np.array(label_list, dtype=int)\n",
    "\n",
    "        return pred_list, conf_list, label_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "52873040",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ODINPostprocessor(OODPostprocessor):\n",
    "    def __init__(self, temperature, noise):\n",
    "        super(OODPostprocessor)\n",
    "        self.temperature = temperature\n",
    "        self.noise = noise\n",
    "        \n",
    "    def postprocess(self, net: nn.Module, data):\n",
    "        net.eval()\n",
    "        data.requires_grad = True\n",
    "        output = net(data)\n",
    "\n",
    "        # Calculating the perturbation we need to add, that is,\n",
    "        # the sign of gradient of cross entropy loss w.r.t. input\n",
    "        criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "        labels = output.detach().argmax(axis=1)\n",
    "\n",
    "        # Using temperature scaling\n",
    "        output = output / self.temperature\n",
    "\n",
    "        loss = criterion(output, labels)\n",
    "        loss.backward()\n",
    "\n",
    "        # Normalizing the gradient to binary in {0, 1}\n",
    "        gradient = torch.ge(data.grad.detach(), 0)\n",
    "        gradient = (gradient.float() - 0.5) * 2\n",
    "\n",
    "        # Scaling values taken from original code       \n",
    "        gradient[:, 0] = (gradient[:, 0]) / (63.0 / 255.0)\n",
    "        if gradient.shape[1] == 3:\n",
    "            gradient[:, 1] = (gradient[:, 1]) / (62.1 / 255.0)\n",
    "            gradient[:, 2] = (gradient[:, 2]) / (66.7 / 255.0)\n",
    "\n",
    "        # Adding small perturbations to images\n",
    "        tempInputs = torch.add(data.detach(), gradient, alpha=-self.noise)\n",
    "        output = net(tempInputs)\n",
    "        output = output / self.temperature\n",
    "\n",
    "        # Calculating the confidence after adding perturbations\n",
    "        nnOutput = output.detach()\n",
    "        nnOutput = nnOutput - nnOutput.max(dim=1, keepdims=True).values\n",
    "        nnOutput = nnOutput.exp() / nnOutput.exp().sum(dim=1, keepdims=True)\n",
    "\n",
    "        conf, pred = nnOutput.max(dim=1)\n",
    "\n",
    "        return pred, conf"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d1d6994",
   "metadata": {},
   "source": [
    "#### We consider the Maximum Classifier Discrepancy Post OODN method\n",
    "\n",
    "https://arxiv.org/pdf/1712.02560.pdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1ccac9d5",
   "metadata": {
    "id": "7L45tl2cRbdX",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "class MCDPostprocessor(OODPostprocessor):\n",
    "    def __init__(self, samples: int = 30):\n",
    "        super(OODPostprocessor)\n",
    "        self.samples = samples  #: number :math:`N` of samples\n",
    "\n",
    "    def postprocess(self, model: torch.nn.Module, x: torch.Tensor) -> torch.Tensor:\n",
    "        mode_switch = False\n",
    "        if not model.training:\n",
    "            mode_switch = True\n",
    "\n",
    "            model.train()\n",
    "\n",
    "            for mod in model.modules():\n",
    "                # reset batch norm layers.\n",
    "                # TODO: are there other layers?\n",
    "                if isinstance(mod, (nn.BatchNorm1d, nn.BatchNorm2d, nn.BatchNorm3d)):\n",
    "                    mod.train(False)\n",
    "\n",
    "        results = None\n",
    "        with torch.no_grad():\n",
    "            for i in range(self.samples):\n",
    "                output = model(x).softmax(dim=1)\n",
    "                if results is None:\n",
    "                    results = torch.zeros(size=output.shape).to(device)\n",
    "                results += output\n",
    "        results /= self.samples\n",
    "\n",
    "        if mode_switch:\n",
    "            model.eval()\n",
    "        \n",
    "        conf, pred = results.max(dim=1)\n",
    "\n",
    "        return pred, conf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9b35a9a1",
   "metadata": {
    "id": "0NHU_CaCRbdX",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def get_postprocessor(postprocessor_type=\"odin\"):\n",
    "    if postprocessor_type == \"odin\":\n",
    "        postprocessor = ODINPostprocessor(1000, 0.0014)\n",
    "    elif postprocessor_type == \"mcd\":\n",
    "        postprocessor = MCDPostprocessor(30)\n",
    "    return postprocessor"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "338742a6",
   "metadata": {},
   "source": [
    "### Supported Out of Distribution Detection Metrics\n",
    "\n",
    "What metrics do we specifically care about here?\n",
    "\n",
    "**FPR@95** measures the false positive rate (FPR) when the true positive rate (TPR) is\n",
    "equal to 95%. Lower scores indicate better performance. \n",
    "\n",
    "**AUROC** measures the area under the\n",
    "Receiver Operating Characteristic (ROC) curve, which displays the relationship between TPR and\n",
    "FPR. The area under the ROC curve can be interpreted as the probability that a positive ID example\n",
    "will have a higher detection score than a negative OOD example. \n",
    "\n",
    "**AUPR** measures the area under\n",
    "the Precision-Recall (PR) curve. The PR curve is created by plotting precision versus recall. Similar\n",
    "to AUROC, we consider ID samples as positive, so that the score corresponds to the AUPR-In metric\n",
    "in some works"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c5d6c1d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_oodn_metrics(model, postprocessor_type, id_test_loader, ood_test_loader, ood_name):\n",
    "    postprocessor = get_postprocessor(postprocessor_type)\n",
    "    id_pred, id_conf, id_gt = postprocessor.inference(\n",
    "                model, id_test_loader)\n",
    "\n",
    "    ood_pred, ood_conf, ood_gt = postprocessor.inference(\n",
    "        model, ood_test_loader)\n",
    "\n",
    "    ood_gt = -1 * np.ones_like(ood_gt)  # hard set to -1 as ood\n",
    "    pred = np.concatenate([id_pred, ood_pred])\n",
    "    conf = np.concatenate([id_conf, ood_conf])\n",
    "    label = np.concatenate([id_gt, ood_gt])\n",
    "    ood_metrics = metrics.compute_all_metrics(conf, label, pred)\n",
    "\n",
    "    return print_and_get_formatted_metrics(ood_metrics, ood_name)\n",
    "\n",
    "def print_and_get_formatted_metrics(metrics, dataset_name):\n",
    "    [fpr, auroc, aupr_in, aupr_out,\n",
    "     ccr_4, ccr_3, ccr_2, ccr_1, accuracy] \\\n",
    "     = metrics\n",
    "\n",
    "    write_content = {\n",
    "        'dataset': dataset_name,\n",
    "        'FPR@95': '{:.2f}'.format(100 * fpr),\n",
    "        'AUROC': '{:.2f}'.format(100 * auroc),\n",
    "        'AUPR_IN': '{:.2f}'.format(100 * aupr_in),\n",
    "        'AUPR_OUT': '{:.2f}'.format(100 * aupr_out),\n",
    "        'CCR_4': '{:.2f}'.format(100 * ccr_4),\n",
    "        'CCR_3': '{:.2f}'.format(100 * ccr_3),\n",
    "        'CCR_2': '{:.2f}'.format(100 * ccr_2),\n",
    "        'CCR_1': '{:.2f}'.format(100 * ccr_1),\n",
    "        'ACC': '{:.2f}'.format(100 * accuracy)\n",
    "    }\n",
    "\n",
    "    fieldnames = list(write_content.keys())\n",
    "\n",
    "    # print ood metric results\n",
    "    print('FPR@95: {:.2f}, AUROC: {:.2f}'.format(100 * fpr, 100 * auroc),\n",
    "          end=' ',\n",
    "          flush=True)\n",
    "    print('AUPR_IN: {:.2f}, AUPR_OUT: {:.2f}'.format(\n",
    "        100 * aupr_in, 100 * aupr_out),\n",
    "          flush=True)\n",
    "    print('CCR: {:.2f}, {:.2f}, {:.2f}, {:.2f},'.format(\n",
    "        ccr_4 * 100, ccr_3 * 100, ccr_2 * 100, ccr_1 * 100),\n",
    "          end=' ',\n",
    "          flush=True)\n",
    "    print('ACC: {:.2f}'.format(accuracy * 100), flush=True)\n",
    "    print(u'\\u2500' * 70, flush=True)\n",
    "    return write_content\n",
    "\n",
    "def load_results_into_df(dir_path):\n",
    "    res_files = [dir_path+each for each in listdir(dir_path)]\n",
    "    all_results = []\n",
    "    columns = ['optimizer_type', 'activation_function_type', 'postprocessor_type', 'trial', 'AUROC', 'ACC']\n",
    "    for fp in res_files:\n",
    "        f = open(fp)\n",
    "        data = json.load(f)\n",
    "        for trial, results in data.items():\n",
    "            all_results.append([\n",
    "                    results['optimizer_type'],\n",
    "                    results['activation_function_type'],\n",
    "                    results['postprocessor_type'],\n",
    "                    trial,\n",
    "                    float(results['AUROC']),\n",
    "                    float(results['ACC'])\n",
    "                ])\n",
    "    df = pd.DataFrame(all_results, columns=columns)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f872ebda",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_optimizer(model, config):\n",
    "    params = model.parameters()\n",
    "    lr = config['lr']\n",
    "    momentum = config['momentum']\n",
    "    weight_decay = config['weight_decay']\n",
    "    optimizer_type = config['optimizer_type']\n",
    "    \n",
    "    print(f'Getting optimizer for type: {optimizer_type}...')\n",
    "    if optimizer_type == 'SGD':\n",
    "        return SGD(params, \n",
    "              lr=lr, \n",
    "              momentum=momentum,\n",
    "              weight_decay=weight_decay)\n",
    "    elif optimizer_type == 'Adam':\n",
    "        return Adam(params, \n",
    "                    lr=lr, \n",
    "                    weight_decay=weight_decay)\n",
    "    else:\n",
    "        raise Exception(\"Invalid optimizer_type provided, only SGD and Adam are supported currently\")\n",
    "\n",
    "def get_wilds_loader(dataset, split, batch_size):\n",
    "    d = dataset.get_subset(\n",
    "        split,\n",
    "        frac=0.1,\n",
    "        transform=transforms.Compose(\n",
    "            [transforms.Resize((448, 448)), transforms.ToTensor()]\n",
    "        ),\n",
    "    )\n",
    "    # Prepare the standard data loader\n",
    "    return get_train_loader(\"standard\", d, batch_size=batch_size, num_workers=4, pin_memory=True)\n",
    "\n",
    "def get_data_loaders(config):\n",
    "    data_loaders = {}\n",
    "    dataset_name = config[\"dataset_name\"]\n",
    "    dataset_type = config[\"dataset_type\"]\n",
    "    batch_size = config['batch_size']\n",
    "    \n",
    "    wilds_id_test_split = \"id_val\" if dataset_name == \"camelyon17\" else \"id_test\"\n",
    "    if dataset_type == \"wilds\":\n",
    "        # wilds dataset\n",
    "        dataset = get_dataset(dataset=dataset_name, download=True)\n",
    "        \n",
    "        data_loaders[\"train\"] = get_wilds_loader(dataset, \"train\", batch_size)\n",
    "        data_loaders[\"ood_test\"] = get_wilds_loader(dataset, \"test\", batch_size)\n",
    "        data_loaders[\"id_test\"] = get_wilds_loader(dataset, wilds_id_test_split, batch_size)\n",
    "    elif dataset_name == \"mnist\":\n",
    "        # mnist dataset\n",
    "        train_dataset = mnist.MNIST(root='data', download=True, train=True, transform=ToTensor())\n",
    "        test_dataset = mnist.MNIST(root='data', download=True, train=False, transform=ToTensor())\n",
    "        fashion_test_dataset = mnist.FashionMNIST(root='data', download=True,train=False,transform=ToTensor())\n",
    "\n",
    "        data_loaders[\"train\"] = DataLoader(train_dataset, batch_size=batch_size)\n",
    "        data_loaders[\"id_test\"] = DataLoader(test_dataset, batch_size=batch_size)\n",
    "        data_loaders[\"ood_test\"] = DataLoader(fashion_test_dataset, batch_size=batch_size)\n",
    "    \n",
    "    return data_loaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ee26224e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_resnet_model_given_opti_activation_fn(config):\n",
    "    # get the train loader\n",
    "    train_loader = config[\"data_loaders\"][\"train\"]\n",
    "    \n",
    "    # get the resnet model with the replaced activation functions\n",
    "    model = get_model(config)\n",
    "    model.to(device)\n",
    "    \n",
    "    # get the optimizer\n",
    "    sgd = get_optimizer(model, config)\n",
    "    \n",
    "    loss_fn = CrossEntropyLoss()\n",
    "\n",
    "    for current_epoch in range(config['epochs']):\n",
    "        model.train()\n",
    "        epoch_start = time.time()\n",
    "        print('Training epoch: {}'.format(current_epoch))\n",
    "        \n",
    "        time_per_hundred = time.time()\n",
    "        for idx, (loader_data) in enumerate(train_loader):\n",
    "            train_x, train_label = loader_data[0].cuda(), loader_data[1].cuda()\n",
    "            sgd.zero_grad()\n",
    "            predict_y = model(train_x.float())\n",
    "            loss = loss_fn(predict_y, train_label.long())\n",
    "            if idx % 100 == 0:\n",
    "                print('idx: {}, loss: {}, time taken: {}'.format(idx, loss.sum().item(), time.time()-time_per_hundred))\n",
    "                time_per_hundred = time.time()\n",
    "            loss.backward()\n",
    "            sgd.step()\n",
    "        print(f\"Time take for epoch {current_epoch}: {time.time() - epoch_start}s\")\n",
    "    \n",
    "    torch.save(model, config['model_name'])\n",
    "    return model\n",
    "\n",
    "def run_full_oodn_pipeline(config):\n",
    "    metrics = {}\n",
    "    for i in range(config[\"trials\"]):\n",
    "        t = time.time()\n",
    "        model_name = f\"models/{config['dataset_name']}_{config['network']}_{config['postprocessor_type']}_{config['activation_function_type']}_{config['optimizer_type']}_{i}.pkl\"\n",
    "        print(f'Running model: {model_name}...')\n",
    "        config['model_name'] = model_name\n",
    "        # train model\n",
    "        model = train_resnet_model_given_opti_activation_fn(config)\n",
    "        # calculate oodn metrics\n",
    "        metrics[i] = calculate_oodn_metrics(model,\n",
    "                               config['postprocessor_type'],\n",
    "                               config[\"data_loaders\"][\"id_test\"], \n",
    "                               config[\"data_loaders\"][\"ood_test\"], \n",
    "                               config[\"dataset_name\"])\n",
    "        metrics[i]['optimizer_type'] = config['optimizer_type']\n",
    "        metrics[i]['activation_function_type'] = config['activation_function_type']\n",
    "        metrics[i]['postprocessor_type'] = config['postprocessor_type']\n",
    "        metrics[i]['time_taken'] = time.time() - t\n",
    "        print(f\"Time taken to train: {metrics[i]['time_taken']}\")\n",
    "        \n",
    "    experiment_name = f\"{config['results_dir']}/{config['dataset_name']}_{config['network']}_{config['postprocessor_type']}_{config['activation_function_type']}_{config['optimizer_type']}.json\"\n",
    "    with open(experiment_name, 'w') as fp:\n",
    "        json.dump(metrics, fp)\n",
    "    return metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c992663",
   "metadata": {},
   "source": [
    "### Study 1: LeNet5, MNIST as the ID Dataset, FashionMNIST as the OOD Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae7e58bf",
   "metadata": {},
   "source": [
    "#### Study 1(a): Combination: SGD + ReLU"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c41a53f",
   "metadata": {},
   "source": [
    "#### ODIN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "de1880d7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running model: models/mnist_lenet_odin_relu_SGD_0.pkl...\n",
      "Getting optimizer for type: SGD...\n",
      "Training epoch: 0\n",
      "idx: 0, loss: 2.3107709884643555, time taken: 0.016290903091430664\n",
      "idx: 100, loss: 0.2591329514980316, time taken: 0.9920833110809326\n",
      "idx: 200, loss: 0.18179017305374146, time taken: 0.983135461807251\n",
      "idx: 300, loss: 0.18219703435897827, time taken: 1.2073335647583008\n",
      "idx: 400, loss: 0.1705045849084854, time taken: 0.9965109825134277\n",
      "Time take for epoch 0: 4.872047662734985s\n",
      "Training epoch: 1\n",
      "idx: 0, loss: 0.049608729779720306, time taken: 0.00919032096862793\n",
      "idx: 100, loss: 0.0975547730922699, time taken: 1.003889799118042\n",
      "idx: 200, loss: 0.06459632515907288, time taken: 0.9914870262145996\n",
      "idx: 300, loss: 0.07444804161787033, time taken: 0.9995100498199463\n",
      "idx: 400, loss: 0.19108620285987854, time taken: 1.000260829925537\n",
      "Time take for epoch 1: 4.699322462081909s\n",
      "Training epoch: 2\n",
      "idx: 0, loss: 0.04568091034889221, time taken: 0.00902700424194336\n",
      "idx: 100, loss: 0.10087908804416656, time taken: 0.9965994358062744\n",
      "idx: 200, loss: 0.0736146792769432, time taken: 0.9848401546478271\n",
      "idx: 300, loss: 0.0504014752805233, time taken: 0.9941465854644775\n",
      "idx: 400, loss: 0.11009316891431808, time taken: 0.9770712852478027\n",
      "Time take for epoch 2: 4.622553586959839s\n",
      "Training epoch: 3\n",
      "idx: 0, loss: 0.057830892503261566, time taken: 0.009058952331542969\n",
      "idx: 100, loss: 0.028144747018814087, time taken: 0.9825282096862793\n",
      "idx: 200, loss: 0.05137007310986519, time taken: 0.9876613616943359\n",
      "idx: 300, loss: 0.0643543004989624, time taken: 0.9798099994659424\n",
      "idx: 400, loss: 0.12536707520484924, time taken: 0.9859678745269775\n",
      "Time take for epoch 3: 4.615171432495117s\n",
      "Training epoch: 4\n",
      "idx: 0, loss: 0.03275535628199577, time taken: 0.00922536849975586\n",
      "idx: 100, loss: 0.031061680987477303, time taken: 0.9909143447875977\n",
      "idx: 200, loss: 0.03359995782375336, time taken: 0.9852280616760254\n",
      "idx: 300, loss: 0.04511228948831558, time taken: 0.9874849319458008\n",
      "idx: 400, loss: 0.1429394781589508, time taken: 0.990757942199707\n",
      "Time take for epoch 4: 4.633073568344116s\n",
      "Training epoch: 5\n",
      "idx: 0, loss: 0.011692405678331852, time taken: 0.009403705596923828\n",
      "idx: 100, loss: 0.0039851064793765545, time taken: 1.0051727294921875\n",
      "idx: 200, loss: 0.06531678140163422, time taken: 0.986882209777832\n",
      "idx: 300, loss: 0.089501291513443, time taken: 1.0175771713256836\n",
      "idx: 400, loss: 0.1269802749156952, time taken: 0.9929044246673584\n",
      "Time take for epoch 5: 4.6822474002838135s\n",
      "Training epoch: 6\n",
      "idx: 0, loss: 0.02342776209115982, time taken: 0.009004592895507812\n",
      "idx: 100, loss: 0.038030415773391724, time taken: 0.9932825565338135\n",
      "idx: 200, loss: 0.060923248529434204, time taken: 1.0017268657684326\n",
      "idx: 300, loss: 0.024528518319129944, time taken: 0.9926795959472656\n",
      "idx: 400, loss: 0.0743761658668518, time taken: 0.9964089393615723\n",
      "Time take for epoch 6: 4.706239700317383s\n",
      "Training epoch: 7\n",
      "idx: 0, loss: 0.011614561080932617, time taken: 0.010206222534179688\n",
      "idx: 100, loss: 0.01206947024911642, time taken: 1.0046374797821045\n",
      "idx: 200, loss: 0.06673333048820496, time taken: 0.9884607791900635\n",
      "idx: 300, loss: 0.04606751352548599, time taken: 0.9886128902435303\n",
      "idx: 400, loss: 0.07796841859817505, time taken: 0.9938693046569824\n",
      "Time take for epoch 7: 4.657261848449707s\n",
      "Training epoch: 8\n",
      "idx: 0, loss: 0.08107129484415054, time taken: 0.009591341018676758\n",
      "idx: 100, loss: 0.013938119634985924, time taken: 0.9769933223724365\n",
      "idx: 200, loss: 0.023444347083568573, time taken: 0.992401123046875\n",
      "idx: 300, loss: 0.04434327781200409, time taken: 1.0304555892944336\n",
      "idx: 400, loss: 0.06570208072662354, time taken: 1.0543255805969238\n",
      "Time take for epoch 8: 4.769639253616333s\n",
      "Training epoch: 9\n",
      "idx: 0, loss: 0.016600020229816437, time taken: 0.009377717971801758\n",
      "idx: 100, loss: 0.03289647772908211, time taken: 0.9970967769622803\n",
      "idx: 200, loss: 0.06425607204437256, time taken: 0.9799327850341797\n",
      "idx: 300, loss: 0.03481653705239296, time taken: 0.9873661994934082\n",
      "idx: 400, loss: 0.12185468524694443, time taken: 0.9822914600372314\n",
      "Time take for epoch 9: 4.630271673202515s\n",
      "Performing inference on batch: 0\n",
      "Performing inference on batch: 50\n",
      "Performing inference on batch: 0\n",
      "Performing inference on batch: 50\n",
      "FPR@95: 1.50, AUROC: 99.40 AUPR_IN: 99.50, AUPR_OUT: 99.28\n",
      "CCR: 66.49, 83.34, 93.16, 97.26, ACC: 98.21\n",
      "──────────────────────────────────────────────────────────────────────\n",
      "Time taken to train: 51.51332950592041\n",
      "Running model: models/mnist_lenet_odin_relu_SGD_1.pkl...\n",
      "Getting optimizer for type: SGD...\n",
      "Training epoch: 0\n",
      "idx: 0, loss: 2.3172996044158936, time taken: 0.010024547576904297\n",
      "idx: 100, loss: 0.2801782786846161, time taken: 1.0099842548370361\n",
      "idx: 200, loss: 0.3622437119483948, time taken: 1.0226292610168457\n",
      "idx: 300, loss: 0.13076990842819214, time taken: 1.0141770839691162\n",
      "idx: 400, loss: 0.2892927825450897, time taken: 0.9946417808532715\n",
      "Time take for epoch 0: 4.7275071144104s\n",
      "Training epoch: 1\n",
      "idx: 0, loss: 0.09372518956661224, time taken: 0.008882284164428711\n",
      "idx: 100, loss: 0.12023400515317917, time taken: 0.995948076248169\n",
      "idx: 200, loss: 0.11826838552951813, time taken: 0.9867000579833984\n",
      "idx: 300, loss: 0.052651166915893555, time taken: 0.983121395111084\n",
      "idx: 400, loss: 0.12842312455177307, time taken: 0.9887545108795166\n",
      "Time take for epoch 1: 4.634749174118042s\n",
      "Training epoch: 2\n",
      "idx: 0, loss: 0.046488769352436066, time taken: 0.008966684341430664\n",
      "idx: 100, loss: 0.09062884002923965, time taken: 0.9965686798095703\n",
      "idx: 200, loss: 0.12159673124551773, time taken: 1.0125646591186523\n",
      "idx: 300, loss: 0.055142439901828766, time taken: 1.032367467880249\n",
      "idx: 400, loss: 0.0630563274025917, time taken: 1.0077834129333496\n",
      "Time take for epoch 2: 4.932436227798462s\n",
      "Training epoch: 3\n",
      "idx: 0, loss: 0.0319761261343956, time taken: 0.008968591690063477\n",
      "idx: 100, loss: 0.06794089823961258, time taken: 0.9862868785858154\n",
      "idx: 200, loss: 0.14994339644908905, time taken: 0.9826204776763916\n",
      "idx: 300, loss: 0.04115898907184601, time taken: 1.0092380046844482\n",
      "idx: 400, loss: 0.05278734490275383, time taken: 0.9989883899688721\n",
      "Time take for epoch 3: 4.657927513122559s\n",
      "Training epoch: 4\n",
      "idx: 0, loss: 0.03813755884766579, time taken: 0.009174823760986328\n",
      "idx: 100, loss: 0.10632031410932541, time taken: 1.019601583480835\n",
      "idx: 200, loss: 0.06446550786495209, time taken: 0.9999876022338867\n",
      "idx: 300, loss: 0.07168523967266083, time taken: 0.9968516826629639\n",
      "idx: 400, loss: 0.06333432346582413, time taken: 1.0152437686920166\n",
      "Time take for epoch 4: 4.713170528411865s\n",
      "Training epoch: 5\n",
      "idx: 0, loss: 0.015387512743473053, time taken: 0.009228706359863281\n",
      "idx: 100, loss: 0.007135477382689714, time taken: 0.994565486907959\n",
      "idx: 200, loss: 0.06350802630186081, time taken: 0.9908275604248047\n",
      "idx: 300, loss: 0.05294938385486603, time taken: 0.9897260665893555\n",
      "idx: 400, loss: 0.08301013708114624, time taken: 1.0038063526153564\n",
      "Time take for epoch 5: 4.663633346557617s\n",
      "Training epoch: 6\n",
      "idx: 0, loss: 0.03604235127568245, time taken: 0.008916378021240234\n",
      "idx: 100, loss: 0.03060198947787285, time taken: 0.9796497821807861\n",
      "idx: 200, loss: 0.1169927790760994, time taken: 0.9831316471099854\n",
      "idx: 300, loss: 0.030178647488355637, time taken: 0.9917473793029785\n",
      "idx: 400, loss: 0.057831160724163055, time taken: 0.9877407550811768\n",
      "Time take for epoch 6: 4.616171836853027s\n",
      "Training epoch: 7\n",
      "idx: 0, loss: 0.03515898808836937, time taken: 0.009032487869262695\n",
      "idx: 100, loss: 0.013227111659944057, time taken: 0.9881994724273682\n",
      "idx: 200, loss: 0.08300286531448364, time taken: 0.9926941394805908\n",
      "idx: 300, loss: 0.03828669711947441, time taken: 0.9920129776000977\n",
      "idx: 400, loss: 0.019708050414919853, time taken: 0.9968020915985107\n",
      "Time take for epoch 7: 4.65550684928894s\n",
      "Training epoch: 8\n",
      "idx: 0, loss: 0.019773416221141815, time taken: 0.00962376594543457\n",
      "idx: 100, loss: 0.027415718883275986, time taken: 1.022061824798584\n",
      "idx: 200, loss: 0.07110654562711716, time taken: 1.0077471733093262\n",
      "idx: 300, loss: 0.04131927713751793, time taken: 1.0225272178649902\n",
      "idx: 400, loss: 0.07741730660200119, time taken: 1.015718698501587\n",
      "Time take for epoch 8: 4.773477792739868s\n",
      "Training epoch: 9\n",
      "idx: 0, loss: 0.025239868089556694, time taken: 0.00959634780883789\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "idx: 100, loss: 0.03807500749826431, time taken: 0.9945220947265625\n",
      "idx: 200, loss: 0.09613689035177231, time taken: 0.9967730045318604\n",
      "idx: 300, loss: 0.04140741750597954, time taken: 0.9968740940093994\n",
      "idx: 400, loss: 0.04109680652618408, time taken: 0.9932870864868164\n",
      "Time take for epoch 9: 4.665702819824219s\n",
      "Performing inference on batch: 0\n",
      "Performing inference on batch: 50\n",
      "Performing inference on batch: 0\n",
      "Performing inference on batch: 50\n",
      "FPR@95: 1.03, AUROC: 99.62 AUPR_IN: 99.66, AUPR_OUT: 99.58\n",
      "CCR: 49.92, 86.67, 94.39, 97.63, ACC: 98.19\n",
      "──────────────────────────────────────────────────────────────────────\n",
      "Time taken to train: 49.472259759902954\n",
      "Running model: models/mnist_lenet_odin_relu_SGD_2.pkl...\n",
      "Getting optimizer for type: SGD...\n",
      "Training epoch: 0\n",
      "idx: 0, loss: 2.3102641105651855, time taken: 0.008780956268310547\n",
      "idx: 100, loss: 0.4469568133354187, time taken: 0.9988772869110107\n",
      "idx: 200, loss: 0.19983994960784912, time taken: 0.9965133666992188\n",
      "idx: 300, loss: 0.17732372879981995, time taken: 1.0187196731567383\n",
      "idx: 400, loss: 0.37621286511421204, time taken: 1.0440967082977295\n",
      "Time take for epoch 0: 4.75039005279541s\n",
      "Training epoch: 1\n",
      "idx: 0, loss: 0.134952574968338, time taken: 0.009303092956542969\n",
      "idx: 100, loss: 0.1281881183385849, time taken: 0.9925744533538818\n",
      "idx: 200, loss: 0.13048692047595978, time taken: 0.9938514232635498\n",
      "idx: 300, loss: 0.17058993875980377, time taken: 1.0097630023956299\n",
      "idx: 400, loss: 0.18939247727394104, time taken: 0.9919970035552979\n",
      "Time take for epoch 1: 4.684510707855225s\n",
      "Training epoch: 2\n",
      "idx: 0, loss: 0.15934064984321594, time taken: 0.00902557373046875\n",
      "idx: 100, loss: 0.049033962190151215, time taken: 0.995863676071167\n",
      "idx: 200, loss: 0.14801153540611267, time taken: 1.000662088394165\n",
      "idx: 300, loss: 0.1051260232925415, time taken: 1.0015537738800049\n",
      "idx: 400, loss: 0.16351360082626343, time taken: 0.9959635734558105\n",
      "Time take for epoch 2: 4.682389497756958s\n",
      "Training epoch: 3\n",
      "idx: 0, loss: 0.04472069814801216, time taken: 0.00899958610534668\n",
      "idx: 100, loss: 0.08318308740854263, time taken: 0.9911148548126221\n",
      "idx: 200, loss: 0.10972891747951508, time taken: 0.990455150604248\n",
      "idx: 300, loss: 0.07797806710004807, time taken: 1.0081062316894531\n",
      "idx: 400, loss: 0.12451378256082535, time taken: 1.005197525024414\n",
      "Time take for epoch 3: 4.6874542236328125s\n",
      "Training epoch: 4\n",
      "idx: 0, loss: 0.04400625824928284, time taken: 0.009243011474609375\n",
      "idx: 100, loss: 0.06885161250829697, time taken: 0.9791967868804932\n",
      "idx: 200, loss: 0.1085958331823349, time taken: 0.9811809062957764\n",
      "idx: 300, loss: 0.0839507132768631, time taken: 1.0168514251708984\n",
      "idx: 400, loss: 0.13420282304286957, time taken: 1.1427998542785645\n",
      "Time take for epoch 4: 4.968298435211182s\n",
      "Training epoch: 5\n",
      "idx: 0, loss: 0.045249033719301224, time taken: 0.020515918731689453\n",
      "idx: 100, loss: 0.07591765373945236, time taken: 1.267369031906128\n",
      "idx: 200, loss: 0.06989331543445587, time taken: 1.0105817317962646\n",
      "idx: 300, loss: 0.10112258046865463, time taken: 1.0084145069122314\n",
      "idx: 400, loss: 0.075784832239151, time taken: 1.0114529132843018\n",
      "Time take for epoch 5: 5.001894474029541s\n",
      "Training epoch: 6\n",
      "idx: 0, loss: 0.04160686954855919, time taken: 0.009029150009155273\n",
      "idx: 100, loss: 0.01849519833922386, time taken: 1.013267993927002\n",
      "idx: 200, loss: 0.09299556165933609, time taken: 1.0280442237854004\n",
      "idx: 300, loss: 0.09844148904085159, time taken: 1.0201976299285889\n",
      "idx: 400, loss: 0.14198856055736542, time taken: 1.0388810634613037\n",
      "Time take for epoch 6: 4.798413038253784s\n",
      "Training epoch: 7\n",
      "idx: 0, loss: 0.048869047313928604, time taken: 0.010453939437866211\n",
      "idx: 100, loss: 0.05830885469913483, time taken: 1.0339300632476807\n",
      "idx: 200, loss: 0.051033731549978256, time taken: 1.0041241645812988\n",
      "idx: 300, loss: 0.0666986033320427, time taken: 1.0212607383728027\n",
      "idx: 400, loss: 0.09337688982486725, time taken: 1.0213840007781982\n",
      "Time take for epoch 7: 4.77751350402832s\n",
      "Training epoch: 8\n",
      "idx: 0, loss: 0.042831532657146454, time taken: 0.008978128433227539\n",
      "idx: 100, loss: 0.034469667822122574, time taken: 1.004410743713379\n",
      "idx: 200, loss: 0.08700556308031082, time taken: 1.0062711238861084\n",
      "idx: 300, loss: 0.08750300854444504, time taken: 1.0125563144683838\n",
      "idx: 400, loss: 0.0838860273361206, time taken: 1.0206139087677002\n",
      "Time take for epoch 8: 4.748060703277588s\n",
      "Training epoch: 9\n",
      "idx: 0, loss: 0.07018884271383286, time taken: 0.009409666061401367\n",
      "idx: 100, loss: 0.03341096267104149, time taken: 1.0486750602722168\n",
      "idx: 200, loss: 0.029474789276719093, time taken: 1.0013954639434814\n",
      "idx: 300, loss: 0.07561178505420685, time taken: 1.0082755088806152\n",
      "idx: 400, loss: 0.07809422165155411, time taken: 1.006554365158081\n",
      "Time take for epoch 9: 4.752333402633667s\n",
      "Performing inference on batch: 0\n",
      "Performing inference on batch: 50\n",
      "Performing inference on batch: 0\n",
      "Performing inference on batch: 50\n",
      "FPR@95: 1.75, AUROC: 99.52 AUPR_IN: 99.57, AUPR_OUT: 99.50\n",
      "CCR: 75.61, 84.23, 92.80, 97.72, ACC: 98.65\n",
      "──────────────────────────────────────────────────────────────────────\n",
      "Time taken to train: 50.21369981765747\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{0: {'dataset': 'mnist',\n",
       "  'FPR@95': '1.50',\n",
       "  'AUROC': '99.40',\n",
       "  'AUPR_IN': '99.50',\n",
       "  'AUPR_OUT': '99.28',\n",
       "  'CCR_4': '66.49',\n",
       "  'CCR_3': '83.34',\n",
       "  'CCR_2': '93.16',\n",
       "  'CCR_1': '97.26',\n",
       "  'ACC': '98.21',\n",
       "  'optimizer_type': 'SGD',\n",
       "  'activation_function_type': 'relu',\n",
       "  'postprocessor_type': 'odin',\n",
       "  'time_taken': 51.51332950592041},\n",
       " 1: {'dataset': 'mnist',\n",
       "  'FPR@95': '1.03',\n",
       "  'AUROC': '99.62',\n",
       "  'AUPR_IN': '99.66',\n",
       "  'AUPR_OUT': '99.58',\n",
       "  'CCR_4': '49.92',\n",
       "  'CCR_3': '86.67',\n",
       "  'CCR_2': '94.39',\n",
       "  'CCR_1': '97.63',\n",
       "  'ACC': '98.19',\n",
       "  'optimizer_type': 'SGD',\n",
       "  'activation_function_type': 'relu',\n",
       "  'postprocessor_type': 'odin',\n",
       "  'time_taken': 49.472259759902954},\n",
       " 2: {'dataset': 'mnist',\n",
       "  'FPR@95': '1.75',\n",
       "  'AUROC': '99.52',\n",
       "  'AUPR_IN': '99.57',\n",
       "  'AUPR_OUT': '99.50',\n",
       "  'CCR_4': '75.61',\n",
       "  'CCR_3': '84.23',\n",
       "  'CCR_2': '92.80',\n",
       "  'CCR_1': '97.72',\n",
       "  'ACC': '98.65',\n",
       "  'optimizer_type': 'SGD',\n",
       "  'activation_function_type': 'relu',\n",
       "  'postprocessor_type': 'odin',\n",
       "  'time_taken': 50.21369981765747}}"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "config_1a = {\n",
    "    \"batch_size\": 128,\n",
    "    \"n_classes\": 10,\n",
    "    \"dataset_name\": \"mnist\",\n",
    "    \"epochs\": 10,\n",
    "    \"version\": time.time(),\n",
    "    \"lr\": 0.1,\n",
    "    \"momentum\": 0.9,\n",
    "    \"weight_decay\": 0.0005,\n",
    "    \"optimizer_type\": \"SGD\",\n",
    "    \"activation_function_type\": \"relu\",\n",
    "    \"network\": \"lenet\",\n",
    "    \"postprocessor_type\": \"odin\",\n",
    "    \"dataset_type\": \"mnist\",\n",
    "    \"trials\": 3,\n",
    "    \"results_dir\": \"mnist-study\"\n",
    "}\n",
    "config_1a[\"data_loaders\"] = get_data_loaders(config_1a)\n",
    "run_full_oodn_pipeline(config_1a)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e36392b7",
   "metadata": {},
   "source": [
    "#### MCD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "71e60745",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running model: models/mnist_lenet_mcd_relu_SGD_0.pkl...\n",
      "Getting optimizer for type: SGD...\n",
      "Training epoch: 0\n",
      "idx: 0, loss: 2.3041369915008545, time taken: 0.00941777229309082\n",
      "idx: 100, loss: 0.29034051299095154, time taken: 1.01137375831604\n",
      "idx: 200, loss: 0.20892561972141266, time taken: 0.9974749088287354\n",
      "idx: 300, loss: 0.14768998324871063, time taken: 1.005979061126709\n",
      "idx: 400, loss: 0.3825826942920685, time taken: 1.0021300315856934\n",
      "Time take for epoch 0: 4.716005086898804s\n",
      "Training epoch: 1\n",
      "idx: 0, loss: 0.07344602048397064, time taken: 0.00898289680480957\n",
      "idx: 100, loss: 0.10576103627681732, time taken: 0.9942357540130615\n",
      "idx: 200, loss: 0.18464992940425873, time taken: 1.0064194202423096\n",
      "idx: 300, loss: 0.0687417984008789, time taken: 1.0503413677215576\n",
      "idx: 400, loss: 0.24697965383529663, time taken: 1.0413062572479248\n",
      "Time take for epoch 1: 4.8107500076293945s\n",
      "Training epoch: 2\n",
      "idx: 0, loss: 0.08865907043218613, time taken: 0.009688138961791992\n",
      "idx: 100, loss: 0.0706261619925499, time taken: 1.0047221183776855\n",
      "idx: 200, loss: 0.26074501872062683, time taken: 0.9910509586334229\n",
      "idx: 300, loss: 0.08340514451265335, time taken: 0.9929964542388916\n",
      "idx: 400, loss: 0.1182161346077919, time taken: 1.0163745880126953\n",
      "Time take for epoch 2: 4.689857244491577s\n",
      "Training epoch: 3\n",
      "idx: 0, loss: 0.060739267617464066, time taken: 0.009727001190185547\n",
      "idx: 100, loss: 0.08447759598493576, time taken: 1.0391592979431152\n",
      "idx: 200, loss: 0.16440367698669434, time taken: 1.0119624137878418\n",
      "idx: 300, loss: 0.09581610560417175, time taken: 1.0046687126159668\n",
      "idx: 400, loss: 0.16522613167762756, time taken: 1.0011951923370361\n",
      "Time take for epoch 3: 4.746786117553711s\n",
      "Training epoch: 4\n",
      "idx: 0, loss: 0.04552454501390457, time taken: 0.008965730667114258\n",
      "idx: 100, loss: 0.06214326247572899, time taken: 0.9907243251800537\n",
      "idx: 200, loss: 0.10879217088222504, time taken: 0.9959702491760254\n",
      "idx: 300, loss: 0.06304524093866348, time taken: 1.0236968994140625\n",
      "idx: 400, loss: 0.1476980447769165, time taken: 0.9841549396514893\n",
      "Time take for epoch 4: 4.671355724334717s\n",
      "Training epoch: 5\n",
      "idx: 0, loss: 0.050103809684515, time taken: 0.009180307388305664\n",
      "idx: 100, loss: 0.04726562276482582, time taken: 0.9916532039642334\n",
      "idx: 200, loss: 0.10125682502985, time taken: 0.9939069747924805\n",
      "idx: 300, loss: 0.0811016783118248, time taken: 0.9887619018554688\n",
      "idx: 400, loss: 0.07547200471162796, time taken: 0.9851181507110596\n",
      "Time take for epoch 5: 4.638615846633911s\n",
      "Training epoch: 6\n",
      "idx: 0, loss: 0.03562828153371811, time taken: 0.009050130844116211\n",
      "idx: 100, loss: 0.05274980515241623, time taken: 0.9957625865936279\n",
      "idx: 200, loss: 0.12332993000745773, time taken: 0.9797508716583252\n",
      "idx: 300, loss: 0.03609403595328331, time taken: 1.0246996879577637\n",
      "idx: 400, loss: 0.09607242047786713, time taken: 1.0107834339141846\n",
      "Time take for epoch 6: 4.72369122505188s\n",
      "Training epoch: 7\n",
      "idx: 0, loss: 0.059667717665433884, time taken: 0.009649515151977539\n",
      "idx: 100, loss: 0.04185529053211212, time taken: 1.0145821571350098\n",
      "idx: 200, loss: 0.13730241358280182, time taken: 1.2203752994537354\n",
      "idx: 300, loss: 0.06307603418827057, time taken: 1.0260982513427734\n",
      "idx: 400, loss: 0.1819206327199936, time taken: 0.9992060661315918\n",
      "Time take for epoch 7: 4.956271171569824s\n",
      "Training epoch: 8\n",
      "idx: 0, loss: 0.040903206914663315, time taken: 0.00896906852722168\n",
      "idx: 100, loss: 0.039715126156806946, time taken: 1.0227289199829102\n",
      "idx: 200, loss: 0.1154390275478363, time taken: 1.0054824352264404\n",
      "idx: 300, loss: 0.06974901258945465, time taken: 0.9963293075561523\n",
      "idx: 400, loss: 0.04791165515780449, time taken: 1.014854907989502\n",
      "Time take for epoch 8: 4.731198310852051s\n",
      "Training epoch: 9\n",
      "idx: 0, loss: 0.03254089131951332, time taken: 0.009807109832763672\n",
      "idx: 100, loss: 0.041444823145866394, time taken: 1.0110886096954346\n",
      "idx: 200, loss: 0.16466765105724335, time taken: 0.9971256256103516\n",
      "idx: 300, loss: 0.10916856676340103, time taken: 1.0000247955322266\n",
      "idx: 400, loss: 0.12952709197998047, time taken: 1.0161306858062744\n",
      "Time take for epoch 9: 4.709523677825928s\n",
      "Performing inference on batch: 0\n",
      "Performing inference on batch: 50\n",
      "Performing inference on batch: 0\n",
      "Performing inference on batch: 50\n",
      "FPR@95: 5.48, AUROC: 98.82 AUPR_IN: 98.97, AUPR_OUT: 98.73\n",
      "CCR: 26.89, 72.35, 87.60, 94.91, ACC: 96.99\n",
      "──────────────────────────────────────────────────────────────────────\n",
      "Time taken to train: 50.958593130111694\n",
      "Running model: models/mnist_lenet_mcd_relu_SGD_1.pkl...\n",
      "Getting optimizer for type: SGD...\n",
      "Training epoch: 0\n",
      "idx: 0, loss: 2.2982118129730225, time taken: 0.008742809295654297\n",
      "idx: 100, loss: 0.7419594526290894, time taken: 1.0003416538238525\n",
      "idx: 200, loss: 0.330139696598053, time taken: 1.016183614730835\n",
      "idx: 300, loss: 0.19903966784477234, time taken: 1.0494487285614014\n",
      "idx: 400, loss: 0.5874232053756714, time taken: 1.043241262435913\n",
      "Time take for epoch 0: 4.792780160903931s\n",
      "Training epoch: 1\n",
      "idx: 0, loss: 0.15947048366069794, time taken: 0.009422540664672852\n",
      "idx: 100, loss: 0.33172184228897095, time taken: 1.0003795623779297\n",
      "idx: 200, loss: 0.2816339433193207, time taken: 0.9926128387451172\n",
      "idx: 300, loss: 0.20618608593940735, time taken: 1.004260778427124\n",
      "idx: 400, loss: 0.24270832538604736, time taken: 1.0174503326416016\n",
      "Time take for epoch 1: 4.703640699386597s\n",
      "Training epoch: 2\n",
      "idx: 0, loss: 0.3481810688972473, time taken: 0.009188175201416016\n",
      "idx: 100, loss: 0.10855314135551453, time taken: 0.9962916374206543\n",
      "idx: 200, loss: 0.17024804651737213, time taken: 1.0043153762817383\n",
      "idx: 300, loss: 0.15885619819164276, time taken: 1.0073654651641846\n",
      "idx: 400, loss: 0.2711435854434967, time taken: 1.010115146636963\n",
      "Time take for epoch 2: 4.712214946746826s\n",
      "Training epoch: 3\n",
      "idx: 0, loss: 0.16618475317955017, time taken: 0.009375810623168945\n",
      "idx: 100, loss: 0.08696489036083221, time taken: 1.0030860900878906\n",
      "idx: 200, loss: 0.18935348093509674, time taken: 1.0060322284698486\n",
      "idx: 300, loss: 0.09539098292589188, time taken: 1.0044958591461182\n",
      "idx: 400, loss: 0.1847437620162964, time taken: 0.9992873668670654\n",
      "Time take for epoch 3: 4.706406593322754s\n",
      "Training epoch: 4\n",
      "idx: 0, loss: 0.1091507077217102, time taken: 0.008896350860595703\n",
      "idx: 100, loss: 0.13795319199562073, time taken: 0.9977560043334961\n",
      "idx: 200, loss: 0.14318379759788513, time taken: 1.0064888000488281\n",
      "idx: 300, loss: 0.10115236043930054, time taken: 1.0211601257324219\n",
      "idx: 400, loss: 0.14441925287246704, time taken: 1.009843111038208\n",
      "Time take for epoch 4: 4.7348268032073975s\n",
      "Training epoch: 5\n",
      "idx: 0, loss: 0.17711332440376282, time taken: 0.009534358978271484\n",
      "idx: 100, loss: 0.09921887516975403, time taken: 1.034740686416626\n",
      "idx: 200, loss: 0.16225163638591766, time taken: 0.9969959259033203\n",
      "idx: 300, loss: 0.11890403181314468, time taken: 1.030501127243042\n",
      "idx: 400, loss: 0.18114182353019714, time taken: 0.9911971092224121\n",
      "Time take for epoch 5: 4.7462098598480225s\n",
      "Training epoch: 6\n",
      "idx: 0, loss: 0.07720202207565308, time taken: 0.009076118469238281\n",
      "idx: 100, loss: 0.11965497583150864, time taken: 0.9932992458343506\n",
      "idx: 200, loss: 0.1526094675064087, time taken: 1.000180721282959\n",
      "idx: 300, loss: 0.12090858072042465, time taken: 1.0164375305175781\n",
      "idx: 400, loss: 0.1918843686580658, time taken: 1.0039286613464355\n",
      "Time take for epoch 6: 4.701024770736694s\n",
      "Training epoch: 7\n",
      "idx: 0, loss: 0.10043404251337051, time taken: 0.009041547775268555\n",
      "idx: 100, loss: 0.15860319137573242, time taken: 0.9847214221954346\n",
      "idx: 200, loss: 0.1576113998889923, time taken: 0.9742910861968994\n",
      "idx: 300, loss: 0.10466307401657104, time taken: 0.9916150569915771\n",
      "idx: 400, loss: 0.15032652020454407, time taken: 0.9915461540222168\n",
      "Time take for epoch 7: 4.629768371582031s\n",
      "Training epoch: 8\n",
      "idx: 0, loss: 0.05879759043455124, time taken: 0.009119033813476562\n",
      "idx: 100, loss: 0.09468381106853485, time taken: 0.9807987213134766\n",
      "idx: 200, loss: 0.10919985920190811, time taken: 1.0018997192382812\n",
      "idx: 300, loss: 0.10764040052890778, time taken: 1.0016365051269531\n",
      "idx: 400, loss: 0.16545972228050232, time taken: 0.9832444190979004\n",
      "Time take for epoch 8: 4.674202919006348s\n",
      "Training epoch: 9\n",
      "idx: 0, loss: 0.11468976736068726, time taken: 0.00934147834777832\n",
      "idx: 100, loss: 0.13418006896972656, time taken: 1.2106125354766846\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "idx: 200, loss: 0.14070814847946167, time taken: 0.9845829010009766\n",
      "idx: 300, loss: 0.10133273154497147, time taken: 0.9909062385559082\n",
      "idx: 400, loss: 0.18348412215709686, time taken: 0.9801931381225586\n",
      "Time take for epoch 9: 4.841415166854858s\n",
      "Performing inference on batch: 0\n",
      "Performing inference on batch: 50\n",
      "Performing inference on batch: 0\n",
      "Performing inference on batch: 50\n",
      "FPR@95: 23.99, AUROC: 95.97 AUPR_IN: 96.42, AUPR_OUT: 95.47\n",
      "CCR: 13.00, 34.59, 61.43, 89.24, ACC: 96.47\n",
      "──────────────────────────────────────────────────────────────────────\n",
      "Time taken to train: 50.79097890853882\n",
      "Running model: models/mnist_lenet_mcd_relu_SGD_2.pkl...\n",
      "Getting optimizer for type: SGD...\n",
      "Training epoch: 0\n",
      "idx: 0, loss: 2.3208749294281006, time taken: 0.009003639221191406\n",
      "idx: 100, loss: 0.6104536652565002, time taken: 1.0265252590179443\n",
      "idx: 200, loss: 0.17620675265789032, time taken: 1.0480754375457764\n",
      "idx: 300, loss: 0.12093239277601242, time taken: 0.9974884986877441\n",
      "idx: 400, loss: 0.24563606083393097, time taken: 1.1505250930786133\n",
      "Time take for epoch 0: 4.996403694152832s\n",
      "Training epoch: 1\n",
      "idx: 0, loss: 0.2080029547214508, time taken: 0.009032726287841797\n",
      "idx: 100, loss: 0.07916489988565445, time taken: 1.031846284866333\n",
      "idx: 200, loss: 0.135910764336586, time taken: 1.0491442680358887\n",
      "idx: 300, loss: 0.10365460067987442, time taken: 1.029691219329834\n",
      "idx: 400, loss: 0.23116089403629303, time taken: 1.0258533954620361\n",
      "Time take for epoch 1: 4.821695804595947s\n",
      "Training epoch: 2\n",
      "idx: 0, loss: 0.07135152071714401, time taken: 0.009102106094360352\n",
      "idx: 100, loss: 0.05966610088944435, time taken: 1.0253980159759521\n",
      "idx: 200, loss: 0.10910923779010773, time taken: 1.041792392730713\n",
      "idx: 300, loss: 0.08128083497285843, time taken: 1.0476360321044922\n",
      "idx: 400, loss: 0.15734520554542542, time taken: 1.010296106338501\n",
      "Time take for epoch 2: 4.8198301792144775s\n",
      "Training epoch: 3\n",
      "idx: 0, loss: 0.07176803797483444, time taken: 0.009599685668945312\n",
      "idx: 100, loss: 0.06500428915023804, time taken: 0.9960763454437256\n",
      "idx: 200, loss: 0.08629955351352692, time taken: 0.9847152233123779\n",
      "idx: 300, loss: 0.06682882457971573, time taken: 1.0032477378845215\n",
      "idx: 400, loss: 0.16669102013111115, time taken: 0.9998352527618408\n",
      "Time take for epoch 3: 4.703782320022583s\n",
      "Training epoch: 4\n",
      "idx: 0, loss: 0.10136667639017105, time taken: 0.009722471237182617\n",
      "idx: 100, loss: 0.035333842039108276, time taken: 0.9964151382446289\n",
      "idx: 200, loss: 0.09713870286941528, time taken: 1.007704257965088\n",
      "idx: 300, loss: 0.05116375908255577, time taken: 0.9922904968261719\n",
      "idx: 400, loss: 0.0986693948507309, time taken: 0.986405611038208\n",
      "Time take for epoch 4: 4.672602653503418s\n",
      "Training epoch: 5\n",
      "idx: 0, loss: 0.05479830130934715, time taken: 0.009151935577392578\n",
      "idx: 100, loss: 0.07016253471374512, time taken: 0.983497142791748\n",
      "idx: 200, loss: 0.08110329508781433, time taken: 0.9960117340087891\n",
      "idx: 300, loss: 0.06005286052823067, time taken: 0.9929714202880859\n",
      "idx: 400, loss: 0.10070104151964188, time taken: 0.9948115348815918\n",
      "Time take for epoch 5: 4.646003007888794s\n",
      "Training epoch: 6\n",
      "idx: 0, loss: 0.07213635742664337, time taken: 0.009323358535766602\n",
      "idx: 100, loss: 0.02246425300836563, time taken: 1.0018811225891113\n",
      "idx: 200, loss: 0.08220282196998596, time taken: 0.9815387725830078\n",
      "idx: 300, loss: 0.07710301876068115, time taken: 1.009052038192749\n",
      "idx: 400, loss: 0.10751806944608688, time taken: 0.9934487342834473\n",
      "Time take for epoch 6: 4.702998876571655s\n",
      "Training epoch: 7\n",
      "idx: 0, loss: 0.08098721504211426, time taken: 0.009157657623291016\n",
      "idx: 100, loss: 0.0358700193464756, time taken: 1.0580472946166992\n",
      "idx: 200, loss: 0.03578488156199455, time taken: 1.0288395881652832\n",
      "idx: 300, loss: 0.05719683691859245, time taken: 1.0267627239227295\n",
      "idx: 400, loss: 0.063088558614254, time taken: 1.0471422672271729\n",
      "Time take for epoch 7: 4.870668649673462s\n",
      "Training epoch: 8\n",
      "idx: 0, loss: 0.07880823314189911, time taken: 0.00938725471496582\n",
      "idx: 100, loss: 0.04678482189774513, time taken: 1.1004693508148193\n",
      "idx: 200, loss: 0.10265877097845078, time taken: 1.2350099086761475\n",
      "idx: 300, loss: 0.06759775429964066, time taken: 1.043877124786377\n",
      "idx: 400, loss: 0.12904340028762817, time taken: 1.0740039348602295\n",
      "Time take for epoch 8: 5.186415672302246s\n",
      "Training epoch: 9\n",
      "idx: 0, loss: 0.0591156929731369, time taken: 0.015931129455566406\n",
      "idx: 100, loss: 0.03353649750351906, time taken: 1.2637526988983154\n",
      "idx: 200, loss: 0.04883585497736931, time taken: 1.32192063331604\n",
      "idx: 300, loss: 0.04679430276155472, time taken: 1.1537225246429443\n",
      "idx: 400, loss: 0.10794661939144135, time taken: 1.1553113460540771\n",
      "Time take for epoch 9: 5.817024230957031s\n",
      "Performing inference on batch: 0\n",
      "Performing inference on batch: 50\n",
      "Performing inference on batch: 0\n",
      "Performing inference on batch: 50\n",
      "FPR@95: 8.94, AUROC: 98.45 AUPR_IN: 98.68, AUPR_OUT: 98.26\n",
      "CCR: 61.72, 72.82, 86.09, 94.66, ACC: 97.95\n",
      "──────────────────────────────────────────────────────────────────────\n",
      "Time taken to train: 54.09544587135315\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{0: {'dataset': 'mnist',\n",
       "  'FPR@95': '5.48',\n",
       "  'AUROC': '98.82',\n",
       "  'AUPR_IN': '98.97',\n",
       "  'AUPR_OUT': '98.73',\n",
       "  'CCR_4': '26.89',\n",
       "  'CCR_3': '72.35',\n",
       "  'CCR_2': '87.60',\n",
       "  'CCR_1': '94.91',\n",
       "  'ACC': '96.99',\n",
       "  'optimizer_type': 'SGD',\n",
       "  'activation_function_type': 'relu',\n",
       "  'postprocessor_type': 'mcd',\n",
       "  'time_taken': 50.958593130111694},\n",
       " 1: {'dataset': 'mnist',\n",
       "  'FPR@95': '23.99',\n",
       "  'AUROC': '95.97',\n",
       "  'AUPR_IN': '96.42',\n",
       "  'AUPR_OUT': '95.47',\n",
       "  'CCR_4': '13.00',\n",
       "  'CCR_3': '34.59',\n",
       "  'CCR_2': '61.43',\n",
       "  'CCR_1': '89.24',\n",
       "  'ACC': '96.47',\n",
       "  'optimizer_type': 'SGD',\n",
       "  'activation_function_type': 'relu',\n",
       "  'postprocessor_type': 'mcd',\n",
       "  'time_taken': 50.79097890853882},\n",
       " 2: {'dataset': 'mnist',\n",
       "  'FPR@95': '8.94',\n",
       "  'AUROC': '98.45',\n",
       "  'AUPR_IN': '98.68',\n",
       "  'AUPR_OUT': '98.26',\n",
       "  'CCR_4': '61.72',\n",
       "  'CCR_3': '72.82',\n",
       "  'CCR_2': '86.09',\n",
       "  'CCR_1': '94.66',\n",
       "  'ACC': '97.95',\n",
       "  'optimizer_type': 'SGD',\n",
       "  'activation_function_type': 'relu',\n",
       "  'postprocessor_type': 'mcd',\n",
       "  'time_taken': 54.09544587135315}}"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "config_1_1a = {\n",
    "    \"batch_size\": 128,\n",
    "    \"n_classes\": 10,\n",
    "    \"dataset_name\": \"mnist\",\n",
    "    \"epochs\": 10,\n",
    "    \"version\": time.time(),\n",
    "    \"lr\": 0.1,\n",
    "    \"momentum\": 0.9,\n",
    "    \"weight_decay\": 0.0005,\n",
    "    \"optimizer_type\": \"SGD\",\n",
    "    \"activation_function_type\": \"relu\",\n",
    "    \"network\": \"lenet\",\n",
    "    \"postprocessor_type\": \"mcd\",\n",
    "    \"dataset_type\": \"mnist\",\n",
    "    \"trials\": 3,\n",
    "    \"results_dir\": \"mnist-study\"\n",
    "}\n",
    "config_1_1a[\"data_loaders\"] = get_data_loaders(config_1_1a)\n",
    "run_full_oodn_pipeline(config_1_1a)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2be2d7df",
   "metadata": {},
   "source": [
    "#### 1 (b) SGD + SoftPlus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "7a3ae7d8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running model: models/mnist_lenet_odin_softplus_SGD_0.pkl...\n",
      "Getting optimizer for type: SGD...\n",
      "Training epoch: 0\n",
      "idx: 0, loss: 2.3718485832214355, time taken: 0.009566783905029297\n",
      "idx: 100, loss: 2.3032381534576416, time taken: 1.0866444110870361\n",
      "idx: 200, loss: 1.3475463390350342, time taken: 1.063671588897705\n",
      "idx: 300, loss: 0.2671454846858978, time taken: 1.0491371154785156\n",
      "idx: 400, loss: 0.47210097312927246, time taken: 1.2400872707366943\n",
      "Time take for epoch 0: 5.3507068157196045s\n",
      "Training epoch: 1\n",
      "idx: 0, loss: 0.14156891405582428, time taken: 0.012911796569824219\n",
      "idx: 100, loss: 0.11166047304868698, time taken: 1.2283711433410645\n",
      "idx: 200, loss: 0.33546292781829834, time taken: 1.047506332397461\n",
      "idx: 300, loss: 0.06544164568185806, time taken: 1.0868539810180664\n",
      "idx: 400, loss: 0.24700260162353516, time taken: 1.0451445579528809\n",
      "Time take for epoch 1: 5.132681846618652s\n",
      "Training epoch: 2\n",
      "idx: 0, loss: 0.07973635196685791, time taken: 0.009329080581665039\n",
      "idx: 100, loss: 0.047516461461782455, time taken: 1.05692458152771\n",
      "idx: 200, loss: 0.2680935263633728, time taken: 1.0562822818756104\n",
      "idx: 300, loss: 0.046310905367136, time taken: 1.0725398063659668\n",
      "idx: 400, loss: 0.206587016582489, time taken: 1.2779903411865234\n",
      "Time take for epoch 2: 5.374783277511597s\n",
      "Training epoch: 3\n",
      "idx: 0, loss: 0.06315424293279648, time taken: 0.018217086791992188\n",
      "idx: 100, loss: 0.07217354327440262, time taken: 1.3171677589416504\n",
      "idx: 200, loss: 0.09641133248806, time taken: 1.3364708423614502\n",
      "idx: 300, loss: 0.04748924821615219, time taken: 1.167220115661621\n",
      "idx: 400, loss: 0.1522851437330246, time taken: 1.0518546104431152\n",
      "Time take for epoch 3: 5.620758771896362s\n",
      "Training epoch: 4\n",
      "idx: 0, loss: 0.045252878218889236, time taken: 0.00984048843383789\n",
      "idx: 100, loss: 0.02430090680718422, time taken: 1.1018028259277344\n",
      "idx: 200, loss: 0.16488617658615112, time taken: 1.0281500816345215\n",
      "idx: 300, loss: 0.04082592576742172, time taken: 1.0953056812286377\n",
      "idx: 400, loss: 0.2482348531484604, time taken: 1.1694183349609375\n",
      "Time take for epoch 4: 5.178961992263794s\n",
      "Training epoch: 5\n",
      "idx: 0, loss: 0.05079498887062073, time taken: 0.010886430740356445\n",
      "idx: 100, loss: 0.025997759774327278, time taken: 1.0454583168029785\n",
      "idx: 200, loss: 0.15315495431423187, time taken: 1.054943561553955\n",
      "idx: 300, loss: 0.04065771773457527, time taken: 1.0507049560546875\n",
      "idx: 400, loss: 0.14576131105422974, time taken: 1.0836353302001953\n",
      "Time take for epoch 5: 4.9932966232299805s\n",
      "Training epoch: 6\n",
      "idx: 0, loss: 0.03602186590433121, time taken: 0.01163029670715332\n",
      "idx: 100, loss: 0.01239548809826374, time taken: 1.1087307929992676\n",
      "idx: 200, loss: 0.07643686980009079, time taken: 1.065359115600586\n",
      "idx: 300, loss: 0.07212039828300476, time taken: 1.0803723335266113\n",
      "idx: 400, loss: 0.1385122686624527, time taken: 1.0449841022491455\n",
      "Time take for epoch 6: 5.036241769790649s\n",
      "Training epoch: 7\n",
      "idx: 0, loss: 0.033216994255781174, time taken: 0.01135706901550293\n",
      "idx: 100, loss: 0.018634552136063576, time taken: 1.0898468494415283\n",
      "idx: 200, loss: 0.12247557193040848, time taken: 1.1628329753875732\n",
      "idx: 300, loss: 0.09797687083482742, time taken: 1.054016351699829\n",
      "idx: 400, loss: 0.07541768997907639, time taken: 1.0645263195037842\n",
      "Time take for epoch 7: 5.103020429611206s\n",
      "Training epoch: 8\n",
      "idx: 0, loss: 0.029875604435801506, time taken: 0.013155460357666016\n",
      "idx: 100, loss: 0.029363123700022697, time taken: 1.0691683292388916\n",
      "idx: 200, loss: 0.12458733469247818, time taken: 1.1835346221923828\n",
      "idx: 300, loss: 0.06333673000335693, time taken: 1.014158010482788\n",
      "idx: 400, loss: 0.1722574383020401, time taken: 0.9930596351623535\n",
      "Time take for epoch 8: 4.95343279838562s\n",
      "Training epoch: 9\n",
      "idx: 0, loss: 0.026022983714938164, time taken: 0.009230375289916992\n",
      "idx: 100, loss: 0.01716633327305317, time taken: 0.9650490283966064\n",
      "idx: 200, loss: 0.08099397271871567, time taken: 0.9733519554138184\n",
      "idx: 300, loss: 0.06037792190909386, time taken: 0.9742677211761475\n",
      "idx: 400, loss: 0.11014973372220993, time taken: 0.9784102439880371\n",
      "Time take for epoch 9: 4.5717644691467285s\n",
      "Performing inference on batch: 0\n",
      "Performing inference on batch: 50\n",
      "Performing inference on batch: 0\n",
      "Performing inference on batch: 50\n",
      "FPR@95: 3.65, AUROC: 99.17 AUPR_IN: 99.19, AUPR_OUT: 99.17\n",
      "CCR: 37.85, 54.76, 86.31, 97.47, ACC: 98.33\n",
      "──────────────────────────────────────────────────────────────────────\n",
      "Time taken to train: 53.89000749588013\n",
      "Running model: models/mnist_lenet_odin_softplus_SGD_1.pkl...\n",
      "Getting optimizer for type: SGD...\n",
      "Training epoch: 0\n",
      "idx: 0, loss: 2.485910177230835, time taken: 0.011248588562011719\n",
      "idx: 100, loss: 2.3065903186798096, time taken: 1.081498622894287\n",
      "idx: 200, loss: 2.296354293823242, time taken: 1.0617427825927734\n",
      "idx: 300, loss: 2.3809759616851807, time taken: 1.0889461040496826\n",
      "idx: 400, loss: 2.2298293113708496, time taken: 1.3485395908355713\n",
      "Time take for epoch 0: 5.297257900238037s\n",
      "Training epoch: 1\n",
      "idx: 0, loss: 1.7675480842590332, time taken: 0.009394168853759766\n",
      "idx: 100, loss: 1.640271782875061, time taken: 1.0933618545532227\n",
      "idx: 200, loss: 0.8755995631217957, time taken: 1.1102192401885986\n",
      "idx: 300, loss: 0.25831398367881775, time taken: 1.040839672088623\n",
      "idx: 400, loss: 0.3290415406227112, time taken: 1.0349721908569336\n",
      "Time take for epoch 1: 5.07728123664856s\n",
      "Training epoch: 2\n",
      "idx: 0, loss: 0.11368101090192795, time taken: 0.013830423355102539\n",
      "idx: 100, loss: 0.08361818641424179, time taken: 1.0495679378509521\n",
      "idx: 200, loss: 0.17459556460380554, time taken: 1.055863380432129\n",
      "idx: 300, loss: 0.09624876081943512, time taken: 1.0612995624542236\n",
      "idx: 400, loss: 0.21240122616291046, time taken: 1.080916166305542\n",
      "Time take for epoch 2: 4.97877836227417s\n",
      "Training epoch: 3\n",
      "idx: 0, loss: 0.025721777230501175, time taken: 0.010039806365966797\n",
      "idx: 100, loss: 0.10342545807361603, time taken: 1.0646231174468994\n",
      "idx: 200, loss: 0.14237186312675476, time taken: 1.0598247051239014\n",
      "idx: 300, loss: 0.07141023129224777, time taken: 1.055413007736206\n",
      "idx: 400, loss: 0.21063828468322754, time taken: 1.050652265548706\n",
      "Time take for epoch 3: 4.956762075424194s\n",
      "Training epoch: 4\n",
      "idx: 0, loss: 0.026125775650143623, time taken: 0.009914636611938477\n",
      "idx: 100, loss: 0.16294538974761963, time taken: 1.0777459144592285\n",
      "idx: 200, loss: 0.07693613320589066, time taken: 1.0696971416473389\n",
      "idx: 300, loss: 0.08155865222215652, time taken: 1.0527045726776123\n",
      "idx: 400, loss: 0.16609959304332733, time taken: 1.0772361755371094\n",
      "Time take for epoch 4: 5.1574387550354s\n",
      "Training epoch: 5\n",
      "idx: 0, loss: 0.0318424254655838, time taken: 0.021788597106933594\n",
      "idx: 100, loss: 0.18256613612174988, time taken: 1.088798999786377\n",
      "idx: 200, loss: 0.09595579653978348, time taken: 1.084547519683838\n",
      "idx: 300, loss: 0.08582703024148941, time taken: 1.0699481964111328\n",
      "idx: 400, loss: 0.16103969514369965, time taken: 1.0595173835754395\n",
      "Time take for epoch 5: 5.040771961212158s\n",
      "Training epoch: 6\n",
      "idx: 0, loss: 0.029948770999908447, time taken: 0.010319232940673828\n",
      "idx: 100, loss: 0.06233922019600868, time taken: 1.0657567977905273\n",
      "idx: 200, loss: 0.10132429748773575, time taken: 1.204472303390503\n",
      "idx: 300, loss: 0.07786613702774048, time taken: 1.3366668224334717\n",
      "idx: 400, loss: 0.19442865252494812, time taken: 1.2768964767456055\n",
      "Time take for epoch 6: 5.834607124328613s\n",
      "Training epoch: 7\n",
      "idx: 0, loss: 0.02042458765208721, time taken: 0.013709545135498047\n",
      "idx: 100, loss: 0.06974192708730698, time taken: 1.3031413555145264\n",
      "idx: 200, loss: 0.08719547837972641, time taken: 1.2358496189117432\n",
      "idx: 300, loss: 0.032935548573732376, time taken: 1.0713109970092773\n",
      "idx: 400, loss: 0.2512189745903015, time taken: 1.070864200592041\n",
      "Time take for epoch 7: 5.423027992248535s\n",
      "Training epoch: 8\n",
      "idx: 0, loss: 0.006883048918098211, time taken: 0.010192394256591797\n",
      "idx: 100, loss: 0.0689195841550827, time taken: 1.0658042430877686\n",
      "idx: 200, loss: 0.09708932042121887, time taken: 1.1179537773132324\n",
      "idx: 300, loss: 0.03641544282436371, time taken: 1.0796825885772705\n",
      "idx: 400, loss: 0.20128105580806732, time taken: 1.075732946395874\n",
      "Time take for epoch 8: 5.069478750228882s\n",
      "Training epoch: 9\n",
      "idx: 0, loss: 0.027135994285345078, time taken: 0.009669780731201172\n",
      "idx: 100, loss: 0.06381283700466156, time taken: 1.0631768703460693\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "idx: 200, loss: 0.06157349422574043, time taken: 1.336702585220337\n",
      "idx: 300, loss: 0.03858104720711708, time taken: 1.3417222499847412\n",
      "idx: 400, loss: 0.13049939274787903, time taken: 1.291152000427246\n",
      "Time take for epoch 9: 5.840482950210571s\n",
      "Performing inference on batch: 0\n",
      "Performing inference on batch: 50\n",
      "Performing inference on batch: 0\n",
      "Performing inference on batch: 50\n",
      "FPR@95: 4.65, AUROC: 98.65 AUPR_IN: 98.95, AUPR_OUT: 98.14\n",
      "CCR: 36.44, 71.84, 88.73, 95.84, ACC: 97.92\n",
      "──────────────────────────────────────────────────────────────────────\n",
      "Time taken to train: 55.54051423072815\n",
      "Running model: models/mnist_lenet_odin_softplus_SGD_2.pkl...\n",
      "Getting optimizer for type: SGD...\n",
      "Training epoch: 0\n",
      "idx: 0, loss: 2.3162033557891846, time taken: 0.015664100646972656\n",
      "idx: 100, loss: 2.3032705783843994, time taken: 1.138742208480835\n",
      "idx: 200, loss: 0.510703980922699, time taken: 1.0561707019805908\n",
      "idx: 300, loss: 0.4456235468387604, time taken: 1.0522348880767822\n",
      "idx: 400, loss: 0.5848256945610046, time taken: 1.0489938259124756\n",
      "Time take for epoch 0: 5.02325177192688s\n",
      "Training epoch: 1\n",
      "idx: 0, loss: 0.21165819466114044, time taken: 0.012309789657592773\n",
      "idx: 100, loss: 0.13048934936523438, time taken: 1.0641679763793945\n",
      "idx: 200, loss: 0.13106751441955566, time taken: 1.0828754901885986\n",
      "idx: 300, loss: 0.10422917455434799, time taken: 1.3144071102142334\n",
      "idx: 400, loss: 0.34030789136886597, time taken: 1.0807135105133057\n",
      "Time take for epoch 1: 5.278249025344849s\n",
      "Training epoch: 2\n",
      "idx: 0, loss: 0.07805874198675156, time taken: 0.009738683700561523\n",
      "idx: 100, loss: 0.09590020030736923, time taken: 1.1066968441009521\n",
      "idx: 200, loss: 0.09074850380420685, time taken: 1.293452501296997\n",
      "idx: 300, loss: 0.09388863295316696, time taken: 1.216428279876709\n",
      "idx: 400, loss: 0.22904275357723236, time taken: 1.0680146217346191\n",
      "Time take for epoch 2: 5.45076322555542s\n",
      "Training epoch: 3\n",
      "idx: 0, loss: 0.07490842044353485, time taken: 0.010114192962646484\n",
      "idx: 100, loss: 0.0434226430952549, time taken: 1.056999683380127\n",
      "idx: 200, loss: 0.06498557329177856, time taken: 1.079991340637207\n",
      "idx: 300, loss: 0.06664586812257767, time taken: 1.2852697372436523\n",
      "idx: 400, loss: 0.21727241575717926, time taken: 1.3362605571746826\n",
      "Time take for epoch 3: 5.653520822525024s\n",
      "Training epoch: 4\n",
      "idx: 0, loss: 0.06774332374334335, time taken: 0.014635086059570312\n",
      "idx: 100, loss: 0.032969217747449875, time taken: 1.3097879886627197\n",
      "idx: 200, loss: 0.07476970553398132, time taken: 1.3208236694335938\n",
      "idx: 300, loss: 0.07329531013965607, time taken: 1.331655502319336\n",
      "idx: 400, loss: 0.21035709977149963, time taken: 1.1805307865142822\n",
      "Time take for epoch 4: 5.865634441375732s\n",
      "Training epoch: 5\n",
      "idx: 0, loss: 0.04862802475690842, time taken: 0.009897232055664062\n",
      "idx: 100, loss: 0.014076201245188713, time taken: 1.044673204421997\n",
      "idx: 200, loss: 0.0957689881324768, time taken: 1.0396592617034912\n",
      "idx: 300, loss: 0.10424455255270004, time taken: 1.0660631656646729\n",
      "idx: 400, loss: 0.182607501745224, time taken: 1.0669779777526855\n",
      "Time take for epoch 5: 5.010422945022583s\n",
      "Training epoch: 6\n",
      "idx: 0, loss: 0.0469132736325264, time taken: 0.014118432998657227\n",
      "idx: 100, loss: 0.05217732861638069, time taken: 1.0556108951568604\n",
      "idx: 200, loss: 0.0881020575761795, time taken: 1.0458087921142578\n",
      "idx: 300, loss: 0.05599663034081459, time taken: 1.0493826866149902\n",
      "idx: 400, loss: 0.18311381340026855, time taken: 1.057676076889038\n",
      "Time take for epoch 6: 4.952686786651611s\n",
      "Training epoch: 7\n",
      "idx: 0, loss: 0.06315305829048157, time taken: 0.010595560073852539\n",
      "idx: 100, loss: 0.07837142795324326, time taken: 1.2386536598205566\n",
      "idx: 200, loss: 0.0653412789106369, time taken: 1.2886788845062256\n",
      "idx: 300, loss: 0.05502217262983322, time taken: 1.3533554077148438\n",
      "idx: 400, loss: 0.15611915290355682, time taken: 1.125748634338379\n",
      "Time take for epoch 7: 5.731707572937012s\n",
      "Training epoch: 8\n",
      "idx: 0, loss: 0.09199672937393188, time taken: 0.011933326721191406\n",
      "idx: 100, loss: 0.06205188110470772, time taken: 1.0697460174560547\n",
      "idx: 200, loss: 0.04847751185297966, time taken: 1.0638580322265625\n",
      "idx: 300, loss: 0.055322300642728806, time taken: 1.0607857704162598\n",
      "idx: 400, loss: 0.14161363244056702, time taken: 1.061244249343872\n",
      "Time take for epoch 8: 5.022045135498047s\n",
      "Training epoch: 9\n",
      "idx: 0, loss: 0.07679781317710876, time taken: 0.012587308883666992\n",
      "idx: 100, loss: 0.03758250176906586, time taken: 1.104875087738037\n",
      "idx: 200, loss: 0.04559096321463585, time taken: 1.0630688667297363\n",
      "idx: 300, loss: 0.07569067925214767, time taken: 1.0673274993896484\n",
      "idx: 400, loss: 0.1950414478778839, time taken: 1.0711472034454346\n",
      "Time take for epoch 9: 5.0542097091674805s\n",
      "Performing inference on batch: 0\n",
      "Performing inference on batch: 50\n",
      "Performing inference on batch: 0\n",
      "Performing inference on batch: 50\n",
      "FPR@95: 3.61, AUROC: 99.23 AUPR_IN: 99.30, AUPR_OUT: 99.19\n",
      "CCR: 35.25, 75.29, 89.49, 97.23, ACC: 98.51\n",
      "──────────────────────────────────────────────────────────────────────\n",
      "Time taken to train: 55.76370978355408\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{0: {'dataset': 'mnist',\n",
       "  'FPR@95': '3.65',\n",
       "  'AUROC': '99.17',\n",
       "  'AUPR_IN': '99.19',\n",
       "  'AUPR_OUT': '99.17',\n",
       "  'CCR_4': '37.85',\n",
       "  'CCR_3': '54.76',\n",
       "  'CCR_2': '86.31',\n",
       "  'CCR_1': '97.47',\n",
       "  'ACC': '98.33',\n",
       "  'optimizer_type': 'SGD',\n",
       "  'activation_function_type': 'softplus',\n",
       "  'postprocessor_type': 'odin',\n",
       "  'time_taken': 53.89000749588013},\n",
       " 1: {'dataset': 'mnist',\n",
       "  'FPR@95': '4.65',\n",
       "  'AUROC': '98.65',\n",
       "  'AUPR_IN': '98.95',\n",
       "  'AUPR_OUT': '98.14',\n",
       "  'CCR_4': '36.44',\n",
       "  'CCR_3': '71.84',\n",
       "  'CCR_2': '88.73',\n",
       "  'CCR_1': '95.84',\n",
       "  'ACC': '97.92',\n",
       "  'optimizer_type': 'SGD',\n",
       "  'activation_function_type': 'softplus',\n",
       "  'postprocessor_type': 'odin',\n",
       "  'time_taken': 55.54051423072815},\n",
       " 2: {'dataset': 'mnist',\n",
       "  'FPR@95': '3.61',\n",
       "  'AUROC': '99.23',\n",
       "  'AUPR_IN': '99.30',\n",
       "  'AUPR_OUT': '99.19',\n",
       "  'CCR_4': '35.25',\n",
       "  'CCR_3': '75.29',\n",
       "  'CCR_2': '89.49',\n",
       "  'CCR_1': '97.23',\n",
       "  'ACC': '98.51',\n",
       "  'optimizer_type': 'SGD',\n",
       "  'activation_function_type': 'softplus',\n",
       "  'postprocessor_type': 'odin',\n",
       "  'time_taken': 55.76370978355408}}"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "config_1b = {\n",
    "    \"batch_size\": 128,\n",
    "    \"dataset_name\": \"mnist\",\n",
    "    \"n_classes\": 10,\n",
    "    \"epochs\": 10,\n",
    "    \"version\": time.time(),\n",
    "    \"lr\": 0.1,\n",
    "    \"momentum\": 0.9,\n",
    "    \"weight_decay\": 0.0005,\n",
    "    \"optimizer_type\": \"SGD\",\n",
    "    \"activation_function_type\": \"softplus\",\n",
    "    \"network\": \"lenet\",\n",
    "    \"postprocessor_type\": \"odin\",\n",
    "    \"dataset_type\": \"mnist\",\n",
    "    \"trials\": 3,\n",
    "    \"results_dir\": \"mnist-study\"\n",
    "}\n",
    "config_1b[\"data_loaders\"] = get_data_loaders(config_1b)\n",
    "run_full_oodn_pipeline(config_1b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "5bbc028e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running model: models/mnist_lenet_mcd_softplus_SGD_0.pkl...\n",
      "Getting optimizer for type: SGD...\n",
      "Training epoch: 0\n",
      "idx: 0, loss: 2.3969497680664062, time taken: 0.02117300033569336\n",
      "idx: 100, loss: 2.305872678756714, time taken: 1.0806331634521484\n",
      "idx: 200, loss: 2.323749542236328, time taken: 1.059751033782959\n",
      "idx: 300, loss: 2.2967991828918457, time taken: 1.0730648040771484\n",
      "idx: 400, loss: 1.9109351634979248, time taken: 1.0473692417144775\n",
      "Time take for epoch 0: 5.007572650909424s\n",
      "Training epoch: 1\n",
      "idx: 0, loss: 1.2711639404296875, time taken: 0.011802911758422852\n",
      "idx: 100, loss: 0.3356267809867859, time taken: 1.0962979793548584\n",
      "idx: 200, loss: 0.39382028579711914, time taken: 1.0523560047149658\n",
      "idx: 300, loss: 0.37495359778404236, time taken: 1.0539612770080566\n",
      "idx: 400, loss: 0.4912671148777008, time taken: 1.0574727058410645\n",
      "Time take for epoch 1: 4.9890546798706055s\n",
      "Training epoch: 2\n",
      "idx: 0, loss: 0.23660379648208618, time taken: 0.011170148849487305\n",
      "idx: 100, loss: 0.30767905712127686, time taken: 1.0645010471343994\n",
      "idx: 200, loss: 0.2598818242549896, time taken: 1.0610287189483643\n",
      "idx: 300, loss: 0.24907514452934265, time taken: 1.393293857574463\n",
      "idx: 400, loss: 0.24625535309314728, time taken: 1.074728012084961\n",
      "Time take for epoch 2: 5.339649438858032s\n",
      "Training epoch: 3\n",
      "idx: 0, loss: 0.1717141717672348, time taken: 0.012433528900146484\n",
      "idx: 100, loss: 0.20421670377254486, time taken: 1.070880651473999\n",
      "idx: 200, loss: 0.20682694017887115, time taken: 1.0477030277252197\n",
      "idx: 300, loss: 0.18192878365516663, time taken: 1.0836570262908936\n",
      "idx: 400, loss: 0.29441356658935547, time taken: 1.0635955333709717\n",
      "Time take for epoch 3: 5.001251935958862s\n",
      "Training epoch: 4\n",
      "idx: 0, loss: 0.15706461668014526, time taken: 0.009379386901855469\n",
      "idx: 100, loss: 0.1466410607099533, time taken: 1.067082405090332\n",
      "idx: 200, loss: 0.17382274568080902, time taken: 1.0680713653564453\n",
      "idx: 300, loss: 0.20359160006046295, time taken: 1.0700936317443848\n",
      "idx: 400, loss: 0.2975619435310364, time taken: 1.0515315532684326\n",
      "Time take for epoch 4: 4.982125759124756s\n",
      "Training epoch: 5\n",
      "idx: 0, loss: 0.11882290244102478, time taken: 0.009512662887573242\n",
      "idx: 100, loss: 0.14211533963680267, time taken: 1.158372402191162\n",
      "idx: 200, loss: 0.13669288158416748, time taken: 1.0444250106811523\n",
      "idx: 300, loss: 0.08808769285678864, time taken: 1.0450520515441895\n",
      "idx: 400, loss: 0.29607993364334106, time taken: 1.092543363571167\n",
      "Time take for epoch 5: 5.064460039138794s\n",
      "Training epoch: 6\n",
      "idx: 0, loss: 0.09363461285829544, time taken: 0.009649276733398438\n",
      "idx: 100, loss: 0.06664043664932251, time taken: 1.052170753479004\n",
      "idx: 200, loss: 0.10270502418279648, time taken: 1.051903486251831\n",
      "idx: 300, loss: 0.05112843215465546, time taken: 1.0513889789581299\n",
      "idx: 400, loss: 0.1868545114994049, time taken: 1.0617012977600098\n",
      "Time take for epoch 6: 4.963625192642212s\n",
      "Training epoch: 7\n",
      "idx: 0, loss: 0.08043403923511505, time taken: 0.011635780334472656\n",
      "idx: 100, loss: 0.04094359651207924, time taken: 1.0842220783233643\n",
      "idx: 200, loss: 0.15312419831752777, time taken: 1.0444505214691162\n",
      "idx: 300, loss: 0.0658315047621727, time taken: 1.0557398796081543\n",
      "idx: 400, loss: 0.19640488922595978, time taken: 1.0491061210632324\n",
      "Time take for epoch 7: 4.946086883544922s\n",
      "Training epoch: 8\n",
      "idx: 0, loss: 0.06648483127355576, time taken: 0.009428024291992188\n",
      "idx: 100, loss: 0.06297049671411514, time taken: 1.0457780361175537\n",
      "idx: 200, loss: 0.1579483449459076, time taken: 1.0483038425445557\n",
      "idx: 300, loss: 0.06409698724746704, time taken: 1.1745812892913818\n",
      "idx: 400, loss: 0.22496967017650604, time taken: 1.3605005741119385\n",
      "Time take for epoch 8: 5.545400142669678s\n",
      "Training epoch: 9\n",
      "idx: 0, loss: 0.04097229614853859, time taken: 0.017330169677734375\n",
      "idx: 100, loss: 0.15983469784259796, time taken: 1.3417274951934814\n",
      "idx: 200, loss: 0.10620072484016418, time taken: 1.3040180206298828\n",
      "idx: 300, loss: 0.0736018717288971, time taken: 1.3276023864746094\n",
      "idx: 400, loss: 0.14318062365055084, time taken: 1.3271312713623047\n",
      "Time take for epoch 9: 6.197656631469727s\n",
      "Performing inference on batch: 0\n",
      "Performing inference on batch: 50\n",
      "Performing inference on batch: 0\n",
      "Performing inference on batch: 50\n",
      "FPR@95: 9.90, AUROC: 98.29 AUPR_IN: 98.55, AUPR_OUT: 98.08\n",
      "CCR: 43.40, 70.02, 85.26, 94.45, ACC: 97.86\n",
      "──────────────────────────────────────────────────────────────────────\n",
      "Time taken to train: 56.9134042263031\n",
      "Running model: models/mnist_lenet_mcd_softplus_SGD_1.pkl...\n",
      "Getting optimizer for type: SGD...\n",
      "Training epoch: 0\n",
      "idx: 0, loss: 2.3919575214385986, time taken: 0.012823820114135742\n",
      "idx: 100, loss: 2.305671215057373, time taken: 1.1027121543884277\n",
      "idx: 200, loss: 0.9358437061309814, time taken: 1.1286985874176025\n",
      "idx: 300, loss: 0.29378610849380493, time taken: 1.161006212234497\n",
      "idx: 400, loss: 0.5334318280220032, time taken: 1.0835819244384766\n",
      "Time take for epoch 0: 5.205881834030151s\n",
      "Training epoch: 1\n",
      "idx: 0, loss: 0.13425253331661224, time taken: 0.009290456771850586\n",
      "idx: 100, loss: 0.07242722064256668, time taken: 1.0649445056915283\n",
      "idx: 200, loss: 0.17424632608890533, time taken: 1.0506343841552734\n",
      "idx: 300, loss: 0.08123446255922318, time taken: 1.1149787902832031\n",
      "idx: 400, loss: 0.2715674340724945, time taken: 1.0927367210388184\n",
      "Time take for epoch 1: 5.2380852699279785s\n",
      "Training epoch: 2\n",
      "idx: 0, loss: 0.07530363649129868, time taken: 0.013076305389404297\n",
      "idx: 100, loss: 0.06102530285716057, time taken: 1.0985190868377686\n",
      "idx: 200, loss: 0.0805448591709137, time taken: 1.0889403820037842\n",
      "idx: 300, loss: 0.07914400100708008, time taken: 1.060401201248169\n",
      "idx: 400, loss: 0.23077665269374847, time taken: 1.0817346572875977\n",
      "Time take for epoch 2: 5.359443187713623s\n",
      "Training epoch: 3\n",
      "idx: 0, loss: 0.06124433875083923, time taken: 0.016726016998291016\n",
      "idx: 100, loss: 0.023440426215529442, time taken: 1.121748447418213\n",
      "idx: 200, loss: 0.07074989378452301, time taken: 1.0973029136657715\n",
      "idx: 300, loss: 0.06546042114496231, time taken: 1.064147710800171\n",
      "idx: 400, loss: 0.13236895203590393, time taken: 1.0617973804473877\n",
      "Time take for epoch 3: 5.090071201324463s\n",
      "Training epoch: 4\n",
      "idx: 0, loss: 0.07854172587394714, time taken: 0.009517192840576172\n",
      "idx: 100, loss: 0.051801182329654694, time taken: 1.0502583980560303\n",
      "idx: 200, loss: 0.08128493279218674, time taken: 1.0557146072387695\n",
      "idx: 300, loss: 0.08340577036142349, time taken: 1.069145917892456\n",
      "idx: 400, loss: 0.09793420881032944, time taken: 1.1460928916931152\n",
      "Time take for epoch 4: 5.223106861114502s\n",
      "Training epoch: 5\n",
      "idx: 0, loss: 0.06621333956718445, time taken: 0.01721978187561035\n",
      "idx: 100, loss: 0.037724848836660385, time taken: 1.0850865840911865\n",
      "idx: 200, loss: 0.04889687895774841, time taken: 1.0561044216156006\n",
      "idx: 300, loss: 0.054901063442230225, time taken: 1.0357918739318848\n",
      "idx: 400, loss: 0.11358534544706345, time taken: 1.063779592514038\n",
      "Time take for epoch 5: 4.974135160446167s\n",
      "Training epoch: 6\n",
      "idx: 0, loss: 0.05553784593939781, time taken: 0.009934663772583008\n",
      "idx: 100, loss: 0.032118961215019226, time taken: 1.0429418087005615\n",
      "idx: 200, loss: 0.06504775583744049, time taken: 1.0471994876861572\n",
      "idx: 300, loss: 0.07128974050283432, time taken: 1.0462138652801514\n",
      "idx: 400, loss: 0.247439444065094, time taken: 1.043921947479248\n",
      "Time take for epoch 6: 4.897234678268433s\n",
      "Training epoch: 7\n",
      "idx: 0, loss: 0.050619155168533325, time taken: 0.009341955184936523\n",
      "idx: 100, loss: 0.07409985363483429, time taken: 1.1082179546356201\n",
      "idx: 200, loss: 0.06096353381872177, time taken: 1.0616190433502197\n",
      "idx: 300, loss: 0.04307084158062935, time taken: 1.0542571544647217\n",
      "idx: 400, loss: 0.08412246406078339, time taken: 1.0524461269378662\n",
      "Time take for epoch 7: 4.999792814254761s\n",
      "Training epoch: 8\n",
      "idx: 0, loss: 0.04414694383740425, time taken: 0.010909318923950195\n",
      "idx: 100, loss: 0.0547577403485775, time taken: 1.0625698566436768\n",
      "idx: 200, loss: 0.05851538106799126, time taken: 1.047081470489502\n",
      "idx: 300, loss: 0.050620365887880325, time taken: 1.0724372863769531\n",
      "idx: 400, loss: 0.1272404044866562, time taken: 1.0431029796600342\n",
      "Time take for epoch 8: 4.955788850784302s\n",
      "Training epoch: 9\n",
      "idx: 0, loss: 0.031800415366888046, time taken: 0.01129150390625\n",
      "idx: 100, loss: 0.045250020921230316, time taken: 1.0472404956817627\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "idx: 200, loss: 0.07735861092805862, time taken: 1.0630450248718262\n",
      "idx: 300, loss: 0.06182503327727318, time taken: 1.0735399723052979\n",
      "idx: 400, loss: 0.11808710545301437, time taken: 1.064002513885498\n",
      "Time take for epoch 9: 4.9802563190460205s\n",
      "Performing inference on batch: 0\n",
      "Performing inference on batch: 50\n",
      "Performing inference on batch: 0\n",
      "Performing inference on batch: 50\n",
      "FPR@95: 7.12, AUROC: 98.30 AUPR_IN: 98.70, AUPR_OUT: 97.81\n",
      "CCR: 48.13, 77.56, 90.23, 95.28, ACC: 98.12\n",
      "──────────────────────────────────────────────────────────────────────\n",
      "Time taken to train: 55.63301873207092\n",
      "Running model: models/mnist_lenet_mcd_softplus_SGD_2.pkl...\n",
      "Getting optimizer for type: SGD...\n",
      "Training epoch: 0\n",
      "idx: 0, loss: 2.3448333740234375, time taken: 0.011051654815673828\n",
      "idx: 100, loss: 2.305781841278076, time taken: 1.0472984313964844\n",
      "idx: 200, loss: 2.319713592529297, time taken: 1.0453503131866455\n",
      "idx: 300, loss: 1.990025281906128, time taken: 1.083644151687622\n",
      "idx: 400, loss: 1.0800501108169556, time taken: 1.0559751987457275\n",
      "Time take for epoch 0: 4.964121580123901s\n",
      "Training epoch: 1\n",
      "idx: 0, loss: 0.8380609750747681, time taken: 0.009874820709228516\n",
      "idx: 100, loss: 0.254711389541626, time taken: 1.0638160705566406\n",
      "idx: 200, loss: 0.1138918325304985, time taken: 1.1545283794403076\n",
      "idx: 300, loss: 0.13850025832653046, time taken: 1.0494904518127441\n",
      "idx: 400, loss: 0.2546302080154419, time taken: 1.068082332611084\n",
      "Time take for epoch 1: 5.064705848693848s\n",
      "Training epoch: 2\n",
      "idx: 0, loss: 0.08100854605436325, time taken: 0.00990605354309082\n",
      "idx: 100, loss: 0.06598460674285889, time taken: 1.2304842472076416\n",
      "idx: 200, loss: 0.11813616007566452, time taken: 1.209761381149292\n",
      "idx: 300, loss: 0.12134986370801926, time taken: 1.0647084712982178\n",
      "idx: 400, loss: 0.23983992636203766, time taken: 1.0594077110290527\n",
      "Time take for epoch 2: 5.30210280418396s\n",
      "Training epoch: 3\n",
      "idx: 0, loss: 0.061188552528619766, time taken: 0.013785362243652344\n",
      "idx: 100, loss: 0.09643968194723129, time taken: 1.0777778625488281\n",
      "idx: 200, loss: 0.15059660375118256, time taken: 1.1085801124572754\n",
      "idx: 300, loss: 0.07703109085559845, time taken: 1.060908555984497\n",
      "idx: 400, loss: 0.19481460750102997, time taken: 1.095550775527954\n",
      "Time take for epoch 3: 5.2609336376190186s\n",
      "Training epoch: 4\n",
      "idx: 0, loss: 0.03560173884034157, time taken: 0.01955723762512207\n",
      "idx: 100, loss: 0.06315944343805313, time taken: 1.1711320877075195\n",
      "idx: 200, loss: 0.142313614487648, time taken: 1.044645071029663\n",
      "idx: 300, loss: 0.039643097668886185, time taken: 1.114454746246338\n",
      "idx: 400, loss: 0.15767401456832886, time taken: 1.0616886615753174\n",
      "Time take for epoch 4: 5.198042392730713s\n",
      "Training epoch: 5\n",
      "idx: 0, loss: 0.08237773180007935, time taken: 0.011774063110351562\n",
      "idx: 100, loss: 0.04615570604801178, time taken: 1.1251862049102783\n",
      "idx: 200, loss: 0.1826252043247223, time taken: 1.0645687580108643\n",
      "idx: 300, loss: 0.048981595784425735, time taken: 1.070009469985962\n",
      "idx: 400, loss: 0.10932709276676178, time taken: 1.0734760761260986\n",
      "Time take for epoch 5: 5.092198133468628s\n",
      "Training epoch: 6\n",
      "idx: 0, loss: 0.03466300666332245, time taken: 0.011321783065795898\n",
      "idx: 100, loss: 0.05183758959174156, time taken: 1.0705616474151611\n",
      "idx: 200, loss: 0.1388167291879654, time taken: 1.06880784034729\n",
      "idx: 300, loss: 0.041149865835905075, time taken: 1.1903948783874512\n",
      "idx: 400, loss: 0.21452032029628754, time taken: 1.2355947494506836\n",
      "Time take for epoch 6: 5.290019273757935s\n",
      "Training epoch: 7\n",
      "idx: 0, loss: 0.10821998119354248, time taken: 0.009441614151000977\n",
      "idx: 100, loss: 0.045770641416311264, time taken: 1.0712401866912842\n",
      "idx: 200, loss: 0.12684226036071777, time taken: 1.0699803829193115\n",
      "idx: 300, loss: 0.057996973395347595, time taken: 1.0640168190002441\n",
      "idx: 400, loss: 0.16464658081531525, time taken: 1.0657978057861328\n",
      "Time take for epoch 7: 5.0217790603637695s\n",
      "Training epoch: 8\n",
      "idx: 0, loss: 0.06988276541233063, time taken: 0.010753393173217773\n",
      "idx: 100, loss: 0.048577409237623215, time taken: 1.1440355777740479\n",
      "idx: 200, loss: 0.07950565963983536, time taken: 1.1131467819213867\n",
      "idx: 300, loss: 0.046482063829898834, time taken: 1.0907411575317383\n",
      "idx: 400, loss: 0.1528930962085724, time taken: 1.070216178894043\n",
      "Time take for epoch 8: 5.1825432777404785s\n",
      "Training epoch: 9\n",
      "idx: 0, loss: 0.035846028476953506, time taken: 0.010750532150268555\n",
      "idx: 100, loss: 0.023366060107946396, time taken: 1.301922082901001\n",
      "idx: 200, loss: 0.11599274724721909, time taken: 1.0843265056610107\n",
      "idx: 300, loss: 0.0375945046544075, time taken: 1.0705945491790771\n",
      "idx: 400, loss: 0.13637036085128784, time taken: 1.0930416584014893\n",
      "Time take for epoch 9: 5.300848007202148s\n",
      "Performing inference on batch: 0\n",
      "Performing inference on batch: 50\n",
      "Performing inference on batch: 0\n",
      "Performing inference on batch: 50\n",
      "FPR@95: 25.25, AUROC: 96.59 AUPR_IN: 97.55, AUPR_OUT: 95.23\n",
      "CCR: 39.79, 75.68, 85.35, 92.15, ACC: 98.27\n",
      "──────────────────────────────────────────────────────────────────────\n",
      "Time taken to train: 56.323583126068115\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{0: {'dataset': 'mnist',\n",
       "  'FPR@95': '9.90',\n",
       "  'AUROC': '98.29',\n",
       "  'AUPR_IN': '98.55',\n",
       "  'AUPR_OUT': '98.08',\n",
       "  'CCR_4': '43.40',\n",
       "  'CCR_3': '70.02',\n",
       "  'CCR_2': '85.26',\n",
       "  'CCR_1': '94.45',\n",
       "  'ACC': '97.86',\n",
       "  'optimizer_type': 'SGD',\n",
       "  'activation_function_type': 'softplus',\n",
       "  'postprocessor_type': 'mcd',\n",
       "  'time_taken': 56.9134042263031},\n",
       " 1: {'dataset': 'mnist',\n",
       "  'FPR@95': '7.12',\n",
       "  'AUROC': '98.30',\n",
       "  'AUPR_IN': '98.70',\n",
       "  'AUPR_OUT': '97.81',\n",
       "  'CCR_4': '48.13',\n",
       "  'CCR_3': '77.56',\n",
       "  'CCR_2': '90.23',\n",
       "  'CCR_1': '95.28',\n",
       "  'ACC': '98.12',\n",
       "  'optimizer_type': 'SGD',\n",
       "  'activation_function_type': 'softplus',\n",
       "  'postprocessor_type': 'mcd',\n",
       "  'time_taken': 55.63301873207092},\n",
       " 2: {'dataset': 'mnist',\n",
       "  'FPR@95': '25.25',\n",
       "  'AUROC': '96.59',\n",
       "  'AUPR_IN': '97.55',\n",
       "  'AUPR_OUT': '95.23',\n",
       "  'CCR_4': '39.79',\n",
       "  'CCR_3': '75.68',\n",
       "  'CCR_2': '85.35',\n",
       "  'CCR_1': '92.15',\n",
       "  'ACC': '98.27',\n",
       "  'optimizer_type': 'SGD',\n",
       "  'activation_function_type': 'softplus',\n",
       "  'postprocessor_type': 'mcd',\n",
       "  'time_taken': 56.323583126068115}}"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "config_1_1b = {\n",
    "    \"batch_size\": 128,\n",
    "    \"dataset_name\": \"mnist\",\n",
    "    \"n_classes\": 10,\n",
    "    \"epochs\": 10,\n",
    "    \"version\": time.time(),\n",
    "    \"lr\": 0.1,\n",
    "    \"momentum\": 0.9,\n",
    "    \"weight_decay\": 0.0005,\n",
    "    \"optimizer_type\": \"SGD\",\n",
    "    \"activation_function_type\": \"softplus\",\n",
    "    \"network\": \"lenet\",\n",
    "    \"postprocessor_type\": \"mcd\",\n",
    "    \"dataset_type\": \"mnist\",\n",
    "    \"trials\": 3,\n",
    "    \"results_dir\": \"mnist-study\"\n",
    "}\n",
    "config_1_1b[\"data_loaders\"] = get_data_loaders(config_1_1b)\n",
    "run_full_oodn_pipeline(config_1_1b)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "966af048",
   "metadata": {},
   "source": [
    "#### 1(c) Adam + ReLU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "38bf5903",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running model: models/mnist_lenet_odin_relu_Adam_0.pkl...\n",
      "Getting optimizer for type: Adam...\n",
      "Training epoch: 0\n",
      "idx: 0, loss: 2.302553653717041, time taken: 0.013901472091674805\n",
      "idx: 100, loss: 0.28000783920288086, time taken: 1.118457555770874\n",
      "idx: 200, loss: 0.1414969563484192, time taken: 1.1110692024230957\n",
      "idx: 300, loss: 0.12729781866073608, time taken: 1.127894401550293\n",
      "idx: 400, loss: 0.29341307282447815, time taken: 1.1033143997192383\n",
      "Time take for epoch 0: 5.232776880264282s\n",
      "Training epoch: 1\n",
      "idx: 0, loss: 0.1049453392624855, time taken: 0.011766672134399414\n",
      "idx: 100, loss: 0.05889567360281944, time taken: 1.1290693283081055\n",
      "idx: 200, loss: 0.1544564962387085, time taken: 1.1138193607330322\n",
      "idx: 300, loss: 0.09296706318855286, time taken: 1.092811107635498\n",
      "idx: 400, loss: 0.20761510729789734, time taken: 1.0934405326843262\n",
      "Time take for epoch 1: 5.198179483413696s\n",
      "Training epoch: 2\n",
      "idx: 0, loss: 0.04594803601503372, time taken: 0.013196229934692383\n",
      "idx: 100, loss: 0.04202667623758316, time taken: 1.1355535984039307\n",
      "idx: 200, loss: 0.13392935693264008, time taken: 1.1060514450073242\n",
      "idx: 300, loss: 0.0417325496673584, time taken: 1.0868237018585205\n",
      "idx: 400, loss: 0.1274029016494751, time taken: 1.1060700416564941\n",
      "Time take for epoch 2: 5.196915626525879s\n",
      "Training epoch: 3\n",
      "idx: 0, loss: 0.08632521331310272, time taken: 0.012001752853393555\n",
      "idx: 100, loss: 0.028527643531560898, time taken: 1.1117208003997803\n",
      "idx: 200, loss: 0.10381894558668137, time taken: 1.1133008003234863\n",
      "idx: 300, loss: 0.05073969066143036, time taken: 1.116687536239624\n",
      "idx: 400, loss: 0.12204297631978989, time taken: 1.1038341522216797\n",
      "Time take for epoch 3: 5.364858865737915s\n",
      "Training epoch: 4\n",
      "idx: 0, loss: 0.10758497565984726, time taken: 0.010168790817260742\n",
      "idx: 100, loss: 0.02613360434770584, time taken: 1.4093518257141113\n",
      "idx: 200, loss: 0.07273299992084503, time taken: 1.4165239334106445\n",
      "idx: 300, loss: 0.046473048627376556, time taken: 1.288686990737915\n",
      "idx: 400, loss: 0.12196499109268188, time taken: 1.097407341003418\n",
      "Time take for epoch 4: 6.132319211959839s\n",
      "Training epoch: 5\n",
      "idx: 0, loss: 0.08595336228609085, time taken: 0.009595632553100586\n",
      "idx: 100, loss: 0.018451476469635963, time taken: 1.3772249221801758\n",
      "idx: 200, loss: 0.11805732548236847, time taken: 1.362133502960205\n",
      "idx: 300, loss: 0.03506774827837944, time taken: 1.2505121231079102\n",
      "idx: 400, loss: 0.08583956211805344, time taken: 1.0928456783294678\n",
      "Time take for epoch 5: 5.8601179122924805s\n",
      "Training epoch: 6\n",
      "idx: 0, loss: 0.016947640106081963, time taken: 0.011985301971435547\n",
      "idx: 100, loss: 0.013713524676859379, time taken: 1.2863759994506836\n",
      "idx: 200, loss: 0.11128868907690048, time taken: 1.3896832466125488\n",
      "idx: 300, loss: 0.03311679884791374, time taken: 1.3487727642059326\n",
      "idx: 400, loss: 0.07502143830060959, time taken: 1.4710371494293213\n",
      "Time take for epoch 6: 6.4573633670806885s\n",
      "Training epoch: 7\n",
      "idx: 0, loss: 0.04358570650219917, time taken: 0.012918710708618164\n",
      "idx: 100, loss: 0.03707094490528107, time taken: 1.3659663200378418\n",
      "idx: 200, loss: 0.11662014573812485, time taken: 1.3128557205200195\n",
      "idx: 300, loss: 0.05676758661866188, time taken: 1.1003694534301758\n",
      "idx: 400, loss: 0.07589571923017502, time taken: 1.0856966972351074\n",
      "Time take for epoch 7: 5.618765830993652s\n",
      "Training epoch: 8\n",
      "idx: 0, loss: 0.05877657234668732, time taken: 0.009356975555419922\n",
      "idx: 100, loss: 0.028693977743387222, time taken: 1.1065449714660645\n",
      "idx: 200, loss: 0.10296013951301575, time taken: 1.1007113456726074\n",
      "idx: 300, loss: 0.03694705665111542, time taken: 1.1168363094329834\n",
      "idx: 400, loss: 0.0994354709982872, time taken: 1.0990660190582275\n",
      "Time take for epoch 8: 5.215447187423706s\n",
      "Training epoch: 9\n",
      "idx: 0, loss: 0.032057587057352066, time taken: 0.01309657096862793\n",
      "idx: 100, loss: 0.06358659267425537, time taken: 1.240844964981079\n",
      "idx: 200, loss: 0.08912256360054016, time taken: 1.4023005962371826\n",
      "idx: 300, loss: 0.039534252136945724, time taken: 1.229424238204956\n",
      "idx: 400, loss: 0.05826161429286003, time taken: 1.0977237224578857\n",
      "Time take for epoch 9: 5.723612308502197s\n",
      "Performing inference on batch: 0\n",
      "Performing inference on batch: 50\n",
      "Performing inference on batch: 0\n",
      "Performing inference on batch: 50\n",
      "FPR@95: 1.75, AUROC: 99.29 AUPR_IN: 99.40, AUPR_OUT: 99.17\n",
      "CCR: 55.04, 84.44, 92.46, 96.19, ACC: 97.44\n",
      "──────────────────────────────────────────────────────────────────────\n",
      "Time taken to train: 58.74810719490051\n",
      "Running model: models/mnist_lenet_odin_relu_Adam_1.pkl...\n",
      "Getting optimizer for type: Adam...\n",
      "Training epoch: 0\n",
      "idx: 0, loss: 2.3053081035614014, time taken: 0.017969846725463867\n",
      "idx: 100, loss: 0.1521642804145813, time taken: 1.1170098781585693\n",
      "idx: 200, loss: 0.21540535986423492, time taken: 1.2608389854431152\n",
      "idx: 300, loss: 0.12174132466316223, time taken: 1.100127935409546\n",
      "idx: 400, loss: 0.340687096118927, time taken: 1.1494503021240234\n",
      "Time take for epoch 0: 5.404627799987793s\n",
      "Training epoch: 1\n",
      "idx: 0, loss: 0.039897311478853226, time taken: 0.010095596313476562\n",
      "idx: 100, loss: 0.06220478564500809, time taken: 1.1125802993774414\n",
      "idx: 200, loss: 0.08059768378734589, time taken: 1.101071834564209\n",
      "idx: 300, loss: 0.12902776896953583, time taken: 1.1268086433410645\n",
      "idx: 400, loss: 0.1861957460641861, time taken: 1.1304638385772705\n",
      "Time take for epoch 1: 5.266712427139282s\n",
      "Training epoch: 2\n",
      "idx: 0, loss: 0.08022233098745346, time taken: 0.01265859603881836\n",
      "idx: 100, loss: 0.09841696172952652, time taken: 1.1210992336273193\n",
      "idx: 200, loss: 0.10783915966749191, time taken: 1.1713101863861084\n",
      "idx: 300, loss: 0.09193764626979828, time taken: 1.1637892723083496\n",
      "idx: 400, loss: 0.12056498974561691, time taken: 1.1437506675720215\n",
      "Time take for epoch 2: 5.382466554641724s\n",
      "Training epoch: 3\n",
      "idx: 0, loss: 0.030350562185049057, time taken: 0.01298069953918457\n",
      "idx: 100, loss: 0.058744072914123535, time taken: 1.1276538372039795\n",
      "idx: 200, loss: 0.08068069070577621, time taken: 1.1761054992675781\n",
      "idx: 300, loss: 0.07990734279155731, time taken: 1.1188983917236328\n",
      "idx: 400, loss: 0.17577771842479706, time taken: 1.148158073425293\n",
      "Time take for epoch 3: 5.347843647003174s\n",
      "Training epoch: 4\n",
      "idx: 0, loss: 0.02357957884669304, time taken: 0.010654449462890625\n",
      "idx: 100, loss: 0.0993649959564209, time taken: 1.1272971630096436\n",
      "idx: 200, loss: 0.0839671716094017, time taken: 1.1222281455993652\n",
      "idx: 300, loss: 0.0685104951262474, time taken: 1.407630205154419\n",
      "idx: 400, loss: 0.14268246293067932, time taken: 1.152189016342163\n",
      "Time take for epoch 4: 5.564712762832642s\n",
      "Training epoch: 5\n",
      "idx: 0, loss: 0.05127750337123871, time taken: 0.013815641403198242\n",
      "idx: 100, loss: 0.051465101540088654, time taken: 1.0964770317077637\n",
      "idx: 200, loss: 0.09792902320623398, time taken: 1.0962300300598145\n",
      "idx: 300, loss: 0.048007141798734665, time taken: 1.083411455154419\n",
      "idx: 400, loss: 0.06965220719575882, time taken: 1.1308019161224365\n",
      "Time take for epoch 5: 5.158711194992065s\n",
      "Training epoch: 6\n",
      "idx: 0, loss: 0.039880070835351944, time taken: 0.01150822639465332\n",
      "idx: 100, loss: 0.0430414117872715, time taken: 1.1023967266082764\n",
      "idx: 200, loss: 0.11195671558380127, time taken: 1.1077673435211182\n",
      "idx: 300, loss: 0.07988642901182175, time taken: 1.1416070461273193\n",
      "idx: 400, loss: 0.13715749979019165, time taken: 1.1202070713043213\n",
      "Time take for epoch 6: 5.381370544433594s\n",
      "Training epoch: 7\n",
      "idx: 0, loss: 0.010989150032401085, time taken: 0.016101837158203125\n",
      "idx: 100, loss: 0.032658789306879044, time taken: 1.1453723907470703\n",
      "idx: 200, loss: 0.0675697922706604, time taken: 1.0865483283996582\n",
      "idx: 300, loss: 0.07755331695079803, time taken: 1.0905671119689941\n",
      "idx: 400, loss: 0.12721970677375793, time taken: 1.10060715675354\n",
      "Time take for epoch 7: 5.194313287734985s\n",
      "Training epoch: 8\n",
      "idx: 0, loss: 0.04913616180419922, time taken: 0.012476921081542969\n",
      "idx: 100, loss: 0.06101008132100105, time taken: 1.0963220596313477\n",
      "idx: 200, loss: 0.08748842030763626, time taken: 1.102452039718628\n",
      "idx: 300, loss: 0.07076886296272278, time taken: 1.18983793258667\n",
      "idx: 400, loss: 0.10106032341718674, time taken: 1.3093345165252686\n",
      "Time take for epoch 8: 5.50751519203186s\n",
      "Training epoch: 9\n",
      "idx: 0, loss: 0.02366366609930992, time taken: 0.012753009796142578\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "idx: 100, loss: 0.02613396756350994, time taken: 1.216752052307129\n",
      "idx: 200, loss: 0.100645512342453, time taken: 1.1088371276855469\n",
      "idx: 300, loss: 0.07560759037733078, time taken: 1.1201374530792236\n",
      "idx: 400, loss: 0.09658131748437881, time taken: 1.1147878170013428\n",
      "Time take for epoch 9: 5.325292110443115s\n",
      "Performing inference on batch: 0\n",
      "Performing inference on batch: 50\n",
      "Performing inference on batch: 0\n",
      "Performing inference on batch: 50\n",
      "FPR@95: 2.80, AUROC: 99.26 AUPR_IN: 99.32, AUPR_OUT: 99.23\n",
      "CCR: 43.84, 66.05, 89.83, 96.78, ACC: 97.88\n",
      "──────────────────────────────────────────────────────────────────────\n",
      "Time taken to train: 56.29766273498535\n",
      "Running model: models/mnist_lenet_odin_relu_Adam_2.pkl...\n",
      "Getting optimizer for type: Adam...\n",
      "Training epoch: 0\n",
      "idx: 0, loss: 2.313971996307373, time taken: 0.012202262878417969\n",
      "idx: 100, loss: 0.14131981134414673, time taken: 1.1448302268981934\n",
      "idx: 200, loss: 0.1397102177143097, time taken: 1.1313438415527344\n",
      "idx: 300, loss: 0.11277240514755249, time taken: 1.1128759384155273\n",
      "idx: 400, loss: 0.26914510130882263, time taken: 1.1065328121185303\n",
      "Time take for epoch 0: 5.278846979141235s\n",
      "Training epoch: 1\n",
      "idx: 0, loss: 0.13854439556598663, time taken: 0.009469032287597656\n",
      "idx: 100, loss: 0.07696828246116638, time taken: 1.1867451667785645\n",
      "idx: 200, loss: 0.11835090070962906, time taken: 1.2096004486083984\n",
      "idx: 300, loss: 0.07057715952396393, time taken: 1.1178169250488281\n",
      "idx: 400, loss: 0.14920642971992493, time taken: 1.0923514366149902\n",
      "Time take for epoch 1: 5.3541789054870605s\n",
      "Training epoch: 2\n",
      "idx: 0, loss: 0.04992358759045601, time taken: 0.0109710693359375\n",
      "idx: 100, loss: 0.0744747668504715, time taken: 1.108067512512207\n",
      "idx: 200, loss: 0.07523741573095322, time taken: 1.1165363788604736\n",
      "idx: 300, loss: 0.04846617579460144, time taken: 1.094196081161499\n",
      "idx: 400, loss: 0.11743192374706268, time taken: 1.0790696144104004\n",
      "Time take for epoch 2: 5.146812915802002s\n",
      "Training epoch: 3\n",
      "idx: 0, loss: 0.16689704358577728, time taken: 0.010452508926391602\n",
      "idx: 100, loss: 0.03529879078269005, time taken: 1.1332221031188965\n",
      "idx: 200, loss: 0.055891457945108414, time taken: 1.3906705379486084\n",
      "idx: 300, loss: 0.05694006383419037, time taken: 1.3760013580322266\n",
      "idx: 400, loss: 0.1802491545677185, time taken: 1.1014020442962646\n",
      "Time take for epoch 3: 5.752620220184326s\n",
      "Training epoch: 4\n",
      "idx: 0, loss: 0.055278681218624115, time taken: 0.009761333465576172\n",
      "idx: 100, loss: 0.04737916216254234, time taken: 1.0872182846069336\n",
      "idx: 200, loss: 0.09795891493558884, time taken: 1.0865938663482666\n",
      "idx: 300, loss: 0.0622219517827034, time taken: 1.0950684547424316\n",
      "idx: 400, loss: 0.14554619789123535, time taken: 1.1282403469085693\n",
      "Time take for epoch 4: 5.1706647872924805s\n",
      "Training epoch: 5\n",
      "idx: 0, loss: 0.04141220077872276, time taken: 0.011942863464355469\n",
      "idx: 100, loss: 0.03628889471292496, time taken: 1.1265785694122314\n",
      "idx: 200, loss: 0.08395592868328094, time taken: 1.2597873210906982\n",
      "idx: 300, loss: 0.059806693345308304, time taken: 1.3613708019256592\n",
      "idx: 400, loss: 0.08322370797395706, time taken: 1.103318214416504\n",
      "Time take for epoch 5: 5.61553168296814s\n",
      "Training epoch: 6\n",
      "idx: 0, loss: 0.029127594083547592, time taken: 0.013760805130004883\n",
      "idx: 100, loss: 0.049924034625291824, time taken: 1.1098339557647705\n",
      "idx: 200, loss: 0.08296371251344681, time taken: 1.1238515377044678\n",
      "idx: 300, loss: 0.06360984593629837, time taken: 1.25246262550354\n",
      "idx: 400, loss: 0.12936855852603912, time taken: 1.13621187210083\n",
      "Time take for epoch 6: 5.3846352100372314s\n",
      "Training epoch: 7\n",
      "idx: 0, loss: 0.059676144272089005, time taken: 0.009999752044677734\n",
      "idx: 100, loss: 0.011448199860751629, time taken: 1.1263477802276611\n",
      "idx: 200, loss: 0.08963467180728912, time taken: 1.1020944118499756\n",
      "idx: 300, loss: 0.059199802577495575, time taken: 1.0840637683868408\n",
      "idx: 400, loss: 0.14335080981254578, time taken: 1.0901665687561035\n",
      "Time take for epoch 7: 5.157017946243286s\n",
      "Training epoch: 8\n",
      "idx: 0, loss: 0.07791721820831299, time taken: 0.01233816146850586\n",
      "idx: 100, loss: 0.038035281002521515, time taken: 1.1003108024597168\n",
      "idx: 200, loss: 0.06547774374485016, time taken: 1.1205470561981201\n",
      "idx: 300, loss: 0.054936110973358154, time taken: 1.112081527709961\n",
      "idx: 400, loss: 0.1621597558259964, time taken: 1.0931072235107422\n",
      "Time take for epoch 8: 5.180702447891235s\n",
      "Training epoch: 9\n",
      "idx: 0, loss: 0.09285574406385422, time taken: 0.013017892837524414\n",
      "idx: 100, loss: 0.04320657253265381, time taken: 1.0984995365142822\n",
      "idx: 200, loss: 0.08956021070480347, time taken: 1.0906612873077393\n",
      "idx: 300, loss: 0.05145814269781113, time taken: 1.112865924835205\n",
      "idx: 400, loss: 0.0839906856417656, time taken: 1.181382179260254\n",
      "Time take for epoch 9: 5.251175880432129s\n",
      "Performing inference on batch: 0\n",
      "Performing inference on batch: 50\n",
      "Performing inference on batch: 0\n",
      "Performing inference on batch: 50\n",
      "FPR@95: 0.07, AUROC: 99.86 AUPR_IN: 99.88, AUPR_OUT: 99.85\n",
      "CCR: 89.81, 94.73, 97.14, 98.20, ACC: 98.39\n",
      "──────────────────────────────────────────────────────────────────────\n",
      "Time taken to train: 56.01585817337036\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{0: {'dataset': 'mnist',\n",
       "  'FPR@95': '1.75',\n",
       "  'AUROC': '99.29',\n",
       "  'AUPR_IN': '99.40',\n",
       "  'AUPR_OUT': '99.17',\n",
       "  'CCR_4': '55.04',\n",
       "  'CCR_3': '84.44',\n",
       "  'CCR_2': '92.46',\n",
       "  'CCR_1': '96.19',\n",
       "  'ACC': '97.44',\n",
       "  'optimizer_type': 'Adam',\n",
       "  'activation_function_type': 'relu',\n",
       "  'postprocessor_type': 'odin',\n",
       "  'time_taken': 58.74810719490051},\n",
       " 1: {'dataset': 'mnist',\n",
       "  'FPR@95': '2.80',\n",
       "  'AUROC': '99.26',\n",
       "  'AUPR_IN': '99.32',\n",
       "  'AUPR_OUT': '99.23',\n",
       "  'CCR_4': '43.84',\n",
       "  'CCR_3': '66.05',\n",
       "  'CCR_2': '89.83',\n",
       "  'CCR_1': '96.78',\n",
       "  'ACC': '97.88',\n",
       "  'optimizer_type': 'Adam',\n",
       "  'activation_function_type': 'relu',\n",
       "  'postprocessor_type': 'odin',\n",
       "  'time_taken': 56.29766273498535},\n",
       " 2: {'dataset': 'mnist',\n",
       "  'FPR@95': '0.07',\n",
       "  'AUROC': '99.86',\n",
       "  'AUPR_IN': '99.88',\n",
       "  'AUPR_OUT': '99.85',\n",
       "  'CCR_4': '89.81',\n",
       "  'CCR_3': '94.73',\n",
       "  'CCR_2': '97.14',\n",
       "  'CCR_1': '98.20',\n",
       "  'ACC': '98.39',\n",
       "  'optimizer_type': 'Adam',\n",
       "  'activation_function_type': 'relu',\n",
       "  'postprocessor_type': 'odin',\n",
       "  'time_taken': 56.01585817337036}}"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "config_1c = {\n",
    "    \"batch_size\": 128,\n",
    "    \"dataset_name\": \"mnist\",\n",
    "    \"n_classes\": 10,\n",
    "    \"epochs\": 10,\n",
    "    \"version\": time.time(),\n",
    "    \"lr\": 0.01,\n",
    "    \"momentum\": 0.9,\n",
    "    \"weight_decay\": 0.0005,\n",
    "    \"optimizer_type\": \"Adam\",\n",
    "    \"activation_function_type\": \"relu\",\n",
    "    \"network\": \"lenet\",\n",
    "    \"postprocessor_type\": \"odin\",\n",
    "    \"dataset_type\": \"mnist\",\n",
    "    \"trials\": 3,\n",
    "    \"results_dir\": \"mnist-study\"\n",
    "}\n",
    "config_1c[\"data_loaders\"] = get_data_loaders(config_1c)\n",
    "run_full_oodn_pipeline(config_1c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "495c8d51",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running model: models/mnist_lenet_mcd_relu_Adam_0.pkl...\n",
      "Getting optimizer for type: Adam...\n",
      "Training epoch: 0\n",
      "idx: 0, loss: 2.315467596054077, time taken: 0.01088714599609375\n",
      "idx: 100, loss: 0.18580283224582672, time taken: 1.1522655487060547\n",
      "idx: 200, loss: 0.15429630875587463, time taken: 1.0996689796447754\n",
      "idx: 300, loss: 0.09404754638671875, time taken: 1.1279420852661133\n",
      "idx: 400, loss: 0.2952556312084198, time taken: 1.1384093761444092\n",
      "Time take for epoch 0: 5.325622081756592s\n",
      "Training epoch: 1\n",
      "idx: 0, loss: 0.10620678961277008, time taken: 0.00960683822631836\n",
      "idx: 100, loss: 0.13662971556186676, time taken: 1.154064655303955\n",
      "idx: 200, loss: 0.1432105302810669, time taken: 1.110403060913086\n",
      "idx: 300, loss: 0.062432173639535904, time taken: 1.1145029067993164\n",
      "idx: 400, loss: 0.17716443538665771, time taken: 1.1192762851715088\n",
      "Time take for epoch 1: 5.3026511669158936s\n",
      "Training epoch: 2\n",
      "idx: 0, loss: 0.09528520703315735, time taken: 0.009609460830688477\n",
      "idx: 100, loss: 0.11496812850236893, time taken: 1.142845630645752\n",
      "idx: 200, loss: 0.0895601212978363, time taken: 1.1676514148712158\n",
      "idx: 300, loss: 0.08028388768434525, time taken: 1.1060206890106201\n",
      "idx: 400, loss: 0.2924489378929138, time taken: 1.1146562099456787\n",
      "Time take for epoch 2: 5.458564043045044s\n",
      "Training epoch: 3\n",
      "idx: 0, loss: 0.08727404475212097, time taken: 0.01587986946105957\n",
      "idx: 100, loss: 0.05704279616475105, time taken: 1.5027203559875488\n",
      "idx: 200, loss: 0.14698930084705353, time taken: 1.1657936573028564\n",
      "idx: 300, loss: 0.065786212682724, time taken: 1.1828680038452148\n",
      "idx: 400, loss: 0.16683946549892426, time taken: 1.0955865383148193\n",
      "Time take for epoch 3: 5.748464584350586s\n",
      "Training epoch: 4\n",
      "idx: 0, loss: 0.09677506238222122, time taken: 0.012582540512084961\n",
      "idx: 100, loss: 0.06759282946586609, time taken: 1.1834795475006104\n",
      "idx: 200, loss: 0.08016896992921829, time taken: 1.2242119312286377\n",
      "idx: 300, loss: 0.0440678596496582, time taken: 1.1246564388275146\n",
      "idx: 400, loss: 0.14797315001487732, time taken: 1.3743185997009277\n",
      "Time take for epoch 4: 5.702423334121704s\n",
      "Training epoch: 5\n",
      "idx: 0, loss: 0.08745716512203217, time taken: 0.009986162185668945\n",
      "idx: 100, loss: 0.059030380100011826, time taken: 1.2324261665344238\n",
      "idx: 200, loss: 0.08950791507959366, time taken: 1.1358649730682373\n",
      "idx: 300, loss: 0.05349355936050415, time taken: 1.2546195983886719\n",
      "idx: 400, loss: 0.2129516750574112, time taken: 1.5797767639160156\n",
      "Time take for epoch 5: 6.066587924957275s\n",
      "Training epoch: 6\n",
      "idx: 0, loss: 0.07810302078723907, time taken: 0.0131988525390625\n",
      "idx: 100, loss: 0.043011974543333054, time taken: 1.0980825424194336\n",
      "idx: 200, loss: 0.08348987996578217, time taken: 1.0992193222045898\n",
      "idx: 300, loss: 0.06311972439289093, time taken: 1.0965373516082764\n",
      "idx: 400, loss: 0.11776451021432877, time taken: 1.0884950160980225\n",
      "Time take for epoch 6: 5.1772027015686035s\n",
      "Training epoch: 7\n",
      "idx: 0, loss: 0.1239062249660492, time taken: 0.011595487594604492\n",
      "idx: 100, loss: 0.0642128586769104, time taken: 1.1143808364868164\n",
      "idx: 200, loss: 0.08174042403697968, time taken: 1.1316742897033691\n",
      "idx: 300, loss: 0.046762749552726746, time taken: 1.412480354309082\n",
      "idx: 400, loss: 0.19403530657291412, time taken: 1.2922003269195557\n",
      "Time take for epoch 7: 5.708384275436401s\n",
      "Training epoch: 8\n",
      "idx: 0, loss: 0.06337612867355347, time taken: 0.011797189712524414\n",
      "idx: 100, loss: 0.04391993209719658, time taken: 1.0505456924438477\n",
      "idx: 200, loss: 0.0599420964717865, time taken: 1.0305728912353516\n",
      "idx: 300, loss: 0.07487133145332336, time taken: 1.043989658355713\n",
      "idx: 400, loss: 0.2033865600824356, time taken: 1.0412037372589111\n",
      "Time take for epoch 8: 4.894112586975098s\n",
      "Training epoch: 9\n",
      "idx: 0, loss: 0.10149959474802017, time taken: 0.009233474731445312\n",
      "idx: 100, loss: 0.033690765500068665, time taken: 1.1291847229003906\n",
      "idx: 200, loss: 0.12202853709459305, time taken: 1.1256895065307617\n",
      "idx: 300, loss: 0.07115129381418228, time taken: 1.105137825012207\n",
      "idx: 400, loss: 0.11656516045331955, time taken: 1.1252689361572266\n",
      "Time take for epoch 9: 5.247974157333374s\n",
      "Performing inference on batch: 0\n",
      "Performing inference on batch: 50\n",
      "Performing inference on batch: 0\n",
      "Performing inference on batch: 50\n",
      "FPR@95: 9.19, AUROC: 98.21 AUPR_IN: 98.39, AUPR_OUT: 98.12\n",
      "CCR: 34.25, 49.21, 80.74, 94.50, ACC: 97.84\n",
      "──────────────────────────────────────────────────────────────────────\n",
      "Time taken to train: 59.438806772232056\n",
      "Running model: models/mnist_lenet_mcd_relu_Adam_1.pkl...\n",
      "Getting optimizer for type: Adam...\n",
      "Training epoch: 0\n",
      "idx: 0, loss: 2.2983529567718506, time taken: 0.013427972793579102\n",
      "idx: 100, loss: 0.1145375445485115, time taken: 1.281907558441162\n",
      "idx: 200, loss: 0.12730273604393005, time taken: 1.443906307220459\n",
      "idx: 300, loss: 0.11143536120653152, time taken: 1.0730626583099365\n",
      "idx: 400, loss: 0.38824209570884705, time taken: 1.1596086025238037\n",
      "Time take for epoch 0: 5.727744817733765s\n",
      "Training epoch: 1\n",
      "idx: 0, loss: 0.10639175772666931, time taken: 0.010746240615844727\n",
      "idx: 100, loss: 0.038846857845783234, time taken: 1.1380603313446045\n",
      "idx: 200, loss: 0.17871585488319397, time taken: 1.1189956665039062\n",
      "idx: 300, loss: 0.08016103506088257, time taken: 1.117110252380371\n",
      "idx: 400, loss: 0.2807046175003052, time taken: 1.1329095363616943\n",
      "Time take for epoch 1: 5.3659868240356445s\n",
      "Training epoch: 2\n",
      "idx: 0, loss: 0.10752175003290176, time taken: 0.016048192977905273\n",
      "idx: 100, loss: 0.03975518047809601, time taken: 1.4355201721191406\n",
      "idx: 200, loss: 0.0835854634642601, time taken: 1.1039323806762695\n",
      "idx: 300, loss: 0.07491190731525421, time taken: 1.288104772567749\n",
      "idx: 400, loss: 0.3269158601760864, time taken: 1.1091117858886719\n",
      "Time take for epoch 2: 5.7089033126831055s\n",
      "Training epoch: 3\n",
      "idx: 0, loss: 0.11683807522058487, time taken: 0.012843608856201172\n",
      "idx: 100, loss: 0.06248105689883232, time taken: 1.0909438133239746\n",
      "idx: 200, loss: 0.11538711190223694, time taken: 1.102510929107666\n",
      "idx: 300, loss: 0.0728488564491272, time taken: 1.1048622131347656\n",
      "idx: 400, loss: 0.13866233825683594, time taken: 1.102515459060669\n",
      "Time take for epoch 3: 5.191064119338989s\n",
      "Training epoch: 4\n",
      "idx: 0, loss: 0.08868001401424408, time taken: 0.009188175201416016\n",
      "idx: 100, loss: 0.054391391575336456, time taken: 1.2934355735778809\n",
      "idx: 200, loss: 0.0705282986164093, time taken: 1.1707849502563477\n",
      "idx: 300, loss: 0.06360819935798645, time taken: 1.239961862564087\n",
      "idx: 400, loss: 0.11091752350330353, time taken: 1.1252589225769043\n",
      "Time take for epoch 4: 5.578321218490601s\n",
      "Training epoch: 5\n",
      "idx: 0, loss: 0.0856255441904068, time taken: 0.009637117385864258\n",
      "idx: 100, loss: 0.05372149869799614, time taken: 1.0997381210327148\n",
      "idx: 200, loss: 0.03538563847541809, time taken: 1.1078002452850342\n",
      "idx: 300, loss: 0.08021878451108932, time taken: 1.1357967853546143\n",
      "idx: 400, loss: 0.1624336987733841, time taken: 1.2973637580871582\n",
      "Time take for epoch 5: 5.463717460632324s\n",
      "Training epoch: 6\n",
      "idx: 0, loss: 0.07649075984954834, time taken: 0.013106346130371094\n",
      "idx: 100, loss: 0.043611038476228714, time taken: 1.4913508892059326\n",
      "idx: 200, loss: 0.1150604635477066, time taken: 1.1093995571136475\n",
      "idx: 300, loss: 0.06726652383804321, time taken: 1.1148560047149658\n",
      "idx: 400, loss: 0.08516246825456619, time taken: 1.089228868484497\n",
      "Time take for epoch 6: 5.583315849304199s\n",
      "Training epoch: 7\n",
      "idx: 0, loss: 0.06557852774858475, time taken: 0.012132883071899414\n",
      "idx: 100, loss: 0.04233948886394501, time taken: 1.1338939666748047\n",
      "idx: 200, loss: 0.06493452936410904, time taken: 1.0916004180908203\n",
      "idx: 300, loss: 0.07312195003032684, time taken: 1.0844838619232178\n",
      "idx: 400, loss: 0.058095782995224, time taken: 1.0904853343963623\n",
      "Time take for epoch 7: 5.203100681304932s\n",
      "Training epoch: 8\n",
      "idx: 0, loss: 0.04995013400912285, time taken: 0.009557247161865234\n",
      "idx: 100, loss: 0.014470129273831844, time taken: 1.1011440753936768\n",
      "idx: 200, loss: 0.10987858474254608, time taken: 1.0954971313476562\n",
      "idx: 300, loss: 0.08473986387252808, time taken: 1.192762851715088\n",
      "idx: 400, loss: 0.07991547137498856, time taken: 1.1062235832214355\n",
      "Time take for epoch 8: 5.2544615268707275s\n",
      "Training epoch: 9\n",
      "idx: 0, loss: 0.06850431114435196, time taken: 0.011875391006469727\n",
      "idx: 100, loss: 0.03089500218629837, time taken: 1.1063075065612793\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "idx: 200, loss: 0.0923265889286995, time taken: 1.0961582660675049\n",
      "idx: 300, loss: 0.059856709092855453, time taken: 1.1508381366729736\n",
      "idx: 400, loss: 0.07363149523735046, time taken: 1.1946306228637695\n",
      "Time take for epoch 9: 5.309803247451782s\n",
      "Performing inference on batch: 0\n",
      "Performing inference on batch: 50\n",
      "Performing inference on batch: 0\n",
      "Performing inference on batch: 50\n",
      "FPR@95: 4.14, AUROC: 99.09 AUPR_IN: 99.21, AUPR_OUT: 99.00\n",
      "CCR: 68.42, 80.19, 90.49, 96.49, ACC: 98.20\n",
      "──────────────────────────────────────────────────────────────────────\n",
      "Time taken to train: 59.01862144470215\n",
      "Running model: models/mnist_lenet_mcd_relu_Adam_2.pkl...\n",
      "Getting optimizer for type: Adam...\n",
      "Training epoch: 0\n",
      "idx: 0, loss: 2.3059170246124268, time taken: 0.00960993766784668\n",
      "idx: 100, loss: 0.1333780288696289, time taken: 1.1127848625183105\n",
      "idx: 200, loss: 0.14914080500602722, time taken: 1.1316158771514893\n",
      "idx: 300, loss: 0.08159365504980087, time taken: 1.1259143352508545\n",
      "idx: 400, loss: 0.2137652486562729, time taken: 1.179725170135498\n",
      "Time take for epoch 0: 5.515277624130249s\n",
      "Training epoch: 1\n",
      "idx: 0, loss: 0.10697763413190842, time taken: 0.019972562789916992\n",
      "idx: 100, loss: 0.06282852590084076, time taken: 1.4135048389434814\n",
      "idx: 200, loss: 0.1297517716884613, time taken: 1.1946334838867188\n",
      "idx: 300, loss: 0.06033497676253319, time taken: 1.1118121147155762\n",
      "idx: 400, loss: 0.14503401517868042, time taken: 1.1219356060028076\n",
      "Time take for epoch 1: 5.61969780921936s\n",
      "Training epoch: 2\n",
      "idx: 0, loss: 0.09146825969219208, time taken: 0.01172018051147461\n",
      "idx: 100, loss: 0.060361701995134354, time taken: 1.1125609874725342\n",
      "idx: 200, loss: 0.06743732839822769, time taken: 1.117903232574463\n",
      "idx: 300, loss: 0.08082038909196854, time taken: 1.1157898902893066\n",
      "idx: 400, loss: 0.15945996344089508, time taken: 1.1323730945587158\n",
      "Time take for epoch 2: 5.239915609359741s\n",
      "Training epoch: 3\n",
      "idx: 0, loss: 0.04090557619929314, time taken: 0.012809276580810547\n",
      "idx: 100, loss: 0.04455505311489105, time taken: 1.1119351387023926\n",
      "idx: 200, loss: 0.10523020476102829, time taken: 1.1879239082336426\n",
      "idx: 300, loss: 0.08596106618642807, time taken: 1.1063892841339111\n",
      "idx: 400, loss: 0.11281602829694748, time taken: 1.3678736686706543\n",
      "Time take for epoch 3: 5.751146554946899s\n",
      "Training epoch: 4\n",
      "idx: 0, loss: 0.03455356881022453, time taken: 0.012498140335083008\n",
      "idx: 100, loss: 0.04318493232131004, time taken: 1.1474473476409912\n",
      "idx: 200, loss: 0.07231957465410233, time taken: 1.1792011260986328\n",
      "idx: 300, loss: 0.06451772153377533, time taken: 1.1166386604309082\n",
      "idx: 400, loss: 0.13491177558898926, time taken: 1.1325037479400635\n",
      "Time take for epoch 4: 5.541241645812988s\n",
      "Training epoch: 5\n",
      "idx: 0, loss: 0.08149480074644089, time taken: 0.01152801513671875\n",
      "idx: 100, loss: 0.07771757990121841, time taken: 1.133620023727417\n",
      "idx: 200, loss: 0.06704117357730865, time taken: 1.0933914184570312\n",
      "idx: 300, loss: 0.07320968806743622, time taken: 1.1222822666168213\n",
      "idx: 400, loss: 0.08253256976604462, time taken: 1.133296251296997\n",
      "Time take for epoch 5: 5.287139654159546s\n",
      "Training epoch: 6\n",
      "idx: 0, loss: 0.048999328166246414, time taken: 0.010103940963745117\n",
      "idx: 100, loss: 0.05148829519748688, time taken: 1.173527717590332\n",
      "idx: 200, loss: 0.09016912430524826, time taken: 1.3976988792419434\n",
      "idx: 300, loss: 0.07550293952226639, time taken: 1.0859184265136719\n",
      "idx: 400, loss: 0.16742633283138275, time taken: 1.099057674407959\n",
      "Time take for epoch 6: 5.526458024978638s\n",
      "Training epoch: 7\n",
      "idx: 0, loss: 0.10032761096954346, time taken: 0.009528636932373047\n",
      "idx: 100, loss: 0.06429032236337662, time taken: 1.111682653427124\n",
      "idx: 200, loss: 0.1799802929162979, time taken: 1.1077394485473633\n",
      "idx: 300, loss: 0.07331449538469315, time taken: 1.1181180477142334\n",
      "idx: 400, loss: 0.08036339282989502, time taken: 1.1347806453704834\n",
      "Time take for epoch 7: 5.244450092315674s\n",
      "Training epoch: 8\n",
      "idx: 0, loss: 0.05657707527279854, time taken: 0.011345624923706055\n",
      "idx: 100, loss: 0.0526590533554554, time taken: 1.09725022315979\n",
      "idx: 200, loss: 0.06674392521381378, time taken: 1.0939836502075195\n",
      "idx: 300, loss: 0.07397221028804779, time taken: 1.0937223434448242\n",
      "idx: 400, loss: 0.1262701451778412, time taken: 1.093973159790039\n",
      "Time take for epoch 8: 5.1340649127960205s\n",
      "Training epoch: 9\n",
      "idx: 0, loss: 0.05346917361021042, time taken: 0.011005878448486328\n",
      "idx: 100, loss: 0.03494221717119217, time taken: 1.0928130149841309\n",
      "idx: 200, loss: 0.08264203369617462, time taken: 1.1051568984985352\n",
      "idx: 300, loss: 0.06979010254144669, time taken: 1.1050245761871338\n",
      "idx: 400, loss: 0.12549369037151337, time taken: 1.0883326530456543\n",
      "Time take for epoch 9: 5.140132188796997s\n",
      "Performing inference on batch: 0\n",
      "Performing inference on batch: 50\n",
      "Performing inference on batch: 0\n",
      "Performing inference on batch: 50\n",
      "FPR@95: 12.91, AUROC: 97.89 AUPR_IN: 98.29, AUPR_OUT: 97.56\n",
      "CCR: 54.88, 73.70, 85.49, 93.06, ACC: 96.87\n",
      "──────────────────────────────────────────────────────────────────────\n",
      "Time taken to train: 58.53911900520325\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{0: {'dataset': 'mnist',\n",
       "  'FPR@95': '9.19',\n",
       "  'AUROC': '98.21',\n",
       "  'AUPR_IN': '98.39',\n",
       "  'AUPR_OUT': '98.12',\n",
       "  'CCR_4': '34.25',\n",
       "  'CCR_3': '49.21',\n",
       "  'CCR_2': '80.74',\n",
       "  'CCR_1': '94.50',\n",
       "  'ACC': '97.84',\n",
       "  'optimizer_type': 'Adam',\n",
       "  'activation_function_type': 'relu',\n",
       "  'postprocessor_type': 'mcd',\n",
       "  'time_taken': 59.438806772232056},\n",
       " 1: {'dataset': 'mnist',\n",
       "  'FPR@95': '4.14',\n",
       "  'AUROC': '99.09',\n",
       "  'AUPR_IN': '99.21',\n",
       "  'AUPR_OUT': '99.00',\n",
       "  'CCR_4': '68.42',\n",
       "  'CCR_3': '80.19',\n",
       "  'CCR_2': '90.49',\n",
       "  'CCR_1': '96.49',\n",
       "  'ACC': '98.20',\n",
       "  'optimizer_type': 'Adam',\n",
       "  'activation_function_type': 'relu',\n",
       "  'postprocessor_type': 'mcd',\n",
       "  'time_taken': 59.01862144470215},\n",
       " 2: {'dataset': 'mnist',\n",
       "  'FPR@95': '12.91',\n",
       "  'AUROC': '97.89',\n",
       "  'AUPR_IN': '98.29',\n",
       "  'AUPR_OUT': '97.56',\n",
       "  'CCR_4': '54.88',\n",
       "  'CCR_3': '73.70',\n",
       "  'CCR_2': '85.49',\n",
       "  'CCR_1': '93.06',\n",
       "  'ACC': '96.87',\n",
       "  'optimizer_type': 'Adam',\n",
       "  'activation_function_type': 'relu',\n",
       "  'postprocessor_type': 'mcd',\n",
       "  'time_taken': 58.53911900520325}}"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "config_1_1c = {\n",
    "    \"batch_size\": 128,\n",
    "    \"dataset_name\": \"mnist\",\n",
    "    \"n_classes\": 10,\n",
    "    \"epochs\": 10,\n",
    "    \"version\": time.time(),\n",
    "    \"lr\": 0.01,\n",
    "    \"momentum\": 0.9,\n",
    "    \"weight_decay\": 0.0005,\n",
    "    \"optimizer_type\": \"Adam\",\n",
    "    \"activation_function_type\": \"relu\",\n",
    "    \"network\": \"lenet\",\n",
    "    \"postprocessor_type\": \"mcd\",\n",
    "    \"dataset_type\": \"mnist\",\n",
    "    \"trials\": 3,\n",
    "    \"results_dir\": \"mnist-study\"\n",
    "}\n",
    "config_1_1c[\"data_loaders\"] = get_data_loaders(config_1_1c)\n",
    "run_full_oodn_pipeline(config_1_1c)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60a72681",
   "metadata": {},
   "source": [
    "#### 1(d) Adam + Softplus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "39e851fb",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running model: models/mnist_lenet_odin_softplus_Adam_0.pkl...\n",
      "Getting optimizer for type: Adam...\n",
      "Training epoch: 0\n",
      "idx: 0, loss: 2.4867539405822754, time taken: 0.01294088363647461\n",
      "idx: 100, loss: 2.3137519359588623, time taken: 1.0919625759124756\n",
      "idx: 200, loss: 2.3062570095062256, time taken: 1.1259357929229736\n",
      "idx: 300, loss: 2.2964324951171875, time taken: 1.0678155422210693\n",
      "idx: 400, loss: 2.311978816986084, time taken: 1.0967864990234375\n",
      "Time take for epoch 0: 5.3076536655426025s\n",
      "Training epoch: 1\n",
      "idx: 0, loss: 2.2973134517669678, time taken: 0.015149831771850586\n",
      "idx: 100, loss: 2.3036019802093506, time taken: 1.3365702629089355\n",
      "idx: 200, loss: 2.3831276893615723, time taken: 1.3034815788269043\n",
      "idx: 300, loss: 2.297569751739502, time taken: 1.0715382099151611\n",
      "idx: 400, loss: 2.3055648803710938, time taken: 1.0908071994781494\n",
      "Time take for epoch 1: 5.661466121673584s\n",
      "Training epoch: 2\n",
      "idx: 0, loss: 2.295820951461792, time taken: 0.013700723648071289\n",
      "idx: 100, loss: 2.3035471439361572, time taken: 1.3553977012634277\n",
      "idx: 200, loss: 2.3033547401428223, time taken: 1.0844614505767822\n",
      "idx: 300, loss: 1.5093740224838257, time taken: 1.1221950054168701\n",
      "idx: 400, loss: 0.7630167603492737, time taken: 1.367398977279663\n",
      "Time take for epoch 2: 5.8536903858184814s\n",
      "Training epoch: 3\n",
      "idx: 0, loss: 0.2873985469341278, time taken: 0.012815237045288086\n",
      "idx: 100, loss: 0.3869263231754303, time taken: 1.2696113586425781\n",
      "idx: 200, loss: 0.2153187394142151, time taken: 1.0460631847381592\n",
      "idx: 300, loss: 0.2546539306640625, time taken: 1.0569193363189697\n",
      "idx: 400, loss: 0.37022966146469116, time taken: 1.0574650764465332\n",
      "Time take for epoch 3: 5.155584096908569s\n",
      "Training epoch: 4\n",
      "idx: 0, loss: 0.1675885021686554, time taken: 0.016040802001953125\n",
      "idx: 100, loss: 0.2073965072631836, time taken: 1.0510175228118896\n",
      "idx: 200, loss: 0.17434507608413696, time taken: 1.045713186264038\n",
      "idx: 300, loss: 0.1804671287536621, time taken: 1.0561518669128418\n",
      "idx: 400, loss: 0.30628594756126404, time taken: 1.0533154010772705\n",
      "Time take for epoch 4: 4.96598219871521s\n",
      "Training epoch: 5\n",
      "idx: 0, loss: 0.09360379725694656, time taken: 0.013298988342285156\n",
      "idx: 100, loss: 0.18875545263290405, time taken: 1.0608491897583008\n",
      "idx: 200, loss: 0.1569252908229828, time taken: 1.0612382888793945\n",
      "idx: 300, loss: 0.14708201587200165, time taken: 1.1515309810638428\n",
      "idx: 400, loss: 0.3032185733318329, time taken: 1.3370864391326904\n",
      "Time take for epoch 5: 5.4033520221710205s\n",
      "Training epoch: 6\n",
      "idx: 0, loss: 0.07815311849117279, time taken: 0.01327824592590332\n",
      "idx: 100, loss: 0.16551251709461212, time taken: 1.0789496898651123\n",
      "idx: 200, loss: 0.1627749651670456, time taken: 1.0923449993133545\n",
      "idx: 300, loss: 0.1470157355070114, time taken: 1.0779592990875244\n",
      "idx: 400, loss: 0.28519847989082336, time taken: 1.305272102355957\n",
      "Time take for epoch 6: 5.345470666885376s\n",
      "Training epoch: 7\n",
      "idx: 0, loss: 0.08842997252941132, time taken: 0.010736465454101562\n",
      "idx: 100, loss: 0.14375972747802734, time taken: 1.0873894691467285\n",
      "idx: 200, loss: 0.16179053485393524, time taken: 1.1141409873962402\n",
      "idx: 300, loss: 0.14643242955207825, time taken: 1.3031792640686035\n",
      "idx: 400, loss: 0.2760441303253174, time taken: 1.3004984855651855\n",
      "Time take for epoch 7: 5.687695264816284s\n",
      "Training epoch: 8\n",
      "idx: 0, loss: 0.11270296573638916, time taken: 0.018955469131469727\n",
      "idx: 100, loss: 0.13142180442810059, time taken: 1.2065544128417969\n",
      "idx: 200, loss: 0.17518837749958038, time taken: 1.1066615581512451\n",
      "idx: 300, loss: 0.14012321829795837, time taken: 1.065765142440796\n",
      "idx: 400, loss: 0.2871915400028229, time taken: 1.0566232204437256\n",
      "Time take for epoch 8: 5.179109811782837s\n",
      "Training epoch: 9\n",
      "idx: 0, loss: 0.11743950843811035, time taken: 0.009081363677978516\n",
      "idx: 100, loss: 0.1292864829301834, time taken: 1.0595345497131348\n",
      "idx: 200, loss: 0.1549733281135559, time taken: 1.1089410781860352\n",
      "idx: 300, loss: 0.14647848904132843, time taken: 1.1053647994995117\n",
      "idx: 400, loss: 0.27782878279685974, time taken: 1.0773251056671143\n",
      "Time take for epoch 9: 5.075485706329346s\n",
      "Performing inference on batch: 0\n",
      "Performing inference on batch: 50\n",
      "Performing inference on batch: 0\n",
      "Performing inference on batch: 50\n",
      "FPR@95: 39.63, AUROC: 92.68 AUPR_IN: 93.52, AUPR_OUT: 91.72\n",
      "CCR: 4.24, 19.90, 54.15, 77.61, ACC: 93.81\n",
      "──────────────────────────────────────────────────────────────────────\n",
      "Time taken to train: 56.324368715286255\n",
      "Running model: models/mnist_lenet_odin_softplus_Adam_1.pkl...\n",
      "Getting optimizer for type: Adam...\n",
      "Training epoch: 0\n",
      "idx: 0, loss: 2.3790242671966553, time taken: 0.010980367660522461\n",
      "idx: 100, loss: 2.306929111480713, time taken: 1.2224559783935547\n",
      "idx: 200, loss: 2.3078725337982178, time taken: 1.2307085990905762\n",
      "idx: 300, loss: 2.297271966934204, time taken: 1.2158682346343994\n",
      "idx: 400, loss: 2.3044614791870117, time taken: 1.2203121185302734\n",
      "Time take for epoch 0: 5.629238128662109s\n",
      "Training epoch: 1\n",
      "idx: 0, loss: 2.2913401126861572, time taken: 0.010009765625\n",
      "idx: 100, loss: 0.47512200474739075, time taken: 1.1874263286590576\n",
      "idx: 200, loss: 0.17891697585582733, time taken: 1.0685474872589111\n",
      "idx: 300, loss: 0.20589450001716614, time taken: 1.0675103664398193\n",
      "idx: 400, loss: 0.1746789515018463, time taken: 1.0678932666778564\n",
      "Time take for epoch 1: 5.118765592575073s\n",
      "Training epoch: 2\n",
      "idx: 0, loss: 0.16569165885448456, time taken: 0.012689828872680664\n",
      "idx: 100, loss: 0.16596850752830505, time taken: 1.12754487991333\n",
      "idx: 200, loss: 0.12082109600305557, time taken: 1.074289321899414\n",
      "idx: 300, loss: 0.14698421955108643, time taken: 1.0727007389068604\n",
      "idx: 400, loss: 0.20058903098106384, time taken: 1.1035833358764648\n",
      "Time take for epoch 2: 5.105421543121338s\n",
      "Training epoch: 3\n",
      "idx: 0, loss: 0.10088901966810226, time taken: 0.012979269027709961\n",
      "idx: 100, loss: 0.13988110423088074, time taken: 1.0698716640472412\n",
      "idx: 200, loss: 0.14656572043895721, time taken: 1.0614707469940186\n",
      "idx: 300, loss: 0.1619943231344223, time taken: 1.1154332160949707\n",
      "idx: 400, loss: 0.22376640141010284, time taken: 1.0846242904663086\n",
      "Time take for epoch 3: 5.062329292297363s\n",
      "Training epoch: 4\n",
      "idx: 0, loss: 0.08040425181388855, time taken: 0.01089334487915039\n",
      "idx: 100, loss: 0.1047886535525322, time taken: 1.0672869682312012\n",
      "idx: 200, loss: 0.11541023850440979, time taken: 1.1002209186553955\n",
      "idx: 300, loss: 0.1440856009721756, time taken: 1.055955171585083\n",
      "idx: 400, loss: 0.2505345642566681, time taken: 1.0538396835327148\n",
      "Time take for epoch 4: 5.0094122886657715s\n",
      "Training epoch: 5\n",
      "idx: 0, loss: 0.06727276742458344, time taken: 0.009096145629882812\n",
      "idx: 100, loss: 0.08686771243810654, time taken: 1.0738961696624756\n",
      "idx: 200, loss: 0.07490119338035583, time taken: 1.073019027709961\n",
      "idx: 300, loss: 0.1420609951019287, time taken: 1.085587501525879\n",
      "idx: 400, loss: 0.22607727348804474, time taken: 1.0673000812530518\n",
      "Time take for epoch 5: 5.0865318775177s\n",
      "Training epoch: 6\n",
      "idx: 0, loss: 0.08020967245101929, time taken: 0.010424137115478516\n",
      "idx: 100, loss: 0.07090354710817337, time taken: 1.0759315490722656\n",
      "idx: 200, loss: 0.10308505594730377, time taken: 1.0502510070800781\n",
      "idx: 300, loss: 0.13081127405166626, time taken: 1.054103136062622\n",
      "idx: 400, loss: 0.20534588396549225, time taken: 1.0568959712982178\n",
      "Time take for epoch 6: 4.964821100234985s\n",
      "Training epoch: 7\n",
      "idx: 0, loss: 0.06172691285610199, time taken: 0.011839151382446289\n",
      "idx: 100, loss: 0.054783519357442856, time taken: 1.054945945739746\n",
      "idx: 200, loss: 0.07503097504377365, time taken: 1.0657999515533447\n",
      "idx: 300, loss: 0.11529567837715149, time taken: 1.058396816253662\n",
      "idx: 400, loss: 0.2100866436958313, time taken: 1.3324196338653564\n",
      "Time take for epoch 7: 5.2343363761901855s\n",
      "Training epoch: 8\n",
      "idx: 0, loss: 0.08240710943937302, time taken: 0.009030580520629883\n",
      "idx: 100, loss: 0.07681328803300858, time taken: 1.0607664585113525\n",
      "idx: 200, loss: 0.10083872079849243, time taken: 1.066547155380249\n",
      "idx: 300, loss: 0.10792186111211777, time taken: 1.051978588104248\n",
      "idx: 400, loss: 0.19016025960445404, time taken: 1.0624957084655762\n",
      "Time take for epoch 8: 4.968176364898682s\n",
      "Training epoch: 9\n",
      "idx: 0, loss: 0.09096701443195343, time taken: 0.010819196701049805\n",
      "idx: 100, loss: 0.05732261762022972, time taken: 1.0505695343017578\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "idx: 200, loss: 0.10514513403177261, time taken: 1.0458641052246094\n",
      "idx: 300, loss: 0.1100369393825531, time taken: 1.0846061706542969\n",
      "idx: 400, loss: 0.19702760875225067, time taken: 1.2940168380737305\n",
      "Time take for epoch 9: 5.201056957244873s\n",
      "Performing inference on batch: 0\n",
      "Performing inference on batch: 50\n",
      "Performing inference on batch: 0\n",
      "Performing inference on batch: 50\n",
      "FPR@95: 24.07, AUROC: 95.02 AUPR_IN: 94.94, AUPR_OUT: 95.23\n",
      "CCR: 9.76, 23.79, 42.58, 84.65, ACC: 96.61\n",
      "──────────────────────────────────────────────────────────────────────\n",
      "Time taken to train: 54.05677795410156\n",
      "Running model: models/mnist_lenet_odin_softplus_Adam_2.pkl...\n",
      "Getting optimizer for type: Adam...\n",
      "Training epoch: 0\n",
      "idx: 0, loss: 2.3333449363708496, time taken: 0.01078653335571289\n",
      "idx: 100, loss: 1.7437829971313477, time taken: 1.046682357788086\n",
      "idx: 200, loss: 0.3491598963737488, time taken: 1.0483002662658691\n",
      "idx: 300, loss: 0.13251887261867523, time taken: 1.0524356365203857\n",
      "idx: 400, loss: 0.3481087386608124, time taken: 1.0542356967926025\n",
      "Time take for epoch 0: 4.932068586349487s\n",
      "Training epoch: 1\n",
      "idx: 0, loss: 0.08838196098804474, time taken: 0.011884212493896484\n",
      "idx: 100, loss: 0.09605617076158524, time taken: 1.0540854930877686\n",
      "idx: 200, loss: 0.14975512027740479, time taken: 1.0627105236053467\n",
      "idx: 300, loss: 0.09631115943193436, time taken: 1.0728402137756348\n",
      "idx: 400, loss: 0.25909316539764404, time taken: 1.0602471828460693\n",
      "Time take for epoch 1: 5.071954250335693s\n",
      "Training epoch: 2\n",
      "idx: 0, loss: 0.08414056897163391, time taken: 0.013607025146484375\n",
      "idx: 100, loss: 0.03820332884788513, time taken: 1.2567684650421143\n",
      "idx: 200, loss: 0.07501737773418427, time taken: 1.3192758560180664\n",
      "idx: 300, loss: 0.08925976604223251, time taken: 1.332824468612671\n",
      "idx: 400, loss: 0.21361957490444183, time taken: 1.1026482582092285\n",
      "Time take for epoch 2: 5.755089998245239s\n",
      "Training epoch: 3\n",
      "idx: 0, loss: 0.08028803020715714, time taken: 0.011037111282348633\n",
      "idx: 100, loss: 0.07597579807043076, time taken: 1.0627455711364746\n",
      "idx: 200, loss: 0.05673093721270561, time taken: 1.0446498394012451\n",
      "idx: 300, loss: 0.07634298503398895, time taken: 1.0552642345428467\n",
      "idx: 400, loss: 0.24618537724018097, time taken: 1.1726195812225342\n",
      "Time take for epoch 3: 5.159633636474609s\n",
      "Training epoch: 4\n",
      "idx: 0, loss: 0.11715328693389893, time taken: 0.008947372436523438\n",
      "idx: 100, loss: 0.08466034382581711, time taken: 1.0403416156768799\n",
      "idx: 200, loss: 0.08815920352935791, time taken: 1.0307643413543701\n",
      "idx: 300, loss: 0.07887206226587296, time taken: 1.0407724380493164\n",
      "idx: 400, loss: 0.16251057386398315, time taken: 1.0488941669464111\n",
      "Time take for epoch 4: 4.89347243309021s\n",
      "Training epoch: 5\n",
      "idx: 0, loss: 0.09451591223478317, time taken: 0.011153221130371094\n",
      "idx: 100, loss: 0.09356742352247238, time taken: 1.1043097972869873\n",
      "idx: 200, loss: 0.06043113395571709, time taken: 1.2365520000457764\n",
      "idx: 300, loss: 0.0802062526345253, time taken: 1.2152774333953857\n",
      "idx: 400, loss: 0.18360398709774017, time taken: 1.1257646083831787\n",
      "Time take for epoch 5: 5.407153129577637s\n",
      "Training epoch: 6\n",
      "idx: 0, loss: 0.048748452216386795, time taken: 0.008978843688964844\n",
      "idx: 100, loss: 0.03763685002923012, time taken: 1.07086181640625\n",
      "idx: 200, loss: 0.0817563608288765, time taken: 1.1859564781188965\n",
      "idx: 300, loss: 0.08052810281515121, time taken: 1.146209716796875\n",
      "idx: 400, loss: 0.3172908425331116, time taken: 1.0631887912750244\n",
      "Time take for epoch 6: 5.223305702209473s\n",
      "Training epoch: 7\n",
      "idx: 0, loss: 0.04086306691169739, time taken: 0.012876033782958984\n",
      "idx: 100, loss: 0.03927411139011383, time taken: 1.0962646007537842\n",
      "idx: 200, loss: 0.09014636278152466, time taken: 1.0608983039855957\n",
      "idx: 300, loss: 0.07881305366754532, time taken: 1.0437922477722168\n",
      "idx: 400, loss: 0.12140563130378723, time taken: 1.043212652206421\n",
      "Time take for epoch 7: 4.9543867111206055s\n",
      "Training epoch: 8\n",
      "idx: 0, loss: 0.061774030327796936, time taken: 0.009744405746459961\n",
      "idx: 100, loss: 0.05002180114388466, time taken: 1.0404534339904785\n",
      "idx: 200, loss: 0.07921834290027618, time taken: 1.0730667114257812\n",
      "idx: 300, loss: 0.07617581635713577, time taken: 1.0727860927581787\n",
      "idx: 400, loss: 0.10482326149940491, time taken: 1.0979759693145752\n",
      "Time take for epoch 8: 5.296525478363037s\n",
      "Training epoch: 9\n",
      "idx: 0, loss: 0.11220156401395798, time taken: 0.014595746994018555\n",
      "idx: 100, loss: 0.0684019923210144, time taken: 1.1553497314453125\n",
      "idx: 200, loss: 0.07645611464977264, time taken: 1.0821759700775146\n",
      "idx: 300, loss: 0.06139909103512764, time taken: 1.1150307655334473\n",
      "idx: 400, loss: 0.16526278853416443, time taken: 1.0792620182037354\n",
      "Time take for epoch 9: 5.165806770324707s\n",
      "Performing inference on batch: 0\n",
      "Performing inference on batch: 50\n",
      "Performing inference on batch: 0\n",
      "Performing inference on batch: 50\n",
      "FPR@95: 9.58, AUROC: 98.39 AUPR_IN: 98.59, AUPR_OUT: 98.28\n",
      "CCR: 55.18, 69.09, 84.15, 94.21, ACC: 97.71\n",
      "──────────────────────────────────────────────────────────────────────\n",
      "Time taken to train: 54.88141632080078\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{0: {'dataset': 'mnist',\n",
       "  'FPR@95': '39.63',\n",
       "  'AUROC': '92.68',\n",
       "  'AUPR_IN': '93.52',\n",
       "  'AUPR_OUT': '91.72',\n",
       "  'CCR_4': '4.24',\n",
       "  'CCR_3': '19.90',\n",
       "  'CCR_2': '54.15',\n",
       "  'CCR_1': '77.61',\n",
       "  'ACC': '93.81',\n",
       "  'optimizer_type': 'Adam',\n",
       "  'activation_function_type': 'softplus',\n",
       "  'postprocessor_type': 'odin',\n",
       "  'time_taken': 56.324368715286255},\n",
       " 1: {'dataset': 'mnist',\n",
       "  'FPR@95': '24.07',\n",
       "  'AUROC': '95.02',\n",
       "  'AUPR_IN': '94.94',\n",
       "  'AUPR_OUT': '95.23',\n",
       "  'CCR_4': '9.76',\n",
       "  'CCR_3': '23.79',\n",
       "  'CCR_2': '42.58',\n",
       "  'CCR_1': '84.65',\n",
       "  'ACC': '96.61',\n",
       "  'optimizer_type': 'Adam',\n",
       "  'activation_function_type': 'softplus',\n",
       "  'postprocessor_type': 'odin',\n",
       "  'time_taken': 54.05677795410156},\n",
       " 2: {'dataset': 'mnist',\n",
       "  'FPR@95': '9.58',\n",
       "  'AUROC': '98.39',\n",
       "  'AUPR_IN': '98.59',\n",
       "  'AUPR_OUT': '98.28',\n",
       "  'CCR_4': '55.18',\n",
       "  'CCR_3': '69.09',\n",
       "  'CCR_2': '84.15',\n",
       "  'CCR_1': '94.21',\n",
       "  'ACC': '97.71',\n",
       "  'optimizer_type': 'Adam',\n",
       "  'activation_function_type': 'softplus',\n",
       "  'postprocessor_type': 'odin',\n",
       "  'time_taken': 54.88141632080078}}"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "config_1d = {\n",
    "    \"batch_size\": 128,\n",
    "    \"dataset_name\": \"mnist\",\n",
    "    \"n_classes\": 10,\n",
    "    \"epochs\": 10,\n",
    "    \"version\": time.time(),\n",
    "    \"lr\": 0.01,\n",
    "    \"momentum\": 0.9,\n",
    "    \"weight_decay\": 0.0005,\n",
    "    \"optimizer_type\": \"Adam\",\n",
    "    \"activation_function_type\": \"softplus\",\n",
    "    \"network\": \"lenet\",\n",
    "    \"postprocessor_type\": \"odin\",\n",
    "    \"dataset_type\": \"mnist\",\n",
    "    \"trials\": 3,\n",
    "    \"results_dir\": \"mnist-study\"\n",
    "}\n",
    "config_1d[\"data_loaders\"] = get_data_loaders(config_1d)\n",
    "run_full_oodn_pipeline(config_1d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "8d1b7652",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running model: models/mnist_lenet_mcd_softplus_Adam_0.pkl...\n",
      "Getting optimizer for type: Adam...\n",
      "Training epoch: 0\n",
      "idx: 0, loss: 2.353691816329956, time taken: 0.018357038497924805\n",
      "idx: 100, loss: 2.3137669563293457, time taken: 1.4791052341461182\n",
      "idx: 200, loss: 1.5023689270019531, time taken: 1.3667633533477783\n",
      "idx: 300, loss: 0.44497811794281006, time taken: 1.3123645782470703\n",
      "idx: 400, loss: 0.4015829861164093, time taken: 1.1107428073883057\n",
      "Time take for epoch 0: 5.999896049499512s\n",
      "Training epoch: 1\n",
      "idx: 0, loss: 0.11189687997102737, time taken: 0.010910987854003906\n",
      "idx: 100, loss: 0.15927621722221375, time taken: 1.0646929740905762\n",
      "idx: 200, loss: 0.1227123960852623, time taken: 1.0906193256378174\n",
      "idx: 300, loss: 0.08286695927381516, time taken: 1.060987949371338\n",
      "idx: 400, loss: 0.21853095293045044, time taken: 1.0454885959625244\n",
      "Time take for epoch 1: 5.025881052017212s\n",
      "Training epoch: 2\n",
      "idx: 0, loss: 0.06880941987037659, time taken: 0.012098073959350586\n",
      "idx: 100, loss: 0.11438366025686264, time taken: 1.0568253993988037\n",
      "idx: 200, loss: 0.08614455908536911, time taken: 1.051135540008545\n",
      "idx: 300, loss: 0.0730472207069397, time taken: 1.066218614578247\n",
      "idx: 400, loss: 0.19604283571243286, time taken: 1.040513038635254\n",
      "Time take for epoch 2: 4.939913034439087s\n",
      "Training epoch: 3\n",
      "idx: 0, loss: 0.06418339163064957, time taken: 0.009197473526000977\n",
      "idx: 100, loss: 0.13562896847724915, time taken: 1.0499122142791748\n",
      "idx: 200, loss: 0.06628476083278656, time taken: 1.0306355953216553\n",
      "idx: 300, loss: 0.08594532310962677, time taken: 1.0379648208618164\n",
      "idx: 400, loss: 0.1707267016172409, time taken: 1.0412483215332031\n",
      "Time take for epoch 3: 4.913369417190552s\n",
      "Training epoch: 4\n",
      "idx: 0, loss: 0.05231726914644241, time taken: 0.011182069778442383\n",
      "idx: 100, loss: 0.12432076781988144, time taken: 1.061976432800293\n",
      "idx: 200, loss: 0.10453267395496368, time taken: 1.3123102188110352\n",
      "idx: 300, loss: 0.0691601112484932, time taken: 1.2495331764221191\n",
      "idx: 400, loss: 0.16836196184158325, time taken: 1.0582499504089355\n",
      "Time take for epoch 4: 5.424566268920898s\n",
      "Training epoch: 5\n",
      "idx: 0, loss: 0.04705891013145447, time taken: 0.009189605712890625\n",
      "idx: 100, loss: 0.06113703176379204, time taken: 1.0676076412200928\n",
      "idx: 200, loss: 0.05737786740064621, time taken: 1.0565481185913086\n",
      "idx: 300, loss: 0.06863190978765488, time taken: 1.0475280284881592\n",
      "idx: 400, loss: 0.17870013415813446, time taken: 1.0497279167175293\n",
      "Time take for epoch 5: 4.936758041381836s\n",
      "Training epoch: 6\n",
      "idx: 0, loss: 0.04723186790943146, time taken: 0.00931096076965332\n",
      "idx: 100, loss: 0.06997749209403992, time taken: 1.3786015510559082\n",
      "idx: 200, loss: 0.05678325891494751, time taken: 1.0604641437530518\n",
      "idx: 300, loss: 0.06304290890693665, time taken: 1.0520539283752441\n",
      "idx: 400, loss: 0.20979908108711243, time taken: 1.0546817779541016\n",
      "Time take for epoch 6: 5.275310516357422s\n",
      "Training epoch: 7\n",
      "idx: 0, loss: 0.053142137825489044, time taken: 0.01151585578918457\n",
      "idx: 100, loss: 0.051470737904310226, time taken: 1.0491218566894531\n",
      "idx: 200, loss: 0.06824532896280289, time taken: 1.0587680339813232\n",
      "idx: 300, loss: 0.05462327226996422, time taken: 1.0471391677856445\n",
      "idx: 400, loss: 0.14225822687149048, time taken: 1.0406086444854736\n",
      "Time take for epoch 7: 4.934317111968994s\n",
      "Training epoch: 8\n",
      "idx: 0, loss: 0.050790611654520035, time taken: 0.017503023147583008\n",
      "idx: 100, loss: 0.04751626402139664, time taken: 1.0450835227966309\n",
      "idx: 200, loss: 0.07777052372694016, time taken: 1.0460553169250488\n",
      "idx: 300, loss: 0.06774353235960007, time taken: 1.053659200668335\n",
      "idx: 400, loss: 0.21401602029800415, time taken: 1.117039442062378\n",
      "Time take for epoch 8: 4.9974753856658936s\n",
      "Training epoch: 9\n",
      "idx: 0, loss: 0.07520141452550888, time taken: 0.009878158569335938\n",
      "idx: 100, loss: 0.051724694669246674, time taken: 1.0619337558746338\n",
      "idx: 200, loss: 0.059894442558288574, time taken: 1.0486829280853271\n",
      "idx: 300, loss: 0.06246144324541092, time taken: 1.1012248992919922\n",
      "idx: 400, loss: 0.2224283516407013, time taken: 1.1235191822052002\n",
      "Time take for epoch 9: 5.064837455749512s\n",
      "Performing inference on batch: 0\n",
      "Performing inference on batch: 50\n",
      "Performing inference on batch: 0\n",
      "Performing inference on batch: 50\n",
      "FPR@95: 41.63, AUROC: 94.48 AUPR_IN: 95.95, AUPR_OUT: 91.68\n",
      "CCR: 34.59, 55.71, 71.79, 88.20, ACC: 97.90\n",
      "──────────────────────────────────────────────────────────────────────\n",
      "Time taken to train: 56.13298273086548\n",
      "Running model: models/mnist_lenet_mcd_softplus_Adam_1.pkl...\n",
      "Getting optimizer for type: Adam...\n",
      "Training epoch: 0\n",
      "idx: 0, loss: 2.517474889755249, time taken: 0.010545015335083008\n",
      "idx: 100, loss: 1.4449313879013062, time taken: 1.040966272354126\n",
      "idx: 200, loss: 0.31527259945869446, time taken: 1.066985845565796\n",
      "idx: 300, loss: 0.17217972874641418, time taken: 1.0768132209777832\n",
      "idx: 400, loss: 0.20235390961170197, time taken: 1.2111494541168213\n",
      "Time take for epoch 0: 5.3058507442474365s\n",
      "Training epoch: 1\n",
      "idx: 0, loss: 0.1069221943616867, time taken: 0.012704133987426758\n",
      "idx: 100, loss: 0.06760990619659424, time taken: 1.2903079986572266\n",
      "idx: 200, loss: 0.15788067877292633, time taken: 1.2829902172088623\n",
      "idx: 300, loss: 0.1022953912615776, time taken: 1.3039827346801758\n",
      "idx: 400, loss: 0.1691567450761795, time taken: 1.2002968788146973\n",
      "Time take for epoch 1: 5.860283613204956s\n",
      "Training epoch: 2\n",
      "idx: 0, loss: 0.05749999359250069, time taken: 0.013140439987182617\n",
      "idx: 100, loss: 0.049395639449357986, time taken: 1.091841697692871\n",
      "idx: 200, loss: 0.09508497267961502, time taken: 1.074510097503662\n",
      "idx: 300, loss: 0.06766822934150696, time taken: 1.0828578472137451\n",
      "idx: 400, loss: 0.18093550205230713, time taken: 1.0696234703063965\n",
      "Time take for epoch 2: 5.228545188903809s\n",
      "Training epoch: 3\n",
      "idx: 0, loss: 0.046080224215984344, time taken: 0.013703584671020508\n",
      "idx: 100, loss: 0.05317318066954613, time taken: 1.3047888278961182\n",
      "idx: 200, loss: 0.06978410482406616, time taken: 1.1104497909545898\n",
      "idx: 300, loss: 0.059687625616788864, time taken: 1.2562620639801025\n",
      "idx: 400, loss: 0.13683123886585236, time taken: 1.0914359092712402\n",
      "Time take for epoch 3: 5.488096714019775s\n",
      "Training epoch: 4\n",
      "idx: 0, loss: 0.03639661893248558, time taken: 0.009195327758789062\n",
      "idx: 100, loss: 0.08314617723226547, time taken: 1.0427823066711426\n",
      "idx: 200, loss: 0.06565559655427933, time taken: 1.1007769107818604\n",
      "idx: 300, loss: 0.09447623789310455, time taken: 1.0355801582336426\n",
      "idx: 400, loss: 0.14344589412212372, time taken: 1.0451219081878662\n",
      "Time take for epoch 4: 4.998901128768921s\n",
      "Training epoch: 5\n",
      "idx: 0, loss: 0.03165092691779137, time taken: 0.009085655212402344\n",
      "idx: 100, loss: 0.024238107725977898, time taken: 1.0687570571899414\n",
      "idx: 200, loss: 0.07732012867927551, time taken: 1.0418169498443604\n",
      "idx: 300, loss: 0.09987228363752365, time taken: 1.0482728481292725\n",
      "idx: 400, loss: 0.1675613969564438, time taken: 1.0525810718536377\n",
      "Time take for epoch 5: 4.943486928939819s\n",
      "Training epoch: 6\n",
      "idx: 0, loss: 0.04100485518574715, time taken: 0.009168148040771484\n",
      "idx: 100, loss: 0.036196183413267136, time taken: 1.0547332763671875\n",
      "idx: 200, loss: 0.06972038000822067, time taken: 1.0500941276550293\n",
      "idx: 300, loss: 0.1023896336555481, time taken: 1.0895743370056152\n",
      "idx: 400, loss: 0.1969728022813797, time taken: 1.3145685195922852\n",
      "Time take for epoch 6: 5.227339267730713s\n",
      "Training epoch: 7\n",
      "idx: 0, loss: 0.048846449702978134, time taken: 0.009241342544555664\n",
      "idx: 100, loss: 0.023210231214761734, time taken: 1.0542032718658447\n",
      "idx: 200, loss: 0.07565292716026306, time taken: 1.0527207851409912\n",
      "idx: 300, loss: 0.0624874047935009, time taken: 1.0449700355529785\n",
      "idx: 400, loss: 0.1790858656167984, time taken: 1.0499179363250732\n",
      "Time take for epoch 7: 4.925676584243774s\n",
      "Training epoch: 8\n",
      "idx: 0, loss: 0.031283386051654816, time taken: 0.011026382446289062\n",
      "idx: 100, loss: 0.06141335889697075, time taken: 1.0745909214019775\n",
      "idx: 200, loss: 0.07262954860925674, time taken: 1.0431745052337646\n",
      "idx: 300, loss: 0.08075638860464096, time taken: 1.2022969722747803\n",
      "idx: 400, loss: 0.18836183845996857, time taken: 1.2600653171539307\n",
      "Time take for epoch 8: 5.306960821151733s\n",
      "Training epoch: 9\n",
      "idx: 0, loss: 0.0537184439599514, time taken: 0.009139776229858398\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "idx: 100, loss: 0.03830929473042488, time taken: 1.0471446514129639\n",
      "idx: 200, loss: 0.06321410834789276, time taken: 1.1186833381652832\n",
      "idx: 300, loss: 0.060200389474630356, time taken: 1.222710132598877\n",
      "idx: 400, loss: 0.205159991979599, time taken: 1.264312505722046\n",
      "Time take for epoch 9: 5.498885154724121s\n",
      "Performing inference on batch: 0\n",
      "Performing inference on batch: 50\n",
      "Performing inference on batch: 0\n",
      "Performing inference on batch: 50\n",
      "FPR@95: 29.09, AUROC: 94.62 AUPR_IN: 95.05, AUPR_OUT: 94.23\n",
      "CCR: 10.40, 24.61, 52.52, 85.33, ACC: 97.42\n",
      "──────────────────────────────────────────────────────────────────────\n",
      "Time taken to train: 57.39354372024536\n",
      "Running model: models/mnist_lenet_mcd_softplus_Adam_2.pkl...\n",
      "Getting optimizer for type: Adam...\n",
      "Training epoch: 0\n",
      "idx: 0, loss: 2.428304433822632, time taken: 0.01504826545715332\n",
      "idx: 100, loss: 1.0391908884048462, time taken: 1.1295280456542969\n",
      "idx: 200, loss: 0.24591122567653656, time taken: 1.0662751197814941\n",
      "idx: 300, loss: 0.14067403972148895, time taken: 1.0269062519073486\n",
      "idx: 400, loss: 0.42841026186943054, time taken: 1.0279202461242676\n",
      "Time take for epoch 0: 4.965432405471802s\n",
      "Training epoch: 1\n",
      "idx: 0, loss: 0.08663162589073181, time taken: 0.009099721908569336\n",
      "idx: 100, loss: 0.11719430983066559, time taken: 1.0404975414276123\n",
      "idx: 200, loss: 0.1880389004945755, time taken: 1.029155969619751\n",
      "idx: 300, loss: 0.0906299501657486, time taken: 1.0297398567199707\n",
      "idx: 400, loss: 0.27260345220565796, time taken: 1.0416624546051025\n",
      "Time take for epoch 1: 4.848361253738403s\n",
      "Training epoch: 2\n",
      "idx: 0, loss: 0.06005977466702461, time taken: 0.008839130401611328\n",
      "idx: 100, loss: 0.17588473856449127, time taken: 1.0320558547973633\n",
      "idx: 200, loss: 0.1249166876077652, time taken: 1.043363094329834\n",
      "idx: 300, loss: 0.08418306708335876, time taken: 1.0357859134674072\n",
      "idx: 400, loss: 0.2961694002151489, time taken: 1.0458977222442627\n",
      "Time take for epoch 2: 4.881441354751587s\n",
      "Training epoch: 3\n",
      "idx: 0, loss: 0.08400183171033859, time taken: 0.009323835372924805\n",
      "idx: 100, loss: 0.05784926936030388, time taken: 1.0213596820831299\n",
      "idx: 200, loss: 0.17904089391231537, time taken: 1.045863151550293\n",
      "idx: 300, loss: 0.06270148605108261, time taken: 1.0508954524993896\n",
      "idx: 400, loss: 0.21550098061561584, time taken: 1.0545694828033447\n",
      "Time take for epoch 3: 4.8907411098480225s\n",
      "Training epoch: 4\n",
      "idx: 0, loss: 0.05726621299982071, time taken: 0.008748769760131836\n",
      "idx: 100, loss: 0.06827991455793381, time taken: 1.1161470413208008\n",
      "idx: 200, loss: 0.10042288154363632, time taken: 1.0480637550354004\n",
      "idx: 300, loss: 0.07378916442394257, time taken: 1.036864995956421\n",
      "idx: 400, loss: 0.2626047730445862, time taken: 1.030216932296753\n",
      "Time take for epoch 4: 4.9471282958984375s\n",
      "Training epoch: 5\n",
      "idx: 0, loss: 0.11041785776615143, time taken: 0.00879049301147461\n",
      "idx: 100, loss: 0.045221611857414246, time taken: 1.0366978645324707\n",
      "idx: 200, loss: 0.10601359605789185, time taken: 1.0427329540252686\n",
      "idx: 300, loss: 0.049346376210451126, time taken: 1.171067237854004\n",
      "idx: 400, loss: 0.13870970904827118, time taken: 1.1656861305236816\n",
      "Time take for epoch 5: 5.155466556549072s\n",
      "Training epoch: 6\n",
      "idx: 0, loss: 0.05199757590889931, time taken: 0.008747100830078125\n",
      "idx: 100, loss: 0.06330711394548416, time taken: 1.0356698036193848\n",
      "idx: 200, loss: 0.14152733981609344, time taken: 1.0675280094146729\n",
      "idx: 300, loss: 0.05597483366727829, time taken: 1.0569517612457275\n",
      "idx: 400, loss: 0.11321747303009033, time taken: 1.1092829704284668\n",
      "Time take for epoch 6: 4.999189376831055s\n",
      "Training epoch: 7\n",
      "idx: 0, loss: 0.04192410036921501, time taken: 0.009259223937988281\n",
      "idx: 100, loss: 0.14590154588222504, time taken: 1.054689645767212\n",
      "idx: 200, loss: 0.18020835518836975, time taken: 1.0538456439971924\n",
      "idx: 300, loss: 0.0857095792889595, time taken: 1.0500140190124512\n",
      "idx: 400, loss: 0.1480102837085724, time taken: 1.3457558155059814\n",
      "Time take for epoch 7: 5.241108655929565s\n",
      "Training epoch: 8\n",
      "idx: 0, loss: 0.07935793697834015, time taken: 0.009678840637207031\n",
      "idx: 100, loss: 0.08332397788763046, time taken: 1.05415678024292\n",
      "idx: 200, loss: 0.11069216579198837, time taken: 1.1411173343658447\n",
      "idx: 300, loss: 0.07420371472835541, time taken: 1.3025164604187012\n",
      "idx: 400, loss: 0.22977590560913086, time taken: 1.1162781715393066\n",
      "Time take for epoch 8: 5.338866949081421s\n",
      "Training epoch: 9\n",
      "idx: 0, loss: 0.04957161471247673, time taken: 0.008943557739257812\n",
      "idx: 100, loss: 0.04788470268249512, time taken: 1.0382983684539795\n",
      "idx: 200, loss: 0.12845200300216675, time taken: 1.0455601215362549\n",
      "idx: 300, loss: 0.07195345312356949, time taken: 1.0431835651397705\n",
      "idx: 400, loss: 0.14022748172283173, time taken: 1.0438051223754883\n",
      "Time take for epoch 9: 4.891435384750366s\n",
      "Performing inference on batch: 0\n",
      "Performing inference on batch: 50\n",
      "Performing inference on batch: 0\n",
      "Performing inference on batch: 50\n",
      "FPR@95: 24.29, AUROC: 95.93 AUPR_IN: 96.53, AUPR_OUT: 95.02\n",
      "CCR: 16.29, 32.34, 66.10, 89.93, ACC: 97.85\n",
      "──────────────────────────────────────────────────────────────────────\n",
      "Time taken to train: 54.727500438690186\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{0: {'dataset': 'mnist',\n",
       "  'FPR@95': '41.63',\n",
       "  'AUROC': '94.48',\n",
       "  'AUPR_IN': '95.95',\n",
       "  'AUPR_OUT': '91.68',\n",
       "  'CCR_4': '34.59',\n",
       "  'CCR_3': '55.71',\n",
       "  'CCR_2': '71.79',\n",
       "  'CCR_1': '88.20',\n",
       "  'ACC': '97.90',\n",
       "  'optimizer_type': 'Adam',\n",
       "  'activation_function_type': 'softplus',\n",
       "  'postprocessor_type': 'mcd',\n",
       "  'time_taken': 56.13298273086548},\n",
       " 1: {'dataset': 'mnist',\n",
       "  'FPR@95': '29.09',\n",
       "  'AUROC': '94.62',\n",
       "  'AUPR_IN': '95.05',\n",
       "  'AUPR_OUT': '94.23',\n",
       "  'CCR_4': '10.40',\n",
       "  'CCR_3': '24.61',\n",
       "  'CCR_2': '52.52',\n",
       "  'CCR_1': '85.33',\n",
       "  'ACC': '97.42',\n",
       "  'optimizer_type': 'Adam',\n",
       "  'activation_function_type': 'softplus',\n",
       "  'postprocessor_type': 'mcd',\n",
       "  'time_taken': 57.39354372024536},\n",
       " 2: {'dataset': 'mnist',\n",
       "  'FPR@95': '24.29',\n",
       "  'AUROC': '95.93',\n",
       "  'AUPR_IN': '96.53',\n",
       "  'AUPR_OUT': '95.02',\n",
       "  'CCR_4': '16.29',\n",
       "  'CCR_3': '32.34',\n",
       "  'CCR_2': '66.10',\n",
       "  'CCR_1': '89.93',\n",
       "  'ACC': '97.85',\n",
       "  'optimizer_type': 'Adam',\n",
       "  'activation_function_type': 'softplus',\n",
       "  'postprocessor_type': 'mcd',\n",
       "  'time_taken': 54.727500438690186}}"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "config_1_1d = {\n",
    "    \"batch_size\": 128,\n",
    "    \"dataset_name\": \"mnist\",\n",
    "    \"n_classes\": 10,\n",
    "    \"epochs\": 10,\n",
    "    \"version\": time.time(),\n",
    "    \"lr\": 0.01,\n",
    "    \"momentum\": 0.9,\n",
    "    \"weight_decay\": 0.0005,\n",
    "    \"optimizer_type\": \"Adam\",\n",
    "    \"activation_function_type\": \"softplus\",\n",
    "    \"network\": \"lenet\",\n",
    "    \"postprocessor_type\": \"mcd\",\n",
    "    \"dataset_type\": \"mnist\",\n",
    "    \"trials\": 3,\n",
    "    \"results_dir\": \"mnist-study\"\n",
    "}\n",
    "config_1_1d[\"data_loaders\"] = get_data_loaders(config_1_1d)\n",
    "run_full_oodn_pipeline(config_1_1d)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f12abb2",
   "metadata": {},
   "source": [
    "### Robustness Analysis For Study 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "ed57b8a4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>optimizer_type</th>\n",
       "      <th>activation_function_type</th>\n",
       "      <th>postprocessor_type</th>\n",
       "      <th>trial</th>\n",
       "      <th>AUROC</th>\n",
       "      <th>ACC</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>SGD</td>\n",
       "      <td>softplus</td>\n",
       "      <td>odin</td>\n",
       "      <td>0</td>\n",
       "      <td>99.17</td>\n",
       "      <td>98.33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>SGD</td>\n",
       "      <td>softplus</td>\n",
       "      <td>odin</td>\n",
       "      <td>1</td>\n",
       "      <td>98.65</td>\n",
       "      <td>97.92</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>SGD</td>\n",
       "      <td>softplus</td>\n",
       "      <td>odin</td>\n",
       "      <td>2</td>\n",
       "      <td>99.23</td>\n",
       "      <td>98.51</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Adam</td>\n",
       "      <td>softplus</td>\n",
       "      <td>odin</td>\n",
       "      <td>0</td>\n",
       "      <td>92.68</td>\n",
       "      <td>93.81</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Adam</td>\n",
       "      <td>softplus</td>\n",
       "      <td>odin</td>\n",
       "      <td>1</td>\n",
       "      <td>95.02</td>\n",
       "      <td>96.61</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Adam</td>\n",
       "      <td>softplus</td>\n",
       "      <td>odin</td>\n",
       "      <td>2</td>\n",
       "      <td>98.39</td>\n",
       "      <td>97.71</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Adam</td>\n",
       "      <td>relu</td>\n",
       "      <td>mcd</td>\n",
       "      <td>0</td>\n",
       "      <td>98.21</td>\n",
       "      <td>97.84</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Adam</td>\n",
       "      <td>relu</td>\n",
       "      <td>mcd</td>\n",
       "      <td>1</td>\n",
       "      <td>99.09</td>\n",
       "      <td>98.20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Adam</td>\n",
       "      <td>relu</td>\n",
       "      <td>mcd</td>\n",
       "      <td>2</td>\n",
       "      <td>97.89</td>\n",
       "      <td>96.87</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>SGD</td>\n",
       "      <td>relu</td>\n",
       "      <td>mcd</td>\n",
       "      <td>0</td>\n",
       "      <td>98.82</td>\n",
       "      <td>96.99</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>SGD</td>\n",
       "      <td>relu</td>\n",
       "      <td>mcd</td>\n",
       "      <td>1</td>\n",
       "      <td>95.97</td>\n",
       "      <td>96.47</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>SGD</td>\n",
       "      <td>relu</td>\n",
       "      <td>mcd</td>\n",
       "      <td>2</td>\n",
       "      <td>98.45</td>\n",
       "      <td>97.95</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>SGD</td>\n",
       "      <td>relu</td>\n",
       "      <td>odin</td>\n",
       "      <td>0</td>\n",
       "      <td>99.40</td>\n",
       "      <td>98.21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>SGD</td>\n",
       "      <td>relu</td>\n",
       "      <td>odin</td>\n",
       "      <td>1</td>\n",
       "      <td>99.62</td>\n",
       "      <td>98.19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>SGD</td>\n",
       "      <td>relu</td>\n",
       "      <td>odin</td>\n",
       "      <td>2</td>\n",
       "      <td>99.52</td>\n",
       "      <td>98.65</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>SGD</td>\n",
       "      <td>softplus</td>\n",
       "      <td>mcd</td>\n",
       "      <td>0</td>\n",
       "      <td>98.29</td>\n",
       "      <td>97.86</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>SGD</td>\n",
       "      <td>softplus</td>\n",
       "      <td>mcd</td>\n",
       "      <td>1</td>\n",
       "      <td>98.30</td>\n",
       "      <td>98.12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>SGD</td>\n",
       "      <td>softplus</td>\n",
       "      <td>mcd</td>\n",
       "      <td>2</td>\n",
       "      <td>96.59</td>\n",
       "      <td>98.27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Adam</td>\n",
       "      <td>relu</td>\n",
       "      <td>odin</td>\n",
       "      <td>0</td>\n",
       "      <td>99.29</td>\n",
       "      <td>97.44</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>Adam</td>\n",
       "      <td>relu</td>\n",
       "      <td>odin</td>\n",
       "      <td>1</td>\n",
       "      <td>99.26</td>\n",
       "      <td>97.88</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>Adam</td>\n",
       "      <td>relu</td>\n",
       "      <td>odin</td>\n",
       "      <td>2</td>\n",
       "      <td>99.86</td>\n",
       "      <td>98.39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>Adam</td>\n",
       "      <td>softplus</td>\n",
       "      <td>mcd</td>\n",
       "      <td>0</td>\n",
       "      <td>94.48</td>\n",
       "      <td>97.90</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>Adam</td>\n",
       "      <td>softplus</td>\n",
       "      <td>mcd</td>\n",
       "      <td>1</td>\n",
       "      <td>94.62</td>\n",
       "      <td>97.42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>Adam</td>\n",
       "      <td>softplus</td>\n",
       "      <td>mcd</td>\n",
       "      <td>2</td>\n",
       "      <td>95.93</td>\n",
       "      <td>97.85</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   optimizer_type activation_function_type postprocessor_type trial  AUROC  \\\n",
       "0             SGD                 softplus               odin     0  99.17   \n",
       "1             SGD                 softplus               odin     1  98.65   \n",
       "2             SGD                 softplus               odin     2  99.23   \n",
       "3            Adam                 softplus               odin     0  92.68   \n",
       "4            Adam                 softplus               odin     1  95.02   \n",
       "5            Adam                 softplus               odin     2  98.39   \n",
       "6            Adam                     relu                mcd     0  98.21   \n",
       "7            Adam                     relu                mcd     1  99.09   \n",
       "8            Adam                     relu                mcd     2  97.89   \n",
       "9             SGD                     relu                mcd     0  98.82   \n",
       "10            SGD                     relu                mcd     1  95.97   \n",
       "11            SGD                     relu                mcd     2  98.45   \n",
       "12            SGD                     relu               odin     0  99.40   \n",
       "13            SGD                     relu               odin     1  99.62   \n",
       "14            SGD                     relu               odin     2  99.52   \n",
       "15            SGD                 softplus                mcd     0  98.29   \n",
       "16            SGD                 softplus                mcd     1  98.30   \n",
       "17            SGD                 softplus                mcd     2  96.59   \n",
       "18           Adam                     relu               odin     0  99.29   \n",
       "19           Adam                     relu               odin     1  99.26   \n",
       "20           Adam                     relu               odin     2  99.86   \n",
       "21           Adam                 softplus                mcd     0  94.48   \n",
       "22           Adam                 softplus                mcd     1  94.62   \n",
       "23           Adam                 softplus                mcd     2  95.93   \n",
       "\n",
       "      ACC  \n",
       "0   98.33  \n",
       "1   97.92  \n",
       "2   98.51  \n",
       "3   93.81  \n",
       "4   96.61  \n",
       "5   97.71  \n",
       "6   97.84  \n",
       "7   98.20  \n",
       "8   96.87  \n",
       "9   96.99  \n",
       "10  96.47  \n",
       "11  97.95  \n",
       "12  98.21  \n",
       "13  98.19  \n",
       "14  98.65  \n",
       "15  97.86  \n",
       "16  98.12  \n",
       "17  98.27  \n",
       "18  97.44  \n",
       "19  97.88  \n",
       "20  98.39  \n",
       "21  97.90  \n",
       "22  97.42  \n",
       "23  97.85  "
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_study_1 = load_results_into_df('mnist-study/')\n",
    "df_study_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "37b29ba6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>min</th>\n",
       "      <th>25%</th>\n",
       "      <th>50%</th>\n",
       "      <th>75%</th>\n",
       "      <th>max</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>optimizer_type</th>\n",
       "      <th>activation_function_type</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">Adam</th>\n",
       "      <th>relu</th>\n",
       "      <td>6.0</td>\n",
       "      <td>98.933333</td>\n",
       "      <td>0.738774</td>\n",
       "      <td>97.89</td>\n",
       "      <td>98.4300</td>\n",
       "      <td>99.175</td>\n",
       "      <td>99.2825</td>\n",
       "      <td>99.86</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>softplus</th>\n",
       "      <td>6.0</td>\n",
       "      <td>95.186667</td>\n",
       "      <td>1.894494</td>\n",
       "      <td>92.68</td>\n",
       "      <td>94.5150</td>\n",
       "      <td>94.820</td>\n",
       "      <td>95.7025</td>\n",
       "      <td>98.39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">SGD</th>\n",
       "      <th>relu</th>\n",
       "      <td>6.0</td>\n",
       "      <td>98.630000</td>\n",
       "      <td>1.379072</td>\n",
       "      <td>95.97</td>\n",
       "      <td>98.5425</td>\n",
       "      <td>99.110</td>\n",
       "      <td>99.4900</td>\n",
       "      <td>99.62</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>softplus</th>\n",
       "      <td>6.0</td>\n",
       "      <td>98.371667</td>\n",
       "      <td>0.963087</td>\n",
       "      <td>96.59</td>\n",
       "      <td>98.2925</td>\n",
       "      <td>98.475</td>\n",
       "      <td>99.0400</td>\n",
       "      <td>99.23</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         count       mean       std    min  \\\n",
       "optimizer_type activation_function_type                                      \n",
       "Adam           relu                        6.0  98.933333  0.738774  97.89   \n",
       "               softplus                    6.0  95.186667  1.894494  92.68   \n",
       "SGD            relu                        6.0  98.630000  1.379072  95.97   \n",
       "               softplus                    6.0  98.371667  0.963087  96.59   \n",
       "\n",
       "                                             25%     50%      75%    max  \n",
       "optimizer_type activation_function_type                                   \n",
       "Adam           relu                      98.4300  99.175  99.2825  99.86  \n",
       "               softplus                  94.5150  94.820  95.7025  98.39  \n",
       "SGD            relu                      98.5425  99.110  99.4900  99.62  \n",
       "               softplus                  98.2925  98.475  99.0400  99.23  "
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_study_1.groupby(['optimizer_type', 'activation_function_type'])['AUROC'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "999547f7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>min</th>\n",
       "      <th>25%</th>\n",
       "      <th>50%</th>\n",
       "      <th>75%</th>\n",
       "      <th>max</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>activation_function_type</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>relu</th>\n",
       "      <td>12.0</td>\n",
       "      <td>98.781667</td>\n",
       "      <td>1.066607</td>\n",
       "      <td>95.97</td>\n",
       "      <td>98.39</td>\n",
       "      <td>99.175</td>\n",
       "      <td>99.430</td>\n",
       "      <td>99.86</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>softplus</th>\n",
       "      <td>12.0</td>\n",
       "      <td>96.779167</td>\n",
       "      <td>2.195365</td>\n",
       "      <td>92.68</td>\n",
       "      <td>94.92</td>\n",
       "      <td>97.440</td>\n",
       "      <td>98.455</td>\n",
       "      <td>99.23</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                          count       mean       std    min    25%     50%  \\\n",
       "activation_function_type                                                     \n",
       "relu                       12.0  98.781667  1.066607  95.97  98.39  99.175   \n",
       "softplus                   12.0  96.779167  2.195365  92.68  94.92  97.440   \n",
       "\n",
       "                             75%    max  \n",
       "activation_function_type                 \n",
       "relu                      99.430  99.86  \n",
       "softplus                  98.455  99.23  "
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_study_1.groupby(['activation_function_type'])['AUROC'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "4784b707",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>min</th>\n",
       "      <th>25%</th>\n",
       "      <th>50%</th>\n",
       "      <th>75%</th>\n",
       "      <th>max</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>optimizer_type</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Adam</th>\n",
       "      <td>12.0</td>\n",
       "      <td>97.060000</td>\n",
       "      <td>2.389123</td>\n",
       "      <td>92.68</td>\n",
       "      <td>94.9200</td>\n",
       "      <td>98.050</td>\n",
       "      <td>99.1325</td>\n",
       "      <td>99.86</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SGD</th>\n",
       "      <td>12.0</td>\n",
       "      <td>98.500833</td>\n",
       "      <td>1.142051</td>\n",
       "      <td>95.97</td>\n",
       "      <td>98.2975</td>\n",
       "      <td>98.735</td>\n",
       "      <td>99.2725</td>\n",
       "      <td>99.62</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                count       mean       std    min      25%     50%      75%  \\\n",
       "optimizer_type                                                                \n",
       "Adam             12.0  97.060000  2.389123  92.68  94.9200  98.050  99.1325   \n",
       "SGD              12.0  98.500833  1.142051  95.97  98.2975  98.735  99.2725   \n",
       "\n",
       "                  max  \n",
       "optimizer_type         \n",
       "Adam            99.86  \n",
       "SGD             99.62  "
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_study_1.groupby(['optimizer_type'])['AUROC'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "7cba6e7b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>min</th>\n",
       "      <th>25%</th>\n",
       "      <th>50%</th>\n",
       "      <th>75%</th>\n",
       "      <th>max</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>postprocessor_type</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>mcd</th>\n",
       "      <td>12.0</td>\n",
       "      <td>97.220000</td>\n",
       "      <td>1.629311</td>\n",
       "      <td>94.48</td>\n",
       "      <td>95.960</td>\n",
       "      <td>98.050</td>\n",
       "      <td>98.3375</td>\n",
       "      <td>99.09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>odin</th>\n",
       "      <td>12.0</td>\n",
       "      <td>98.340833</td>\n",
       "      <td>2.191954</td>\n",
       "      <td>92.68</td>\n",
       "      <td>98.585</td>\n",
       "      <td>99.245</td>\n",
       "      <td>99.4300</td>\n",
       "      <td>99.86</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    count       mean       std    min     25%     50%  \\\n",
       "postprocessor_type                                                      \n",
       "mcd                  12.0  97.220000  1.629311  94.48  95.960  98.050   \n",
       "odin                 12.0  98.340833  2.191954  92.68  98.585  99.245   \n",
       "\n",
       "                        75%    max  \n",
       "postprocessor_type                  \n",
       "mcd                 98.3375  99.09  \n",
       "odin                99.4300  99.86  "
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_study_1.groupby(['postprocessor_type'])['AUROC'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "3b18798c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def perform_oodn_analysis_on_preloaded_model(model_path, dataset_name, postprocessor_type, id_test, ood_test):\n",
    "    model = torch.load(model_path)\n",
    "    return calculate_oodn_metrics(model,\n",
    "                                   postprocessor_type,\n",
    "                                   id_test,\n",
    "                                   ood_test,\n",
    "                                   dataset_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "b1805c49",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Performing inference on batch: 0\n",
      "Performing inference on batch: 50\n",
      "Performing inference on batch: 0\n",
      "Performing inference on batch: 50\n",
      "FPR@95: 45.00, AUROC: 92.68 AUPR_IN: 93.77, AUPR_OUT: 91.00\n",
      "CCR: 1.08, 25.41, 51.53, 82.04, ACC: 95.29\n",
      "──────────────────────────────────────────────────────────────────────\n"
     ]
    }
   ],
   "source": [
    "perform_oodn_analysis_on_preloaded_model('/home/rdr2143/cifar_resnet50_odin_relu_SGD_0.pkl', 'odin', )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "a8fba289",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Performing inference on batch: 0\n",
      "Performing inference on batch: 50\n",
      "Performing inference on batch: 0\n",
      "Performing inference on batch: 50\n",
      "FPR@95: 30.70, AUROC: 93.93 AUPR_IN: 94.30, AUPR_OUT: 93.41\n",
      "CCR: 3.44, 20.72, 50.02, 81.76, ACC: 95.28\n",
      "──────────────────────────────────────────────────────────────────────\n"
     ]
    }
   ],
   "source": [
    "perform_oodn_analysis_on_preloaded_model('models/lenet_mnist_softplus_Adam_0.pkl', config_1a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e1cb4be",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
