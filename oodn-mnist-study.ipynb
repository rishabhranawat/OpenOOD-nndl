{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e9c08843",
   "metadata": {},
   "source": [
    "### Exploring The Impact of Optimizers and Activation Functions On OODN "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9b10d253",
   "metadata": {},
   "outputs": [],
   "source": [
    "from os import listdir\n",
    "\n",
    "import time\n",
    "import json\n",
    "\n",
    "import torch\n",
    "\n",
    "from torchvision.datasets import mnist, FashionMNIST\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision.transforms import ToTensor\n",
    "from torch.optim import SGD, Adam\n",
    "from torch.nn import Module\n",
    "from torch import nn\n",
    "from torch.nn import CrossEntropyLoss\n",
    "from torchvision.models.resnet import Bottleneck, ResNet\n",
    "\n",
    "from wilds import get_dataset\n",
    "from wilds.common.data_loaders import get_train_loader\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from openood.evaluators import metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "656f1978",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0\n"
     ]
    }
   ],
   "source": [
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1560babc",
   "metadata": {},
   "source": [
    "### Supported Activation Functions\n",
    "\n",
    "For activation functions, we are considering ReLU, Softplus, Swish. *Note that we may conduct experiments for a subset based on the compute resources available*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3313226f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_activation_fn(activation):\n",
    "    if activation == 'relu':\n",
    "        return nn.ReLU()\n",
    "    elif activation == 'softplus':\n",
    "        return nn.Softplus()\n",
    "    elif activation == 'swish':\n",
    "        return nn.Swish()\n",
    "    return None"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45540f49",
   "metadata": {},
   "source": [
    "### Supported Networks\n",
    "\n",
    "Currently, we support LeNet and ResNet50."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf27a4d4",
   "metadata": {},
   "source": [
    "### LeNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0beec4a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LeNet(nn.Module):\n",
    "    def __init__(self, num_classes, num_channel=3, activation='relu'):\n",
    "        super(LeNet, self).__init__()\n",
    "        self.num_classes = num_classes\n",
    "        self.feature_size = 84\n",
    "        self.block1 = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=num_channel,\n",
    "                      out_channels=6,\n",
    "                      kernel_size=5,\n",
    "                      stride=1,\n",
    "                      padding=2), get_activation_fn(activation), nn.MaxPool2d(kernel_size=2))\n",
    "\n",
    "        self.block2 = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=6, out_channels=16, kernel_size=5, stride=1),\n",
    "             get_activation_fn(activation), nn.MaxPool2d(kernel_size=2))\n",
    "\n",
    "        self.block3 = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=16,\n",
    "                      out_channels=120,\n",
    "                      kernel_size=5,\n",
    "                      stride=1), get_activation_fn(activation))\n",
    "\n",
    "        self.classifier1 = nn.Linear(in_features=120, out_features=84)\n",
    "        self.relu = get_activation_fn(activation)\n",
    "        self.fc = nn.Linear(in_features=84, out_features=num_classes)\n",
    "\n",
    "    def get_fc(self):\n",
    "        fc = self.fc\n",
    "        return fc.weight.cpu().detach().numpy(), fc.bias.cpu().detach().numpy()\n",
    "\n",
    "    def forward(self, x, return_feature=False, return_feature_list=False):\n",
    "        feature1 = self.block1(x)\n",
    "        feature2 = self.block2(feature1)\n",
    "        feature3 = self.block3(feature2)\n",
    "        feature3 = feature3.view(feature3.shape[0], -1)\n",
    "        feature = self.relu(self.classifier1(feature3))\n",
    "        logits_cls = self.fc(feature)\n",
    "        feature_list = [feature1, feature2, feature3, feature]\n",
    "        if return_feature:\n",
    "            return logits_cls, feature\n",
    "        elif return_feature_list:\n",
    "            return logits_cls, feature_list\n",
    "        else:\n",
    "            return logits_cls\n",
    "\n",
    "    def forward_threshold(self, x, threshold):\n",
    "        feature1 = self.block1(x)\n",
    "        feature2 = self.block2(feature1)\n",
    "        feature3 = self.block3(feature2)\n",
    "        feature3 = feature3.view(feature3.shape[0], -1)\n",
    "        feature = self.relu(self.classifier1(feature3))\n",
    "        feature = feature.clip(max=threshold)\n",
    "        logits_cls = self.fc(feature)\n",
    "\n",
    "        return logits_cls"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09018e71",
   "metadata": {},
   "source": [
    "### ResNet50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "fe9cc86f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResNet50(ResNet):\n",
    "    def __init__(self,\n",
    "                 block=Bottleneck,\n",
    "                 layers=[3, 4, 6, 3],\n",
    "                 num_classes=1000):\n",
    "        super(ResNet50, self).__init__(block=block,\n",
    "                                       layers=layers,\n",
    "                                       num_classes=num_classes)\n",
    "        self.feature_size = 2048\n",
    "\n",
    "\n",
    "    def forward(self, x, return_feature=False, return_feature_list=False):\n",
    "        feature1 = self.relu(self.bn1(self.conv1(x)))\n",
    "        feature1 = self.maxpool(feature1)\n",
    "        feature2 = self.layer1(feature1)\n",
    "        feature3 = self.layer2(feature2)\n",
    "        feature4 = self.layer3(feature3)\n",
    "        feature5 = self.layer4(feature4)\n",
    "        feature5 = self.avgpool(feature5)\n",
    "        feature = feature5.view(feature5.size(0), -1)\n",
    "        logits_cls = self.fc(feature)\n",
    "\n",
    "        feature_list = [feature1, feature2, feature3, feature4, feature5]\n",
    "        if return_feature:\n",
    "            return logits_cls, feature\n",
    "        elif return_feature_list:\n",
    "            return logits_cls, feature_list\n",
    "        else:\n",
    "            return logits_cls\n",
    "\n",
    "    def forward_threshold(self, x, threshold):\n",
    "        feature1 = self.relu(self.bn1(self.conv1(x)))\n",
    "        feature1 = self.maxpool(feature1)\n",
    "        feature2 = self.layer1(feature1)\n",
    "        feature3 = self.layer2(feature2)\n",
    "        feature4 = self.layer3(feature3)\n",
    "        feature5 = self.layer4(feature4)\n",
    "        feature5 = self.avgpool(feature5)\n",
    "        feature = feature5.clip(max=threshold)\n",
    "        feature = feature.view(feature.size(0), -1)\n",
    "        logits_cls = self.fc(feature)\n",
    "\n",
    "        return logits_cls\n",
    "\n",
    "    def get_fc(self):\n",
    "        fc = self.fc\n",
    "        return fc.weight.cpu().detach().numpy(), fc.bias.cpu().detach().numpy()\n",
    "    \n",
    "def get_resnet_model(activation_function_type, n_classes):\n",
    "    resnet_model = ResNet50(num_classes=n_classes)\n",
    "    resnet_model.to(device)    \n",
    "    return resnet_model\n",
    "\n",
    "def set_activation_function(resnet_model, activation_function_type):\n",
    "    resnet_model.relu = get_activation_fn(activation_function_type)\n",
    "    resnet_model.layer1[0].relu = get_activation_fn(activation_function_type)\n",
    "    resnet_model.layer1[1].relu = get_activation_fn(activation_function_type)\n",
    "    resnet_model.layer1[2].relu = get_activation_fn(activation_function_type)\n",
    "\n",
    "    resnet_model.layer2[0].relu = get_activation_fn(activation_function_type)\n",
    "    resnet_model.layer2[1].relu = get_activation_fn(activation_function_type)\n",
    "    resnet_model.layer2[2].relu = get_activation_fn(activation_function_type)\n",
    "    resnet_model.layer2[3].relu = get_activation_fn(activation_function_type)\n",
    "\n",
    "    resnet_model.layer3[0].relu = get_activation_fn(activation_function_type)\n",
    "    resnet_model.layer3[1].relu = get_activation_fn(activation_function_type)\n",
    "    resnet_model.layer3[2].relu = get_activation_fn(activation_function_type)\n",
    "    resnet_model.layer3[3].relu = get_activation_fn(activation_function_type)\n",
    "    resnet_model.layer3[4].relu = get_activation_fn(activation_function_type)\n",
    "    resnet_model.layer3[5].relu = get_activation_fn(activation_function_type)\n",
    "\n",
    "\n",
    "    resnet_model.layer4[0].relu = get_activation_fn(activation_function_type)\n",
    "    resnet_model.layer4[1].relu = get_activation_fn(activation_function_type)\n",
    "    resnet_model.layer4[2].relu = get_activation_fn(activation_function_type)\n",
    "    \n",
    "    return resnet_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ed366e10",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_model(config):\n",
    "    activation_function_type = config[\"activation_function_type\"]\n",
    "    network_type = config[\"network\"]\n",
    "    n_classes = config[\"n_classes\"]\n",
    "    \n",
    "    if network_type == \"lenet\":\n",
    "        model =  LeNet(num_classes=n_classes, num_channel=1, activation=activation_function_type)\n",
    "    elif network_type == \"resnet50\":\n",
    "        model = get_resnet_model(activation_function_type, n_classes)\n",
    "    else:\n",
    "        raise Exception(\"Currently we only support lenet or resnet50\")\n",
    "    \n",
    "    return model\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d03e75b",
   "metadata": {},
   "source": [
    "### Supported Post-Hoc OODN Processors"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7324715e",
   "metadata": {},
   "source": [
    "#### The first post processor we consider is ODIN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "98e8b33e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class OODPostprocessor():\n",
    "    \n",
    "    def inference(self, net: nn.Module, data_loader: DataLoader):\n",
    "        pred_list, conf_list, label_list = [], [], []\n",
    "        for idx, loaded_data in enumerate(data_loader):\n",
    "            data, label = loaded_data[0], loaded_data[1]\n",
    "            if idx % 50 == 0:\n",
    "                print(f'Performing inference on batch: {idx}')\n",
    "            pred, conf = self.postprocess(net, data.to(device))\n",
    "            for idx in range(len(data)):\n",
    "                pred_list.append(pred[idx].tolist())\n",
    "                conf_list.append(conf[idx].tolist())\n",
    "                label_list.append(label[idx].tolist())\n",
    "\n",
    "        # convert values into numpy array\n",
    "        pred_list = np.array(pred_list, dtype=int)\n",
    "        conf_list = np.array(conf_list)\n",
    "        label_list = np.array(label_list, dtype=int)\n",
    "\n",
    "        return pred_list, conf_list, label_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "52873040",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ODINPostprocessor(OODPostprocessor):\n",
    "    def __init__(self, temperature, noise):\n",
    "        super(OODPostprocessor)\n",
    "        self.temperature = temperature\n",
    "        self.noise = noise\n",
    "        \n",
    "    def postprocess(self, net: nn.Module, data):\n",
    "        net.eval()\n",
    "        data.requires_grad = True\n",
    "        output = net(data)\n",
    "\n",
    "        # Calculating the perturbation we need to add, that is,\n",
    "        # the sign of gradient of cross entropy loss w.r.t. input\n",
    "        criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "        labels = output.detach().argmax(axis=1)\n",
    "\n",
    "        # Using temperature scaling\n",
    "        output = output / self.temperature\n",
    "\n",
    "        loss = criterion(output, labels)\n",
    "        loss.backward()\n",
    "\n",
    "        # Normalizing the gradient to binary in {0, 1}\n",
    "        gradient = torch.ge(data.grad.detach(), 0)\n",
    "        gradient = (gradient.float() - 0.5) * 2\n",
    "\n",
    "        # Scaling values taken from original code       \n",
    "        gradient[:, 0] = (gradient[:, 0]) / (63.0 / 255.0)\n",
    "        if gradient.shape[1] == 3:\n",
    "            gradient[:, 1] = (gradient[:, 1]) / (62.1 / 255.0)\n",
    "            gradient[:, 2] = (gradient[:, 2]) / (66.7 / 255.0)\n",
    "\n",
    "        # Adding small perturbations to images\n",
    "        tempInputs = torch.add(data.detach(), gradient, alpha=-self.noise)\n",
    "        output = net(tempInputs)\n",
    "        output = output / self.temperature\n",
    "\n",
    "        # Calculating the confidence after adding perturbations\n",
    "        nnOutput = output.detach()\n",
    "        nnOutput = nnOutput - nnOutput.max(dim=1, keepdims=True).values\n",
    "        nnOutput = nnOutput.exp() / nnOutput.exp().sum(dim=1, keepdims=True)\n",
    "\n",
    "        conf, pred = nnOutput.max(dim=1)\n",
    "\n",
    "        return pred, conf"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d1d6994",
   "metadata": {},
   "source": [
    "#### We consider the Maximum Classifier Discrepancy Post OODN method\n",
    "\n",
    "https://arxiv.org/pdf/1712.02560.pdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "1ccac9d5",
   "metadata": {
    "id": "7L45tl2cRbdX",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "class MCDPostprocessor(OODPostprocessor):\n",
    "    def __init__(self, samples: int = 30):\n",
    "        super(OODPostprocessor)\n",
    "        self.samples = samples  #: number :math:`N` of samples\n",
    "\n",
    "    def postprocess(self, model: torch.nn.Module, x: torch.Tensor) -> torch.Tensor:\n",
    "        mode_switch = False\n",
    "        if not model.training:\n",
    "            mode_switch = True\n",
    "\n",
    "            model.train()\n",
    "\n",
    "            for mod in model.modules():\n",
    "                # reset batch norm layers.\n",
    "                # TODO: are there other layers?\n",
    "                if isinstance(mod, (nn.BatchNorm1d, nn.BatchNorm2d, nn.BatchNorm3d)):\n",
    "                    mod.train(False)\n",
    "\n",
    "        results = None\n",
    "        with torch.no_grad():\n",
    "            for i in range(self.samples):\n",
    "                output = model(x).softmax(dim=1)\n",
    "                if results is None:\n",
    "                    results = torch.zeros(size=output.shape).to(device)\n",
    "                results += output\n",
    "        results /= self.samples\n",
    "\n",
    "        if mode_switch:\n",
    "            model.eval()\n",
    "        \n",
    "        conf, pred = results.max(dim=1)\n",
    "\n",
    "        return pred, conf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "9b35a9a1",
   "metadata": {
    "id": "0NHU_CaCRbdX",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def get_postprocessor(postprocessor_type=\"odin\"):\n",
    "    if postprocessor_type == \"odin\":\n",
    "        postprocessor = ODINPostprocessor(1000, 0.0014)\n",
    "    elif postprocessor_type == \"mcd\":\n",
    "        postprocessor = MCDPostprocessor(30)\n",
    "    return postprocessor"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "338742a6",
   "metadata": {},
   "source": [
    "### Supported Out of Distribution Detection Metrics\n",
    "\n",
    "What metrics do we specifically care about here?\n",
    "\n",
    "**FPR@95** measures the false positive rate (FPR) when the true positive rate (TPR) is\n",
    "equal to 95%. Lower scores indicate better performance. \n",
    "\n",
    "**AUROC** measures the area under the\n",
    "Receiver Operating Characteristic (ROC) curve, which displays the relationship between TPR and\n",
    "FPR. The area under the ROC curve can be interpreted as the probability that a positive ID example\n",
    "will have a higher detection score than a negative OOD example. \n",
    "\n",
    "**AUPR** measures the area under\n",
    "the Precision-Recall (PR) curve. The PR curve is created by plotting precision versus recall. Similar\n",
    "to AUROC, we consider ID samples as positive, so that the score corresponds to the AUPR-In metric\n",
    "in some works"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "c5d6c1d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_oodn_metrics(model, postprocessor_type, id_test_loader, ood_test_loader, ood_name):\n",
    "    postprocessor = get_postprocessor(postprocessor_type)\n",
    "    id_pred, id_conf, id_gt = postprocessor.inference(\n",
    "                model, id_test_loader)\n",
    "\n",
    "    ood_pred, ood_conf, ood_gt = postprocessor.inference(\n",
    "        model, ood_test_loader)\n",
    "\n",
    "    ood_gt = -1 * np.ones_like(ood_gt)  # hard set to -1 as ood\n",
    "    pred = np.concatenate([id_pred, ood_pred])\n",
    "    conf = np.concatenate([id_conf, ood_conf])\n",
    "    label = np.concatenate([id_gt, ood_gt])\n",
    "    ood_metrics = metrics.compute_all_metrics(conf, label, pred)\n",
    "\n",
    "    return print_and_get_formatted_metrics(ood_metrics, ood_name)\n",
    "\n",
    "def print_and_get_formatted_metrics(metrics, dataset_name):\n",
    "    [fpr, auroc, aupr_in, aupr_out,\n",
    "     ccr_4, ccr_3, ccr_2, ccr_1, accuracy] \\\n",
    "     = metrics\n",
    "\n",
    "    write_content = {\n",
    "        'dataset': dataset_name,\n",
    "        'FPR@95': '{:.2f}'.format(100 * fpr),\n",
    "        'AUROC': '{:.2f}'.format(100 * auroc),\n",
    "        'AUPR_IN': '{:.2f}'.format(100 * aupr_in),\n",
    "        'AUPR_OUT': '{:.2f}'.format(100 * aupr_out),\n",
    "        'CCR_4': '{:.2f}'.format(100 * ccr_4),\n",
    "        'CCR_3': '{:.2f}'.format(100 * ccr_3),\n",
    "        'CCR_2': '{:.2f}'.format(100 * ccr_2),\n",
    "        'CCR_1': '{:.2f}'.format(100 * ccr_1),\n",
    "        'ACC': '{:.2f}'.format(100 * accuracy)\n",
    "    }\n",
    "\n",
    "    fieldnames = list(write_content.keys())\n",
    "\n",
    "    # print ood metric results\n",
    "    print('FPR@95: {:.2f}, AUROC: {:.2f}'.format(100 * fpr, 100 * auroc),\n",
    "          end=' ',\n",
    "          flush=True)\n",
    "    print('AUPR_IN: {:.2f}, AUPR_OUT: {:.2f}'.format(\n",
    "        100 * aupr_in, 100 * aupr_out),\n",
    "          flush=True)\n",
    "    print('CCR: {:.2f}, {:.2f}, {:.2f}, {:.2f},'.format(\n",
    "        ccr_4 * 100, ccr_3 * 100, ccr_2 * 100, ccr_1 * 100),\n",
    "          end=' ',\n",
    "          flush=True)\n",
    "    print('ACC: {:.2f}'.format(accuracy * 100), flush=True)\n",
    "    print(u'\\u2500' * 70, flush=True)\n",
    "    return write_content\n",
    "\n",
    "def load_results_into_df(dir_path):\n",
    "    res_files = [dir_path+each for each in listdir(dir_path)]\n",
    "    all_results = []\n",
    "    columns = ['optimizer_type', 'activation_function_type', 'postprocessor_type', 'trial', 'AUROC']\n",
    "    for fp in res_files:\n",
    "        f = open(fp)\n",
    "        data = json.load(f)\n",
    "        for trial, results in data.items():\n",
    "            all_results.append([\n",
    "                    results['optimizer_type'],\n",
    "                    results['activation_function_type'],\n",
    "                    results['postprocessor_type'],\n",
    "                    trial,\n",
    "                    float(results['AUROC'])\n",
    "                ])\n",
    "    df = pd.DataFrame(all_results, columns=columns)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "f872ebda",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_optimizer(model, config):\n",
    "    params = model.parameters()\n",
    "    lr = config['lr']\n",
    "    momentum = config['momentum']\n",
    "    weight_decay = config['weight_decay']\n",
    "    optimizer_type = config['optimizer_type']\n",
    "    \n",
    "    print(f'Getting optimizer for type: {optimizer_type}...')\n",
    "    if optimizer_type == 'SGD':\n",
    "        return SGD(params, \n",
    "              lr=lr, \n",
    "              momentum=momentum,\n",
    "              weight_decay=weight_decay)\n",
    "    elif optimizer_type == 'Adam':\n",
    "        return Adam(params, \n",
    "                    lr=lr, \n",
    "                    weight_decay=weight_decay)\n",
    "    else:\n",
    "        raise Exception(\"Invalid optimizer_type provided, only SGD and Adam are supported currently\")\n",
    "\n",
    "def get_wilds_loader(dataset, split, batch_size):\n",
    "    d = dataset.get_subset(\n",
    "        split,\n",
    "        frac=0.1,\n",
    "        transform=transforms.Compose(\n",
    "            [transforms.Resize((448, 448)), transforms.ToTensor()]\n",
    "        ),\n",
    "    )\n",
    "    # Prepare the standard data loader\n",
    "    return get_train_loader(\"standard\", d, batch_size=batch_size, num_workers=4, pin_memory=True)\n",
    "\n",
    "def get_data_loaders(config):\n",
    "    data_loaders = {}\n",
    "    dataset_name = config[\"dataset_name\"]\n",
    "    dataset_type = config[\"dataset_type\"]\n",
    "    batch_size = config['batch_size']\n",
    "    \n",
    "    wilds_id_test_split = \"id_val\" if dataset_name == \"camelyon17\" else \"id_test\"\n",
    "    if dataset_type == \"wilds\":\n",
    "        # wilds dataset\n",
    "        dataset = get_dataset(dataset=dataset_name, download=True)\n",
    "        \n",
    "        data_loaders[\"train\"] = get_wilds_loader(dataset, \"train\", batch_size)\n",
    "        data_loaders[\"ood_test\"] = get_wilds_loader(dataset, \"test\", batch_size)\n",
    "        data_loaders[\"id_test\"] = get_wilds_loader(dataset, wilds_id_test_split, batch_size)\n",
    "    elif dataset_name == \"mnist\":\n",
    "        # mnist dataset\n",
    "        train_dataset = mnist.MNIST(root='data', download=True, train=True, transform=ToTensor())\n",
    "        test_dataset = mnist.MNIST(root='data', download=True, train=False, transform=ToTensor())\n",
    "        fashion_test_dataset = mnist.FashionMNIST(root='data', download=True,train=False,transform=ToTensor())\n",
    "\n",
    "        data_loaders[\"train\"] = DataLoader(train_dataset, batch_size=batch_size)\n",
    "        data_loaders[\"id_test\"] = DataLoader(test_dataset, batch_size=batch_size)\n",
    "        data_loaders[\"ood_test\"] = DataLoader(fashion_test_dataset, batch_size=batch_size)\n",
    "    \n",
    "    return data_loaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "ee26224e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_resnet_model_given_opti_activation_fn(config):\n",
    "    # get the train loader\n",
    "    train_loader = config[\"data_loaders\"][\"train\"]\n",
    "    \n",
    "    # get the resnet model with the replaced activation functions\n",
    "    model = get_model(config)\n",
    "    model.to(device)\n",
    "    \n",
    "    # get the optimizer\n",
    "    sgd = get_optimizer(model, config)\n",
    "    \n",
    "    loss_fn = CrossEntropyLoss()\n",
    "\n",
    "    for current_epoch in range(config['epochs']):\n",
    "        model.train()\n",
    "        epoch_start = time.time()\n",
    "        print('Training epoch: {}'.format(current_epoch))\n",
    "        \n",
    "        time_per_hundred = time.time()\n",
    "        for idx, (loader_data) in enumerate(train_loader):\n",
    "            train_x, train_label = loader_data[0].cuda(), loader_data[1].cuda()\n",
    "            sgd.zero_grad()\n",
    "            predict_y = model(train_x.float())\n",
    "            loss = loss_fn(predict_y, train_label.long())\n",
    "            if idx % 100 == 0:\n",
    "                print('idx: {}, loss: {}, time taken: {}'.format(idx, loss.sum().item(), time.time()-time_per_hundred))\n",
    "                time_per_hundred = time.time()\n",
    "            loss.backward()\n",
    "            sgd.step()\n",
    "        print(f\"Time take for epoch {current_epoch}: {time.time() - epoch_start}s\")\n",
    "    \n",
    "    torch.save(model, config['model_name'])\n",
    "    return model\n",
    "\n",
    "def run_full_oodn_pipeline(config):\n",
    "    metrics = {}\n",
    "    for i in range(config[\"trials\"]):\n",
    "        t = time.time()\n",
    "        model_name = f\"models/{config['dataset_name']}_{config['network']}_{config['postprocessor_type']}_{config['activation_function_type']}_{config['optimizer_type']}_{i}.pkl\"\n",
    "        print(f'Running model: {model_name}...')\n",
    "        config['model_name'] = model_name\n",
    "        # train model\n",
    "        model = train_resnet_model_given_opti_activation_fn(config)\n",
    "        # calculate oodn metrics\n",
    "        metrics[i] = calculate_oodn_metrics(model,\n",
    "                               config['postprocessor_type'],\n",
    "                               config[\"data_loaders\"][\"id_test\"], \n",
    "                               config[\"data_loaders\"][\"ood_test\"], \n",
    "                               config[\"dataset_name\"])\n",
    "        metrics[i]['optimizer_type'] = config['optimizer_type']\n",
    "        metrics[i]['activation_function_type'] = config['activation_function_type']\n",
    "        metrics[i]['postprocessor_type'] = config['postprocessor_type']\n",
    "        metrics[i]['time_taken'] = time.time() - t\n",
    "        print(f\"Time taken to train: {metrics[i]['time_taken']}\")\n",
    "        \n",
    "    experiment_name = f\"{config['results_dir']}/{config['dataset_name']}_{config['network']}_{config['postprocessor_type']}_{config['activation_function_type']}_{config['optimizer_type']}.json\"\n",
    "    with open(experiment_name, 'w') as fp:\n",
    "        json.dump(metrics, fp)\n",
    "    return metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c992663",
   "metadata": {},
   "source": [
    "### Study 1: LeNet5, MNIST as the ID Dataset, FashionMNIST as the OOD Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae7e58bf",
   "metadata": {},
   "source": [
    "#### Study 1(a): Combination: SGD + ReLU"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c41a53f",
   "metadata": {},
   "source": [
    "#### ODIN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "de1880d7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "config_1a = {\n",
    "    \"batch_size\": 128,\n",
    "    \"n_classes\": 10,\n",
    "    \"dataset_name\": \"mnist\",\n",
    "    \"epochs\": 10,\n",
    "    \"version\": time.time(),\n",
    "    \"lr\": 0.1,\n",
    "    \"momentum\": 0.9,\n",
    "    \"weight_decay\": 0.0005,\n",
    "    \"optimizer_type\": \"SGD\",\n",
    "    \"activation_function_type\": \"relu\",\n",
    "    \"network\": \"lenet\",\n",
    "    \"postprocessor_type\": \"odin\",\n",
    "    \"dataset_type\": \"mnist\",\n",
    "    \"trials\": 3,\n",
    "    \"results_dir\": \"mnist-study\"\n",
    "}\n",
    "config_1a[\"data_loaders\"] = get_data_loaders(config_1a)\n",
    "run_full_oodn_pipeline(config_1a)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e36392b7",
   "metadata": {},
   "source": [
    "#### MCD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "71e60745",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running model: models/mnist_lenet_mcd_relu_SGD_0.pkl...\n",
      "Getting optimizer for type: SGD...\n",
      "Training epoch: 0\n",
      "idx: 0, loss: 2.2967536449432373, time taken: 0.00898599624633789\n",
      "idx: 100, loss: 0.2458113431930542, time taken: 0.9537761211395264\n",
      "idx: 200, loss: 0.3505885601043701, time taken: 0.9808645248413086\n",
      "idx: 300, loss: 0.09110728651285172, time taken: 0.9493944644927979\n",
      "idx: 400, loss: 0.23323051631450653, time taken: 0.9486937522888184\n",
      "Time take for epoch 0: 4.483798027038574s\n",
      "Training epoch: 1\n",
      "idx: 0, loss: 0.07201088964939117, time taken: 0.008733272552490234\n",
      "idx: 100, loss: 0.11222241073846817, time taken: 0.9483945369720459\n",
      "idx: 200, loss: 0.06680341809988022, time taken: 0.9406368732452393\n",
      "idx: 300, loss: 0.06127895787358284, time taken: 0.9487392902374268\n",
      "idx: 400, loss: 0.3410691022872925, time taken: 0.9534344673156738\n",
      "Time take for epoch 1: 4.442000865936279s\n",
      "Training epoch: 2\n",
      "idx: 0, loss: 0.055400170385837555, time taken: 0.008737564086914062\n",
      "idx: 100, loss: 0.02290661819279194, time taken: 0.9290652275085449\n",
      "idx: 200, loss: 0.07176447659730911, time taken: 0.945462703704834\n",
      "idx: 300, loss: 0.08365117013454437, time taken: 0.960151195526123\n",
      "idx: 400, loss: 0.09648090600967407, time taken: 0.9333670139312744\n",
      "Time take for epoch 2: 4.414436101913452s\n",
      "Training epoch: 3\n",
      "idx: 0, loss: 0.045817840844392776, time taken: 0.008496522903442383\n",
      "idx: 100, loss: 0.023358860984444618, time taken: 0.9361839294433594\n",
      "idx: 200, loss: 0.03861464932560921, time taken: 0.9970321655273438\n",
      "idx: 300, loss: 0.06564550846815109, time taken: 0.9623079299926758\n",
      "idx: 400, loss: 0.17362019419670105, time taken: 0.9476156234741211\n",
      "Time take for epoch 3: 4.50759482383728s\n",
      "Training epoch: 4\n",
      "idx: 0, loss: 0.08390820771455765, time taken: 0.008736371994018555\n",
      "idx: 100, loss: 0.018519507721066475, time taken: 0.9861471652984619\n",
      "idx: 200, loss: 0.05796099081635475, time taken: 1.1251065731048584\n",
      "idx: 300, loss: 0.05274789780378342, time taken: 0.9410617351531982\n",
      "idx: 400, loss: 0.08641698211431503, time taken: 0.9315786361694336\n",
      "Time take for epoch 4: 4.629573106765747s\n",
      "Training epoch: 5\n",
      "idx: 0, loss: 0.056848276406526566, time taken: 0.008585929870605469\n",
      "idx: 100, loss: 0.03158925473690033, time taken: 0.9505705833435059\n",
      "idx: 200, loss: 0.06864004582166672, time taken: 0.9398667812347412\n",
      "idx: 300, loss: 0.03369897976517677, time taken: 0.9371814727783203\n",
      "idx: 400, loss: 0.11928463727235794, time taken: 0.9435670375823975\n",
      "Time take for epoch 5: 4.426197290420532s\n",
      "Training epoch: 6\n",
      "idx: 0, loss: 0.06169016286730766, time taken: 0.008912801742553711\n",
      "idx: 100, loss: 0.017717765644192696, time taken: 0.9501421451568604\n",
      "idx: 200, loss: 0.03796439617872238, time taken: 0.9606108665466309\n",
      "idx: 300, loss: 0.03252572566270828, time taken: 0.9502558708190918\n",
      "idx: 400, loss: 0.14608724415302277, time taken: 0.9443891048431396\n",
      "Time take for epoch 6: 4.456597089767456s\n",
      "Training epoch: 7\n",
      "idx: 0, loss: 0.06376795470714569, time taken: 0.008582592010498047\n",
      "idx: 100, loss: 0.0323333665728569, time taken: 0.9461205005645752\n",
      "idx: 200, loss: 0.06203601509332657, time taken: 0.9594664573669434\n",
      "idx: 300, loss: 0.03695741295814514, time taken: 0.9634792804718018\n",
      "idx: 400, loss: 0.12061966955661774, time taken: 0.9512271881103516\n",
      "Time take for epoch 7: 4.496336936950684s\n",
      "Training epoch: 8\n",
      "idx: 0, loss: 0.033364053815603256, time taken: 0.00867319107055664\n",
      "idx: 100, loss: 0.051908835768699646, time taken: 0.9452602863311768\n",
      "idx: 200, loss: 0.06971181929111481, time taken: 0.9488484859466553\n",
      "idx: 300, loss: 0.03672059252858162, time taken: 0.9474647045135498\n",
      "idx: 400, loss: 0.07228036969900131, time taken: 0.9472620487213135\n",
      "Time take for epoch 8: 4.438705682754517s\n",
      "Training epoch: 9\n",
      "idx: 0, loss: 0.041725702583789825, time taken: 0.008530616760253906\n",
      "idx: 100, loss: 0.02410748600959778, time taken: 0.9462952613830566\n",
      "idx: 200, loss: 0.04245642200112343, time taken: 0.949343204498291\n",
      "idx: 300, loss: 0.048512060195207596, time taken: 0.969961404800415\n",
      "idx: 400, loss: 0.05038805678486824, time taken: 0.9528505802154541\n",
      "Time take for epoch 9: 4.46688175201416s\n",
      "Using MCD OOD Postprocess...\n",
      "Performing inference on batch: 0\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "postprocess() takes 2 positional arguments but 3 were given",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_13316/2779243297.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     17\u001b[0m }\n\u001b[1;32m     18\u001b[0m \u001b[0mconfig_1_1a\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"data_loaders\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_data_loaders\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconfig_1_1a\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m \u001b[0mrun_full_oodn_pipeline\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconfig_1_1a\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/tmp/ipykernel_13316/3821424809.py\u001b[0m in \u001b[0;36mrun_full_oodn_pipeline\u001b[0;34m(config)\u001b[0m\n\u001b[1;32m     47\u001b[0m                                \u001b[0mconfig\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"data_loaders\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"id_test\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     48\u001b[0m                                \u001b[0mconfig\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"data_loaders\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"ood_test\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 49\u001b[0;31m                                config[\"dataset_name\"])\n\u001b[0m\u001b[1;32m     50\u001b[0m         \u001b[0mmetrics\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'optimizer_type'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'optimizer_type'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m         \u001b[0mmetrics\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'activation_function_type'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'activation_function_type'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_13316/3652814332.py\u001b[0m in \u001b[0;36mcalculate_oodn_metrics\u001b[0;34m(model, postprocessor_type, id_test_loader, ood_test_loader, ood_name)\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0mpostprocessor\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_postprocessor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpostprocessor_type\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     id_pred, id_conf, id_gt = postprocessor.inference(\n\u001b[0;32m----> 4\u001b[0;31m                 model, id_test_loader)\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m     ood_pred, ood_conf, ood_gt = postprocessor.inference(\n",
      "\u001b[0;32m/tmp/ipykernel_13316/3365483331.py\u001b[0m in \u001b[0;36minference\u001b[0;34m(self, net, data_loader)\u001b[0m\n\u001b[1;32m     37\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0midx\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;36m50\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m                 \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'Performing inference on batch: {idx}'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 39\u001b[0;31m             \u001b[0mpred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpostprocess\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnet\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     40\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     41\u001b[0m                 \u001b[0mpred_list\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpred\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtolist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: postprocess() takes 2 positional arguments but 3 were given"
     ]
    }
   ],
   "source": [
    "config_1_1a = {\n",
    "    \"batch_size\": 128,\n",
    "    \"n_classes\": 10,\n",
    "    \"dataset_name\": \"mnist\",\n",
    "    \"epochs\": 10,\n",
    "    \"version\": time.time(),\n",
    "    \"lr\": 0.1,\n",
    "    \"momentum\": 0.9,\n",
    "    \"weight_decay\": 0.0005,\n",
    "    \"optimizer_type\": \"SGD\",\n",
    "    \"activation_function_type\": \"relu\",\n",
    "    \"network\": \"lenet\",\n",
    "    \"postprocessor_type\": \"mcd\",\n",
    "    \"dataset_type\": \"mnist\",\n",
    "    \"trials\": 3,\n",
    "    \"results_dir\": \"mnist-study\"\n",
    "}\n",
    "config_1_1a[\"data_loaders\"] = get_data_loaders(config_1_1a)\n",
    "run_full_oodn_pipeline(config_1_1a)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2be2d7df",
   "metadata": {},
   "source": [
    "#### 1 (b) SGD + SoftPlus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7a3ae7d8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/torchvision/datasets/mnist.py:498: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  ../torch/csrc/utils/tensor_numpy.cpp:180.)\n",
      "  return torch.from_numpy(parsed.astype(m[2], copy=False)).view(*s)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running model: models/lenet_mnist_softplus_SGD_0.pkl...\n",
      "Getting optimizer for type: SGD...\n",
      "Training epoch: 0\n",
      "idx: 0, loss: 2.3213627338409424\n",
      "idx: 100, loss: 2.2994141578674316\n",
      "idx: 200, loss: 0.6801586151123047\n",
      "idx: 300, loss: 0.43440037965774536\n",
      "idx: 400, loss: 0.39628586173057556\n",
      "Training epoch: 1\n",
      "idx: 0, loss: 0.11309085041284561\n",
      "idx: 100, loss: 0.14323793351650238\n",
      "idx: 200, loss: 0.15335214138031006\n",
      "idx: 300, loss: 0.09007233381271362\n",
      "idx: 400, loss: 0.4375433027744293\n",
      "Training epoch: 2\n",
      "idx: 0, loss: 0.06423605978488922\n",
      "idx: 100, loss: 0.16616109013557434\n",
      "idx: 200, loss: 0.12796740233898163\n",
      "idx: 300, loss: 0.0667390376329422\n",
      "idx: 400, loss: 0.22158698737621307\n",
      "Training epoch: 3\n",
      "idx: 0, loss: 0.08575321733951569\n",
      "idx: 100, loss: 0.10658863186836243\n",
      "idx: 200, loss: 0.10456061363220215\n",
      "idx: 300, loss: 0.033075228333473206\n",
      "idx: 400, loss: 0.17125645279884338\n",
      "Training epoch: 4\n",
      "idx: 0, loss: 0.06995586305856705\n",
      "idx: 100, loss: 0.08943136781454086\n",
      "idx: 200, loss: 0.1137051209807396\n",
      "idx: 300, loss: 0.05099984630942345\n",
      "idx: 400, loss: 0.1452948898077011\n",
      "Training epoch: 5\n",
      "idx: 0, loss: 0.07756977528333664\n",
      "idx: 100, loss: 0.08968091756105423\n",
      "idx: 200, loss: 0.07368429005146027\n",
      "idx: 300, loss: 0.06329349428415298\n",
      "idx: 400, loss: 0.1424768716096878\n",
      "Training epoch: 6\n",
      "idx: 0, loss: 0.0705520361661911\n",
      "idx: 100, loss: 0.08824557065963745\n",
      "idx: 200, loss: 0.08328544348478317\n",
      "idx: 300, loss: 0.07291574776172638\n",
      "idx: 400, loss: 0.07134860008955002\n",
      "Training epoch: 7\n",
      "idx: 0, loss: 0.04726111516356468\n",
      "idx: 100, loss: 0.08220779895782471\n",
      "idx: 200, loss: 0.08599381893873215\n",
      "idx: 300, loss: 0.06829414516687393\n",
      "idx: 400, loss: 0.09467200934886932\n",
      "Training epoch: 8\n",
      "idx: 0, loss: 0.04844902083277702\n",
      "idx: 100, loss: 0.09656278043985367\n",
      "idx: 200, loss: 0.06844652444124222\n",
      "idx: 300, loss: 0.050697892904281616\n",
      "idx: 400, loss: 0.06410185247659683\n",
      "Training epoch: 9\n",
      "idx: 0, loss: 0.02980155311524868\n",
      "idx: 100, loss: 0.1073208674788475\n",
      "idx: 200, loss: 0.0456104576587677\n",
      "idx: 300, loss: 0.058913517743349075\n",
      "idx: 400, loss: 0.20525787770748138\n",
      "Performing inference on batch: 0\n",
      "Performing inference on batch: 50\n",
      "Performing inference on batch: 0\n",
      "Performing inference on batch: 50\n",
      "FPR@95: 9.36, AUROC: 98.15 AUPR_IN: 98.37, AUPR_OUT: 97.87\n",
      "CCR: 21.26, 56.62, 79.24, 94.45, ACC: 98.18\n",
      "──────────────────────────────────────────────────────────────────────\n",
      "Running model: models/lenet_mnist_softplus_SGD_1.pkl...\n",
      "Getting optimizer for type: SGD...\n",
      "Training epoch: 0\n",
      "idx: 0, loss: 2.340564250946045\n",
      "idx: 100, loss: 2.3042221069335938\n",
      "idx: 200, loss: 0.23932592570781708\n",
      "idx: 300, loss: 0.23715950548648834\n",
      "idx: 400, loss: 0.35143598914146423\n",
      "Training epoch: 1\n",
      "idx: 0, loss: 0.25570544600486755\n",
      "idx: 100, loss: 0.08965296298265457\n",
      "idx: 200, loss: 0.2026396244764328\n",
      "idx: 300, loss: 0.09726960211992264\n",
      "idx: 400, loss: 0.20405049622058868\n",
      "Training epoch: 2\n",
      "idx: 0, loss: 0.10757985711097717\n",
      "idx: 100, loss: 0.08597750961780548\n",
      "idx: 200, loss: 0.16338738799095154\n",
      "idx: 300, loss: 0.09358516335487366\n",
      "idx: 400, loss: 0.1641247719526291\n",
      "Training epoch: 3\n",
      "idx: 0, loss: 0.06549914926290512\n",
      "idx: 100, loss: 0.0553508922457695\n",
      "idx: 200, loss: 0.23190993070602417\n",
      "idx: 300, loss: 0.08197367191314697\n",
      "idx: 400, loss: 0.21125712990760803\n",
      "Training epoch: 4\n",
      "idx: 0, loss: 0.07635047286748886\n",
      "idx: 100, loss: 0.04840325936675072\n",
      "idx: 200, loss: 0.17399811744689941\n",
      "idx: 300, loss: 0.07466737926006317\n",
      "idx: 400, loss: 0.15498124063014984\n",
      "Training epoch: 5\n",
      "idx: 0, loss: 0.03472725301980972\n",
      "idx: 100, loss: 0.06558939069509506\n",
      "idx: 200, loss: 0.08220434188842773\n",
      "idx: 300, loss: 0.06107501685619354\n",
      "idx: 400, loss: 0.1041223481297493\n",
      "Training epoch: 6\n",
      "idx: 0, loss: 0.09051346778869629\n",
      "idx: 100, loss: 0.0376189723610878\n",
      "idx: 200, loss: 0.1045953631401062\n",
      "idx: 300, loss: 0.06998647749423981\n",
      "idx: 400, loss: 0.08101313561201096\n",
      "Training epoch: 7\n",
      "idx: 0, loss: 0.07954522967338562\n",
      "idx: 100, loss: 0.05563792586326599\n",
      "idx: 200, loss: 0.12171963602304459\n",
      "idx: 300, loss: 0.04025961831212044\n",
      "idx: 400, loss: 0.12863612174987793\n",
      "Training epoch: 8\n",
      "idx: 0, loss: 0.07049321383237839\n",
      "idx: 100, loss: 0.04732326418161392\n",
      "idx: 200, loss: 0.10554666072130203\n",
      "idx: 300, loss: 0.0545891709625721\n",
      "idx: 400, loss: 0.04472426325082779\n",
      "Training epoch: 9\n",
      "idx: 0, loss: 0.019484130665659904\n",
      "idx: 100, loss: 0.045578449964523315\n",
      "idx: 200, loss: 0.07182364165782928\n",
      "idx: 300, loss: 0.054722197353839874\n",
      "idx: 400, loss: 0.07371360808610916\n",
      "Performing inference on batch: 0\n",
      "Performing inference on batch: 50\n",
      "Performing inference on batch: 0\n",
      "Performing inference on batch: 50\n",
      "FPR@95: 1.06, AUROC: 99.63 AUPR_IN: 99.67, AUPR_OUT: 99.60\n",
      "CCR: 46.94, 86.31, 94.22, 98.12, ACC: 98.57\n",
      "──────────────────────────────────────────────────────────────────────\n",
      "Running model: models/lenet_mnist_softplus_SGD_2.pkl...\n",
      "Getting optimizer for type: SGD...\n",
      "Training epoch: 0\n",
      "idx: 0, loss: 2.3525376319885254\n",
      "idx: 100, loss: 2.3054494857788086\n",
      "idx: 200, loss: 1.7902894020080566\n",
      "idx: 300, loss: 0.5173228979110718\n",
      "idx: 400, loss: 0.47754189372062683\n",
      "Training epoch: 1\n",
      "idx: 0, loss: 0.23702143132686615\n",
      "idx: 100, loss: 0.22601914405822754\n",
      "idx: 200, loss: 0.130754292011261\n",
      "idx: 300, loss: 0.115021713078022\n",
      "idx: 400, loss: 0.21892577409744263\n",
      "Training epoch: 2\n",
      "idx: 0, loss: 0.07942605763673782\n",
      "idx: 100, loss: 0.08060328662395477\n",
      "idx: 200, loss: 0.15846829116344452\n",
      "idx: 300, loss: 0.06967801600694656\n",
      "idx: 400, loss: 0.1922159492969513\n",
      "Training epoch: 3\n",
      "idx: 0, loss: 0.04551476612687111\n",
      "idx: 100, loss: 0.07854946702718735\n",
      "idx: 200, loss: 0.08389110118150711\n",
      "idx: 300, loss: 0.06830671429634094\n",
      "idx: 400, loss: 0.16256046295166016\n",
      "Training epoch: 4\n",
      "idx: 0, loss: 0.05975007265806198\n",
      "idx: 100, loss: 0.07362326234579086\n",
      "idx: 200, loss: 0.06570834666490555\n",
      "idx: 300, loss: 0.06394948065280914\n",
      "idx: 400, loss: 0.2927684187889099\n",
      "Training epoch: 5\n",
      "idx: 0, loss: 0.046504709869623184\n",
      "idx: 100, loss: 0.02651253156363964\n",
      "idx: 200, loss: 0.12765347957611084\n",
      "idx: 300, loss: 0.08307305723428726\n",
      "idx: 400, loss: 0.16962724924087524\n",
      "Training epoch: 6\n",
      "idx: 0, loss: 0.0705505907535553\n",
      "idx: 100, loss: 0.02988520823419094\n",
      "idx: 200, loss: 0.10861888527870178\n",
      "idx: 300, loss: 0.07745248824357986\n",
      "idx: 400, loss: 0.16986863315105438\n",
      "Training epoch: 7\n",
      "idx: 0, loss: 0.10025081038475037\n",
      "idx: 100, loss: 0.0157212782651186\n",
      "idx: 200, loss: 0.10764442384243011\n",
      "idx: 300, loss: 0.06416156888008118\n",
      "idx: 400, loss: 0.1405385285615921\n",
      "Training epoch: 8\n",
      "idx: 0, loss: 0.05972478911280632\n",
      "idx: 100, loss: 0.04353516921401024\n",
      "idx: 200, loss: 0.052103713154792786\n",
      "idx: 300, loss: 0.05491691082715988\n",
      "idx: 400, loss: 0.14069050550460815\n",
      "Training epoch: 9\n",
      "idx: 0, loss: 0.10925847291946411\n",
      "idx: 100, loss: 0.03168914094567299\n",
      "idx: 200, loss: 0.058655913919210434\n",
      "idx: 300, loss: 0.09176629781723022\n",
      "idx: 400, loss: 0.13908885419368744\n",
      "Performing inference on batch: 0\n",
      "Performing inference on batch: 50\n",
      "Performing inference on batch: 0\n",
      "Performing inference on batch: 50\n",
      "FPR@95: 3.42, AUROC: 99.15 AUPR_IN: 99.23, AUPR_OUT: 99.07\n",
      "CCR: 18.20, 69.25, 88.15, 97.16, ACC: 98.36\n",
      "──────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{0: {'dataset': 'mnist',\n",
       "  'FPR@95': '9.36',\n",
       "  'AUROC': '98.15',\n",
       "  'AUPR_IN': '98.37',\n",
       "  'AUPR_OUT': '97.87',\n",
       "  'CCR_4': '21.26',\n",
       "  'CCR_3': '56.62',\n",
       "  'CCR_2': '79.24',\n",
       "  'CCR_1': '94.45',\n",
       "  'ACC': '98.18',\n",
       "  'optimizer_type': 'SGD',\n",
       "  'activation_function_type': 'softplus',\n",
       "  'postprocessor_type': 'odin'},\n",
       " 1: {'dataset': 'mnist',\n",
       "  'FPR@95': '1.06',\n",
       "  'AUROC': '99.63',\n",
       "  'AUPR_IN': '99.67',\n",
       "  'AUPR_OUT': '99.60',\n",
       "  'CCR_4': '46.94',\n",
       "  'CCR_3': '86.31',\n",
       "  'CCR_2': '94.22',\n",
       "  'CCR_1': '98.12',\n",
       "  'ACC': '98.57',\n",
       "  'optimizer_type': 'SGD',\n",
       "  'activation_function_type': 'softplus',\n",
       "  'postprocessor_type': 'odin'},\n",
       " 2: {'dataset': 'mnist',\n",
       "  'FPR@95': '3.42',\n",
       "  'AUROC': '99.15',\n",
       "  'AUPR_IN': '99.23',\n",
       "  'AUPR_OUT': '99.07',\n",
       "  'CCR_4': '18.20',\n",
       "  'CCR_3': '69.25',\n",
       "  'CCR_2': '88.15',\n",
       "  'CCR_1': '97.16',\n",
       "  'ACC': '98.36',\n",
       "  'optimizer_type': 'SGD',\n",
       "  'activation_function_type': 'softplus',\n",
       "  'postprocessor_type': 'odin'}}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "config_1b = {\n",
    "    \"batch_size\": 128,\n",
    "    \"dataset_name\": \"mnist\",\n",
    "    \"n_classes\": 10,\n",
    "    \"epochs\": 10,\n",
    "    \"version\": time.time(),\n",
    "    \"lr\": 0.1,\n",
    "    \"momentum\": 0.9,\n",
    "    \"weight_decay\": 0.0005,\n",
    "    \"optimizer_type\": \"SGD\",\n",
    "    \"activation_function_type\": \"softplus\",\n",
    "    \"network\": \"lenet\",\n",
    "    \"postprocessor_type\": \"odin\",\n",
    "    \"dataset_type\": \"mnist\",\n",
    "    \"trials\": 3,\n",
    "    \"results_dir\": \"mnist-study\"\n",
    "}\n",
    "config_1b[\"data_loaders\"] = get_data_loaders(config_1b)\n",
    "run_full_oodn_pipeline(config_1b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "5bbc028e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running model: models/mnist_lenet_mcd_softplus_SGD_0.pkl...\n",
      "Getting optimizer for type: SGD...\n",
      "Training epoch: 0\n",
      "idx: 0, loss: 2.3624277114868164\n",
      "idx: 100, loss: 2.3057777881622314\n",
      "idx: 200, loss: 2.442692995071411\n",
      "idx: 300, loss: 0.5746510624885559\n",
      "idx: 400, loss: 0.4224349558353424\n",
      "Training epoch: 1\n",
      "idx: 0, loss: 0.17665119469165802\n",
      "idx: 100, loss: 0.2759348452091217\n",
      "idx: 200, loss: 0.3475848436355591\n",
      "idx: 300, loss: 0.12519679963588715\n",
      "idx: 400, loss: 0.19080723822116852\n",
      "Training epoch: 2\n",
      "idx: 0, loss: 0.14175932109355927\n",
      "idx: 100, loss: 0.15821029245853424\n",
      "idx: 200, loss: 0.16171494126319885\n",
      "idx: 300, loss: 0.06106771528720856\n",
      "idx: 400, loss: 0.24474868178367615\n",
      "Training epoch: 3\n",
      "idx: 0, loss: 0.11062025278806686\n",
      "idx: 100, loss: 0.17143307626247406\n",
      "idx: 200, loss: 0.09735853224992752\n",
      "idx: 300, loss: 0.047896698117256165\n",
      "idx: 400, loss: 0.25606343150138855\n",
      "Training epoch: 4\n",
      "idx: 0, loss: 0.05433105304837227\n",
      "idx: 100, loss: 0.05655233934521675\n",
      "idx: 200, loss: 0.10700041055679321\n",
      "idx: 300, loss: 0.043267082422971725\n",
      "idx: 400, loss: 0.16362980008125305\n",
      "Training epoch: 5\n",
      "idx: 0, loss: 0.036192748695611954\n",
      "idx: 100, loss: 0.04763447865843773\n",
      "idx: 200, loss: 0.11405836790800095\n",
      "idx: 300, loss: 0.05070900917053223\n",
      "idx: 400, loss: 0.16231046617031097\n",
      "Training epoch: 6\n",
      "idx: 0, loss: 0.04147440195083618\n",
      "idx: 100, loss: 0.08468136191368103\n",
      "idx: 200, loss: 0.11952701956033707\n",
      "idx: 300, loss: 0.040843766182661057\n",
      "idx: 400, loss: 0.20443850755691528\n",
      "Training epoch: 7\n",
      "idx: 0, loss: 0.026050318032503128\n",
      "idx: 100, loss: 0.0526517778635025\n",
      "idx: 200, loss: 0.08478822559118271\n",
      "idx: 300, loss: 0.050400279462337494\n",
      "idx: 400, loss: 0.12974366545677185\n",
      "Training epoch: 8\n",
      "idx: 0, loss: 0.022101301699876785\n",
      "idx: 100, loss: 0.04593320190906525\n",
      "idx: 200, loss: 0.08966508507728577\n",
      "idx: 300, loss: 0.045452531427145004\n",
      "idx: 400, loss: 0.17974728345870972\n",
      "Training epoch: 9\n",
      "idx: 0, loss: 0.025645015761256218\n",
      "idx: 100, loss: 0.04749678075313568\n",
      "idx: 200, loss: 0.16706418991088867\n",
      "idx: 300, loss: 0.06304420530796051\n",
      "idx: 400, loss: 0.17540869116783142\n",
      "Performing inference on batch: 0\n",
      "Performing inference on batch: 50\n",
      "Performing inference on batch: 0\n",
      "Performing inference on batch: 50\n",
      "FPR@95: 3.74, AUROC: 99.19 AUPR_IN: 99.28, AUPR_OUT: 99.12\n",
      "CCR: 56.84, 74.26, 89.46, 96.09, ACC: 97.55\n",
      "──────────────────────────────────────────────────────────────────────\n",
      "Running model: models/mnist_lenet_mcd_softplus_SGD_1.pkl...\n",
      "Getting optimizer for type: SGD...\n",
      "Training epoch: 0\n",
      "idx: 0, loss: 2.358313798904419\n",
      "idx: 100, loss: 2.300595760345459\n",
      "idx: 200, loss: 2.3080923557281494\n",
      "idx: 300, loss: 1.902052640914917\n",
      "idx: 400, loss: 0.9368475675582886\n",
      "Training epoch: 1\n",
      "idx: 0, loss: 0.5426051616668701\n",
      "idx: 100, loss: 0.561562180519104\n",
      "idx: 200, loss: 0.36840003728866577\n",
      "idx: 300, loss: 0.1793689727783203\n",
      "idx: 400, loss: 0.32057151198387146\n",
      "Training epoch: 2\n",
      "idx: 0, loss: 0.17465054988861084\n",
      "idx: 100, loss: 0.26219698786735535\n",
      "idx: 200, loss: 0.2995263338088989\n",
      "idx: 300, loss: 0.08043472468852997\n",
      "idx: 400, loss: 0.2579437494277954\n",
      "Training epoch: 3\n",
      "idx: 0, loss: 0.06082426384091377\n",
      "idx: 100, loss: 0.14106237888336182\n",
      "idx: 200, loss: 0.18145424127578735\n",
      "idx: 300, loss: 0.08792883157730103\n",
      "idx: 400, loss: 0.27833208441734314\n",
      "Training epoch: 4\n",
      "idx: 0, loss: 0.06522438675165176\n",
      "idx: 100, loss: 0.1495908796787262\n",
      "idx: 200, loss: 0.11481654644012451\n",
      "idx: 300, loss: 0.05822325125336647\n",
      "idx: 400, loss: 0.1469973623752594\n",
      "Training epoch: 5\n",
      "idx: 0, loss: 0.08248787373304367\n",
      "idx: 100, loss: 0.05352740362286568\n",
      "idx: 200, loss: 0.14533962309360504\n",
      "idx: 300, loss: 0.05468719080090523\n",
      "idx: 400, loss: 0.2298019826412201\n",
      "Training epoch: 6\n",
      "idx: 0, loss: 0.04842570796608925\n",
      "idx: 100, loss: 0.054788555949926376\n",
      "idx: 200, loss: 0.15164121985435486\n",
      "idx: 300, loss: 0.040155503898859024\n",
      "idx: 400, loss: 0.12433326244354248\n",
      "Training epoch: 7\n",
      "idx: 0, loss: 0.03460259363055229\n",
      "idx: 100, loss: 0.05647387355566025\n",
      "idx: 200, loss: 0.12015777826309204\n",
      "idx: 300, loss: 0.05915656313300133\n",
      "idx: 400, loss: 0.15610371530056\n",
      "Training epoch: 8\n",
      "idx: 0, loss: 0.05334858596324921\n",
      "idx: 100, loss: 0.034940801560878754\n",
      "idx: 200, loss: 0.10292614251375198\n",
      "idx: 300, loss: 0.05726129934191704\n",
      "idx: 400, loss: 0.16570131480693817\n",
      "Training epoch: 9\n",
      "idx: 0, loss: 0.04518728703260422\n",
      "idx: 100, loss: 0.025892654433846474\n",
      "idx: 200, loss: 0.11310777068138123\n",
      "idx: 300, loss: 0.053713783621788025\n",
      "idx: 400, loss: 0.15766175091266632\n",
      "Performing inference on batch: 0\n",
      "Performing inference on batch: 50\n",
      "Performing inference on batch: 0\n",
      "Performing inference on batch: 50\n",
      "FPR@95: 7.70, AUROC: 98.77 AUPR_IN: 98.91, AUPR_OUT: 98.66\n",
      "CCR: 56.58, 76.99, 85.89, 95.25, ACC: 97.84\n",
      "──────────────────────────────────────────────────────────────────────\n",
      "Running model: models/mnist_lenet_mcd_softplus_SGD_2.pkl...\n",
      "Getting optimizer for type: SGD...\n",
      "Training epoch: 0\n",
      "idx: 0, loss: 2.4611568450927734\n",
      "idx: 100, loss: 2.3013622760772705\n",
      "idx: 200, loss: 2.3078136444091797\n",
      "idx: 300, loss: 1.8653467893600464\n",
      "idx: 400, loss: 0.9115345478057861\n",
      "Training epoch: 1\n",
      "idx: 0, loss: 0.33692795038223267\n",
      "idx: 100, loss: 0.3691193759441376\n",
      "idx: 200, loss: 0.22110484540462494\n",
      "idx: 300, loss: 0.12574435770511627\n",
      "idx: 400, loss: 0.325646311044693\n",
      "Training epoch: 2\n",
      "idx: 0, loss: 0.08682001382112503\n",
      "idx: 100, loss: 0.05499941110610962\n",
      "idx: 200, loss: 0.08582545071840286\n",
      "idx: 300, loss: 0.0867062509059906\n",
      "idx: 400, loss: 0.24435022473335266\n",
      "Training epoch: 3\n",
      "idx: 0, loss: 0.07063283026218414\n",
      "idx: 100, loss: 0.03642430156469345\n",
      "idx: 200, loss: 0.09328758716583252\n",
      "idx: 300, loss: 0.08413387835025787\n",
      "idx: 400, loss: 0.230616956949234\n",
      "Training epoch: 4\n",
      "idx: 0, loss: 0.05995018407702446\n",
      "idx: 100, loss: 0.02766757644712925\n",
      "idx: 200, loss: 0.07222940027713776\n",
      "idx: 300, loss: 0.06638865917921066\n",
      "idx: 400, loss: 0.21311694383621216\n",
      "Training epoch: 5\n",
      "idx: 0, loss: 0.06413447856903076\n",
      "idx: 100, loss: 0.03713635355234146\n",
      "idx: 200, loss: 0.08179650455713272\n",
      "idx: 300, loss: 0.03440895304083824\n",
      "idx: 400, loss: 0.1931542605161667\n",
      "Training epoch: 6\n",
      "idx: 0, loss: 0.08038608729839325\n",
      "idx: 100, loss: 0.03366133198142052\n",
      "idx: 200, loss: 0.07800902426242828\n",
      "idx: 300, loss: 0.05664892494678497\n",
      "idx: 400, loss: 0.1393231749534607\n",
      "Training epoch: 7\n",
      "idx: 0, loss: 0.05741063505411148\n",
      "idx: 100, loss: 0.024911947548389435\n",
      "idx: 200, loss: 0.07957823574542999\n",
      "idx: 300, loss: 0.054513443261384964\n",
      "idx: 400, loss: 0.1573009341955185\n",
      "Training epoch: 8\n",
      "idx: 0, loss: 0.04842023178935051\n",
      "idx: 100, loss: 0.033156219869852066\n",
      "idx: 200, loss: 0.12505480647087097\n",
      "idx: 300, loss: 0.062079574912786484\n",
      "idx: 400, loss: 0.1225867047905922\n",
      "Training epoch: 9\n",
      "idx: 0, loss: 0.03181704506278038\n",
      "idx: 100, loss: 0.05744009464979172\n",
      "idx: 200, loss: 0.17669019103050232\n",
      "idx: 300, loss: 0.05338222160935402\n",
      "idx: 400, loss: 0.12436653673648834\n",
      "Performing inference on batch: 0\n",
      "Performing inference on batch: 50\n",
      "Performing inference on batch: 0\n",
      "Performing inference on batch: 50\n",
      "FPR@95: 17.49, AUROC: 96.35 AUPR_IN: 96.41, AUPR_OUT: 96.39\n",
      "CCR: 13.01, 37.71, 57.03, 88.70, ACC: 97.96\n",
      "──────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{0: {'dataset': 'mnist',\n",
       "  'FPR@95': '3.74',\n",
       "  'AUROC': '99.19',\n",
       "  'AUPR_IN': '99.28',\n",
       "  'AUPR_OUT': '99.12',\n",
       "  'CCR_4': '56.84',\n",
       "  'CCR_3': '74.26',\n",
       "  'CCR_2': '89.46',\n",
       "  'CCR_1': '96.09',\n",
       "  'ACC': '97.55',\n",
       "  'optimizer_type': 'SGD',\n",
       "  'activation_function_type': 'softplus',\n",
       "  'postprocessor_type': 'mcd'},\n",
       " 1: {'dataset': 'mnist',\n",
       "  'FPR@95': '7.70',\n",
       "  'AUROC': '98.77',\n",
       "  'AUPR_IN': '98.91',\n",
       "  'AUPR_OUT': '98.66',\n",
       "  'CCR_4': '56.58',\n",
       "  'CCR_3': '76.99',\n",
       "  'CCR_2': '85.89',\n",
       "  'CCR_1': '95.25',\n",
       "  'ACC': '97.84',\n",
       "  'optimizer_type': 'SGD',\n",
       "  'activation_function_type': 'softplus',\n",
       "  'postprocessor_type': 'mcd'},\n",
       " 2: {'dataset': 'mnist',\n",
       "  'FPR@95': '17.49',\n",
       "  'AUROC': '96.35',\n",
       "  'AUPR_IN': '96.41',\n",
       "  'AUPR_OUT': '96.39',\n",
       "  'CCR_4': '13.01',\n",
       "  'CCR_3': '37.71',\n",
       "  'CCR_2': '57.03',\n",
       "  'CCR_1': '88.70',\n",
       "  'ACC': '97.96',\n",
       "  'optimizer_type': 'SGD',\n",
       "  'activation_function_type': 'softplus',\n",
       "  'postprocessor_type': 'mcd'}}"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "config_1_1b = {\n",
    "    \"batch_size\": 128,\n",
    "    \"dataset_name\": \"mnist\",\n",
    "    \"n_classes\": 10,\n",
    "    \"epochs\": 10,\n",
    "    \"version\": time.time(),\n",
    "    \"lr\": 0.1,\n",
    "    \"momentum\": 0.9,\n",
    "    \"weight_decay\": 0.0005,\n",
    "    \"optimizer_type\": \"SGD\",\n",
    "    \"activation_function_type\": \"softplus\",\n",
    "    \"network\": \"lenet\",\n",
    "    \"postprocessor_type\": \"mcd\",\n",
    "    \"dataset_type\": \"mnist\",\n",
    "    \"trials\": 3,\n",
    "    \"results_dir\": \"mnist-study\"\n",
    "}\n",
    "config_1_1b[\"data_loaders\"] = get_data_loaders(config_1_1b)\n",
    "run_full_oodn_pipeline(config_1_1b)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "966af048",
   "metadata": {},
   "source": [
    "#### 1(c) Adam + ReLU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "38bf5903",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running model: models/lenet_mnist_relu_Adam_0.pkl...\n",
      "Getting optimizer for type: Adam...\n",
      "Training epoch: 0\n",
      "idx: 0, loss: 2.301894187927246\n",
      "idx: 100, loss: 0.11984912306070328\n",
      "idx: 200, loss: 0.15497374534606934\n",
      "idx: 300, loss: 0.06791342049837112\n",
      "idx: 400, loss: 0.22912515699863434\n",
      "Training epoch: 1\n",
      "idx: 0, loss: 0.07157646864652634\n",
      "idx: 100, loss: 0.05058322101831436\n",
      "idx: 200, loss: 0.09429037570953369\n",
      "idx: 300, loss: 0.08827465027570724\n",
      "idx: 400, loss: 0.1425236165523529\n",
      "Training epoch: 2\n",
      "idx: 0, loss: 0.08118437230587006\n",
      "idx: 100, loss: 0.029627040028572083\n",
      "idx: 200, loss: 0.11240573972463608\n",
      "idx: 300, loss: 0.049749165773391724\n",
      "idx: 400, loss: 0.10378781706094742\n",
      "Training epoch: 3\n",
      "idx: 0, loss: 0.05978626012802124\n",
      "idx: 100, loss: 0.04203808680176735\n",
      "idx: 200, loss: 0.12809190154075623\n",
      "idx: 300, loss: 0.072877898812294\n",
      "idx: 400, loss: 0.12331315875053406\n",
      "Training epoch: 4\n",
      "idx: 0, loss: 0.04495770111680031\n",
      "idx: 100, loss: 0.02584172785282135\n",
      "idx: 200, loss: 0.11872470378875732\n",
      "idx: 300, loss: 0.07828597724437714\n",
      "idx: 400, loss: 0.07598255574703217\n",
      "Training epoch: 5\n",
      "idx: 0, loss: 0.05495789647102356\n",
      "idx: 100, loss: 0.037266433238983154\n",
      "idx: 200, loss: 0.10434290766716003\n",
      "idx: 300, loss: 0.10311908274888992\n",
      "idx: 400, loss: 0.11808832734823227\n",
      "Training epoch: 6\n",
      "idx: 0, loss: 0.060246095061302185\n",
      "idx: 100, loss: 0.03131585195660591\n",
      "idx: 200, loss: 0.12608620524406433\n",
      "idx: 300, loss: 0.09490960836410522\n",
      "idx: 400, loss: 0.06511182337999344\n",
      "Training epoch: 7\n",
      "idx: 0, loss: 0.0499860905110836\n",
      "idx: 100, loss: 0.03962114080786705\n",
      "idx: 200, loss: 0.10502298176288605\n",
      "idx: 300, loss: 0.09349831193685532\n",
      "idx: 400, loss: 0.07813948392868042\n",
      "Training epoch: 8\n",
      "idx: 0, loss: 0.07985585182905197\n",
      "idx: 100, loss: 0.02391934208571911\n",
      "idx: 200, loss: 0.12107112258672714\n",
      "idx: 300, loss: 0.10891781747341156\n",
      "idx: 400, loss: 0.0778113380074501\n",
      "Training epoch: 9\n",
      "idx: 0, loss: 0.04968756064772606\n",
      "idx: 100, loss: 0.04941726103425026\n",
      "idx: 200, loss: 0.1538858562707901\n",
      "idx: 300, loss: 0.07793816924095154\n",
      "idx: 400, loss: 0.1059483215212822\n",
      "Performing inference on batch: 0\n",
      "Performing inference on batch: 50\n",
      "Performing inference on batch: 0\n",
      "Performing inference on batch: 50\n",
      "FPR@95: 2.70, AUROC: 99.40 AUPR_IN: 99.44, AUPR_OUT: 99.38\n",
      "CCR: 52.68, 74.63, 91.00, 97.29, ACC: 98.42\n",
      "──────────────────────────────────────────────────────────────────────\n",
      "Running model: models/lenet_mnist_relu_Adam_1.pkl...\n",
      "Getting optimizer for type: Adam...\n",
      "Training epoch: 0\n",
      "idx: 0, loss: 2.293492555618286\n",
      "idx: 100, loss: 0.1070859432220459\n",
      "idx: 200, loss: 0.18924188613891602\n",
      "idx: 300, loss: 0.09109842777252197\n",
      "idx: 400, loss: 0.2963612377643585\n",
      "Training epoch: 1\n",
      "idx: 0, loss: 0.09902137517929077\n",
      "idx: 100, loss: 0.0712750032544136\n",
      "idx: 200, loss: 0.1316186636686325\n",
      "idx: 300, loss: 0.08733689785003662\n",
      "idx: 400, loss: 0.11562913656234741\n",
      "Training epoch: 2\n",
      "idx: 0, loss: 0.12325657159090042\n",
      "idx: 100, loss: 0.10450296103954315\n",
      "idx: 200, loss: 0.11444566398859024\n",
      "idx: 300, loss: 0.06541197001934052\n",
      "idx: 400, loss: 0.16334471106529236\n",
      "Training epoch: 3\n",
      "idx: 0, loss: 0.06405773758888245\n",
      "idx: 100, loss: 0.09464186429977417\n",
      "idx: 200, loss: 0.08733242005109787\n",
      "idx: 300, loss: 0.07983353734016418\n",
      "idx: 400, loss: 0.13288548588752747\n",
      "Training epoch: 4\n",
      "idx: 0, loss: 0.041788797825574875\n",
      "idx: 100, loss: 0.11960559338331223\n",
      "idx: 200, loss: 0.06364922225475311\n",
      "idx: 300, loss: 0.0588051974773407\n",
      "idx: 400, loss: 0.08897693455219269\n",
      "Training epoch: 5\n",
      "idx: 0, loss: 0.07402198761701584\n",
      "idx: 100, loss: 0.027897847816348076\n",
      "idx: 200, loss: 0.0605357363820076\n",
      "idx: 300, loss: 0.07506825774908066\n",
      "idx: 400, loss: 0.09559640288352966\n",
      "Training epoch: 6\n",
      "idx: 0, loss: 0.025842729955911636\n",
      "idx: 100, loss: 0.020025210455060005\n",
      "idx: 200, loss: 0.07151507586240768\n",
      "idx: 300, loss: 0.06313208490610123\n",
      "idx: 400, loss: 0.09809078276157379\n",
      "Training epoch: 7\n",
      "idx: 0, loss: 0.07373160123825073\n",
      "idx: 100, loss: 0.05142107605934143\n",
      "idx: 200, loss: 0.09560370445251465\n",
      "idx: 300, loss: 0.08956504613161087\n",
      "idx: 400, loss: 0.1100311130285263\n",
      "Training epoch: 8\n",
      "idx: 0, loss: 0.03840656578540802\n",
      "idx: 100, loss: 0.08099064230918884\n",
      "idx: 200, loss: 0.07125180959701538\n",
      "idx: 300, loss: 0.06617546826601028\n",
      "idx: 400, loss: 0.1358678936958313\n",
      "Training epoch: 9\n",
      "idx: 0, loss: 0.030743299052119255\n",
      "idx: 100, loss: 0.02863333187997341\n",
      "idx: 200, loss: 0.0692383348941803\n",
      "idx: 300, loss: 0.06162397563457489\n",
      "idx: 400, loss: 0.07264650613069534\n",
      "Performing inference on batch: 0\n",
      "Performing inference on batch: 50\n",
      "Performing inference on batch: 0\n",
      "Performing inference on batch: 50\n",
      "FPR@95: 2.21, AUROC: 99.41 AUPR_IN: 99.47, AUPR_OUT: 99.36\n",
      "CCR: 73.34, 81.76, 91.29, 97.00, ACC: 97.89\n",
      "──────────────────────────────────────────────────────────────────────\n",
      "Running model: models/lenet_mnist_relu_Adam_2.pkl...\n",
      "Getting optimizer for type: Adam...\n",
      "Training epoch: 0\n",
      "idx: 0, loss: 2.3150246143341064\n",
      "idx: 100, loss: 0.09638706594705582\n",
      "idx: 200, loss: 0.0772596001625061\n",
      "idx: 300, loss: 0.06783361732959747\n",
      "idx: 400, loss: 0.28136304020881653\n",
      "Training epoch: 1\n",
      "idx: 0, loss: 0.10244044661521912\n",
      "idx: 100, loss: 0.07415791600942612\n",
      "idx: 200, loss: 0.12683618068695068\n",
      "idx: 300, loss: 0.05580576881766319\n",
      "idx: 400, loss: 0.12959930300712585\n",
      "Training epoch: 2\n",
      "idx: 0, loss: 0.15167661011219025\n",
      "idx: 100, loss: 0.05276137962937355\n",
      "idx: 200, loss: 0.07899244129657745\n",
      "idx: 300, loss: 0.0825977772474289\n",
      "idx: 400, loss: 0.14491266012191772\n",
      "Training epoch: 3\n",
      "idx: 0, loss: 0.04338781535625458\n",
      "idx: 100, loss: 0.039009105414152145\n",
      "idx: 200, loss: 0.050371427088975906\n",
      "idx: 300, loss: 0.0858735591173172\n",
      "idx: 400, loss: 0.11740030348300934\n",
      "Training epoch: 4\n",
      "idx: 0, loss: 0.0560772642493248\n",
      "idx: 100, loss: 0.04598218575119972\n",
      "idx: 200, loss: 0.04679730907082558\n",
      "idx: 300, loss: 0.06849267333745956\n",
      "idx: 400, loss: 0.17239250242710114\n",
      "Training epoch: 5\n",
      "idx: 0, loss: 0.0752267837524414\n",
      "idx: 100, loss: 0.0584476962685585\n",
      "idx: 200, loss: 0.0814000591635704\n",
      "idx: 300, loss: 0.08675199747085571\n",
      "idx: 400, loss: 0.13120029866695404\n",
      "Training epoch: 6\n",
      "idx: 0, loss: 0.06261128187179565\n",
      "idx: 100, loss: 0.040838275104761124\n",
      "idx: 200, loss: 0.0757877305150032\n",
      "idx: 300, loss: 0.08975743502378464\n",
      "idx: 400, loss: 0.09847201406955719\n",
      "Training epoch: 7\n",
      "idx: 0, loss: 0.052738580852746964\n",
      "idx: 100, loss: 0.07920383661985397\n",
      "idx: 200, loss: 0.13834163546562195\n",
      "idx: 300, loss: 0.08015734702348709\n",
      "idx: 400, loss: 0.08001728355884552\n",
      "Training epoch: 8\n",
      "idx: 0, loss: 0.0355585552752018\n",
      "idx: 100, loss: 0.03549942001700401\n",
      "idx: 200, loss: 0.09980328381061554\n",
      "idx: 300, loss: 0.06354200094938278\n",
      "idx: 400, loss: 0.17420224845409393\n",
      "Training epoch: 9\n",
      "idx: 0, loss: 0.02488134801387787\n",
      "idx: 100, loss: 0.01913141831755638\n",
      "idx: 200, loss: 0.07770228385925293\n",
      "idx: 300, loss: 0.06821347028017044\n",
      "idx: 400, loss: 0.050187814980745316\n",
      "Performing inference on batch: 0\n",
      "Performing inference on batch: 50\n",
      "Performing inference on batch: 0\n",
      "Performing inference on batch: 50\n",
      "FPR@95: 0.97, AUROC: 99.55 AUPR_IN: 99.61, AUPR_OUT: 99.51\n",
      "CCR: 73.59, 89.21, 94.54, 97.55, ACC: 98.29\n",
      "──────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{0: {'dataset': 'mnist',\n",
       "  'FPR@95': '2.70',\n",
       "  'AUROC': '99.40',\n",
       "  'AUPR_IN': '99.44',\n",
       "  'AUPR_OUT': '99.38',\n",
       "  'CCR_4': '52.68',\n",
       "  'CCR_3': '74.63',\n",
       "  'CCR_2': '91.00',\n",
       "  'CCR_1': '97.29',\n",
       "  'ACC': '98.42',\n",
       "  'optimizer_type': 'Adam',\n",
       "  'activation_function_type': 'relu',\n",
       "  'postprocessor_type': 'odin'},\n",
       " 1: {'dataset': 'mnist',\n",
       "  'FPR@95': '2.21',\n",
       "  'AUROC': '99.41',\n",
       "  'AUPR_IN': '99.47',\n",
       "  'AUPR_OUT': '99.36',\n",
       "  'CCR_4': '73.34',\n",
       "  'CCR_3': '81.76',\n",
       "  'CCR_2': '91.29',\n",
       "  'CCR_1': '97.00',\n",
       "  'ACC': '97.89',\n",
       "  'optimizer_type': 'Adam',\n",
       "  'activation_function_type': 'relu',\n",
       "  'postprocessor_type': 'odin'},\n",
       " 2: {'dataset': 'mnist',\n",
       "  'FPR@95': '0.97',\n",
       "  'AUROC': '99.55',\n",
       "  'AUPR_IN': '99.61',\n",
       "  'AUPR_OUT': '99.51',\n",
       "  'CCR_4': '73.59',\n",
       "  'CCR_3': '89.21',\n",
       "  'CCR_2': '94.54',\n",
       "  'CCR_1': '97.55',\n",
       "  'ACC': '98.29',\n",
       "  'optimizer_type': 'Adam',\n",
       "  'activation_function_type': 'relu',\n",
       "  'postprocessor_type': 'odin'}}"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "config_1c = {\n",
    "    \"batch_size\": 128,\n",
    "    \"dataset_name\": \"mnist\",\n",
    "    \"n_classes\": 10,\n",
    "    \"epochs\": 10,\n",
    "    \"version\": time.time(),\n",
    "    \"lr\": 0.01,\n",
    "    \"momentum\": 0.9,\n",
    "    \"weight_decay\": 0.0005,\n",
    "    \"optimizer_type\": \"Adam\",\n",
    "    \"activation_function_type\": \"relu\",\n",
    "    \"network\": \"lenet\",\n",
    "    \"postprocessor_type\": \"odin\",\n",
    "    \"dataset_type\": \"mnist\",\n",
    "    \"trials\": 3,\n",
    "    \"results_dir\": \"mnist-study\"\n",
    "}\n",
    "config_1c[\"data_loaders\"] = get_data_loaders(config_1c)\n",
    "run_full_oodn_pipeline(config_1c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "495c8d51",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running model: models/mnist_lenet_mcd_relu_Adam_0.pkl...\n",
      "Getting optimizer for type: Adam...\n",
      "Training epoch: 0\n",
      "idx: 0, loss: 2.3105053901672363\n",
      "idx: 100, loss: 0.16683584451675415\n",
      "idx: 200, loss: 0.16353853046894073\n",
      "idx: 300, loss: 0.11336103826761246\n",
      "idx: 400, loss: 0.36516520380973816\n",
      "Training epoch: 1\n",
      "idx: 0, loss: 0.09431233257055283\n",
      "idx: 100, loss: 0.047792594879865646\n",
      "idx: 200, loss: 0.14638617634773254\n",
      "idx: 300, loss: 0.09262651205062866\n",
      "idx: 400, loss: 0.24459731578826904\n",
      "Training epoch: 2\n",
      "idx: 0, loss: 0.01773892156779766\n",
      "idx: 100, loss: 0.04295041039586067\n",
      "idx: 200, loss: 0.0693758875131607\n",
      "idx: 300, loss: 0.05112284794449806\n",
      "idx: 400, loss: 0.31428009271621704\n",
      "Training epoch: 3\n",
      "idx: 0, loss: 0.07498281449079514\n",
      "idx: 100, loss: 0.04888544976711273\n",
      "idx: 200, loss: 0.08386431634426117\n",
      "idx: 300, loss: 0.07530947774648666\n",
      "idx: 400, loss: 0.2098739743232727\n",
      "Training epoch: 4\n",
      "idx: 0, loss: 0.043862421065568924\n",
      "idx: 100, loss: 0.02606273628771305\n",
      "idx: 200, loss: 0.10874634981155396\n",
      "idx: 300, loss: 0.06559506058692932\n",
      "idx: 400, loss: 0.24702231585979462\n",
      "Training epoch: 5\n",
      "idx: 0, loss: 0.02823050506412983\n",
      "idx: 100, loss: 0.05967910960316658\n",
      "idx: 200, loss: 0.14233636856079102\n",
      "idx: 300, loss: 0.07368937879800797\n",
      "idx: 400, loss: 0.20117537677288055\n",
      "Training epoch: 6\n",
      "idx: 0, loss: 0.06040278822183609\n",
      "idx: 100, loss: 0.055068489164114\n",
      "idx: 200, loss: 0.15563330054283142\n",
      "idx: 300, loss: 0.08211880922317505\n",
      "idx: 400, loss: 0.20983535051345825\n",
      "Training epoch: 7\n",
      "idx: 0, loss: 0.08424745500087738\n",
      "idx: 100, loss: 0.022954024374485016\n",
      "idx: 200, loss: 0.11444947123527527\n",
      "idx: 300, loss: 0.0835021436214447\n",
      "idx: 400, loss: 0.136170893907547\n",
      "Training epoch: 8\n",
      "idx: 0, loss: 0.021492818370461464\n",
      "idx: 100, loss: 0.038989320397377014\n",
      "idx: 200, loss: 0.1544622778892517\n",
      "idx: 300, loss: 0.06238903850317001\n",
      "idx: 400, loss: 0.17060895264148712\n",
      "Training epoch: 9\n",
      "idx: 0, loss: 0.03086627647280693\n",
      "idx: 100, loss: 0.027088744565844536\n",
      "idx: 200, loss: 0.10840286314487457\n",
      "idx: 300, loss: 0.08728226274251938\n",
      "idx: 400, loss: 0.10396642982959747\n",
      "Performing inference on batch: 0\n",
      "Performing inference on batch: 50\n",
      "Performing inference on batch: 0\n",
      "Performing inference on batch: 50\n",
      "FPR@95: 0.25, AUROC: 99.70 AUPR_IN: 99.75, AUPR_OUT: 99.65\n",
      "CCR: 82.60, 92.38, 96.07, 97.89, ACC: 98.31\n",
      "──────────────────────────────────────────────────────────────────────\n",
      "Running model: models/mnist_lenet_mcd_relu_Adam_1.pkl...\n",
      "Getting optimizer for type: Adam...\n",
      "Training epoch: 0\n",
      "idx: 0, loss: 2.302154541015625\n",
      "idx: 100, loss: 0.13728182017803192\n",
      "idx: 200, loss: 0.14708925783634186\n",
      "idx: 300, loss: 0.10631110519170761\n",
      "idx: 400, loss: 0.2877872586250305\n",
      "Training epoch: 1\n",
      "idx: 0, loss: 0.19495582580566406\n",
      "idx: 100, loss: 0.10673167556524277\n",
      "idx: 200, loss: 0.11361312866210938\n",
      "idx: 300, loss: 0.08540783077478409\n",
      "idx: 400, loss: 0.17942075431346893\n",
      "Training epoch: 2\n",
      "idx: 0, loss: 0.06692768633365631\n",
      "idx: 100, loss: 0.035896580666303635\n",
      "idx: 200, loss: 0.09556271135807037\n",
      "idx: 300, loss: 0.10148320347070694\n",
      "idx: 400, loss: 0.10167685896158218\n",
      "Training epoch: 3\n",
      "idx: 0, loss: 0.06670290976762772\n",
      "idx: 100, loss: 0.07881160080432892\n",
      "idx: 200, loss: 0.08315527439117432\n",
      "idx: 300, loss: 0.0675520971417427\n",
      "idx: 400, loss: 0.17442934215068817\n",
      "Training epoch: 4\n",
      "idx: 0, loss: 0.08757153898477554\n",
      "idx: 100, loss: 0.04633903503417969\n",
      "idx: 200, loss: 0.10868118703365326\n",
      "idx: 300, loss: 0.06668378412723541\n",
      "idx: 400, loss: 0.10421440750360489\n",
      "Training epoch: 5\n",
      "idx: 0, loss: 0.06862093508243561\n",
      "idx: 100, loss: 0.06367607414722443\n",
      "idx: 200, loss: 0.0860462635755539\n",
      "idx: 300, loss: 0.08129651844501495\n",
      "idx: 400, loss: 0.1412106156349182\n",
      "Training epoch: 6\n",
      "idx: 0, loss: 0.1602744162082672\n",
      "idx: 100, loss: 0.02828780934214592\n",
      "idx: 200, loss: 0.08111027628183365\n",
      "idx: 300, loss: 0.07422564178705215\n",
      "idx: 400, loss: 0.08604159951210022\n",
      "Training epoch: 7\n",
      "idx: 0, loss: 0.033269237726926804\n",
      "idx: 100, loss: 0.03542861342430115\n",
      "idx: 200, loss: 0.09848149865865707\n",
      "idx: 300, loss: 0.06747830659151077\n",
      "idx: 400, loss: 0.10342496633529663\n",
      "Training epoch: 8\n",
      "idx: 0, loss: 0.12405180186033249\n",
      "idx: 100, loss: 0.025833075866103172\n",
      "idx: 200, loss: 0.11081617325544357\n",
      "idx: 300, loss: 0.05862966179847717\n",
      "idx: 400, loss: 0.23513486981391907\n",
      "Training epoch: 9\n",
      "idx: 0, loss: 0.11300273984670639\n",
      "idx: 100, loss: 0.04666956514120102\n",
      "idx: 200, loss: 0.01855108141899109\n",
      "idx: 300, loss: 0.04932387173175812\n",
      "idx: 400, loss: 0.13714265823364258\n",
      "Performing inference on batch: 0\n",
      "Performing inference on batch: 50\n",
      "Performing inference on batch: 0\n",
      "Performing inference on batch: 50\n",
      "FPR@95: 2.73, AUROC: 99.35 AUPR_IN: 99.42, AUPR_OUT: 99.29\n",
      "CCR: 71.59, 78.44, 90.85, 97.29, ACC: 98.28\n",
      "──────────────────────────────────────────────────────────────────────\n",
      "Running model: models/mnist_lenet_mcd_relu_Adam_2.pkl...\n",
      "Getting optimizer for type: Adam...\n",
      "Training epoch: 0\n",
      "idx: 0, loss: 2.311150550842285\n",
      "idx: 100, loss: 0.19023571908473969\n",
      "idx: 200, loss: 0.15882588922977448\n",
      "idx: 300, loss: 0.18094846606254578\n",
      "idx: 400, loss: 0.1635553389787674\n",
      "Training epoch: 1\n",
      "idx: 0, loss: 0.0779106542468071\n",
      "idx: 100, loss: 0.0935160368680954\n",
      "idx: 200, loss: 0.1450081318616867\n",
      "idx: 300, loss: 0.10962410271167755\n",
      "idx: 400, loss: 0.2694651186466217\n",
      "Training epoch: 2\n",
      "idx: 0, loss: 0.08604158461093903\n",
      "idx: 100, loss: 0.06897665560245514\n",
      "idx: 200, loss: 0.08526169508695602\n",
      "idx: 300, loss: 0.08537566661834717\n",
      "idx: 400, loss: 0.19088692963123322\n",
      "Training epoch: 3\n",
      "idx: 0, loss: 0.016001585870981216\n",
      "idx: 100, loss: 0.015574712306261063\n",
      "idx: 200, loss: 0.09282377362251282\n",
      "idx: 300, loss: 0.09241477400064468\n",
      "idx: 400, loss: 0.14194223284721375\n",
      "Training epoch: 4\n",
      "idx: 0, loss: 0.014671321026980877\n",
      "idx: 100, loss: 0.0852450430393219\n",
      "idx: 200, loss: 0.11033949255943298\n",
      "idx: 300, loss: 0.10523618757724762\n",
      "idx: 400, loss: 0.126130148768425\n",
      "Training epoch: 5\n",
      "idx: 0, loss: 0.01504311989992857\n",
      "idx: 100, loss: 0.0373467355966568\n",
      "idx: 200, loss: 0.12138331681489944\n",
      "idx: 300, loss: 0.08579767495393753\n",
      "idx: 400, loss: 0.13291874527931213\n",
      "Training epoch: 6\n",
      "idx: 0, loss: 0.020385129377245903\n",
      "idx: 100, loss: 0.04666946828365326\n",
      "idx: 200, loss: 0.0963720977306366\n",
      "idx: 300, loss: 0.07184064388275146\n",
      "idx: 400, loss: 0.13098952174186707\n",
      "Training epoch: 7\n",
      "idx: 0, loss: 0.014586934819817543\n",
      "idx: 100, loss: 0.03354716673493385\n",
      "idx: 200, loss: 0.044963594526052475\n",
      "idx: 300, loss: 0.08203528821468353\n",
      "idx: 400, loss: 0.14289741218090057\n",
      "Training epoch: 8\n",
      "idx: 0, loss: 0.026785189285874367\n",
      "idx: 100, loss: 0.01402148138731718\n",
      "idx: 200, loss: 0.0796678438782692\n",
      "idx: 300, loss: 0.0948639065027237\n",
      "idx: 400, loss: 0.13357286155223846\n",
      "Training epoch: 9\n",
      "idx: 0, loss: 0.024531081318855286\n",
      "idx: 100, loss: 0.016586020588874817\n",
      "idx: 200, loss: 0.042022570967674255\n",
      "idx: 300, loss: 0.07092315703630447\n",
      "idx: 400, loss: 0.10767359286546707\n",
      "Performing inference on batch: 0\n",
      "Performing inference on batch: 50\n",
      "Performing inference on batch: 0\n",
      "Performing inference on batch: 50\n",
      "FPR@95: 0.33, AUROC: 99.75 AUPR_IN: 99.78, AUPR_OUT: 99.73\n",
      "CCR: 87.00, 91.07, 95.84, 97.88, ACC: 98.22\n",
      "──────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{0: {'dataset': 'mnist',\n",
       "  'FPR@95': '0.25',\n",
       "  'AUROC': '99.70',\n",
       "  'AUPR_IN': '99.75',\n",
       "  'AUPR_OUT': '99.65',\n",
       "  'CCR_4': '82.60',\n",
       "  'CCR_3': '92.38',\n",
       "  'CCR_2': '96.07',\n",
       "  'CCR_1': '97.89',\n",
       "  'ACC': '98.31',\n",
       "  'optimizer_type': 'Adam',\n",
       "  'activation_function_type': 'relu',\n",
       "  'postprocessor_type': 'mcd'},\n",
       " 1: {'dataset': 'mnist',\n",
       "  'FPR@95': '2.73',\n",
       "  'AUROC': '99.35',\n",
       "  'AUPR_IN': '99.42',\n",
       "  'AUPR_OUT': '99.29',\n",
       "  'CCR_4': '71.59',\n",
       "  'CCR_3': '78.44',\n",
       "  'CCR_2': '90.85',\n",
       "  'CCR_1': '97.29',\n",
       "  'ACC': '98.28',\n",
       "  'optimizer_type': 'Adam',\n",
       "  'activation_function_type': 'relu',\n",
       "  'postprocessor_type': 'mcd'},\n",
       " 2: {'dataset': 'mnist',\n",
       "  'FPR@95': '0.33',\n",
       "  'AUROC': '99.75',\n",
       "  'AUPR_IN': '99.78',\n",
       "  'AUPR_OUT': '99.73',\n",
       "  'CCR_4': '87.00',\n",
       "  'CCR_3': '91.07',\n",
       "  'CCR_2': '95.84',\n",
       "  'CCR_1': '97.88',\n",
       "  'ACC': '98.22',\n",
       "  'optimizer_type': 'Adam',\n",
       "  'activation_function_type': 'relu',\n",
       "  'postprocessor_type': 'mcd'}}"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "config_1_1c = {\n",
    "    \"batch_size\": 128,\n",
    "    \"dataset_name\": \"mnist\",\n",
    "    \"n_classes\": 10,\n",
    "    \"epochs\": 10,\n",
    "    \"version\": time.time(),\n",
    "    \"lr\": 0.01,\n",
    "    \"momentum\": 0.9,\n",
    "    \"weight_decay\": 0.0005,\n",
    "    \"optimizer_type\": \"Adam\",\n",
    "    \"activation_function_type\": \"relu\",\n",
    "    \"network\": \"lenet\",\n",
    "    \"postprocessor_type\": \"mcd\",\n",
    "    \"dataset_type\": \"mnist\",\n",
    "    \"trials\": 3,\n",
    "    \"results_dir\": \"mnist-study\"\n",
    "}\n",
    "config_1_1c[\"data_loaders\"] = get_data_loaders(config_1_1c)\n",
    "run_full_oodn_pipeline(config_1_1c)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60a72681",
   "metadata": {},
   "source": [
    "#### 1(d) Adam + Softplus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "39e851fb",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running model: models/lenet_mnist_softplus_Adam_0.pkl...\n",
      "Getting optimizer for type: Adam...\n",
      "Training epoch: 0\n",
      "idx: 0, loss: 2.3255388736724854\n",
      "idx: 100, loss: 2.3116369247436523\n",
      "idx: 200, loss: 2.305769443511963\n",
      "idx: 300, loss: 2.2983803749084473\n",
      "idx: 400, loss: 2.307865619659424\n",
      "Training epoch: 1\n",
      "idx: 0, loss: 2.276770830154419\n",
      "idx: 100, loss: 0.8078237175941467\n",
      "idx: 200, loss: 0.25390756130218506\n",
      "idx: 300, loss: 0.32934701442718506\n",
      "idx: 400, loss: 0.3490292727947235\n",
      "Training epoch: 2\n",
      "idx: 0, loss: 0.1403365433216095\n",
      "idx: 100, loss: 0.2735982835292816\n",
      "idx: 200, loss: 0.14142420887947083\n",
      "idx: 300, loss: 0.18107478320598602\n",
      "idx: 400, loss: 0.2841825485229492\n",
      "Training epoch: 3\n",
      "idx: 0, loss: 0.10381539165973663\n",
      "idx: 100, loss: 0.18071672320365906\n",
      "idx: 200, loss: 0.11766538769006729\n",
      "idx: 300, loss: 0.14970530569553375\n",
      "idx: 400, loss: 0.25166428089141846\n",
      "Training epoch: 4\n",
      "idx: 0, loss: 0.13393616676330566\n",
      "idx: 100, loss: 0.14538753032684326\n",
      "idx: 200, loss: 0.12768563628196716\n",
      "idx: 300, loss: 0.1438809633255005\n",
      "idx: 400, loss: 0.23875348269939423\n",
      "Training epoch: 5\n",
      "idx: 0, loss: 0.1682489514350891\n",
      "idx: 100, loss: 0.125187948346138\n",
      "idx: 200, loss: 0.10146977007389069\n",
      "idx: 300, loss: 0.1371866911649704\n",
      "idx: 400, loss: 0.24889390170574188\n",
      "Training epoch: 6\n",
      "idx: 0, loss: 0.16242900490760803\n",
      "idx: 100, loss: 0.12314209342002869\n",
      "idx: 200, loss: 0.07206807285547256\n",
      "idx: 300, loss: 0.12145186960697174\n",
      "idx: 400, loss: 0.2527179419994354\n",
      "Training epoch: 7\n",
      "idx: 0, loss: 0.14371009171009064\n",
      "idx: 100, loss: 0.12553422152996063\n",
      "idx: 200, loss: 0.07212996482849121\n",
      "idx: 300, loss: 0.1133328229188919\n",
      "idx: 400, loss: 0.2411177158355713\n",
      "Training epoch: 8\n",
      "idx: 0, loss: 0.1492113322019577\n",
      "idx: 100, loss: 0.1270325928926468\n",
      "idx: 200, loss: 0.07622025161981583\n",
      "idx: 300, loss: 0.13347668945789337\n",
      "idx: 400, loss: 0.2641887366771698\n",
      "Training epoch: 9\n",
      "idx: 0, loss: 0.1303073763847351\n",
      "idx: 100, loss: 0.12316741049289703\n",
      "idx: 200, loss: 0.0875595360994339\n",
      "idx: 300, loss: 0.13701032102108002\n",
      "idx: 400, loss: 0.3080427050590515\n",
      "Performing inference on batch: 0\n",
      "Performing inference on batch: 50\n",
      "Performing inference on batch: 0\n",
      "Performing inference on batch: 50\n",
      "FPR@95: 30.70, AUROC: 93.93 AUPR_IN: 94.30, AUPR_OUT: 93.41\n",
      "CCR: 3.42, 20.72, 50.00, 81.76, ACC: 95.28\n",
      "──────────────────────────────────────────────────────────────────────\n",
      "Running model: models/lenet_mnist_softplus_Adam_1.pkl...\n",
      "Getting optimizer for type: Adam...\n",
      "Training epoch: 0\n",
      "idx: 0, loss: 2.3405096530914307\n",
      "idx: 100, loss: 1.1046229600906372\n",
      "idx: 200, loss: 0.2685489356517792\n",
      "idx: 300, loss: 0.1404259353876114\n",
      "idx: 400, loss: 0.4758177101612091\n",
      "Training epoch: 1\n",
      "idx: 0, loss: 0.11224426329135895\n",
      "idx: 100, loss: 0.13264623284339905\n",
      "idx: 200, loss: 0.1573409140110016\n",
      "idx: 300, loss: 0.05845817178487778\n",
      "idx: 400, loss: 0.14816255867481232\n",
      "Training epoch: 2\n",
      "idx: 0, loss: 0.11375203728675842\n",
      "idx: 100, loss: 0.08551232516765594\n",
      "idx: 200, loss: 0.118370421230793\n",
      "idx: 300, loss: 0.06918679922819138\n",
      "idx: 400, loss: 0.14604556560516357\n",
      "Training epoch: 3\n",
      "idx: 0, loss: 0.1344720721244812\n",
      "idx: 100, loss: 0.06814386695623398\n",
      "idx: 200, loss: 0.16939346492290497\n",
      "idx: 300, loss: 0.07554427534341812\n",
      "idx: 400, loss: 0.12440013885498047\n",
      "Training epoch: 4\n",
      "idx: 0, loss: 0.09729144722223282\n",
      "idx: 100, loss: 0.0858185887336731\n",
      "idx: 200, loss: 0.12555819749832153\n",
      "idx: 300, loss: 0.06559436768293381\n",
      "idx: 400, loss: 0.12955397367477417\n",
      "Training epoch: 5\n",
      "idx: 0, loss: 0.07271065562963486\n",
      "idx: 100, loss: 0.06363765150308609\n",
      "idx: 200, loss: 0.14262747764587402\n",
      "idx: 300, loss: 0.08564385026693344\n",
      "idx: 400, loss: 0.18204116821289062\n",
      "Training epoch: 6\n",
      "idx: 0, loss: 0.09751572459936142\n",
      "idx: 100, loss: 0.08811667561531067\n",
      "idx: 200, loss: 0.1450086236000061\n",
      "idx: 300, loss: 0.07871059328317642\n",
      "idx: 400, loss: 0.15326723456382751\n",
      "Training epoch: 7\n",
      "idx: 0, loss: 0.10136561840772629\n",
      "idx: 100, loss: 0.07258191704750061\n",
      "idx: 200, loss: 0.18079206347465515\n",
      "idx: 300, loss: 0.06459623575210571\n",
      "idx: 400, loss: 0.18128153681755066\n",
      "Training epoch: 8\n",
      "idx: 0, loss: 0.052126094698905945\n",
      "idx: 100, loss: 0.05263349413871765\n",
      "idx: 200, loss: 0.11266246438026428\n",
      "idx: 300, loss: 0.08637259900569916\n",
      "idx: 400, loss: 0.17438673973083496\n",
      "Training epoch: 9\n",
      "idx: 0, loss: 0.04394402354955673\n",
      "idx: 100, loss: 0.0485212542116642\n",
      "idx: 200, loss: 0.08750747889280319\n",
      "idx: 300, loss: 0.06150608882308006\n",
      "idx: 400, loss: 0.17633961141109467\n",
      "Performing inference on batch: 0\n",
      "Performing inference on batch: 50\n",
      "Performing inference on batch: 0\n",
      "Performing inference on batch: 50\n",
      "FPR@95: 5.51, AUROC: 98.81 AUPR_IN: 98.96, AUPR_OUT: 98.67\n",
      "CCR: 43.70, 68.11, 86.62, 95.13, ACC: 97.47\n",
      "──────────────────────────────────────────────────────────────────────\n",
      "Running model: models/lenet_mnist_softplus_Adam_2.pkl...\n",
      "Getting optimizer for type: Adam...\n",
      "Training epoch: 0\n",
      "idx: 0, loss: 2.4221198558807373\n",
      "idx: 100, loss: 2.312039613723755\n",
      "idx: 200, loss: 2.306194305419922\n",
      "idx: 300, loss: 2.299694061279297\n",
      "idx: 400, loss: 2.3050243854522705\n",
      "Training epoch: 1\n",
      "idx: 0, loss: 2.2877562046051025\n",
      "idx: 100, loss: 2.30895733833313\n",
      "idx: 200, loss: 1.5261534452438354\n",
      "idx: 300, loss: 0.8511296510696411\n",
      "idx: 400, loss: 0.7020911574363708\n",
      "Training epoch: 2\n",
      "idx: 0, loss: 0.20907029509544373\n",
      "idx: 100, loss: 0.3291794955730438\n",
      "idx: 200, loss: 0.2950512766838074\n",
      "idx: 300, loss: 0.23336149752140045\n",
      "idx: 400, loss: 0.3269370198249817\n",
      "Training epoch: 3\n",
      "idx: 0, loss: 0.16842445731163025\n",
      "idx: 100, loss: 0.2669447958469391\n",
      "idx: 200, loss: 0.19706901907920837\n",
      "idx: 300, loss: 0.1288926899433136\n",
      "idx: 400, loss: 0.2780193090438843\n",
      "Training epoch: 4\n",
      "idx: 0, loss: 0.1794627159833908\n",
      "idx: 100, loss: 0.22332549095153809\n",
      "idx: 200, loss: 0.15077124536037445\n",
      "idx: 300, loss: 0.11029205471277237\n",
      "idx: 400, loss: 0.2817866802215576\n",
      "Training epoch: 5\n",
      "idx: 0, loss: 0.18127259612083435\n",
      "idx: 100, loss: 0.16727091372013092\n",
      "idx: 200, loss: 0.13531199097633362\n",
      "idx: 300, loss: 0.11126790940761566\n",
      "idx: 400, loss: 0.2621843218803406\n",
      "Training epoch: 6\n",
      "idx: 0, loss: 0.1277046650648117\n",
      "idx: 100, loss: 0.1518840789794922\n",
      "idx: 200, loss: 0.1338602751493454\n",
      "idx: 300, loss: 0.09819823503494263\n",
      "idx: 400, loss: 0.23511849343776703\n",
      "Training epoch: 7\n",
      "idx: 0, loss: 0.15773755311965942\n",
      "idx: 100, loss: 0.1302693635225296\n",
      "idx: 200, loss: 0.11891195178031921\n",
      "idx: 300, loss: 0.11487491428852081\n",
      "idx: 400, loss: 0.22482170164585114\n",
      "Training epoch: 8\n",
      "idx: 0, loss: 0.14453186094760895\n",
      "idx: 100, loss: 0.1280101090669632\n",
      "idx: 200, loss: 0.13013525307178497\n",
      "idx: 300, loss: 0.1115909069776535\n",
      "idx: 400, loss: 0.19540278613567352\n",
      "Training epoch: 9\n",
      "idx: 0, loss: 0.16506829857826233\n",
      "idx: 100, loss: 0.11937467753887177\n",
      "idx: 200, loss: 0.15994501113891602\n",
      "idx: 300, loss: 0.10763005912303925\n",
      "idx: 400, loss: 0.16847139596939087\n",
      "Performing inference on batch: 0\n",
      "Performing inference on batch: 50\n",
      "Performing inference on batch: 0\n",
      "Performing inference on batch: 50\n",
      "FPR@95: 39.54, AUROC: 93.00 AUPR_IN: 93.58, AUPR_OUT: 92.81\n",
      "CCR: 2.51, 19.59, 49.86, 78.18, ACC: 94.28\n",
      "──────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{0: {'dataset': 'mnist',\n",
       "  'FPR@95': '30.70',\n",
       "  'AUROC': '93.93',\n",
       "  'AUPR_IN': '94.30',\n",
       "  'AUPR_OUT': '93.41',\n",
       "  'CCR_4': '3.42',\n",
       "  'CCR_3': '20.72',\n",
       "  'CCR_2': '50.00',\n",
       "  'CCR_1': '81.76',\n",
       "  'ACC': '95.28',\n",
       "  'optimizer_type': 'Adam',\n",
       "  'activation_function_type': 'softplus',\n",
       "  'postprocessor_type': 'odin'},\n",
       " 1: {'dataset': 'mnist',\n",
       "  'FPR@95': '5.51',\n",
       "  'AUROC': '98.81',\n",
       "  'AUPR_IN': '98.96',\n",
       "  'AUPR_OUT': '98.67',\n",
       "  'CCR_4': '43.70',\n",
       "  'CCR_3': '68.11',\n",
       "  'CCR_2': '86.62',\n",
       "  'CCR_1': '95.13',\n",
       "  'ACC': '97.47',\n",
       "  'optimizer_type': 'Adam',\n",
       "  'activation_function_type': 'softplus',\n",
       "  'postprocessor_type': 'odin'},\n",
       " 2: {'dataset': 'mnist',\n",
       "  'FPR@95': '39.54',\n",
       "  'AUROC': '93.00',\n",
       "  'AUPR_IN': '93.58',\n",
       "  'AUPR_OUT': '92.81',\n",
       "  'CCR_4': '2.51',\n",
       "  'CCR_3': '19.59',\n",
       "  'CCR_2': '49.86',\n",
       "  'CCR_1': '78.18',\n",
       "  'ACC': '94.28',\n",
       "  'optimizer_type': 'Adam',\n",
       "  'activation_function_type': 'softplus',\n",
       "  'postprocessor_type': 'odin'}}"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "config_1d = {\n",
    "    \"batch_size\": 128,\n",
    "    \"dataset_name\": \"mnist\",\n",
    "    \"n_classes\": 10,\n",
    "    \"epochs\": 10,\n",
    "    \"version\": time.time(),\n",
    "    \"lr\": 0.01,\n",
    "    \"momentum\": 0.9,\n",
    "    \"weight_decay\": 0.0005,\n",
    "    \"optimizer_type\": \"Adam\",\n",
    "    \"activation_function_type\": \"softplus\",\n",
    "    \"network\": \"lenet\",\n",
    "    \"postprocessor_type\": \"odin\",\n",
    "    \"dataset_type\": \"mnist\",\n",
    "    \"trials\": 3,\n",
    "    \"results_dir\": \"mnist-study\"\n",
    "}\n",
    "config_1d[\"data_loaders\"] = get_data_loaders(config_1d)\n",
    "run_full_oodn_pipeline(config_1d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "8d1b7652",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running model: models/mnist_lenet_mcd_softplus_Adam_0.pkl...\n",
      "Getting optimizer for type: Adam...\n",
      "Training epoch: 0\n",
      "idx: 0, loss: 2.477346897125244\n",
      "idx: 100, loss: 2.309143543243408\n",
      "idx: 200, loss: 2.3063406944274902\n",
      "idx: 300, loss: 2.297903060913086\n",
      "idx: 400, loss: 1.1604360342025757\n",
      "Training epoch: 1\n",
      "idx: 0, loss: 0.37056636810302734\n",
      "idx: 100, loss: 0.36415427923202515\n",
      "idx: 200, loss: 0.14169979095458984\n",
      "idx: 300, loss: 0.20955771207809448\n",
      "idx: 400, loss: 0.40641340613365173\n",
      "Training epoch: 2\n",
      "idx: 0, loss: 0.19860942661762238\n",
      "idx: 100, loss: 0.16836953163146973\n",
      "idx: 200, loss: 0.11009348183870316\n",
      "idx: 300, loss: 0.08757030218839645\n",
      "idx: 400, loss: 0.3184612989425659\n",
      "Training epoch: 3\n",
      "idx: 0, loss: 0.07341178506612778\n",
      "idx: 100, loss: 0.10277615487575531\n",
      "idx: 200, loss: 0.09509484469890594\n",
      "idx: 300, loss: 0.09184584766626358\n",
      "idx: 400, loss: 0.25116777420043945\n",
      "Training epoch: 4\n",
      "idx: 0, loss: 0.1025996208190918\n",
      "idx: 100, loss: 0.07905026525259018\n",
      "idx: 200, loss: 0.06830193847417831\n",
      "idx: 300, loss: 0.0769985094666481\n",
      "idx: 400, loss: 0.26025617122650146\n",
      "Training epoch: 5\n",
      "idx: 0, loss: 0.0756063312292099\n",
      "idx: 100, loss: 0.09014879167079926\n",
      "idx: 200, loss: 0.08020301908254623\n",
      "idx: 300, loss: 0.07628265023231506\n",
      "idx: 400, loss: 0.23918581008911133\n",
      "Training epoch: 6\n",
      "idx: 0, loss: 0.07323913276195526\n",
      "idx: 100, loss: 0.07065686583518982\n",
      "idx: 200, loss: 0.0709984302520752\n",
      "idx: 300, loss: 0.062018249183893204\n",
      "idx: 400, loss: 0.26551035046577454\n",
      "Training epoch: 7\n",
      "idx: 0, loss: 0.059373024851083755\n",
      "idx: 100, loss: 0.03645525127649307\n",
      "idx: 200, loss: 0.13039790093898773\n",
      "idx: 300, loss: 0.07830038666725159\n",
      "idx: 400, loss: 0.18007397651672363\n",
      "Training epoch: 8\n",
      "idx: 0, loss: 0.07170459628105164\n",
      "idx: 100, loss: 0.03922633081674576\n",
      "idx: 200, loss: 0.055835120379924774\n",
      "idx: 300, loss: 0.07035580277442932\n",
      "idx: 400, loss: 0.20161797106266022\n",
      "Training epoch: 9\n",
      "idx: 0, loss: 0.06251587718725204\n",
      "idx: 100, loss: 0.07002079486846924\n",
      "idx: 200, loss: 0.06078196316957474\n",
      "idx: 300, loss: 0.08170034736394882\n",
      "idx: 400, loss: 0.18012259900569916\n",
      "Performing inference on batch: 0\n",
      "Performing inference on batch: 50\n",
      "Performing inference on batch: 0\n",
      "Performing inference on batch: 50\n",
      "FPR@95: 2.74, AUROC: 99.29 AUPR_IN: 99.37, AUPR_OUT: 99.20\n",
      "CCR: 57.37, 72.99, 89.96, 95.97, ACC: 97.12\n",
      "──────────────────────────────────────────────────────────────────────\n",
      "Running model: models/mnist_lenet_mcd_softplus_Adam_1.pkl...\n",
      "Getting optimizer for type: Adam...\n",
      "Training epoch: 0\n",
      "idx: 0, loss: 2.3131253719329834\n",
      "idx: 100, loss: 1.1768726110458374\n",
      "idx: 200, loss: 0.295674592256546\n",
      "idx: 300, loss: 0.21631452441215515\n",
      "idx: 400, loss: 0.28660526871681213\n",
      "Training epoch: 1\n",
      "idx: 0, loss: 0.09437427669763565\n",
      "idx: 100, loss: 0.13071264326572418\n",
      "idx: 200, loss: 0.20083914697170258\n",
      "idx: 300, loss: 0.12828218936920166\n",
      "idx: 400, loss: 0.2758871018886566\n",
      "Training epoch: 2\n",
      "idx: 0, loss: 0.08344027400016785\n",
      "idx: 100, loss: 0.1227387934923172\n",
      "idx: 200, loss: 0.16918499767780304\n",
      "idx: 300, loss: 0.07783360779285431\n",
      "idx: 400, loss: 0.20645059645175934\n",
      "Training epoch: 3\n",
      "idx: 0, loss: 0.08138492703437805\n",
      "idx: 100, loss: 0.15846234560012817\n",
      "idx: 200, loss: 0.13998258113861084\n",
      "idx: 300, loss: 0.062196146696805954\n",
      "idx: 400, loss: 0.21047012507915497\n",
      "Training epoch: 4\n",
      "idx: 0, loss: 0.05455400049686432\n",
      "idx: 100, loss: 0.1493409425020218\n",
      "idx: 200, loss: 0.13448742032051086\n",
      "idx: 300, loss: 0.07117702811956406\n",
      "idx: 400, loss: 0.16418121755123138\n",
      "Training epoch: 5\n",
      "idx: 0, loss: 0.06983302533626556\n",
      "idx: 100, loss: 0.13523586094379425\n",
      "idx: 200, loss: 0.09281019866466522\n",
      "idx: 300, loss: 0.07111489027738571\n",
      "idx: 400, loss: 0.13723783195018768\n",
      "Training epoch: 6\n",
      "idx: 0, loss: 0.04571761190891266\n",
      "idx: 100, loss: 0.06594257801771164\n",
      "idx: 200, loss: 0.12585961818695068\n",
      "idx: 300, loss: 0.07629246264696121\n",
      "idx: 400, loss: 0.11860202997922897\n",
      "Training epoch: 7\n",
      "idx: 0, loss: 0.05397089570760727\n",
      "idx: 100, loss: 0.07975368201732635\n",
      "idx: 200, loss: 0.07690627872943878\n",
      "idx: 300, loss: 0.09174402058124542\n",
      "idx: 400, loss: 0.11775185912847519\n",
      "Training epoch: 8\n",
      "idx: 0, loss: 0.0573258176445961\n",
      "idx: 100, loss: 0.06533345580101013\n",
      "idx: 200, loss: 0.07392542064189911\n",
      "idx: 300, loss: 0.08018840104341507\n",
      "idx: 400, loss: 0.10211493819952011\n",
      "Training epoch: 9\n",
      "idx: 0, loss: 0.0593419075012207\n",
      "idx: 100, loss: 0.08713608980178833\n",
      "idx: 200, loss: 0.08125295490026474\n",
      "idx: 300, loss: 0.09282787144184113\n",
      "idx: 400, loss: 0.11181843280792236\n",
      "Performing inference on batch: 0\n",
      "Performing inference on batch: 50\n",
      "Performing inference on batch: 0\n",
      "Performing inference on batch: 50\n",
      "FPR@95: 19.76, AUROC: 96.68 AUPR_IN: 97.26, AUPR_OUT: 95.92\n",
      "CCR: 31.55, 52.66, 73.68, 90.83, ACC: 98.20\n",
      "──────────────────────────────────────────────────────────────────────\n",
      "Running model: models/mnist_lenet_mcd_softplus_Adam_2.pkl...\n",
      "Getting optimizer for type: Adam...\n",
      "Training epoch: 0\n",
      "idx: 0, loss: 2.5525879859924316\n",
      "idx: 100, loss: 0.9975889325141907\n",
      "idx: 200, loss: 0.24757549166679382\n",
      "idx: 300, loss: 0.11983543634414673\n",
      "idx: 400, loss: 0.3974229395389557\n",
      "Training epoch: 1\n",
      "idx: 0, loss: 0.08506197482347488\n",
      "idx: 100, loss: 0.0743117704987526\n",
      "idx: 200, loss: 0.15997003018856049\n",
      "idx: 300, loss: 0.044898226857185364\n",
      "idx: 400, loss: 0.2327176183462143\n",
      "Training epoch: 2\n",
      "idx: 0, loss: 0.05372751131653786\n",
      "idx: 100, loss: 0.0791180282831192\n",
      "idx: 200, loss: 0.11488223075866699\n",
      "idx: 300, loss: 0.07802256941795349\n",
      "idx: 400, loss: 0.2504972815513611\n",
      "Training epoch: 3\n",
      "idx: 0, loss: 0.051582325249910355\n",
      "idx: 100, loss: 0.06518848985433578\n",
      "idx: 200, loss: 0.11981569975614548\n",
      "idx: 300, loss: 0.0739331990480423\n",
      "idx: 400, loss: 0.25508078932762146\n",
      "Training epoch: 4\n",
      "idx: 0, loss: 0.03801446035504341\n",
      "idx: 100, loss: 0.03150251507759094\n",
      "idx: 200, loss: 0.10421790927648544\n",
      "idx: 300, loss: 0.06475810706615448\n",
      "idx: 400, loss: 0.22420446574687958\n",
      "Training epoch: 5\n",
      "idx: 0, loss: 0.03519812971353531\n",
      "idx: 100, loss: 0.03311101347208023\n",
      "idx: 200, loss: 0.1364501416683197\n",
      "idx: 300, loss: 0.03431552276015282\n",
      "idx: 400, loss: 0.31970953941345215\n",
      "Training epoch: 6\n",
      "idx: 0, loss: 0.01472325250506401\n",
      "idx: 100, loss: 0.032219015061855316\n",
      "idx: 200, loss: 0.09108804911375046\n",
      "idx: 300, loss: 0.0668528601527214\n",
      "idx: 400, loss: 0.32444286346435547\n",
      "Training epoch: 7\n",
      "idx: 0, loss: 0.04057660326361656\n",
      "idx: 100, loss: 0.03889612480998039\n",
      "idx: 200, loss: 0.13069042563438416\n",
      "idx: 300, loss: 0.05485481768846512\n",
      "idx: 400, loss: 0.25554338097572327\n",
      "Training epoch: 8\n",
      "idx: 0, loss: 0.03992469236254692\n",
      "idx: 100, loss: 0.01724741794168949\n",
      "idx: 200, loss: 0.0917581170797348\n",
      "idx: 300, loss: 0.048056576400995255\n",
      "idx: 400, loss: 0.16817328333854675\n",
      "Training epoch: 9\n",
      "idx: 0, loss: 0.04942852258682251\n",
      "idx: 100, loss: 0.033390965312719345\n",
      "idx: 200, loss: 0.062223393470048904\n",
      "idx: 300, loss: 0.04944848641753197\n",
      "idx: 400, loss: 0.188333198428154\n",
      "Performing inference on batch: 0\n",
      "Performing inference on batch: 50\n",
      "Performing inference on batch: 0\n",
      "Performing inference on batch: 50\n",
      "FPR@95: 5.64, AUROC: 98.84 AUPR_IN: 98.99, AUPR_OUT: 98.61\n",
      "CCR: 35.22, 64.05, 86.40, 95.95, ACC: 97.98\n",
      "──────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{0: {'dataset': 'mnist',\n",
       "  'FPR@95': '2.74',\n",
       "  'AUROC': '99.29',\n",
       "  'AUPR_IN': '99.37',\n",
       "  'AUPR_OUT': '99.20',\n",
       "  'CCR_4': '57.37',\n",
       "  'CCR_3': '72.99',\n",
       "  'CCR_2': '89.96',\n",
       "  'CCR_1': '95.97',\n",
       "  'ACC': '97.12',\n",
       "  'optimizer_type': 'Adam',\n",
       "  'activation_function_type': 'softplus',\n",
       "  'postprocessor_type': 'mcd'},\n",
       " 1: {'dataset': 'mnist',\n",
       "  'FPR@95': '19.76',\n",
       "  'AUROC': '96.68',\n",
       "  'AUPR_IN': '97.26',\n",
       "  'AUPR_OUT': '95.92',\n",
       "  'CCR_4': '31.55',\n",
       "  'CCR_3': '52.66',\n",
       "  'CCR_2': '73.68',\n",
       "  'CCR_1': '90.83',\n",
       "  'ACC': '98.20',\n",
       "  'optimizer_type': 'Adam',\n",
       "  'activation_function_type': 'softplus',\n",
       "  'postprocessor_type': 'mcd'},\n",
       " 2: {'dataset': 'mnist',\n",
       "  'FPR@95': '5.64',\n",
       "  'AUROC': '98.84',\n",
       "  'AUPR_IN': '98.99',\n",
       "  'AUPR_OUT': '98.61',\n",
       "  'CCR_4': '35.22',\n",
       "  'CCR_3': '64.05',\n",
       "  'CCR_2': '86.40',\n",
       "  'CCR_1': '95.95',\n",
       "  'ACC': '97.98',\n",
       "  'optimizer_type': 'Adam',\n",
       "  'activation_function_type': 'softplus',\n",
       "  'postprocessor_type': 'mcd'}}"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "config_1_1d = {\n",
    "    \"batch_size\": 128,\n",
    "    \"dataset_name\": \"mnist\",\n",
    "    \"n_classes\": 10,\n",
    "    \"epochs\": 10,\n",
    "    \"version\": time.time(),\n",
    "    \"lr\": 0.01,\n",
    "    \"momentum\": 0.9,\n",
    "    \"weight_decay\": 0.0005,\n",
    "    \"optimizer_type\": \"Adam\",\n",
    "    \"activation_function_type\": \"softplus\",\n",
    "    \"network\": \"lenet\",\n",
    "    \"postprocessor_type\": \"mcd\",\n",
    "    \"dataset_type\": \"mnist\",\n",
    "    \"trials\": 3,\n",
    "    \"results_dir\": \"mnist-study\"\n",
    "}\n",
    "config_1_1d[\"data_loaders\"] = get_data_loaders(config_1_1d)\n",
    "run_full_oodn_pipeline(config_1_1d)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f12abb2",
   "metadata": {},
   "source": [
    "### Robustness Analysis For Study 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "ed57b8a4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>optimizer_type</th>\n",
       "      <th>activation_function_type</th>\n",
       "      <th>postprocessor_type</th>\n",
       "      <th>trial</th>\n",
       "      <th>AUROC</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>SGD</td>\n",
       "      <td>softplus</td>\n",
       "      <td>odin</td>\n",
       "      <td>0</td>\n",
       "      <td>98.15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>SGD</td>\n",
       "      <td>softplus</td>\n",
       "      <td>odin</td>\n",
       "      <td>1</td>\n",
       "      <td>99.63</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>SGD</td>\n",
       "      <td>softplus</td>\n",
       "      <td>odin</td>\n",
       "      <td>2</td>\n",
       "      <td>99.15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Adam</td>\n",
       "      <td>softplus</td>\n",
       "      <td>odin</td>\n",
       "      <td>0</td>\n",
       "      <td>93.93</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Adam</td>\n",
       "      <td>softplus</td>\n",
       "      <td>odin</td>\n",
       "      <td>1</td>\n",
       "      <td>98.81</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Adam</td>\n",
       "      <td>softplus</td>\n",
       "      <td>odin</td>\n",
       "      <td>2</td>\n",
       "      <td>93.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Adam</td>\n",
       "      <td>relu</td>\n",
       "      <td>mcd</td>\n",
       "      <td>0</td>\n",
       "      <td>99.70</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Adam</td>\n",
       "      <td>relu</td>\n",
       "      <td>mcd</td>\n",
       "      <td>1</td>\n",
       "      <td>99.35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Adam</td>\n",
       "      <td>relu</td>\n",
       "      <td>mcd</td>\n",
       "      <td>2</td>\n",
       "      <td>99.75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>SGD</td>\n",
       "      <td>relu</td>\n",
       "      <td>mcd</td>\n",
       "      <td>0</td>\n",
       "      <td>99.15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>SGD</td>\n",
       "      <td>relu</td>\n",
       "      <td>mcd</td>\n",
       "      <td>1</td>\n",
       "      <td>99.14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>SGD</td>\n",
       "      <td>relu</td>\n",
       "      <td>mcd</td>\n",
       "      <td>2</td>\n",
       "      <td>98.71</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>SGD</td>\n",
       "      <td>relu</td>\n",
       "      <td>odin</td>\n",
       "      <td>0</td>\n",
       "      <td>99.60</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>SGD</td>\n",
       "      <td>relu</td>\n",
       "      <td>odin</td>\n",
       "      <td>1</td>\n",
       "      <td>99.36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>SGD</td>\n",
       "      <td>relu</td>\n",
       "      <td>odin</td>\n",
       "      <td>2</td>\n",
       "      <td>99.81</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>SGD</td>\n",
       "      <td>softplus</td>\n",
       "      <td>mcd</td>\n",
       "      <td>0</td>\n",
       "      <td>99.19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>SGD</td>\n",
       "      <td>softplus</td>\n",
       "      <td>mcd</td>\n",
       "      <td>1</td>\n",
       "      <td>98.77</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>SGD</td>\n",
       "      <td>softplus</td>\n",
       "      <td>mcd</td>\n",
       "      <td>2</td>\n",
       "      <td>96.35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Adam</td>\n",
       "      <td>relu</td>\n",
       "      <td>odin</td>\n",
       "      <td>0</td>\n",
       "      <td>99.40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>Adam</td>\n",
       "      <td>relu</td>\n",
       "      <td>odin</td>\n",
       "      <td>1</td>\n",
       "      <td>99.41</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>Adam</td>\n",
       "      <td>relu</td>\n",
       "      <td>odin</td>\n",
       "      <td>2</td>\n",
       "      <td>99.55</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>Adam</td>\n",
       "      <td>softplus</td>\n",
       "      <td>mcd</td>\n",
       "      <td>0</td>\n",
       "      <td>99.29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>Adam</td>\n",
       "      <td>softplus</td>\n",
       "      <td>mcd</td>\n",
       "      <td>1</td>\n",
       "      <td>96.68</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>Adam</td>\n",
       "      <td>softplus</td>\n",
       "      <td>mcd</td>\n",
       "      <td>2</td>\n",
       "      <td>98.84</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   optimizer_type activation_function_type postprocessor_type trial  AUROC\n",
       "0             SGD                 softplus               odin     0  98.15\n",
       "1             SGD                 softplus               odin     1  99.63\n",
       "2             SGD                 softplus               odin     2  99.15\n",
       "3            Adam                 softplus               odin     0  93.93\n",
       "4            Adam                 softplus               odin     1  98.81\n",
       "5            Adam                 softplus               odin     2  93.00\n",
       "6            Adam                     relu                mcd     0  99.70\n",
       "7            Adam                     relu                mcd     1  99.35\n",
       "8            Adam                     relu                mcd     2  99.75\n",
       "9             SGD                     relu                mcd     0  99.15\n",
       "10            SGD                     relu                mcd     1  99.14\n",
       "11            SGD                     relu                mcd     2  98.71\n",
       "12            SGD                     relu               odin     0  99.60\n",
       "13            SGD                     relu               odin     1  99.36\n",
       "14            SGD                     relu               odin     2  99.81\n",
       "15            SGD                 softplus                mcd     0  99.19\n",
       "16            SGD                 softplus                mcd     1  98.77\n",
       "17            SGD                 softplus                mcd     2  96.35\n",
       "18           Adam                     relu               odin     0  99.40\n",
       "19           Adam                     relu               odin     1  99.41\n",
       "20           Adam                     relu               odin     2  99.55\n",
       "21           Adam                 softplus                mcd     0  99.29\n",
       "22           Adam                 softplus                mcd     1  96.68\n",
       "23           Adam                 softplus                mcd     2  98.84"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_study_1 = load_results_into_df('mnist-study/')\n",
    "df_study_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "37b29ba6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>min</th>\n",
       "      <th>25%</th>\n",
       "      <th>50%</th>\n",
       "      <th>75%</th>\n",
       "      <th>max</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>optimizer_type</th>\n",
       "      <th>activation_function_type</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">Adam</th>\n",
       "      <th>relu</th>\n",
       "      <td>6.0</td>\n",
       "      <td>99.526667</td>\n",
       "      <td>0.168127</td>\n",
       "      <td>99.35</td>\n",
       "      <td>99.4025</td>\n",
       "      <td>99.480</td>\n",
       "      <td>99.6625</td>\n",
       "      <td>99.75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>softplus</th>\n",
       "      <td>6.0</td>\n",
       "      <td>96.758333</td>\n",
       "      <td>2.723332</td>\n",
       "      <td>93.00</td>\n",
       "      <td>94.6175</td>\n",
       "      <td>97.745</td>\n",
       "      <td>98.8325</td>\n",
       "      <td>99.29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">SGD</th>\n",
       "      <th>relu</th>\n",
       "      <td>6.0</td>\n",
       "      <td>99.295000</td>\n",
       "      <td>0.387234</td>\n",
       "      <td>98.71</td>\n",
       "      <td>99.1425</td>\n",
       "      <td>99.255</td>\n",
       "      <td>99.5400</td>\n",
       "      <td>99.81</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>softplus</th>\n",
       "      <td>6.0</td>\n",
       "      <td>98.540000</td>\n",
       "      <td>1.181846</td>\n",
       "      <td>96.35</td>\n",
       "      <td>98.3050</td>\n",
       "      <td>98.960</td>\n",
       "      <td>99.1800</td>\n",
       "      <td>99.63</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         count       mean       std    min  \\\n",
       "optimizer_type activation_function_type                                      \n",
       "Adam           relu                        6.0  99.526667  0.168127  99.35   \n",
       "               softplus                    6.0  96.758333  2.723332  93.00   \n",
       "SGD            relu                        6.0  99.295000  0.387234  98.71   \n",
       "               softplus                    6.0  98.540000  1.181846  96.35   \n",
       "\n",
       "                                             25%     50%      75%    max  \n",
       "optimizer_type activation_function_type                                   \n",
       "Adam           relu                      99.4025  99.480  99.6625  99.75  \n",
       "               softplus                  94.6175  97.745  98.8325  99.29  \n",
       "SGD            relu                      99.1425  99.255  99.5400  99.81  \n",
       "               softplus                  98.3050  98.960  99.1800  99.63  "
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_study_1.groupby(['optimizer_type', 'activation_function_type'])['AUROC'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "999547f7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>min</th>\n",
       "      <th>25%</th>\n",
       "      <th>50%</th>\n",
       "      <th>75%</th>\n",
       "      <th>max</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>activation_function_type</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>relu</th>\n",
       "      <td>12.0</td>\n",
       "      <td>99.410833</td>\n",
       "      <td>0.309265</td>\n",
       "      <td>98.71</td>\n",
       "      <td>99.3000</td>\n",
       "      <td>99.405</td>\n",
       "      <td>99.625</td>\n",
       "      <td>99.81</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>softplus</th>\n",
       "      <td>12.0</td>\n",
       "      <td>97.649167</td>\n",
       "      <td>2.207209</td>\n",
       "      <td>93.00</td>\n",
       "      <td>96.5975</td>\n",
       "      <td>98.790</td>\n",
       "      <td>99.160</td>\n",
       "      <td>99.63</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                          count       mean       std    min      25%     50%  \\\n",
       "activation_function_type                                                       \n",
       "relu                       12.0  99.410833  0.309265  98.71  99.3000  99.405   \n",
       "softplus                   12.0  97.649167  2.207209  93.00  96.5975  98.790   \n",
       "\n",
       "                             75%    max  \n",
       "activation_function_type                 \n",
       "relu                      99.625  99.81  \n",
       "softplus                  99.160  99.63  "
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_study_1.groupby(['activation_function_type'])['AUROC'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "4784b707",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>min</th>\n",
       "      <th>25%</th>\n",
       "      <th>50%</th>\n",
       "      <th>75%</th>\n",
       "      <th>max</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>optimizer_type</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Adam</th>\n",
       "      <td>12.0</td>\n",
       "      <td>98.1425</td>\n",
       "      <td>2.339678</td>\n",
       "      <td>93.00</td>\n",
       "      <td>98.2775</td>\n",
       "      <td>99.32</td>\n",
       "      <td>99.445</td>\n",
       "      <td>99.75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SGD</th>\n",
       "      <td>12.0</td>\n",
       "      <td>98.9175</td>\n",
       "      <td>0.926559</td>\n",
       "      <td>96.35</td>\n",
       "      <td>98.7550</td>\n",
       "      <td>99.15</td>\n",
       "      <td>99.420</td>\n",
       "      <td>99.81</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                count     mean       std    min      25%    50%     75%    max\n",
       "optimizer_type                                                                \n",
       "Adam             12.0  98.1425  2.339678  93.00  98.2775  99.32  99.445  99.75\n",
       "SGD              12.0  98.9175  0.926559  96.35  98.7550  99.15  99.420  99.81"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_study_1.groupby(['optimizer_type'])['AUROC'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "3b18798c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def perform_oodn_analysis_on_preloaded_model(model_path, config):\n",
    "    model = torch.load(model_path)\n",
    "    calculate_oodn_metrics(model,\n",
    "                                   config['postprocessor_type'],\n",
    "                                   config[\"data_loaders\"][\"id_test\"],\n",
    "                                   config[\"data_loaders\"][\"ood_test\"],\n",
    "                                   config[\"dataset_name\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "b1805c49",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Performing inference on batch: 0\n",
      "Performing inference on batch: 50\n",
      "Performing inference on batch: 0\n",
      "Performing inference on batch: 50\n",
      "FPR@95: 45.00, AUROC: 92.68 AUPR_IN: 93.77, AUPR_OUT: 91.00\n",
      "CCR: 1.08, 25.41, 51.53, 82.04, ACC: 95.29\n",
      "──────────────────────────────────────────────────────────────────────\n"
     ]
    }
   ],
   "source": [
    "perform_oodn_analysis_on_preloaded_model('models/lenet_mnist_softplus_Adam_0.pkl', config_1_1a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "a8fba289",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Performing inference on batch: 0\n",
      "Performing inference on batch: 50\n",
      "Performing inference on batch: 0\n",
      "Performing inference on batch: 50\n",
      "FPR@95: 30.70, AUROC: 93.93 AUPR_IN: 94.30, AUPR_OUT: 93.41\n",
      "CCR: 3.44, 20.72, 50.02, 81.76, ACC: 95.28\n",
      "──────────────────────────────────────────────────────────────────────\n"
     ]
    }
   ],
   "source": [
    "perform_oodn_analysis_on_preloaded_model('models/lenet_mnist_softplus_Adam_0.pkl', config_1a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e1cb4be",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
