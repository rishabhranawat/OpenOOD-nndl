{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "bhw8NPwVRbdT",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from os import listdir\n",
    "\n",
    "import time\n",
    "import json\n",
    "import copy\n",
    "\n",
    "import torch\n",
    "\n",
    "from torchvision.datasets import mnist, FashionMNIST, CIFAR10, CIFAR100\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision.transforms import ToTensor\n",
    "from torch.optim import SGD, Adam\n",
    "from torch.nn import Module\n",
    "from torch import nn\n",
    "from torch.nn import CrossEntropyLoss\n",
    "from torchvision.models.resnet import Bottleneck, ResNet\n",
    "from torchvision import datasets, models, transforms\n",
    "\n",
    "from wilds import get_dataset\n",
    "from wilds.common.data_loaders import get_train_loader\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from openood.evaluators import metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "11glohxERbdU",
    "outputId": "a412b2d2-d294-470d-b27a-abd3627aa087",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10.2\n"
     ]
    }
   ],
   "source": [
    "print(torch.version.cuda)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "1tHAXNmwRbdU",
    "outputId": "ae15afd4-3c31-4e5c-d557-178f188de89c",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0\n"
     ]
    }
   ],
   "source": [
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "WtgqLe2SajQb",
    "outputId": "3961662e-2a97-4bb0-a56c-11d9e69e79a6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/rdr2143/oodn-final-project/OpenOOD-nndl\r\n"
     ]
    }
   ],
   "source": [
    "!pwd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BWs4cttKRbdU",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Supported Activation Functions\n",
    "\n",
    "For activation functions, we are considering ReLU, Softplus, Swish. *Note that we may conduct experiments for a subset based on the compute resources available*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "wFDrLIC4RbdV",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def get_activation_fn(activation):\n",
    "    if activation == 'relu':\n",
    "        return nn.ReLU()\n",
    "    elif activation == 'softplus':\n",
    "        return nn.Softplus()\n",
    "    elif activation == 'swish':\n",
    "        return nn.Swish()\n",
    "    return None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ORnYhf-1RbdV",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7vRFe847RbdV",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### LeNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "-H6TJweYRbdV",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "class LeNet(nn.Module):\n",
    "    def __init__(self, num_classes, num_channel=3, activation='relu'):\n",
    "        super(LeNet, self).__init__()\n",
    "        self.num_classes = num_classes\n",
    "        self.feature_size = 84\n",
    "        self.block1 = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=num_channel,\n",
    "                      out_channels=6,\n",
    "                      kernel_size=5,\n",
    "                      stride=1,\n",
    "                      padding=2), get_activation_fn(activation), nn.MaxPool2d(kernel_size=2))\n",
    "\n",
    "        self.block2 = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=6, out_channels=16, kernel_size=5, stride=1),\n",
    "             get_activation_fn(activation), nn.MaxPool2d(kernel_size=2))\n",
    "\n",
    "        self.block3 = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=16,\n",
    "                      out_channels=120,\n",
    "                      kernel_size=5,\n",
    "                      stride=1), get_activation_fn(activation))\n",
    "\n",
    "        self.classifier1 = nn.Linear(in_features=120, out_features=84)\n",
    "        self.relu = get_activation_fn(activation)\n",
    "        self.fc = nn.Linear(in_features=84, out_features=num_classes)\n",
    "\n",
    "    def get_fc(self):\n",
    "        fc = self.fc\n",
    "        return fc.weight.cpu().detach().numpy(), fc.bias.cpu().detach().numpy()\n",
    "\n",
    "    def forward(self, x, return_feature=False, return_feature_list=False):\n",
    "        feature1 = self.block1(x)\n",
    "        feature2 = self.block2(feature1)\n",
    "        feature3 = self.block3(feature2)\n",
    "        feature3 = feature3.view(feature3.shape[0], -1)\n",
    "        feature = self.relu(self.classifier1(feature3))\n",
    "        logits_cls = self.fc(feature)\n",
    "        feature_list = [feature1, feature2, feature3, feature]\n",
    "        if return_feature:\n",
    "            return logits_cls, feature\n",
    "        elif return_feature_list:\n",
    "            return logits_cls, feature_list\n",
    "        else:\n",
    "            return logits_cls\n",
    "\n",
    "    def forward_threshold(self, x, threshold):\n",
    "        feature1 = self.block1(x)\n",
    "        feature2 = self.block2(feature1)\n",
    "        feature3 = self.block3(feature2)\n",
    "        feature3 = feature3.view(feature3.shape[0], -1)\n",
    "        feature = self.relu(self.classifier1(feature3))\n",
    "        feature = feature.clip(max=threshold)\n",
    "        logits_cls = self.fc(feature)\n",
    "\n",
    "        return logits_cls"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XYwc4beHRbdV",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### ResNet50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "4EaTD1nVRbdW",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def set_parameter_requires_grad(model):\n",
    "    for name,param in model.named_parameters():\n",
    "        if not (name.startswith('layer4') or name.startswith('fc')):\n",
    "            param.requires_grad = False\n",
    "\n",
    "def get_resnet_model(activation_function_type, n_classes, use_pretrained=True):\n",
    "    resnet_model = models.resnet50(pretrained=use_pretrained)\n",
    "    \n",
    "    # if we use pretrained, then freeze the corresponding layers\n",
    "    if use_pretrained:\n",
    "        set_parameter_requires_grad(resnet_model, feature_extract)\n",
    "\n",
    "    set_activation_function(resnet_model,activation_function_type)\n",
    "    num_ftrs = resnet_model.fc.in_features\n",
    "    resnet_model.fc = nn.Linear(num_ftrs, n_classes)\n",
    "    resnet_model.to(device)\n",
    "    return resnet_model\n",
    "\n",
    "def set_activation_function(resnet_model, activation_function_type):\n",
    "    resnet_model.relu = get_activation_fn(activation_function_type)\n",
    "    resnet_model.layer1[0].relu = get_activation_fn(activation_function_type)\n",
    "    resnet_model.layer1[1].relu = get_activation_fn(activation_function_type)\n",
    "    resnet_model.layer1[2].relu = get_activation_fn(activation_function_type)\n",
    "\n",
    "    resnet_model.layer2[0].relu = get_activation_fn(activation_function_type)\n",
    "    resnet_model.layer2[1].relu = get_activation_fn(activation_function_type)\n",
    "    resnet_model.layer2[2].relu = get_activation_fn(activation_function_type)\n",
    "    resnet_model.layer2[3].relu = get_activation_fn(activation_function_type)\n",
    "\n",
    "    resnet_model.layer3[0].relu = get_activation_fn(activation_function_type)\n",
    "    resnet_model.layer3[1].relu = get_activation_fn(activation_function_type)\n",
    "    resnet_model.layer3[2].relu = get_activation_fn(activation_function_type)\n",
    "    resnet_model.layer3[3].relu = get_activation_fn(activation_function_type)\n",
    "    resnet_model.layer3[4].relu = get_activation_fn(activation_function_type)\n",
    "    resnet_model.layer3[5].relu = get_activation_fn(activation_function_type)\n",
    "\n",
    "\n",
    "    resnet_model.layer4[0].relu = get_activation_fn(activation_function_type)\n",
    "    resnet_model.layer4[1].relu = get_activation_fn(activation_function_type)\n",
    "    resnet_model.layer4[2].relu = get_activation_fn(activation_function_type)\n",
    "\n",
    "    return resnet_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "Mm1fB4piRbdW",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def get_model(config):\n",
    "    activation_function_type = config[\"activation_function_type\"]\n",
    "    network_type = config[\"network\"]\n",
    "    n_classes = config[\"n_classes\"]\n",
    "\n",
    "    if network_type == \"lenet\":\n",
    "        model =  LeNet(num_classes=n_classes, num_channel=1, activation=activation_function_type)\n",
    "    elif network_type == \"resnet50\":\n",
    "        model = get_resnet_model(activation_function_type, n_classes, config['pretrained'])\n",
    "    else:\n",
    "        raise Exception(\"Currently we only support lenet or resnet50\")\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9veLq_LDRbdW",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OKbri3J-RbdW",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Supported Post-Hoc OODN Processors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class OODPostprocessor():\n",
    "    \n",
    "    def inference(self, net: nn.Module, data_loader: DataLoader):\n",
    "        pred_list, conf_list, label_list = [], [], []\n",
    "        for idx, loaded_data in enumerate(data_loader):\n",
    "            data, label = loaded_data[0], loaded_data[1]\n",
    "            if idx % 50 == 0:\n",
    "                print(f'Performing inference on batch: {idx}')\n",
    "            pred, conf = self.postprocess(net, data.to(device))\n",
    "            for idx in range(len(data)):\n",
    "                pred_list.append(pred[idx].tolist())\n",
    "                conf_list.append(conf[idx].tolist())\n",
    "                label_list.append(label[idx].tolist())\n",
    "\n",
    "        # convert values into numpy array\n",
    "        pred_list = np.array(pred_list, dtype=int)\n",
    "        conf_list = np.array(conf_list)\n",
    "        label_list = np.array(label_list, dtype=int)\n",
    "\n",
    "        return pred_list, conf_list, label_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ODINPostprocessor(OODPostprocessor):\n",
    "    def __init__(self, temperature, noise):\n",
    "        super(OODPostprocessor)\n",
    "        self.temperature = temperature\n",
    "        self.noise = noise\n",
    "        \n",
    "    def postprocess(self, net: nn.Module, data):\n",
    "        net.eval()\n",
    "        data.requires_grad = True\n",
    "        output = net(data)\n",
    "\n",
    "        # Calculating the perturbation we need to add, that is,\n",
    "        # the sign of gradient of cross entropy loss w.r.t. input\n",
    "        criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "        labels = output.detach().argmax(axis=1)\n",
    "\n",
    "        # Using temperature scaling\n",
    "        output = output / self.temperature\n",
    "\n",
    "        loss = criterion(output, labels)\n",
    "        loss.backward()\n",
    "\n",
    "        # Normalizing the gradient to binary in {0, 1}\n",
    "        gradient = torch.ge(data.grad.detach(), 0)\n",
    "        gradient = (gradient.float() - 0.5) * 2\n",
    "\n",
    "        # Scaling values taken from original code       \n",
    "        gradient[:, 0] = (gradient[:, 0]) / (63.0 / 255.0)\n",
    "        if gradient.shape[1] == 3:\n",
    "            gradient[:, 1] = (gradient[:, 1]) / (62.1 / 255.0)\n",
    "            gradient[:, 2] = (gradient[:, 2]) / (66.7 / 255.0)\n",
    "\n",
    "        # Adding small perturbations to images\n",
    "        tempInputs = torch.add(data.detach(), gradient, alpha=-self.noise)\n",
    "        output = net(tempInputs)\n",
    "        output = output / self.temperature\n",
    "\n",
    "        # Calculating the confidence after adding perturbations\n",
    "        nnOutput = output.detach()\n",
    "        nnOutput = nnOutput - nnOutput.max(dim=1, keepdims=True).values\n",
    "        nnOutput = nnOutput.exp() / nnOutput.exp().sum(dim=1, keepdims=True)\n",
    "\n",
    "        conf, pred = nnOutput.max(dim=1)\n",
    "\n",
    "        return pred, conf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MCDPostprocessor(OODPostprocessor):\n",
    "    def __init__(self, samples: int = 30):\n",
    "        super(OODPostprocessor)\n",
    "        self.samples = samples  #: number :math:`N` of samples\n",
    "\n",
    "    def postprocess(self, model: torch.nn.Module, x: torch.Tensor) -> torch.Tensor:\n",
    "        mode_switch = False\n",
    "        if not model.training:\n",
    "            mode_switch = True\n",
    "\n",
    "            model.train()\n",
    "\n",
    "            for mod in model.modules():\n",
    "                # reset batch norm layers.\n",
    "                # TODO: are there other layers?\n",
    "                if isinstance(mod, (nn.BatchNorm1d, nn.BatchNorm2d, nn.BatchNorm3d)):\n",
    "                    mod.train(False)\n",
    "\n",
    "        results = None\n",
    "        with torch.no_grad():\n",
    "            for i in range(self.samples):\n",
    "                output = model(x).softmax(dim=1)\n",
    "                if results is None:\n",
    "                    results = torch.zeros(size=output.shape).to(device)\n",
    "                results += output\n",
    "        results /= self.samples\n",
    "\n",
    "        if mode_switch:\n",
    "            model.eval()\n",
    "        \n",
    "        conf, pred = results.max(dim=1)\n",
    "\n",
    "        return pred, conf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_postprocessor(postprocessor_type=\"odin\"):\n",
    "    if postprocessor_type == \"odin\":\n",
    "        postprocessor = ODINPostprocessor(1000, 0.0014)\n",
    "    elif postprocessor_type == \"mcd\":\n",
    "        postprocessor = MCDPostprocessor(30)\n",
    "    return postprocessor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bGtatMpzRbdX",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Supported Out of Distribution Detection Metrics\n",
    "\n",
    "What metrics do we specifically care about here?\n",
    "\n",
    "**FPR@95** measures the false positive rate (FPR) when the true positive rate (TPR) is\n",
    "equal to 95%. Lower scores indicate better performance.\n",
    "\n",
    "**AUROC** measures the area under the\n",
    "Receiver Operating Characteristic (ROC) curve, which displays the relationship between TPR and\n",
    "FPR. The area under the ROC curve can be interpreted as the probability that a positive ID example\n",
    "will have a higher detection score than a negative OOD example.\n",
    "\n",
    "**AUPR** measures the area under\n",
    "the Precision-Recall (PR) curve. The PR curve is created by plotting precision versus recall. Similar\n",
    "to AUROC, we consider ID samples as positive, so that the score corresponds to the AUPR-In metric\n",
    "in some works"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "Xm89cB-XRbdX",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def calculate_oodn_metrics(model, postprocessor_type, id_test_loader, ood_test_loader, ood_name):\n",
    "    postprocessor = get_postprocessor(postprocessor_type)\n",
    "    id_pred, id_conf, id_gt = postprocessor.inference(\n",
    "                model, id_test_loader)\n",
    "\n",
    "    ood_pred, ood_conf, ood_gt = postprocessor.inference(\n",
    "        model, ood_test_loader)\n",
    "\n",
    "    ood_gt = -1 * np.ones_like(ood_gt)  # hard set to -1 as ood\n",
    "    pred = np.concatenate([id_pred, ood_pred])\n",
    "    conf = np.concatenate([id_conf, ood_conf])\n",
    "    label = np.concatenate([id_gt, ood_gt])\n",
    "    ood_metrics = metrics.compute_all_metrics(conf, label, pred)\n",
    "\n",
    "    return print_and_get_formatted_metrics(ood_metrics, ood_name)\n",
    "\n",
    "def print_and_get_formatted_metrics(metrics, dataset_name):\n",
    "    [fpr, auroc, aupr_in, aupr_out,\n",
    "     ccr_4, ccr_3, ccr_2, ccr_1, accuracy] \\\n",
    "     = metrics\n",
    "\n",
    "    write_content = {\n",
    "        'dataset': dataset_name,\n",
    "        'FPR@95': '{:.2f}'.format(100 * fpr),\n",
    "        'AUROC': '{:.2f}'.format(100 * auroc),\n",
    "        'AUPR_IN': '{:.2f}'.format(100 * aupr_in),\n",
    "        'AUPR_OUT': '{:.2f}'.format(100 * aupr_out),\n",
    "        'CCR_4': '{:.2f}'.format(100 * ccr_4),\n",
    "        'CCR_3': '{:.2f}'.format(100 * ccr_3),\n",
    "        'CCR_2': '{:.2f}'.format(100 * ccr_2),\n",
    "        'CCR_1': '{:.2f}'.format(100 * ccr_1),\n",
    "        'ACC': '{:.2f}'.format(100 * accuracy)\n",
    "    }\n",
    "\n",
    "    fieldnames = list(write_content.keys())\n",
    "\n",
    "    # print ood metric results\n",
    "    print('FPR@95: {:.2f}, AUROC: {:.2f}'.format(100 * fpr, 100 * auroc),\n",
    "          end=' ',\n",
    "          flush=True)\n",
    "    print('AUPR_IN: {:.2f}, AUPR_OUT: {:.2f}'.format(\n",
    "        100 * aupr_in, 100 * aupr_out),\n",
    "          flush=True)\n",
    "    print('CCR: {:.2f}, {:.2f}, {:.2f}, {:.2f},'.format(\n",
    "        ccr_4 * 100, ccr_3 * 100, ccr_2 * 100, ccr_1 * 100),\n",
    "          end=' ',\n",
    "          flush=True)\n",
    "    print('ACC: {:.2f}'.format(accuracy * 100), flush=True)\n",
    "    print(u'\\u2500' * 70, flush=True)\n",
    "    return write_content\n",
    "\n",
    "def load_results_into_df(dir_path):\n",
    "    res_files = [dir_path+each for each in listdir(dir_path)]\n",
    "    all_results = []\n",
    "    columns = ['optimizer_type', 'activation_function_type', 'postprocessor_type', 'trial', 'AUROC']\n",
    "    for fp in res_files:\n",
    "        f = open(fp)\n",
    "        data = json.load(f)\n",
    "        for trial, results in data.items():\n",
    "            all_results.append([\n",
    "                    results['optimizer_type'],\n",
    "                    results['activation_function_type'],\n",
    "                    results['postprocessor_type'],\n",
    "                    trial,\n",
    "                    float(results['AUROC'])\n",
    "                ])\n",
    "    df = pd.DataFrame(all_results, columns=columns)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "id": "aEJLZ75aRbdX",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def get_optimizer(model, config):\n",
    "    params = model.parameters()\n",
    "    lr = config['lr']\n",
    "    momentum = config['momentum']\n",
    "    weight_decay = config['weight_decay']\n",
    "    optimizer_type = config['optimizer_type']\n",
    "\n",
    "    print(f'Getting optimizer for type: {optimizer_type}...')\n",
    "    if optimizer_type == 'SGD':\n",
    "        return SGD(params,\n",
    "              lr=lr,\n",
    "              momentum=momentum,\n",
    "              weight_decay=weight_decay)\n",
    "    elif optimizer_type == 'Adam':\n",
    "        return Adam(params,\n",
    "                    lr=lr)\n",
    "    else:\n",
    "        raise Exception(\"Invalid optimizer_type provided, only SGD and Adam are supported currently\")\n",
    "\n",
    "def get_wilds_loader(dataset, split, batch_size):\n",
    "    d = dataset.get_subset(\n",
    "        split,\n",
    "        # frac=0.1,\n",
    "        transform=transforms.Compose(\n",
    "            [transforms.Resize((448, 448)), transforms.ToTensor()]\n",
    "        ),\n",
    "    )\n",
    "    # Prepare the standard data loader\n",
    "    return get_train_loader(\"standard\", d, batch_size=batch_size, num_workers=4)\n",
    "\n",
    "def get_data_loaders(config):\n",
    "    data_loaders = {}\n",
    "    dataset_name = config[\"dataset_name\"]\n",
    "    dataset_type = config[\"dataset_type\"]\n",
    "    batch_size = config['batch_size']\n",
    "\n",
    "    wilds_id_test_split = \"id_val\" if dataset_name == \"camelyon17\" else \"id_test\"\n",
    "    if dataset_type == \"wilds\":\n",
    "        # wilds dataset\n",
    "        dataset = get_dataset(dataset=dataset_name, download=True)\n",
    "        data_loaders[\"train\"] = get_wilds_loader(dataset, \"train\", batch_size)\n",
    "        data_loaders[\"ood_test\"] = get_wilds_loader(dataset, \"test\", batch_size)\n",
    "        data_loaders[\"id_test\"] = get_wilds_loader(dataset, wilds_id_test_split, batch_size)\n",
    "        return\n",
    "    elif dataset_name == \"cifar\":\n",
    "        transform_train = transforms.Compose([\n",
    "            transforms.RandomCrop(32, padding=4),\n",
    "            transforms.RandomHorizontalFlip(),\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),\n",
    "        ])\n",
    "\n",
    "        transform_test = transforms.Compose([\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),\n",
    "        ])\n",
    "        train_dataset = CIFAR10(root='data', download=True, train=True, transform=transform_train)\n",
    "        test_dataset = CIFAR10(root='data', download=True, train=False, transform=transform_test)\n",
    "        ood_test_dataset = CIFAR100(root='data', download=True, train=False, transform=transform_test)\n",
    "        \n",
    "    elif dataset_name == \"mnist\":\n",
    "        # mnist dataset\n",
    "        train_dataset = mnist.MNIST(root='data', download=True, train=True, transform=ToTensor())\n",
    "        test_dataset = mnist.MNIST(root='data', download=True, train=False, transform=ToTensor())\n",
    "        ood_test_dataset = mnist.FashionMNIST(root='data', download=True,train=False,transform=ToTensor())\n",
    "\n",
    "    data_loaders[\"train\"] = DataLoader(train_dataset, batch_size=batch_size, num_workers=4)\n",
    "    data_loaders[\"id_test\"] = DataLoader(test_dataset, batch_size=batch_size, num_workers=4)\n",
    "    data_loaders[\"ood_test\"] = DataLoader(ood_test_dataset, batch_size=batch_size, num_workers=4)\n",
    "\n",
    "    return data_loaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "id": "JfRfN2fNRbdX",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def train_resnet_model_given_opti_activation_fn(config):\n",
    "    # get the train loader\n",
    "    train_loader = config[\"data_loaders\"][\"train\"]\n",
    "\n",
    "    # get the resnet model with the replaced activation functions\n",
    "    model = get_model(config)\n",
    "    model.to(device)\n",
    "\n",
    "    # get the optimizer\n",
    "    sgd = get_optimizer(model, config)\n",
    "\n",
    "    loss_fn = CrossEntropyLoss()\n",
    "    for current_epoch in range(config['epochs']):\n",
    "        tic=time.time()\n",
    "        per_batch_time = time.time()\n",
    "        model.train()\n",
    "        print('Training epoch: {}'.format(current_epoch))\n",
    "        for idx, (loader_data) in enumerate(train_loader):\n",
    "            train_x, train_label = loader_data[0].to(device), loader_data[1].to(device)\n",
    "            sgd.zero_grad()\n",
    "            predict_y = model(train_x.float())\n",
    "            loss = loss_fn(predict_y, train_label.long())\n",
    "            if idx % 100 == 0:\n",
    "                print('idx: {}, loss: {} time take: {}'.format(idx, loss.sum().item(), time.time() - per_batch_time))\n",
    "                per_batch_time = time.time()\n",
    "            loss.backward()\n",
    "            sgd.step()\n",
    "        print(f\"epoch {current_epoch} time taken: {time.time()-tic}s\")\n",
    "    torch.save(model, config['model_name'])\n",
    "\n",
    "    return model\n",
    "\n",
    "def run_full_oodn_pipeline(config):\n",
    "    metrics = {}\n",
    "    for i in range(config[\"trials\"]):\n",
    "        model_name = f\"models/{config['dataset_name']}_{config['network']}_{config['postprocessor_type']}_{config['activation_function_type']}_{config['optimizer_type']}_{i}.pkl\"\n",
    "        print(f'Running model: {model_name}...')\n",
    "        config['model_name'] = model_name\n",
    "        # train model\n",
    "        model = train_resnet_model_given_opti_activation_fn(config)\n",
    "        # calculate oodn metrics\n",
    "        metrics[i] = calculate_oodn_metrics(model,\n",
    "                               config['postprocessor_type'],\n",
    "                               config[\"data_loaders\"][\"id_test\"],\n",
    "                               config[\"data_loaders\"][\"ood_test\"],\n",
    "                               config[\"dataset_name\"])\n",
    "        metrics[i]['optimizer_type'] = config['optimizer_type']\n",
    "        metrics[i]['activation_function_type'] = config['activation_function_type']\n",
    "        metrics[i]['postprocessor_type'] = config['postprocessor_type']\n",
    "\n",
    "    experiment_name = f\"{config['results_dir']}/{config['dataset_name']}_{config['network']}_{config['postprocessor_type']}_{config['activation_function_type']}_{config['optimizer_type']}.json\"\n",
    "    with open(experiment_name, 'w') as fp:\n",
    "        json.dump(metrics, fp)\n",
    "    return metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Study 2: Resnet, CIFAR-10 (ID), CIFAR-100 (OOD)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Study 2(a): Adam + ReLU + Odin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Lzf8wgoTRbdY",
    "outputId": "b0d274c3-4075-4581-97dc-e3fce18f24d2",
    "pycharm": {
     "name": "#%%\n"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "Running model: models/cifar_resnet50_odin_relu_Adam_0.pkl...\n",
      "Getting optimizer for type: Adam...\n",
      "Training epoch: 0\n",
      "idx: 0, loss: 2.429973840713501 time take: 0.2509191036224365\n",
      "idx: 100, loss: 3.1445815563201904 time take: 6.605843782424927\n",
      "idx: 200, loss: 3.0320160388946533 time take: 6.58167576789856\n",
      "idx: 300, loss: 2.0357301235198975 time take: 6.582582235336304\n",
      "epoch 0 time taken: 25.993609189987183s\n",
      "Training epoch: 1\n",
      "idx: 0, loss: 2.0158276557922363 time take: 0.24560880661010742\n",
      "idx: 100, loss: 1.7750670909881592 time take: 6.587856769561768\n",
      "idx: 200, loss: 1.7678837776184082 time take: 6.583316087722778\n",
      "idx: 300, loss: 1.6960535049438477 time take: 6.652765512466431\n",
      "epoch 1 time taken: 26.10966920852661s\n",
      "Training epoch: 2\n",
      "idx: 0, loss: 1.7007710933685303 time take: 0.45514822006225586\n",
      "idx: 100, loss: 1.3905045986175537 time take: 6.6520912647247314\n",
      "idx: 200, loss: 1.4662978649139404 time take: 6.5805823802948\n",
      "idx: 300, loss: 1.5006459951400757 time take: 6.6780335903167725\n",
      "epoch 2 time taken: 26.407979488372803s\n",
      "Training epoch: 3\n",
      "idx: 0, loss: 1.3353502750396729 time take: 0.2624166011810303\n",
      "idx: 100, loss: 1.3243942260742188 time take: 6.599212169647217\n",
      "idx: 200, loss: 1.4102140665054321 time take: 6.584067106246948\n",
      "idx: 300, loss: 1.3928556442260742 time take: 6.590483903884888\n",
      "epoch 3 time taken: 26.10063672065735s\n",
      "Training epoch: 4\n",
      "idx: 0, loss: 1.3879228830337524 time take: 0.25224924087524414\n",
      "idx: 100, loss: 1.1983377933502197 time take: 6.774489879608154\n",
      "idx: 200, loss: 1.2537027597427368 time take: 6.747624635696411\n",
      "idx: 300, loss: 1.2168619632720947 time take: 6.59261155128479\n",
      "epoch 4 time taken: 26.339109659194946s\n",
      "Training epoch: 5\n",
      "idx: 0, loss: 1.1187242269515991 time take: 0.25241661071777344\n",
      "idx: 100, loss: 1.1795109510421753 time take: 6.610428810119629\n",
      "idx: 200, loss: 1.2430949211120605 time take: 6.5916748046875\n",
      "idx: 300, loss: 1.3833400011062622 time take: 6.597599267959595\n",
      "epoch 5 time taken: 26.039023876190186s\n",
      "Training epoch: 6\n",
      "idx: 0, loss: 1.1702966690063477 time take: 0.25303030014038086\n",
      "idx: 100, loss: 1.1042004823684692 time take: 6.597620010375977\n",
      "idx: 200, loss: 1.2051986455917358 time take: 6.588547706604004\n",
      "idx: 300, loss: 1.0260659456253052 time take: 6.636006116867065\n",
      "epoch 6 time taken: 26.17375946044922s\n",
      "Training epoch: 7\n",
      "idx: 0, loss: 1.2835451364517212 time take: 0.24231648445129395\n",
      "idx: 100, loss: 0.9313163757324219 time take: 6.604719638824463\n",
      "idx: 200, loss: 1.1779509782791138 time take: 6.5918238162994385\n",
      "idx: 300, loss: 0.8999757170677185 time take: 6.611107587814331\n",
      "epoch 7 time taken: 26.035030364990234s\n",
      "Training epoch: 8\n",
      "idx: 0, loss: 0.8848156929016113 time take: 0.2597930431365967\n",
      "idx: 100, loss: 0.8813228011131287 time take: 6.796325445175171\n",
      "idx: 200, loss: 0.9537152051925659 time take: 6.737137079238892\n",
      "idx: 300, loss: 0.9202019572257996 time take: 6.72287917137146\n",
      "epoch 8 time taken: 26.579046726226807s\n",
      "Training epoch: 9\n",
      "idx: 0, loss: 0.9117386937141418 time take: 0.25873589515686035\n",
      "idx: 100, loss: 0.9052561521530151 time take: 6.631999969482422\n",
      "idx: 200, loss: 0.9407207369804382 time take: 6.626520395278931\n",
      "idx: 300, loss: 0.8156273365020752 time take: 6.6203320026397705\n",
      "epoch 9 time taken: 26.111121892929077s\n",
      "Training epoch: 10\n",
      "idx: 0, loss: 0.7530161142349243 time take: 0.24126744270324707\n",
      "idx: 100, loss: 0.8753805160522461 time take: 6.6010582447052\n",
      "idx: 200, loss: 0.8667060136795044 time take: 6.586054086685181\n",
      "idx: 300, loss: 0.8458823561668396 time take: 6.586318731307983\n",
      "epoch 10 time taken: 25.989234685897827s\n",
      "Training epoch: 11\n",
      "idx: 0, loss: 1.125815987586975 time take: 0.2468729019165039\n",
      "idx: 100, loss: 0.945044219493866 time take: 6.695728302001953\n",
      "idx: 200, loss: 0.9567622542381287 time take: 6.586900949478149\n",
      "idx: 300, loss: 0.85371994972229 time take: 6.586973190307617\n",
      "epoch 11 time taken: 26.082690238952637s\n",
      "Training epoch: 12\n",
      "idx: 0, loss: 0.80715012550354 time take: 0.24538373947143555\n",
      "idx: 100, loss: 0.7487360835075378 time take: 6.5923237800598145\n",
      "idx: 200, loss: 0.8429386019706726 time take: 6.583547115325928\n",
      "idx: 300, loss: 0.7434133887290955 time take: 6.596329927444458\n",
      "epoch 12 time taken: 25.98866295814514s\n",
      "Training epoch: 13\n",
      "idx: 0, loss: 0.7250117063522339 time take: 0.2618215084075928\n",
      "idx: 100, loss: 0.7967556118965149 time take: 6.59986686706543\n",
      "idx: 200, loss: 0.7410415410995483 time take: 6.738411903381348\n",
      "idx: 300, loss: 0.6937614679336548 time take: 6.723677635192871\n",
      "epoch 13 time taken: 26.42638063430786s\n",
      "Training epoch: 14\n",
      "idx: 0, loss: 0.6414158940315247 time take: 0.23865151405334473\n",
      "idx: 100, loss: 0.7099398374557495 time take: 6.72946572303772\n",
      "idx: 200, loss: 0.7462087869644165 time take: 6.599232912063599\n",
      "idx: 300, loss: 0.6712393760681152 time take: 6.595839023590088\n",
      "epoch 14 time taken: 26.139642238616943s\n",
      "Training epoch: 15\n",
      "idx: 0, loss: 0.7139073014259338 time take: 0.26325249671936035\n",
      "idx: 100, loss: 0.5652002096176147 time take: 6.721598148345947\n",
      "idx: 200, loss: 0.6538335680961609 time take: 6.606085300445557\n",
      "idx: 300, loss: 0.8533799648284912 time take: 6.6482627391815186\n",
      "epoch 15 time taken: 26.215724229812622s\n",
      "Training epoch: 16\n",
      "idx: 0, loss: 0.6184346675872803 time take: 0.24655866622924805\n",
      "idx: 100, loss: 0.5996021032333374 time take: 6.621948957443237\n",
      "idx: 200, loss: 0.9634532928466797 time take: 6.591915607452393\n",
      "idx: 300, loss: 0.6486954092979431 time take: 6.591250658035278\n",
      "epoch 16 time taken: 26.091440200805664s\n",
      "Training epoch: 17\n",
      "idx: 0, loss: 1.234046459197998 time take: 0.254194974899292\n",
      "idx: 100, loss: 1.4683253765106201 time take: 6.595555067062378\n",
      "idx: 200, loss: 1.316489338874817 time take: 6.586945295333862\n",
      "idx: 300, loss: 1.0231877565383911 time take: 6.656747102737427\n",
      "epoch 17 time taken: 26.073298931121826s\n",
      "Training epoch: 18\n",
      "idx: 0, loss: 1.009081244468689 time take: 0.25298237800598145\n",
      "idx: 100, loss: 0.7689114212989807 time take: 6.676458835601807\n",
      "idx: 200, loss: 0.9721382260322571 time take: 6.591350555419922\n",
      "idx: 300, loss: 0.7356604337692261 time take: 6.597162246704102\n",
      "epoch 18 time taken: 26.10403561592102s\n",
      "Training epoch: 19\n",
      "idx: 0, loss: 0.709833562374115 time take: 0.2533531188964844\n",
      "idx: 100, loss: 0.6032328009605408 time take: 6.617300033569336\n",
      "idx: 200, loss: 0.8372319340705872 time take: 6.60408616065979\n",
      "idx: 300, loss: 0.6808153986930847 time take: 6.600780248641968\n",
      "epoch 19 time taken: 26.062426328659058s\n",
      "Training epoch: 20\n",
      "idx: 0, loss: 0.5850920677185059 time take: 0.25253772735595703\n",
      "idx: 100, loss: 0.5925807952880859 time take: 6.63515567779541\n",
      "idx: 200, loss: 0.7478063702583313 time take: 6.693413019180298\n",
      "idx: 300, loss: 0.6940751671791077 time take: 6.60210108757019\n",
      "epoch 20 time taken: 26.16566801071167s\n",
      "Training epoch: 21\n",
      "idx: 0, loss: 0.6171758770942688 time take: 0.2407970428466797\n",
      "idx: 100, loss: 0.6097714304924011 time take: 6.611303091049194\n",
      "idx: 200, loss: 0.6766633987426758 time take: 6.603450536727905\n",
      "idx: 300, loss: 0.5629298686981201 time take: 6.6027326583862305\n",
      "epoch 21 time taken: 26.043721437454224s\n",
      "Training epoch: 22\n",
      "idx: 0, loss: 0.46618273854255676 time take: 0.24545741081237793\n",
      "idx: 100, loss: 0.5410856604576111 time take: 6.614964485168457\n",
      "idx: 200, loss: 0.6856157183647156 time take: 6.602295875549316\n",
      "idx: 300, loss: 0.6277368068695068 time take: 6.674643278121948\n",
      "epoch 22 time taken: 26.125202178955078s\n",
      "Training epoch: 23\n",
      "idx: 0, loss: 0.5829359889030457 time take: 0.2451794147491455\n",
      "idx: 100, loss: 0.5418347716331482 time take: 6.623236417770386\n",
      "idx: 200, loss: 0.6447844505310059 time take: 6.644530296325684\n",
      "idx: 300, loss: 0.5214328169822693 time take: 6.777818202972412\n",
      "epoch 23 time taken: 26.40260910987854s\n",
      "Training epoch: 24\n",
      "idx: 0, loss: 0.43662014603614807 time take: 0.24035906791687012\n",
      "idx: 100, loss: 0.469265878200531 time take: 6.629322528839111\n",
      "idx: 200, loss: 0.5668429136276245 time take: 6.60962700843811\n",
      "idx: 300, loss: 0.5476210117340088 time take: 6.598713397979736\n",
      "epoch 24 time taken: 26.136813640594482s\n",
      "Training epoch: 25\n",
      "idx: 0, loss: 0.5424199104309082 time take: 0.28470492362976074\n",
      "idx: 100, loss: 0.4942139685153961 time take: 6.616248369216919\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "idx: 200, loss: 0.597453773021698 time take: 6.604338645935059\n",
      "idx: 300, loss: 0.5613834261894226 time take: 6.59797215461731\n",
      "epoch 25 time taken: 26.084548950195312s\n",
      "Training epoch: 26\n",
      "idx: 0, loss: 0.46674519777297974 time take: 0.2747359275817871\n",
      "idx: 100, loss: 0.45073235034942627 time take: 6.615034341812134\n",
      "idx: 200, loss: 0.5573427677154541 time take: 6.605945348739624\n",
      "idx: 300, loss: 0.5646507740020752 time take: 6.600234031677246\n",
      "epoch 26 time taken: 26.07901382446289s\n",
      "Training epoch: 27\n",
      "idx: 0, loss: 0.40483447909355164 time take: 0.2372136116027832\n",
      "idx: 100, loss: 0.4371560513973236 time take: 6.6735615730285645\n",
      "idx: 200, loss: 0.6700161099433899 time take: 6.6589274406433105\n",
      "idx: 300, loss: 0.5210594534873962 time take: 6.6518940925598145\n",
      "epoch 27 time taken: 26.20836853981018s\n",
      "Training epoch: 28\n",
      "idx: 0, loss: 0.5300092101097107 time take: 0.2412855625152588\n",
      "idx: 100, loss: 0.43567365407943726 time take: 6.72049355506897\n",
      "idx: 200, loss: 0.5421472787857056 time take: 6.732475757598877\n",
      "idx: 300, loss: 0.4859018325805664 time take: 6.605015754699707\n",
      "epoch 28 time taken: 26.287455081939697s\n",
      "Training epoch: 29\n",
      "idx: 0, loss: 0.4051600992679596 time take: 0.2531406879425049\n",
      "idx: 100, loss: 0.3768112063407898 time take: 6.6165611743927\n",
      "idx: 200, loss: 0.5994210839271545 time take: 6.603435754776001\n",
      "idx: 300, loss: 0.508894145488739 time take: 6.772572040557861\n",
      "epoch 29 time taken: 26.39338755607605s\n",
      "Training epoch: 30\n",
      "idx: 0, loss: 0.5069605112075806 time take: 0.24276304244995117\n",
      "idx: 100, loss: 0.39429089426994324 time take: 6.612145662307739\n",
      "idx: 200, loss: 0.5198826789855957 time take: 6.603655815124512\n",
      "idx: 300, loss: 0.43962562084198 time take: 6.603867769241333\n",
      "epoch 30 time taken: 26.045917987823486s\n",
      "Training epoch: 31\n",
      "idx: 0, loss: 0.36602917313575745 time take: 0.24932622909545898\n",
      "idx: 100, loss: 0.37763333320617676 time take: 6.616546154022217\n",
      "idx: 200, loss: 0.5330601334571838 time take: 6.605478763580322\n",
      "idx: 300, loss: 0.5030922293663025 time take: 6.600196599960327\n",
      "epoch 31 time taken: 26.131986618041992s\n",
      "Training epoch: 32\n",
      "idx: 0, loss: 0.40385445952415466 time take: 0.2856302261352539\n",
      "idx: 100, loss: 0.3589535057544708 time take: 6.615854740142822\n",
      "idx: 200, loss: 0.5147901177406311 time take: 6.6557722091674805\n",
      "idx: 300, loss: 0.41852572560310364 time take: 6.649252891540527\n",
      "epoch 32 time taken: 26.205445528030396s\n",
      "Training epoch: 33\n",
      "idx: 0, loss: 0.3857162892818451 time take: 0.24073076248168945\n",
      "idx: 100, loss: 0.39689740538597107 time take: 6.7249205112457275\n",
      "idx: 200, loss: 0.5674552321434021 time take: 6.717326879501343\n",
      "idx: 300, loss: 0.469630628824234 time take: 6.701671123504639\n",
      "epoch 33 time taken: 26.381283044815063s\n",
      "Training epoch: 34\n",
      "idx: 0, loss: 0.4500008821487427 time take: 0.25928616523742676\n",
      "idx: 100, loss: 0.3086208999156952 time take: 6.715862989425659\n",
      "idx: 200, loss: 0.41133132576942444 time take: 6.606262445449829\n",
      "idx: 300, loss: 0.42024481296539307 time take: 6.605737924575806\n",
      "epoch 34 time taken: 26.172569274902344s\n",
      "Training epoch: 35\n",
      "idx: 0, loss: 0.3656458854675293 time take: 0.2511012554168701\n",
      "idx: 100, loss: 0.268738329410553 time take: 6.707017660140991\n",
      "idx: 200, loss: 0.40065425634384155 time take: 6.621174335479736\n",
      "idx: 300, loss: 0.37083491683006287 time take: 6.602924823760986\n",
      "epoch 35 time taken: 26.298258543014526s\n",
      "Training epoch: 36\n",
      "idx: 0, loss: 0.3116465210914612 time take: 0.2742006778717041\n",
      "idx: 100, loss: 0.40657839179039 time take: 6.62555718421936\n",
      "idx: 200, loss: 0.44226399064064026 time take: 6.67363166809082\n",
      "idx: 300, loss: 0.389006644487381 time take: 6.614746570587158\n",
      "epoch 36 time taken: 26.181769371032715s\n",
      "Training epoch: 37\n",
      "idx: 0, loss: 0.40857845544815063 time take: 0.267960786819458\n",
      "idx: 100, loss: 0.31250470876693726 time take: 6.6230387687683105\n",
      "idx: 200, loss: 0.4999522864818573 time take: 6.646629810333252\n",
      "idx: 300, loss: 0.3896835148334503 time take: 6.635263442993164\n",
      "epoch 37 time taken: 26.163506031036377s\n",
      "Training epoch: 38\n",
      "idx: 0, loss: 0.296750009059906 time take: 0.2739584445953369\n",
      "idx: 100, loss: 0.2697773873806 time take: 6.621429681777954\n",
      "idx: 200, loss: 0.48971039056777954 time take: 6.608995199203491\n",
      "idx: 300, loss: 0.4742026925086975 time take: 6.646395444869995\n",
      "epoch 38 time taken: 26.140215635299683s\n",
      "Training epoch: 39\n",
      "idx: 0, loss: 0.4699289798736572 time take: 0.2532193660736084\n",
      "idx: 100, loss: 0.2984776198863983 time take: 6.755182981491089\n",
      "idx: 200, loss: 0.36229264736175537 time take: 6.818565368652344\n",
      "idx: 300, loss: 0.3669890761375427 time take: 6.687718629837036\n",
      "epoch 39 time taken: 26.500202417373657s\n",
      "Training epoch: 40\n",
      "idx: 0, loss: 0.3223288953304291 time take: 0.259563684463501\n",
      "idx: 100, loss: 0.270237535238266 time take: 6.709141492843628\n",
      "idx: 200, loss: 0.47270914912223816 time take: 6.609561204910278\n",
      "idx: 300, loss: 0.36061668395996094 time take: 6.611093759536743\n",
      "epoch 40 time taken: 26.2364022731781s\n",
      "Training epoch: 41\n",
      "idx: 0, loss: 0.32088956236839294 time take: 0.2548036575317383\n",
      "idx: 100, loss: 0.3190487027168274 time take: 6.70658278465271\n",
      "idx: 200, loss: 0.36052918434143066 time take: 6.61695671081543\n",
      "idx: 300, loss: 0.6905736327171326 time take: 6.6053595542907715\n",
      "epoch 41 time taken: 26.172004461288452s\n",
      "Training epoch: 42\n",
      "idx: 0, loss: 1.2950851917266846 time take: 0.2640414237976074\n",
      "idx: 100, loss: 0.8911758661270142 time take: 6.624068975448608\n",
      "idx: 200, loss: 0.8939116597175598 time take: 6.616691589355469\n",
      "idx: 300, loss: 0.7169846296310425 time take: 6.609541416168213\n",
      "epoch 42 time taken: 26.111639738082886s\n",
      "Training epoch: 43\n",
      "idx: 0, loss: 0.8343636989593506 time take: 0.25074076652526855\n",
      "idx: 100, loss: 0.4982527494430542 time take: 6.747812509536743\n",
      "idx: 200, loss: 0.5762873888015747 time take: 6.6415252685546875\n",
      "idx: 300, loss: 0.5561431050300598 time take: 6.666395902633667\n",
      "epoch 43 time taken: 26.350172519683838s\n",
      "Training epoch: 44\n",
      "idx: 0, loss: 0.510161280632019 time take: 0.26207900047302246\n",
      "idx: 100, loss: 0.3739611804485321 time take: 6.636719226837158\n",
      "idx: 200, loss: 0.5765275359153748 time take: 6.630703926086426\n",
      "idx: 300, loss: 0.45517316460609436 time take: 6.615334987640381\n",
      "epoch 44 time taken: 26.142101526260376s\n",
      "Training epoch: 45\n",
      "idx: 0, loss: 0.4324011206626892 time take: 0.24765968322753906\n",
      "idx: 100, loss: 0.338939905166626 time take: 6.6547019481658936\n",
      "idx: 200, loss: 0.4517316520214081 time take: 6.614991903305054\n",
      "idx: 300, loss: 0.34419286251068115 time take: 6.712765455245972\n",
      "epoch 45 time taken: 26.34160041809082s\n",
      "Training epoch: 46\n",
      "idx: 0, loss: 0.37340047955513 time take: 0.2566862106323242\n",
      "idx: 100, loss: 0.2965507507324219 time take: 6.634514093399048\n",
      "idx: 200, loss: 0.4469919800758362 time take: 6.729496240615845\n",
      "idx: 300, loss: 0.3988385796546936 time take: 6.730931520462036\n",
      "epoch 46 time taken: 26.398518800735474s\n",
      "Training epoch: 47\n",
      "idx: 0, loss: 0.3168496787548065 time take: 0.2514524459838867\n",
      "idx: 100, loss: 0.2663528025150299 time take: 6.642399787902832\n",
      "idx: 200, loss: 0.3321632742881775 time take: 6.615948677062988\n",
      "idx: 300, loss: 0.2954519987106323 time take: 6.610562324523926\n",
      "epoch 47 time taken: 26.150567531585693s\n",
      "Training epoch: 48\n",
      "idx: 0, loss: 0.255519300699234 time take: 0.2657632827758789\n",
      "idx: 100, loss: 0.3400595784187317 time take: 6.6359710693359375\n",
      "idx: 200, loss: 0.3578822910785675 time take: 6.614019155502319\n",
      "idx: 300, loss: 0.2663783133029938 time take: 6.613390922546387\n",
      "epoch 48 time taken: 26.12757635116577s\n",
      "Training epoch: 49\n",
      "idx: 0, loss: 0.3484353721141815 time take: 0.24075651168823242\n",
      "idx: 100, loss: 0.28565117716789246 time take: 6.746904134750366\n",
      "idx: 200, loss: 0.33220377564430237 time take: 6.613431692123413\n",
      "idx: 300, loss: 0.3413771688938141 time take: 6.622251510620117\n",
      "epoch 49 time taken: 26.218403577804565s\n",
      "Training epoch: 50\n",
      "idx: 0, loss: 0.31496793031692505 time take: 0.2748537063598633\n",
      "idx: 100, loss: 0.22334308922290802 time take: 6.710472822189331\n",
      "idx: 200, loss: 0.4013320207595825 time take: 6.707246541976929\n",
      "idx: 300, loss: 0.2748640179634094 time take: 6.833968877792358\n",
      "epoch 50 time taken: 26.63979983329773s\n",
      "Training epoch: 51\n",
      "idx: 0, loss: 0.37211278080940247 time take: 0.26363348960876465\n",
      "idx: 100, loss: 0.2236468344926834 time take: 6.617642164230347\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "idx: 200, loss: 0.3298856019973755 time take: 6.60926628112793\n",
      "idx: 300, loss: 0.261945515871048 time take: 6.671645641326904\n",
      "epoch 51 time taken: 26.160161018371582s\n",
      "Training epoch: 52\n",
      "idx: 0, loss: 0.21253448724746704 time take: 0.25517916679382324\n",
      "idx: 100, loss: 0.2711976170539856 time take: 6.623281955718994\n",
      "idx: 200, loss: 0.38510289788246155 time take: 6.668866395950317\n",
      "idx: 300, loss: 0.34865692257881165 time take: 6.691893815994263\n",
      "epoch 52 time taken: 26.37187385559082s\n",
      "Training epoch: 53\n",
      "idx: 0, loss: 0.18931463360786438 time take: 0.2438039779663086\n",
      "idx: 100, loss: 0.1994004100561142 time take: 6.631709575653076\n",
      "idx: 200, loss: 0.27953147888183594 time take: 6.607300043106079\n",
      "idx: 300, loss: 0.30204665660858154 time take: 6.608463287353516\n",
      "epoch 53 time taken: 26.0798819065094s\n",
      "Training epoch: 54\n",
      "idx: 0, loss: 0.24524739384651184 time take: 0.24196624755859375\n",
      "idx: 100, loss: 0.18782228231430054 time take: 6.711690664291382\n",
      "idx: 200, loss: 0.371204674243927 time take: 6.689245939254761\n",
      "idx: 300, loss: 0.2655726671218872 time take: 6.6796112060546875\n",
      "epoch 54 time taken: 26.39369821548462s\n",
      "Training epoch: 55\n",
      "idx: 0, loss: 0.25967273116111755 time take: 0.2503082752227783\n",
      "idx: 100, loss: 0.26340460777282715 time take: 6.624771595001221\n",
      "idx: 200, loss: 0.3206891715526581 time take: 6.607670783996582\n",
      "idx: 300, loss: 0.20523741841316223 time take: 6.607151985168457\n",
      "epoch 55 time taken: 26.083253860473633s\n",
      "Training epoch: 56\n",
      "idx: 0, loss: 0.25922876596450806 time take: 0.27168726921081543\n",
      "idx: 100, loss: 0.21803919970989227 time take: 6.646587610244751\n",
      "idx: 200, loss: 0.23396573960781097 time take: 6.607344627380371\n",
      "idx: 300, loss: 0.17622151970863342 time take: 6.610415458679199\n",
      "epoch 56 time taken: 26.16805911064148s\n",
      "Training epoch: 57\n",
      "idx: 0, loss: 0.26991307735443115 time take: 0.2511122226715088\n",
      "idx: 100, loss: 0.22458450496196747 time take: 6.630655765533447\n",
      "idx: 200, loss: 0.3816375732421875 time take: 6.607508420944214\n",
      "idx: 300, loss: 0.28751257061958313 time take: 6.607525587081909\n",
      "epoch 57 time taken: 26.085353136062622s\n",
      "Training epoch: 58\n",
      "idx: 0, loss: 0.21216928958892822 time take: 0.2560436725616455\n",
      "idx: 100, loss: 0.12602268159389496 time take: 6.667839288711548\n",
      "idx: 200, loss: 0.34578555822372437 time take: 6.64577054977417\n",
      "idx: 300, loss: 0.17367693781852722 time take: 6.605763912200928\n",
      "epoch 58 time taken: 26.16464328765869s\n",
      "Training epoch: 59\n",
      "idx: 0, loss: 0.20125670731067657 time take: 0.26286959648132324\n",
      "idx: 100, loss: 0.22591477632522583 time take: 6.781619548797607\n",
      "idx: 200, loss: 0.21056608855724335 time take: 6.677940130233765\n",
      "idx: 300, loss: 0.3093376159667969 time take: 6.674513101577759\n",
      "epoch 59 time taken: 26.502922773361206s\n",
      "Training epoch: 60\n",
      "idx: 0, loss: 0.19070978462696075 time take: 0.2553532123565674\n",
      "idx: 100, loss: 0.17031458020210266 time take: 6.646922826766968\n",
      "idx: 200, loss: 0.2551118731498718 time take: 6.714736700057983\n",
      "idx: 300, loss: 0.20872557163238525 time take: 6.672762393951416\n",
      "epoch 60 time taken: 26.279381275177002s\n",
      "Training epoch: 61\n",
      "idx: 0, loss: 0.2398674339056015 time take: 0.26027679443359375\n",
      "idx: 100, loss: 0.3122066259384155 time take: 6.698143243789673\n",
      "idx: 200, loss: 0.3067338466644287 time take: 6.695329189300537\n",
      "idx: 300, loss: 0.2214471846818924 time take: 6.646745681762695\n",
      "epoch 61 time taken: 26.38305377960205s\n",
      "Training epoch: 62\n",
      "idx: 0, loss: 0.2781524956226349 time take: 0.25980186462402344\n",
      "idx: 100, loss: 0.2437860667705536 time take: 6.622742414474487\n",
      "idx: 200, loss: 0.22508883476257324 time take: 6.610331773757935\n",
      "idx: 300, loss: 0.2014458030462265 time take: 6.608910322189331\n",
      "epoch 62 time taken: 26.09113073348999s\n",
      "Training epoch: 63\n",
      "idx: 0, loss: 0.2799432575702667 time take: 0.2511322498321533\n",
      "idx: 100, loss: 0.2566905617713928 time take: 6.6302573680877686\n",
      "idx: 200, loss: 0.3663915693759918 time take: 6.607975721359253\n",
      "idx: 300, loss: 0.18929128348827362 time take: 6.604169130325317\n",
      "epoch 63 time taken: 26.154374599456787s\n",
      "Training epoch: 64\n",
      "idx: 0, loss: 0.16015814244747162 time take: 0.26290035247802734\n",
      "idx: 100, loss: 0.1639900803565979 time take: 6.628343343734741\n",
      "idx: 200, loss: 0.27327701449394226 time take: 6.618783950805664\n",
      "idx: 300, loss: 0.2628348469734192 time take: 6.609576940536499\n",
      "epoch 64 time taken: 26.10914444923401s\n",
      "Training epoch: 65\n",
      "idx: 0, loss: 0.15140917897224426 time take: 0.24311470985412598\n",
      "idx: 100, loss: 0.2915058732032776 time take: 6.623658180236816\n",
      "idx: 200, loss: 0.28482887148857117 time take: 6.608906984329224\n",
      "idx: 300, loss: 0.411536306142807 time take: 6.622454643249512\n",
      "epoch 65 time taken: 26.088173389434814s\n",
      "Training epoch: 66\n",
      "idx: 0, loss: 0.27009254693984985 time take: 0.24146533012390137\n",
      "idx: 100, loss: 0.13402873277664185 time take: 6.709074258804321\n",
      "idx: 200, loss: 0.2351119965314865 time take: 6.645198345184326\n",
      "idx: 300, loss: 0.24610885977745056 time take: 6.646118640899658\n",
      "epoch 66 time taken: 26.26317000389099s\n",
      "Training epoch: 67\n",
      "idx: 0, loss: 0.24743664264678955 time take: 0.2529144287109375\n",
      "idx: 100, loss: 0.10124564170837402 time take: 6.6222825050354\n",
      "idx: 200, loss: 0.23676154017448425 time take: 6.61131477355957\n",
      "idx: 300, loss: 0.22801364958286285 time take: 6.609505891799927\n",
      "epoch 67 time taken: 26.09590244293213s\n",
      "Training epoch: 68\n",
      "idx: 0, loss: 0.26545488834381104 time take: 0.246002197265625\n",
      "idx: 100, loss: 0.2420141100883484 time take: 6.6211793422698975\n",
      "idx: 200, loss: 0.3086569905281067 time take: 6.632923603057861\n",
      "idx: 300, loss: 1.0266376733779907 time take: 6.608631372451782\n",
      "epoch 68 time taken: 26.097962379455566s\n",
      "Training epoch: 69\n",
      "idx: 0, loss: 0.3618776500225067 time take: 0.23361897468566895\n",
      "idx: 100, loss: 0.30026328563690186 time take: 6.633512020111084\n",
      "idx: 200, loss: 0.3513423502445221 time take: 6.607275485992432\n",
      "idx: 300, loss: 0.24762509763240814 time take: 6.62139630317688\n",
      "epoch 69 time taken: 26.084001779556274s\n",
      "Training epoch: 70\n",
      "idx: 0, loss: 0.2942960262298584 time take: 0.2419276237487793\n",
      "idx: 100, loss: 0.12959499657154083 time take: 6.640630483627319\n",
      "idx: 200, loss: 0.19043320417404175 time take: 6.607035398483276\n",
      "idx: 300, loss: 0.18615752458572388 time take: 6.6382200717926025\n",
      "epoch 70 time taken: 26.117682695388794s\n",
      "Training epoch: 71\n",
      "idx: 0, loss: 0.22336018085479736 time take: 0.24895501136779785\n",
      "idx: 100, loss: 0.2471524327993393 time take: 6.623117208480835\n",
      "idx: 200, loss: 0.29003065824508667 time take: 6.6089818477630615\n",
      "idx: 300, loss: 0.26981261372566223 time take: 6.607532024383545\n",
      "epoch 71 time taken: 26.078727960586548s\n",
      "Training epoch: 72\n",
      "idx: 0, loss: 0.1363406479358673 time take: 0.2480173110961914\n",
      "idx: 100, loss: 0.14116087555885315 time take: 6.666687250137329\n",
      "idx: 200, loss: 0.23700480163097382 time take: 6.667191505432129\n",
      "idx: 300, loss: 0.1325051337480545 time take: 6.607063055038452\n",
      "epoch 72 time taken: 26.178027391433716s\n",
      "Training epoch: 73\n",
      "idx: 0, loss: 0.1420445740222931 time take: 0.35956358909606934\n",
      "idx: 100, loss: 0.13395170867443085 time take: 6.675174236297607\n",
      "idx: 200, loss: 0.16384147107601166 time take: 6.748812198638916\n",
      "idx: 300, loss: 0.23923103511333466 time take: 6.753606557846069\n",
      "epoch 73 time taken: 26.52954602241516s\n",
      "Training epoch: 74\n",
      "idx: 0, loss: 0.22281591594219208 time take: 0.23696494102478027\n",
      "idx: 100, loss: 0.10692178457975388 time take: 6.635664939880371\n",
      "idx: 200, loss: 0.2644733190536499 time take: 6.607264995574951\n",
      "idx: 300, loss: 0.14299842715263367 time take: 6.6231889724731445\n",
      "epoch 74 time taken: 26.09231996536255s\n",
      "Training epoch: 75\n",
      "idx: 0, loss: 0.29117879271507263 time take: 0.24585437774658203\n",
      "idx: 100, loss: 0.12355401366949081 time take: 6.631189346313477\n",
      "idx: 200, loss: 0.19354020059108734 time take: 6.752359867095947\n",
      "idx: 300, loss: 0.18414348363876343 time take: 6.614617109298706\n",
      "epoch 75 time taken: 26.231332540512085s\n",
      "Training epoch: 76\n",
      "idx: 0, loss: 0.1281149685382843 time take: 0.24297833442687988\n",
      "idx: 100, loss: 0.07720867544412613 time take: 6.643798351287842\n",
      "idx: 200, loss: 0.2861526906490326 time take: 6.618147611618042\n",
      "idx: 300, loss: 0.16329538822174072 time take: 6.63301157951355\n",
      "epoch 76 time taken: 26.20626187324524s\n",
      "Training epoch: 77\n",
      "idx: 0, loss: 0.15864692628383636 time take: 0.25390005111694336\n",
      "idx: 100, loss: 0.16504274308681488 time take: 6.703033208847046\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "idx: 200, loss: 0.22645197808742523 time take: 6.610750436782837\n",
      "idx: 300, loss: 0.20446710288524628 time take: 6.6332597732543945\n",
      "epoch 77 time taken: 26.188644409179688s\n",
      "Training epoch: 78\n",
      "idx: 0, loss: 0.13726526498794556 time take: 0.2570681571960449\n",
      "idx: 100, loss: 0.08217354863882065 time take: 6.6184821128845215\n",
      "idx: 200, loss: 0.2705938220024109 time take: 6.608604907989502\n",
      "idx: 300, loss: 0.19095657765865326 time take: 6.6150596141815186\n",
      "epoch 78 time taken: 26.09790062904358s\n",
      "Training epoch: 79\n",
      "idx: 0, loss: 0.10920466482639313 time take: 0.2664153575897217\n",
      "idx: 100, loss: 0.2774288058280945 time take: 6.624781608581543\n",
      "idx: 200, loss: 0.23530609905719757 time take: 6.606082916259766\n",
      "idx: 300, loss: 0.1965378075838089 time take: 6.607937812805176\n",
      "epoch 79 time taken: 26.16877269744873s\n",
      "Training epoch: 80\n",
      "idx: 0, loss: 0.2221136838197708 time take: 0.23807144165039062\n",
      "idx: 100, loss: 0.1357584148645401 time take: 6.643655300140381\n",
      "idx: 200, loss: 0.21189424395561218 time take: 6.609174489974976\n",
      "idx: 300, loss: 0.15015511214733124 time take: 6.60973858833313\n",
      "epoch 80 time taken: 26.090019702911377s\n",
      "Training epoch: 81\n",
      "idx: 0, loss: 0.09459725022315979 time take: 0.23656940460205078\n",
      "idx: 100, loss: 0.1235763356089592 time take: 6.735913038253784\n",
      "idx: 200, loss: 0.17143237590789795 time take: 6.613421201705933\n",
      "idx: 300, loss: 0.22039709985256195 time take: 6.606182098388672\n",
      "epoch 81 time taken: 26.192424535751343s\n",
      "Training epoch: 82\n",
      "idx: 0, loss: 0.13564306497573853 time take: 0.2508866786956787\n",
      "idx: 100, loss: 0.1898074746131897 time take: 6.7584240436553955\n",
      "idx: 200, loss: 0.16785630583763123 time take: 6.687091827392578\n",
      "idx: 300, loss: 0.16423630714416504 time take: 6.68949294090271\n",
      "epoch 82 time taken: 26.435717344284058s\n",
      "Training epoch: 83\n",
      "idx: 0, loss: 0.1431550830602646 time take: 0.25035691261291504\n",
      "idx: 100, loss: 0.07128944993019104 time take: 6.615602254867554\n",
      "idx: 200, loss: 0.17670398950576782 time take: 6.608954668045044\n",
      "idx: 300, loss: 0.13990290462970734 time take: 6.605907201766968\n",
      "epoch 83 time taken: 26.084656476974487s\n",
      "Training epoch: 84\n",
      "idx: 0, loss: 0.14419889450073242 time take: 0.2429945468902588\n",
      "idx: 100, loss: 0.20362092554569244 time take: 6.624540090560913\n",
      "idx: 200, loss: 0.23005881905555725 time take: 6.669851541519165\n",
      "idx: 300, loss: 0.12536287307739258 time take: 6.6476969718933105\n",
      "epoch 84 time taken: 26.17869544029236s\n",
      "Training epoch: 85\n",
      "idx: 0, loss: 0.24080036580562592 time take: 0.26505374908447266\n",
      "idx: 100, loss: 0.11284483224153519 time take: 6.620676517486572\n",
      "idx: 200, loss: 0.2485472410917282 time take: 6.605560302734375\n",
      "idx: 300, loss: 0.14008741080760956 time take: 6.606110095977783\n",
      "epoch 85 time taken: 26.088268756866455s\n",
      "Training epoch: 86\n",
      "idx: 0, loss: 0.14014054834842682 time take: 0.25802040100097656\n",
      "idx: 100, loss: 0.16957907378673553 time take: 6.6149742603302\n",
      "idx: 200, loss: 0.13566894829273224 time take: 6.603509902954102\n",
      "idx: 300, loss: 0.11118057370185852 time take: 6.660526990890503\n",
      "epoch 86 time taken: 26.128937005996704s\n",
      "Training epoch: 87\n",
      "idx: 0, loss: 0.12669257819652557 time take: 0.2593986988067627\n",
      "idx: 100, loss: 0.08180121332406998 time take: 6.648425579071045\n",
      "idx: 200, loss: 0.13793231546878815 time take: 6.604820728302002\n",
      "idx: 300, loss: 0.26475217938423157 time take: 6.606395959854126\n",
      "epoch 87 time taken: 26.108230113983154s\n",
      "Training epoch: 88\n",
      "idx: 0, loss: 0.05602787062525749 time take: 0.22693538665771484\n",
      "idx: 100, loss: 0.08676662296056747 time take: 6.629946231842041\n",
      "idx: 200, loss: 0.2614542543888092 time take: 6.605675220489502\n",
      "idx: 300, loss: 0.09606543183326721 time take: 6.604763031005859\n",
      "epoch 88 time taken: 26.054614782333374s\n",
      "Training epoch: 89\n",
      "idx: 0, loss: 0.1988457590341568 time take: 0.2283773422241211\n",
      "idx: 100, loss: 0.12266992032527924 time take: 6.699664354324341\n",
      "idx: 200, loss: 0.26878857612609863 time take: 6.607360363006592\n",
      "idx: 300, loss: 0.1244143694639206 time take: 6.6089348793029785\n",
      "epoch 89 time taken: 26.130517721176147s\n",
      "Training epoch: 90\n",
      "idx: 0, loss: 0.0669235959649086 time take: 0.2315657138824463\n",
      "idx: 100, loss: 0.06287970393896103 time take: 6.616018533706665\n",
      "idx: 200, loss: 0.1877298206090927 time take: 6.654552698135376\n",
      "idx: 300, loss: 0.17032667994499207 time take: 6.624577283859253\n",
      "epoch 90 time taken: 26.114153146743774s\n",
      "Training epoch: 91\n",
      "idx: 0, loss: 0.06673379987478256 time take: 0.2318117618560791\n",
      "idx: 100, loss: 0.101353220641613 time take: 6.617567777633667\n",
      "idx: 200, loss: 0.19525456428527832 time take: 6.663872957229614\n",
      "idx: 300, loss: 0.18193380534648895 time take: 6.612351894378662\n",
      "epoch 91 time taken: 26.11850118637085s\n",
      "Training epoch: 92\n",
      "idx: 0, loss: 0.04324503242969513 time take: 0.257570743560791\n",
      "idx: 100, loss: 0.15201900899410248 time take: 6.616520643234253\n",
      "idx: 200, loss: 0.20084170997142792 time take: 6.645710468292236\n",
      "idx: 300, loss: 0.18656577169895172 time take: 6.7372050285339355\n",
      "epoch 92 time taken: 26.309843063354492s\n",
      "Training epoch: 93\n",
      "idx: 0, loss: 0.09834751486778259 time take: 0.261690616607666\n",
      "idx: 100, loss: 0.0825633704662323 time take: 6.732813358306885\n",
      "idx: 200, loss: 0.13640420138835907 time take: 6.605061292648315\n",
      "idx: 300, loss: 0.1616331785917282 time take: 6.707032203674316\n",
      "epoch 93 time taken: 26.293034076690674s\n",
      "Training epoch: 94\n",
      "idx: 0, loss: 0.0740174725651741 time take: 0.2489321231842041\n",
      "idx: 100, loss: 0.0770978108048439 time take: 6.621090888977051\n",
      "idx: 200, loss: 0.17312054336071014 time take: 6.605494022369385\n",
      "idx: 300, loss: 0.13340449333190918 time take: 6.604626178741455\n",
      "epoch 94 time taken: 26.06821894645691s\n",
      "Training epoch: 95\n",
      "idx: 0, loss: 0.13429518043994904 time take: 0.2583038806915283\n",
      "idx: 100, loss: 0.07388345152139664 time take: 6.615640878677368\n",
      "idx: 200, loss: 0.20823192596435547 time take: 6.606839418411255\n",
      "idx: 300, loss: 0.19722263514995575 time take: 6.61799955368042\n",
      "epoch 95 time taken: 26.151681900024414s\n",
      "Training epoch: 96\n",
      "idx: 0, loss: 0.09237039089202881 time take: 0.2477874755859375\n",
      "idx: 100, loss: 0.16916128993034363 time take: 6.626526355743408\n",
      "idx: 200, loss: 0.18289028108119965 time take: 6.609085559844971\n",
      "idx: 300, loss: 0.14746662974357605 time take: 6.605387926101685\n",
      "epoch 96 time taken: 26.083589553833008s\n",
      "Training epoch: 97\n",
      "idx: 0, loss: 0.12179725617170334 time take: 0.26045989990234375\n",
      "idx: 100, loss: 0.12145990878343582 time take: 6.6182475090026855\n",
      "idx: 200, loss: 0.13849924504756927 time take: 6.606937646865845\n",
      "idx: 300, loss: 0.13047663867473602 time take: 6.606622219085693\n",
      "epoch 97 time taken: 26.07880973815918s\n",
      "Training epoch: 98\n",
      "idx: 0, loss: 0.12336543947458267 time take: 0.25167036056518555\n",
      "idx: 100, loss: 0.08607018738985062 time take: 6.67158317565918\n",
      "idx: 200, loss: 0.15274086594581604 time take: 6.605095386505127\n",
      "idx: 300, loss: 0.13258135318756104 time take: 6.604599237442017\n",
      "epoch 98 time taken: 26.121386528015137s\n",
      "Training epoch: 99\n",
      "idx: 0, loss: 0.10123524814844131 time take: 0.2544384002685547\n",
      "idx: 100, loss: 0.20789466798305511 time take: 6.619776010513306\n",
      "idx: 200, loss: 0.18485575914382935 time take: 6.611340284347534\n",
      "idx: 300, loss: 0.14361582696437836 time take: 6.611104726791382\n",
      "epoch 99 time taken: 26.08774185180664s\n",
      "Performing inference on batch: 0\n",
      "Performing inference on batch: 50\n",
      "Performing inference on batch: 0\n",
      "Performing inference on batch: 50\n",
      "FPR@95: 74.84, AUROC: 82.09 AUPR_IN: 83.53, AUPR_OUT: 78.47\n",
      "CCR: 0.15, 3.41, 20.23, 55.44, ACC: 85.13\n",
      "\n",
      "Running model: models/cifar_resnet50_odin_relu_Adam_1.pkl...\n",
      "Getting optimizer for type: Adam...\n",
      "Training epoch: 0\n",
      "idx: 0, loss: 2.558476209640503 time take: 0.22568106651306152\n",
      "idx: 100, loss: 3.21410870552063 time take: 6.6204304695129395\n",
      "idx: 200, loss: 2.4587743282318115 time take: 6.580999851226807\n",
      "idx: 300, loss: 2.2691140174865723 time take: 6.5793232917785645\n",
      "epoch 0 time taken: 25.96869421005249s\n",
      "Training epoch: 1\n",
      "idx: 0, loss: 1.9263505935668945 time take: 0.26261281967163086\n",
      "idx: 100, loss: 1.8387367725372314 time take: 6.644789218902588\n",
      "idx: 200, loss: 1.7843594551086426 time take: 6.575515985488892\n",
      "idx: 300, loss: 1.6993614435195923 time take: 6.622610092163086\n",
      "epoch 1 time taken: 26.159961700439453s\n",
      "Training epoch: 2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "idx: 0, loss: 1.5828386545181274 time take: 0.25194764137268066\n",
      "idx: 100, loss: 1.444257378578186 time take: 6.684164524078369\n",
      "idx: 200, loss: 1.5520122051239014 time take: 6.586169958114624\n",
      "idx: 300, loss: 1.530279278755188 time take: 6.585282802581787\n",
      "epoch 2 time taken: 26.07736825942993s\n",
      "Training epoch: 3\n",
      "idx: 0, loss: 1.42722749710083 time take: 0.2662222385406494\n",
      "idx: 100, loss: 1.3462961912155151 time take: 6.595289707183838\n",
      "idx: 200, loss: 1.4635869264602661 time take: 6.589477777481079\n",
      "idx: 300, loss: 1.854456901550293 time take: 6.588951110839844\n",
      "epoch 3 time taken: 26.007307529449463s\n",
      "Training epoch: 4\n",
      "idx: 0, loss: 1.487541913986206 time take: 0.27080416679382324\n",
      "idx: 100, loss: 1.3574988842010498 time take: 6.5935564041137695\n",
      "idx: 200, loss: 1.331739902496338 time take: 6.638465642929077\n",
      "idx: 300, loss: 1.2641595602035522 time take: 6.650737047195435\n",
      "epoch 4 time taken: 26.124001502990723s\n",
      "Training epoch: 5\n",
      "idx: 0, loss: 1.29438316822052 time take: 0.23894691467285156\n",
      "idx: 100, loss: 1.2864503860473633 time take: 6.590971946716309\n",
      "idx: 200, loss: 1.2731812000274658 time take: 6.588605642318726\n",
      "idx: 300, loss: 1.1447641849517822 time take: 6.5851891040802\n",
      "epoch 5 time taken: 25.971064567565918s\n",
      "Training epoch: 6\n",
      "idx: 0, loss: 1.1840729713439941 time take: 0.24520230293273926\n",
      "idx: 100, loss: 1.167640209197998 time take: 6.594605207443237\n",
      "idx: 200, loss: 1.2843562364578247 time take: 6.586460828781128\n",
      "idx: 300, loss: 1.0402686595916748 time take: 6.584739446640015\n",
      "epoch 6 time taken: 26.08286428451538s\n",
      "Training epoch: 7\n",
      "idx: 0, loss: 1.2257343530654907 time take: 0.24934911727905273\n",
      "idx: 100, loss: 0.9742569923400879 time take: 6.651966094970703\n",
      "idx: 200, loss: 1.1440829038619995 time take: 6.600234746932983\n",
      "idx: 300, loss: 0.945378839969635 time take: 6.583645582199097\n",
      "epoch 7 time taken: 26.058239936828613s\n",
      "Training epoch: 8\n",
      "idx: 0, loss: 1.0273497104644775 time take: 0.26419687271118164\n",
      "idx: 100, loss: 1.1471830606460571 time take: 6.603032827377319\n",
      "idx: 200, loss: 1.0797070264816284 time take: 6.582943916320801\n",
      "idx: 300, loss: 0.9814538359642029 time take: 6.625694990158081\n",
      "epoch 8 time taken: 26.146844387054443s\n",
      "Training epoch: 9\n",
      "idx: 0, loss: 0.8939801454544067 time take: 0.2754058837890625\n",
      "idx: 100, loss: 0.9174132347106934 time take: 6.644529104232788\n",
      "idx: 200, loss: 1.0530388355255127 time take: 6.582005977630615\n",
      "idx: 300, loss: 0.9304407835006714 time take: 6.603318929672241\n",
      "epoch 9 time taken: 26.075950384140015s\n",
      "Training epoch: 10\n",
      "idx: 0, loss: 1.0336077213287354 time take: 0.22904300689697266\n",
      "idx: 100, loss: 0.8789640069007874 time take: 6.595850467681885\n",
      "idx: 200, loss: 0.9352422952651978 time take: 6.583431243896484\n",
      "idx: 300, loss: 1.442083477973938 time take: 6.583585739135742\n",
      "epoch 10 time taken: 25.961189031600952s\n",
      "Training epoch: 11\n",
      "idx: 0, loss: 1.1187089681625366 time take: 0.24193406105041504\n",
      "idx: 100, loss: 0.8760786652565002 time take: 6.623649835586548\n",
      "idx: 200, loss: 1.0546050071716309 time take: 6.628606081008911\n",
      "idx: 300, loss: 0.8964843153953552 time take: 6.580737352371216\n",
      "epoch 11 time taken: 26.042072534561157s\n",
      "Training epoch: 12\n",
      "idx: 0, loss: 0.9619445204734802 time take: 0.26403164863586426\n",
      "idx: 100, loss: 0.7979698181152344 time take: 6.602689266204834\n",
      "idx: 200, loss: 0.9285707473754883 time take: 6.584793567657471\n",
      "idx: 300, loss: 0.8135713934898376 time take: 6.584289073944092\n",
      "epoch 12 time taken: 26.007776975631714s\n",
      "Training epoch: 13\n",
      "idx: 0, loss: 0.7863958477973938 time take: 0.2552952766418457\n",
      "idx: 100, loss: 0.7516125440597534 time take: 6.618442535400391\n",
      "idx: 200, loss: 0.9074832201004028 time take: 6.587857723236084\n",
      "idx: 300, loss: 0.7724675536155701 time take: 6.624806880950928\n",
      "epoch 13 time taken: 26.119580030441284s\n",
      "Training epoch: 14\n",
      "idx: 0, loss: 0.7507041692733765 time take: 0.2647435665130615\n",
      "idx: 100, loss: 0.9528124332427979 time take: 6.598584413528442\n",
      "idx: 200, loss: 1.040589451789856 time take: 6.588745594024658\n",
      "idx: 300, loss: 0.8803819417953491 time take: 6.587707042694092\n",
      "epoch 14 time taken: 26.011911869049072s\n",
      "Training epoch: 15\n",
      "idx: 0, loss: 0.8283509612083435 time take: 0.24098587036132812\n",
      "idx: 100, loss: 0.6945115327835083 time take: 6.5965869426727295\n",
      "idx: 200, loss: 0.8820525407791138 time take: 6.5861921310424805\n",
      "idx: 300, loss: 0.7207545638084412 time take: 6.589037656784058\n",
      "epoch 15 time taken: 26.00495171546936s\n",
      "Training epoch: 16\n",
      "idx: 0, loss: 0.7777943015098572 time take: 0.4297952651977539\n",
      "idx: 100, loss: 0.824204683303833 time take: 6.658270359039307\n",
      "idx: 200, loss: 0.8672212958335876 time take: 6.597419023513794\n",
      "idx: 300, loss: 0.7977423667907715 time take: 6.601515531539917\n",
      "epoch 16 time taken: 26.26039743423462s\n",
      "Training epoch: 17\n",
      "idx: 0, loss: 0.5859003067016602 time take: 0.2445061206817627\n",
      "idx: 100, loss: 0.7854067087173462 time take: 6.625365972518921\n",
      "idx: 200, loss: 0.7763117551803589 time take: 6.592222690582275\n",
      "idx: 300, loss: 0.6920950412750244 time take: 6.59339165687561\n",
      "epoch 17 time taken: 26.028959274291992s\n",
      "Training epoch: 18\n",
      "idx: 0, loss: 0.622612476348877 time take: 0.24079346656799316\n",
      "idx: 100, loss: 0.6236050724983215 time take: 6.6026694774627686\n",
      "idx: 200, loss: 0.6732543706893921 time take: 6.6202685832977295\n",
      "idx: 300, loss: 0.6845113039016724 time take: 6.610554218292236\n",
      "epoch 18 time taken: 26.08669400215149s\n",
      "Training epoch: 19\n",
      "idx: 0, loss: 0.7408422827720642 time take: 0.27343034744262695\n",
      "idx: 100, loss: 0.8583645224571228 time take: 6.6760149002075195\n",
      "idx: 200, loss: 0.7205632925033569 time take: 6.625875949859619\n",
      "idx: 300, loss: 0.7520243525505066 time take: 6.617116212844849\n",
      "epoch 19 time taken: 26.165271520614624s\n",
      "Training epoch: 20\n",
      "idx: 0, loss: 0.5597286224365234 time take: 0.21683335304260254\n",
      "idx: 100, loss: 0.5768546462059021 time take: 6.617881774902344\n",
      "idx: 200, loss: 0.7301536798477173 time take: 6.5881242752075195\n",
      "idx: 300, loss: 0.7250905632972717 time take: 6.636717319488525\n",
      "epoch 20 time taken: 26.087668895721436s\n",
      "Training epoch: 21\n",
      "idx: 0, loss: 0.5925074219703674 time take: 0.2485973834991455\n",
      "idx: 100, loss: 0.5875961780548096 time take: 6.606988430023193\n",
      "idx: 200, loss: 0.5758960247039795 time take: 6.69114351272583\n",
      "idx: 300, loss: 0.639659583568573 time take: 6.5996294021606445\n",
      "epoch 21 time taken: 26.130030870437622s\n",
      "Training epoch: 22\n",
      "idx: 0, loss: 0.4763200283050537 time take: 0.2453141212463379\n",
      "idx: 100, loss: 0.6318216919898987 time take: 6.628007411956787\n",
      "idx: 200, loss: 0.8213397264480591 time take: 6.599001169204712\n",
      "idx: 300, loss: 0.7276906371116638 time take: 6.595858335494995\n",
      "epoch 22 time taken: 26.09293246269226s\n",
      "Training epoch: 23\n",
      "idx: 0, loss: 0.6496564149856567 time take: 0.24060821533203125\n",
      "idx: 100, loss: 0.5505930781364441 time take: 6.667784690856934\n",
      "idx: 200, loss: 0.6387484669685364 time take: 6.599748373031616\n",
      "idx: 300, loss: 0.6586854457855225 time take: 6.596238851547241\n",
      "epoch 23 time taken: 26.083792448043823s\n",
      "Training epoch: 24\n",
      "idx: 0, loss: 0.45741933584213257 time take: 0.2512936592102051\n",
      "idx: 100, loss: 0.5736691355705261 time take: 6.617753505706787\n",
      "idx: 200, loss: 0.6285687685012817 time take: 6.598309755325317\n",
      "idx: 300, loss: 0.5752633810043335 time take: 6.599242448806763\n",
      "epoch 24 time taken: 26.049386262893677s\n",
      "Training epoch: 25\n",
      "idx: 0, loss: 0.5691851377487183 time take: 0.23762202262878418\n",
      "idx: 100, loss: 0.5351296663284302 time take: 6.69985032081604\n",
      "idx: 200, loss: 0.6102172136306763 time take: 6.61269998550415\n",
      "idx: 300, loss: 0.7714871168136597 time take: 6.61196231842041\n",
      "epoch 25 time taken: 26.218782901763916s\n",
      "Training epoch: 26\n",
      "idx: 0, loss: 0.4989773631095886 time take: 0.23712658882141113\n",
      "idx: 100, loss: 0.5537171363830566 time take: 6.618771314620972\n",
      "idx: 200, loss: 0.5783013105392456 time take: 6.606486558914185\n",
      "idx: 300, loss: 0.5532095432281494 time take: 6.601613521575928\n",
      "epoch 26 time taken: 26.044337272644043s\n",
      "Training epoch: 27\n",
      "idx: 0, loss: 0.48094239830970764 time take: 0.23196029663085938\n",
      "idx: 100, loss: 0.5168156027793884 time take: 6.6351635456085205\n",
      "idx: 200, loss: 0.5725588798522949 time take: 6.632504463195801\n",
      "idx: 300, loss: 0.5229011178016663 time take: 6.60103178024292\n",
      "epoch 27 time taken: 26.084261178970337s\n",
      "Training epoch: 28\n",
      "idx: 0, loss: 0.4911786913871765 time take: 0.21820759773254395\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "idx: 100, loss: 0.41825008392333984 time take: 6.608471632003784\n",
      "idx: 200, loss: 0.6130558848381042 time take: 6.5978217124938965\n",
      "idx: 300, loss: 0.5527329444885254 time take: 6.604417085647583\n",
      "epoch 28 time taken: 26.013185024261475s\n",
      "Training epoch: 29\n",
      "idx: 0, loss: 0.44136032462120056 time take: 0.2511000633239746\n",
      "idx: 100, loss: 0.45198312401771545 time take: 6.611998081207275\n",
      "idx: 200, loss: 0.5535292625427246 time take: 6.601720809936523\n",
      "idx: 300, loss: 0.48668721318244934 time take: 6.614667177200317\n",
      "epoch 29 time taken: 26.20002245903015s\n",
      "Training epoch: 30\n",
      "idx: 0, loss: 0.44375431537628174 time take: 0.22037196159362793\n",
      "idx: 100, loss: 0.4258122444152832 time take: 6.620441198348999\n",
      "idx: 200, loss: 0.5633814334869385 time take: 6.603837013244629\n",
      "idx: 300, loss: 0.5744293332099915 time take: 6.60388970375061\n",
      "epoch 30 time taken: 26.033058404922485s\n",
      "Training epoch: 31\n",
      "idx: 0, loss: 0.38152432441711426 time take: 0.25177931785583496\n",
      "idx: 100, loss: 0.467026025056839 time take: 6.716254711151123\n",
      "idx: 200, loss: 0.6033708453178406 time take: 6.723442792892456\n",
      "idx: 300, loss: 0.522839367389679 time take: 6.712618827819824\n",
      "epoch 31 time taken: 26.478866577148438s\n",
      "Training epoch: 32\n",
      "idx: 0, loss: 0.3592378497123718 time take: 0.23482370376586914\n",
      "idx: 100, loss: 0.3824854791164398 time take: 6.717356204986572\n",
      "idx: 200, loss: 0.5111280679702759 time take: 6.601994276046753\n",
      "idx: 300, loss: 0.4750960171222687 time take: 6.75850510597229\n",
      "epoch 32 time taken: 26.415196180343628s\n",
      "Training epoch: 33\n",
      "idx: 0, loss: 0.5384331941604614 time take: 0.2679862976074219\n",
      "idx: 100, loss: 0.5039435625076294 time take: 6.608344554901123\n",
      "idx: 200, loss: 0.5977756381034851 time take: 6.601300954818726\n",
      "idx: 300, loss: 0.4706145226955414 time take: 6.602515459060669\n",
      "epoch 33 time taken: 26.064669847488403s\n",
      "Training epoch: 34\n",
      "idx: 0, loss: 0.4016730785369873 time take: 0.26038098335266113\n",
      "idx: 100, loss: 0.42719557881355286 time take: 6.615643739700317\n",
      "idx: 200, loss: 0.5012021064758301 time take: 6.636244297027588\n",
      "idx: 300, loss: 0.4180620312690735 time take: 6.601449966430664\n",
      "epoch 34 time taken: 26.098620176315308s\n",
      "Training epoch: 35\n",
      "idx: 0, loss: 0.3406201899051666 time take: 0.24222517013549805\n",
      "idx: 100, loss: 0.3907872140407562 time take: 6.609437942504883\n",
      "idx: 200, loss: 0.4589197337627411 time take: 6.6012349128723145\n",
      "idx: 300, loss: 0.46143028140068054 time take: 6.598894834518433\n",
      "epoch 35 time taken: 26.036179304122925s\n",
      "Training epoch: 36\n",
      "idx: 0, loss: 0.33603614568710327 time take: 0.23885321617126465\n",
      "idx: 100, loss: 0.3799172043800354 time take: 6.620172023773193\n",
      "idx: 200, loss: 0.5308505892753601 time take: 6.6019322872161865\n",
      "idx: 300, loss: 0.4299445152282715 time take: 6.661612033843994\n",
      "epoch 36 time taken: 26.110407829284668s\n",
      "Training epoch: 37\n",
      "idx: 0, loss: 0.2751983106136322 time take: 0.2454984188079834\n",
      "idx: 100, loss: 0.36231982707977295 time take: 6.656503438949585\n",
      "idx: 200, loss: 0.5537633895874023 time take: 6.606444597244263\n",
      "idx: 300, loss: 0.3739337623119354 time take: 6.600206136703491\n",
      "epoch 37 time taken: 26.091572523117065s\n",
      "Training epoch: 38\n",
      "idx: 0, loss: 0.3376789689064026 time take: 0.24152398109436035\n",
      "idx: 100, loss: 0.2799258232116699 time take: 6.6156439781188965\n",
      "idx: 200, loss: 0.4593760669231415 time take: 6.60297417640686\n",
      "idx: 300, loss: 0.36802610754966736 time take: 6.600258111953735\n",
      "epoch 38 time taken: 26.060367107391357s\n",
      "Training epoch: 39\n",
      "idx: 0, loss: 0.44946104288101196 time take: 0.2614552974700928\n",
      "idx: 100, loss: 0.21986672282218933 time take: 6.617029666900635\n",
      "idx: 200, loss: 1.46574068069458 time take: 6.60746693611145\n",
      "idx: 300, loss: 1.4298847913742065 time take: 6.600227355957031\n",
      "epoch 39 time taken: 26.07015299797058s\n",
      "Training epoch: 40\n",
      "idx: 0, loss: 1.1636039018630981 time take: 0.24782896041870117\n",
      "idx: 100, loss: 1.1843836307525635 time take: 6.610765695571899\n",
      "idx: 200, loss: 0.9946455955505371 time take: 6.601391792297363\n",
      "idx: 300, loss: 1.0833971500396729 time take: 6.603587865829468\n",
      "epoch 40 time taken: 26.04911208152771s\n",
      "Training epoch: 41\n",
      "idx: 0, loss: 0.865433394908905 time take: 0.2603721618652344\n",
      "idx: 100, loss: 0.7801944613456726 time take: 6.649230241775513\n",
      "idx: 200, loss: 0.6879196763038635 time take: 6.69843053817749\n",
      "idx: 300, loss: 0.6484375 time take: 6.616911888122559\n",
      "epoch 41 time taken: 26.212131023406982s\n",
      "Training epoch: 42\n",
      "idx: 0, loss: 0.527992844581604 time take: 0.2732961177825928\n",
      "idx: 100, loss: 0.47435012459754944 time take: 6.6239025592803955\n",
      "idx: 200, loss: 0.4885933995246887 time take: 6.608938455581665\n",
      "idx: 300, loss: 0.6067151427268982 time take: 6.608147859573364\n",
      "epoch 42 time taken: 26.106565952301025s\n",
      "Training epoch: 43\n",
      "idx: 0, loss: 0.5292647480964661 time take: 0.23874282836914062\n",
      "idx: 100, loss: 0.4337851107120514 time take: 6.642743110656738\n",
      "idx: 200, loss: 0.5560462474822998 time take: 6.611283540725708\n",
      "idx: 300, loss: 0.5385855436325073 time take: 6.6520915031433105\n",
      "epoch 43 time taken: 26.133481979370117s\n",
      "Training epoch: 44\n",
      "idx: 0, loss: 0.432476669549942 time take: 0.22941040992736816\n",
      "idx: 100, loss: 0.3414272665977478 time take: 6.623942136764526\n",
      "idx: 200, loss: 0.5645729303359985 time take: 6.614715337753296\n",
      "idx: 300, loss: 0.4167396128177643 time take: 6.6123247146606445\n",
      "epoch 44 time taken: 26.07283854484558s\n",
      "Training epoch: 45\n",
      "idx: 0, loss: 0.33091527223587036 time take: 0.24125218391418457\n",
      "idx: 100, loss: 0.26865407824516296 time take: 6.619077920913696\n",
      "idx: 200, loss: 0.446867436170578 time take: 6.6566736698150635\n",
      "idx: 300, loss: 0.40013688802719116 time take: 6.6141417026519775\n",
      "epoch 45 time taken: 26.182401657104492s\n",
      "Training epoch: 46\n",
      "idx: 0, loss: 0.2880971431732178 time take: 0.26213979721069336\n",
      "idx: 100, loss: 0.29557716846466064 time take: 6.622858047485352\n",
      "idx: 200, loss: 0.45300939679145813 time take: 6.608863592147827\n",
      "idx: 300, loss: 0.3892311453819275 time take: 6.609612226486206\n",
      "epoch 46 time taken: 26.096876621246338s\n",
      "Training epoch: 47\n",
      "idx: 0, loss: 0.33259525895118713 time take: 0.26755619049072266\n",
      "idx: 100, loss: 0.21855279803276062 time take: 6.69666051864624\n",
      "idx: 200, loss: 0.425873726606369 time take: 6.649601697921753\n",
      "idx: 300, loss: 0.3251549005508423 time take: 6.660174131393433\n",
      "epoch 47 time taken: 26.27508234977722s\n",
      "Training epoch: 48\n",
      "idx: 0, loss: 0.27405521273612976 time take: 0.2638390064239502\n",
      "idx: 100, loss: 0.28238779306411743 time take: 6.675349950790405\n",
      "idx: 200, loss: 0.7898818850517273 time take: 6.604727268218994\n",
      "idx: 300, loss: 0.4632575213909149 time take: 6.603061199188232\n",
      "epoch 48 time taken: 26.135279655456543s\n",
      "Training epoch: 49\n",
      "idx: 0, loss: 0.35168761014938354 time take: 0.2506527900695801\n",
      "idx: 100, loss: 0.37601321935653687 time take: 6.656621932983398\n",
      "idx: 200, loss: 0.5189995765686035 time take: 6.682981252670288\n",
      "idx: 300, loss: 0.5105990171432495 time take: 6.614274978637695\n",
      "epoch 49 time taken: 26.196388483047485s\n",
      "Training epoch: 50\n",
      "idx: 0, loss: 0.38004565238952637 time take: 0.26602935791015625\n",
      "idx: 100, loss: 0.39911580085754395 time take: 6.805379390716553\n",
      "idx: 200, loss: 0.4914511740207672 time take: 6.706323623657227\n",
      "idx: 300, loss: 0.3996969759464264 time take: 6.640417098999023\n",
      "epoch 50 time taken: 26.62113928794861s\n",
      "Training epoch: 51\n",
      "idx: 0, loss: 0.30350250005722046 time take: 0.26219940185546875\n",
      "idx: 100, loss: 0.24401168525218964 time take: 6.699388027191162\n",
      "idx: 200, loss: 0.3935471773147583 time take: 6.672972917556763\n",
      "idx: 300, loss: 0.33634212613105774 time take: 6.60926365852356\n",
      "epoch 51 time taken: 26.232909440994263s\n",
      "Training epoch: 52\n",
      "idx: 0, loss: 0.2544190287590027 time take: 0.2622547149658203\n",
      "idx: 100, loss: 0.3819003105163574 time take: 6.6207170486450195\n",
      "idx: 200, loss: 0.3432423174381256 time take: 6.617731332778931\n",
      "idx: 300, loss: 0.3091173768043518 time take: 6.646620988845825\n",
      "epoch 52 time taken: 26.139552116394043s\n",
      "Training epoch: 53\n",
      "idx: 0, loss: 0.305521160364151 time take: 0.2462151050567627\n",
      "idx: 100, loss: 0.2683592736721039 time take: 6.620020151138306\n",
      "idx: 200, loss: 0.39257878065109253 time take: 6.649626731872559\n",
      "idx: 300, loss: 0.42953771352767944 time take: 6.61147403717041\n",
      "epoch 53 time taken: 26.11815047264099s\n",
      "Training epoch: 54\n",
      "idx: 0, loss: 0.20976632833480835 time take: 0.26363539695739746\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "idx: 100, loss: 0.1937101036310196 time take: 6.616108417510986\n",
      "idx: 200, loss: 0.3188554644584656 time take: 6.603422164916992\n",
      "idx: 300, loss: 0.450793981552124 time take: 6.60664701461792\n",
      "epoch 54 time taken: 26.077478885650635s\n",
      "Training epoch: 55\n",
      "idx: 0, loss: 0.18588122725486755 time take: 0.25312280654907227\n",
      "idx: 100, loss: 0.28052905201911926 time take: 6.671067476272583\n",
      "idx: 200, loss: 0.6574788689613342 time take: 6.61028265953064\n",
      "idx: 300, loss: 0.41383013129234314 time take: 6.603945970535278\n",
      "epoch 55 time taken: 26.127240896224976s\n",
      "Training epoch: 56\n",
      "idx: 0, loss: 0.36356326937675476 time take: 0.2443833351135254\n",
      "idx: 100, loss: 0.27254390716552734 time take: 6.695274353027344\n",
      "idx: 200, loss: 0.4674862027168274 time take: 6.730895280838013\n",
      "idx: 300, loss: 0.2915031611919403 time take: 6.628110647201538\n",
      "epoch 56 time taken: 26.285008192062378s\n",
      "Training epoch: 57\n",
      "idx: 0, loss: 0.28718307614326477 time take: 0.2659947872161865\n",
      "idx: 100, loss: 0.2894574999809265 time take: 6.645033359527588\n",
      "idx: 200, loss: 0.4427216351032257 time take: 6.663832187652588\n",
      "idx: 300, loss: 0.36331284046173096 time take: 6.604999780654907\n",
      "epoch 57 time taken: 26.172014951705933s\n",
      "Training epoch: 58\n",
      "idx: 0, loss: 0.18975816667079926 time take: 0.25031447410583496\n",
      "idx: 100, loss: 0.232621967792511 time take: 6.620995759963989\n",
      "idx: 200, loss: 0.4080512821674347 time take: 6.607650279998779\n",
      "idx: 300, loss: 0.3093796670436859 time take: 6.658501148223877\n",
      "epoch 58 time taken: 26.126916885375977s\n",
      "Training epoch: 59\n",
      "idx: 0, loss: 0.22410930693149567 time take: 0.24851584434509277\n",
      "idx: 100, loss: 0.21116210520267487 time take: 6.619271516799927\n",
      "idx: 200, loss: 0.38825884461402893 time take: 6.6077704429626465\n",
      "idx: 300, loss: 0.3223182260990143 time take: 6.647049903869629\n",
      "epoch 59 time taken: 26.11053442955017s\n",
      "Training epoch: 60\n",
      "idx: 0, loss: 0.22509703040122986 time take: 0.23203778266906738\n",
      "idx: 100, loss: 0.27735117077827454 time take: 6.614363193511963\n",
      "idx: 200, loss: 0.2914656698703766 time take: 6.610793352127075\n",
      "idx: 300, loss: 0.3779121935367584 time take: 6.6073925495147705\n",
      "epoch 60 time taken: 26.05698871612549s\n",
      "Training epoch: 61\n",
      "idx: 0, loss: 0.21612824499607086 time take: 0.2636854648590088\n",
      "idx: 100, loss: 0.1938292533159256 time take: 6.626417398452759\n",
      "idx: 200, loss: 0.4136385917663574 time take: 6.609107732772827\n",
      "idx: 300, loss: 0.3117348551750183 time take: 6.607478857040405\n",
      "epoch 61 time taken: 26.116732358932495s\n",
      "Training epoch: 62\n",
      "idx: 0, loss: 0.33467939496040344 time take: 0.2517521381378174\n",
      "idx: 100, loss: 0.24146206676959991 time take: 6.628239393234253\n",
      "idx: 200, loss: 0.4021635353565216 time take: 6.630865097045898\n",
      "idx: 300, loss: 0.2679176330566406 time take: 6.606303691864014\n",
      "epoch 62 time taken: 26.229098320007324s\n",
      "Training epoch: 63\n",
      "idx: 0, loss: 0.21809305250644684 time take: 0.2528071403503418\n",
      "idx: 100, loss: 0.17504960298538208 time take: 6.674964904785156\n",
      "idx: 200, loss: 0.23939187824726105 time take: 6.608300685882568\n",
      "idx: 300, loss: 0.35730764269828796 time take: 6.6055450439453125\n",
      "epoch 63 time taken: 26.14312767982483s\n",
      "Training epoch: 64\n",
      "idx: 0, loss: 0.19080352783203125 time take: 0.2453937530517578\n",
      "idx: 100, loss: 0.18909263610839844 time take: 6.7045323848724365\n",
      "idx: 200, loss: 0.29037147760391235 time take: 6.60814356803894\n",
      "idx: 300, loss: 0.3234957754611969 time take: 6.608669996261597\n",
      "epoch 64 time taken: 26.16007947921753s\n",
      "Training epoch: 65\n",
      "idx: 0, loss: 0.2447620928287506 time take: 0.24244379997253418\n",
      "idx: 100, loss: 0.28377193212509155 time take: 6.617897987365723\n",
      "idx: 200, loss: 1.690905213356018 time take: 6.607941389083862\n",
      "idx: 300, loss: 0.5516320466995239 time take: 6.605116128921509\n",
      "epoch 65 time taken: 26.060471296310425s\n",
      "Training epoch: 66\n",
      "idx: 0, loss: 0.6224287152290344 time take: 0.2329413890838623\n",
      "idx: 100, loss: 0.32738617062568665 time take: 6.655497789382935\n",
      "idx: 200, loss: 0.5289494395256042 time take: 6.641311407089233\n",
      "idx: 300, loss: 0.38989514112472534 time take: 6.608873605728149\n",
      "epoch 66 time taken: 26.124749898910522s\n",
      "Training epoch: 67\n",
      "idx: 0, loss: 0.3391847610473633 time take: 0.2390153408050537\n",
      "idx: 100, loss: 0.2482614815235138 time take: 6.764507532119751\n",
      "idx: 200, loss: 0.35359111428260803 time take: 6.645203113555908\n",
      "idx: 300, loss: 0.292767733335495 time take: 6.60602068901062\n",
      "epoch 67 time taken: 26.25114393234253s\n",
      "Training epoch: 68\n",
      "idx: 0, loss: 0.18021848797798157 time take: 0.25162267684936523\n",
      "idx: 100, loss: 0.1457870751619339 time take: 6.614955425262451\n",
      "idx: 200, loss: 0.3619346618652344 time take: 6.6072916984558105\n",
      "idx: 300, loss: 0.2771162688732147 time take: 6.6066741943359375\n",
      "epoch 68 time taken: 26.097604990005493s\n",
      "Training epoch: 69\n",
      "idx: 0, loss: 0.18192318081855774 time take: 0.2610776424407959\n",
      "idx: 100, loss: 0.18852874636650085 time take: 6.690805435180664\n",
      "idx: 200, loss: 0.3262379467487335 time take: 6.730497121810913\n",
      "idx: 300, loss: 0.2828414738178253 time take: 6.6073548793792725\n",
      "epoch 69 time taken: 26.278229475021362s\n",
      "Training epoch: 70\n",
      "idx: 0, loss: 0.23990167677402496 time take: 0.23244714736938477\n",
      "idx: 100, loss: 0.22641527652740479 time take: 6.6328818798065186\n",
      "idx: 200, loss: 0.28350841999053955 time take: 6.6071648597717285\n",
      "idx: 300, loss: 0.2869389057159424 time take: 6.611583709716797\n",
      "epoch 70 time taken: 26.077035903930664s\n",
      "Training epoch: 71\n",
      "idx: 0, loss: 0.138653963804245 time take: 0.2668626308441162\n",
      "idx: 100, loss: 0.1882495880126953 time take: 6.660316705703735\n",
      "idx: 200, loss: 0.29767513275146484 time take: 6.602772235870361\n",
      "idx: 300, loss: 0.22054581344127655 time take: 6.606280088424683\n",
      "epoch 71 time taken: 26.12138271331787s\n",
      "Training epoch: 72\n",
      "idx: 0, loss: 0.19910700619220734 time take: 0.25949549674987793\n",
      "idx: 100, loss: 0.13572578132152557 time take: 6.620594024658203\n",
      "idx: 200, loss: 0.22335076332092285 time take: 6.609229564666748\n",
      "idx: 300, loss: 0.16628022491931915 time take: 6.606026649475098\n",
      "epoch 72 time taken: 26.083995580673218s\n",
      "Training epoch: 73\n",
      "idx: 0, loss: 0.1524621546268463 time take: 0.2523040771484375\n",
      "idx: 100, loss: 0.1912451535463333 time take: 6.6219801902771\n",
      "idx: 200, loss: 0.37222713232040405 time take: 6.64166784286499\n",
      "idx: 300, loss: 0.447238028049469 time take: 6.607868432998657\n",
      "epoch 73 time taken: 26.131729125976562s\n",
      "Training epoch: 74\n",
      "idx: 0, loss: 0.1739930659532547 time take: 0.26766419410705566\n",
      "idx: 100, loss: 0.18161283433437347 time take: 6.619682312011719\n",
      "idx: 200, loss: 0.2063053548336029 time take: 6.6052398681640625\n",
      "idx: 300, loss: 0.15525686740875244 time take: 6.604775428771973\n",
      "epoch 74 time taken: 26.082966566085815s\n",
      "Training epoch: 75\n",
      "idx: 0, loss: 0.24048316478729248 time take: 0.26357412338256836\n",
      "idx: 100, loss: 0.13662360608577728 time take: 6.609656810760498\n",
      "idx: 200, loss: 0.22172150015830994 time take: 6.6076624393463135\n",
      "idx: 300, loss: 0.25210872292518616 time take: 6.716452360153198\n",
      "epoch 75 time taken: 26.18842625617981s\n",
      "Training epoch: 76\n",
      "idx: 0, loss: 0.12082579731941223 time take: 0.2260293960571289\n",
      "idx: 100, loss: 0.17682088911533356 time take: 6.616926431655884\n",
      "idx: 200, loss: 0.2738700211048126 time take: 6.606470108032227\n",
      "idx: 300, loss: 0.1655506193637848 time take: 6.6066365242004395\n",
      "epoch 76 time taken: 26.04884934425354s\n",
      "Training epoch: 77\n",
      "idx: 0, loss: 0.14047889411449432 time take: 0.24315619468688965\n",
      "idx: 100, loss: 0.15112927556037903 time take: 6.61520791053772\n",
      "idx: 200, loss: 0.23111464083194733 time take: 6.605334281921387\n",
      "idx: 300, loss: 0.26540040969848633 time take: 6.607825040817261\n",
      "epoch 77 time taken: 26.083226203918457s\n",
      "Training epoch: 78\n",
      "idx: 0, loss: 0.19260892271995544 time take: 0.2483363151550293\n",
      "idx: 100, loss: 0.192992702126503 time take: 6.619726657867432\n",
      "idx: 200, loss: 0.3020884096622467 time take: 6.622902154922485\n",
      "idx: 300, loss: 0.18796326220035553 time take: 6.607783079147339\n",
      "epoch 78 time taken: 26.09011673927307s\n",
      "Training epoch: 79\n",
      "idx: 0, loss: 0.24859552085399628 time take: 0.24311327934265137\n",
      "idx: 100, loss: 0.1413581520318985 time take: 6.616320371627808\n",
      "idx: 200, loss: 0.25520798563957214 time take: 6.62789511680603\n",
      "idx: 300, loss: 0.1988912671804428 time take: 6.606706619262695\n",
      "epoch 79 time taken: 26.083932876586914s\n",
      "Training epoch: 80\n",
      "idx: 0, loss: 0.13871416449546814 time take: 0.26396822929382324\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "idx: 100, loss: 0.15891627967357635 time take: 6.612596750259399\n",
      "idx: 200, loss: 0.22067543864250183 time take: 6.641980171203613\n",
      "idx: 300, loss: 0.30777692794799805 time take: 6.608111381530762\n",
      "epoch 80 time taken: 26.117828607559204s\n",
      "Training epoch: 81\n",
      "idx: 0, loss: 0.2319861799478531 time take: 0.23457717895507812\n",
      "idx: 100, loss: 0.15951944887638092 time take: 6.638277530670166\n",
      "idx: 200, loss: 0.20585092902183533 time take: 6.654615640640259\n",
      "idx: 300, loss: 0.20347203314304352 time take: 6.778892278671265\n",
      "epoch 81 time taken: 26.372536182403564s\n",
      "Training epoch: 82\n",
      "idx: 0, loss: 0.19607262313365936 time take: 0.26544857025146484\n",
      "idx: 100, loss: 0.1327524334192276 time take: 6.623323202133179\n",
      "idx: 200, loss: 0.21612513065338135 time take: 6.649046182632446\n",
      "idx: 300, loss: 0.23467859625816345 time take: 6.734400749206543\n",
      "epoch 82 time taken: 26.317383527755737s\n",
      "Training epoch: 83\n",
      "idx: 0, loss: 0.20301899313926697 time take: 0.23670077323913574\n",
      "idx: 100, loss: 0.18460744619369507 time take: 6.626976490020752\n",
      "idx: 200, loss: 0.16964074969291687 time take: 6.61079740524292\n",
      "idx: 300, loss: 0.3158283829689026 time take: 6.607305288314819\n",
      "epoch 83 time taken: 26.07161283493042s\n",
      "Training epoch: 84\n",
      "idx: 0, loss: 0.1946660429239273 time take: 0.257230281829834\n",
      "idx: 100, loss: 0.10924721509218216 time take: 6.619632005691528\n",
      "idx: 200, loss: 0.17320290207862854 time take: 6.607953310012817\n",
      "idx: 300, loss: 0.22153235971927643 time take: 6.611575126647949\n",
      "epoch 84 time taken: 26.16642427444458s\n",
      "Training epoch: 85\n",
      "idx: 0, loss: 0.15038001537322998 time take: 0.2238929271697998\n",
      "idx: 100, loss: 0.10450968146324158 time take: 6.619012832641602\n",
      "idx: 200, loss: 0.29922452569007874 time take: 6.612111330032349\n",
      "idx: 300, loss: 0.9936044216156006 time take: 6.660630226135254\n",
      "epoch 85 time taken: 26.145715713500977s\n",
      "Training epoch: 86\n",
      "idx: 0, loss: 0.4297409653663635 time take: 0.2471175193786621\n",
      "idx: 100, loss: 0.2998064160346985 time take: 6.621045827865601\n",
      "idx: 200, loss: 0.31437283754348755 time take: 6.610664367675781\n",
      "idx: 300, loss: 0.26024410128593445 time take: 6.606497049331665\n",
      "epoch 86 time taken: 26.08578872680664s\n",
      "Training epoch: 87\n",
      "idx: 0, loss: 0.2133917361497879 time take: 0.2563140392303467\n",
      "idx: 100, loss: 0.1481473445892334 time take: 6.723295211791992\n",
      "idx: 200, loss: 0.20441246032714844 time take: 6.65979790687561\n",
      "idx: 300, loss: 0.21839089691638947 time take: 6.606171369552612\n",
      "epoch 87 time taken: 26.243369102478027s\n",
      "Training epoch: 88\n",
      "idx: 0, loss: 0.1792137175798416 time take: 0.23563885688781738\n",
      "idx: 100, loss: 0.11576391756534576 time take: 6.63378381729126\n",
      "idx: 200, loss: 0.20278236269950867 time take: 6.613835096359253\n",
      "idx: 300, loss: 0.1912853866815567 time take: 6.608808279037476\n",
      "epoch 88 time taken: 26.084045886993408s\n",
      "Training epoch: 89\n",
      "idx: 0, loss: 0.13208037614822388 time take: 0.2411026954650879\n",
      "idx: 100, loss: 0.13210701942443848 time take: 6.664805889129639\n",
      "idx: 200, loss: 0.18292680382728577 time take: 6.667717456817627\n",
      "idx: 300, loss: 0.1673295944929123 time take: 6.613030195236206\n",
      "epoch 89 time taken: 26.174402475357056s\n",
      "Training epoch: 90\n",
      "idx: 0, loss: 0.14070235192775726 time take: 0.2331998348236084\n",
      "idx: 100, loss: 0.22800980508327484 time take: 6.625319719314575\n",
      "idx: 200, loss: 0.23875121772289276 time take: 6.604190349578857\n",
      "idx: 300, loss: 0.1934383511543274 time take: 6.609766006469727\n",
      "epoch 90 time taken: 26.061135053634644s\n",
      "Training epoch: 91\n",
      "idx: 0, loss: 0.14233185350894928 time take: 0.26738405227661133\n",
      "idx: 100, loss: 0.10033829510211945 time take: 6.619133949279785\n",
      "idx: 200, loss: 0.21977633237838745 time take: 6.6528966426849365\n",
      "idx: 300, loss: 0.1582338660955429 time take: 6.6506125926971436\n",
      "epoch 91 time taken: 26.180105686187744s\n",
      "Training epoch: 92\n",
      "idx: 0, loss: 0.21848034858703613 time take: 0.2585322856903076\n",
      "idx: 100, loss: 0.07558456063270569 time take: 6.617968797683716\n",
      "idx: 200, loss: 0.1261264979839325 time take: 6.832681179046631\n",
      "idx: 300, loss: 0.2263963669538498 time take: 6.619143724441528\n",
      "epoch 92 time taken: 26.32615566253662s\n",
      "Training epoch: 93\n",
      "idx: 0, loss: 0.22956517338752747 time take: 0.24739289283752441\n",
      "idx: 100, loss: 0.18417473137378693 time take: 6.626379013061523\n",
      "idx: 200, loss: 0.17328894138336182 time take: 6.60615348815918\n",
      "idx: 300, loss: 0.15880879759788513 time take: 6.6057469844818115\n",
      "epoch 93 time taken: 26.08306622505188s\n",
      "Training epoch: 94\n",
      "idx: 0, loss: 0.09778106212615967 time take: 0.25310826301574707\n",
      "idx: 100, loss: 0.10172002017498016 time take: 6.6760265827178955\n",
      "idx: 200, loss: 0.23264485597610474 time take: 6.606029748916626\n",
      "idx: 300, loss: 0.19683970510959625 time take: 6.606415748596191\n",
      "epoch 94 time taken: 26.13180661201477s\n",
      "Training epoch: 95\n",
      "idx: 0, loss: 0.09434598684310913 time take: 0.2664802074432373\n",
      "idx: 100, loss: 0.10369646549224854 time take: 6.628326416015625\n",
      "idx: 200, loss: 0.2175089418888092 time take: 6.606353044509888\n",
      "idx: 300, loss: 0.1988038271665573 time take: 6.608372688293457\n",
      "epoch 95 time taken: 26.09981918334961s\n",
      "Training epoch: 96\n",
      "idx: 0, loss: 0.09417802840471268 time take: 0.2572472095489502\n",
      "idx: 100, loss: 0.23215749859809875 time take: 6.617603063583374\n",
      "idx: 200, loss: 0.1772037148475647 time take: 6.661641597747803\n",
      "idx: 300, loss: 0.1495230495929718 time take: 6.61011528968811\n",
      "epoch 96 time taken: 26.138803720474243s\n",
      "Training epoch: 97\n",
      "idx: 0, loss: 0.11051710695028305 time take: 0.24968647956848145\n",
      "idx: 100, loss: 0.11819179356098175 time take: 6.619364023208618\n",
      "idx: 200, loss: 0.18225446343421936 time take: 6.630522727966309\n",
      "idx: 300, loss: 0.11121852695941925 time take: 6.610236406326294\n",
      "epoch 97 time taken: 26.098896265029907s\n",
      "Training epoch: 98\n",
      "idx: 0, loss: 0.16739417612552643 time take: 0.2489013671875\n",
      "idx: 100, loss: 0.216873899102211 time take: 6.614657402038574\n",
      "idx: 200, loss: 0.20342756807804108 time take: 6.607085466384888\n",
      "idx: 300, loss: 0.1323271095752716 time take: 6.657223224639893\n",
      "epoch 98 time taken: 26.119420289993286s\n",
      "Training epoch: 99\n",
      "idx: 0, loss: 0.3507031798362732 time take: 0.2575559616088867\n",
      "idx: 100, loss: 0.17561987042427063 time take: 6.629488945007324\n",
      "idx: 200, loss: 2.3823955059051514 time take: 6.611939430236816\n",
      "idx: 300, loss: 1.013089656829834 time take: 6.6079277992248535\n",
      "epoch 99 time taken: 26.09603261947632s\n",
      "Performing inference on batch: 0\n",
      "Performing inference on batch: 50\n",
      "Performing inference on batch: 0\n",
      "Performing inference on batch: 50\n",
      "FPR@95: 79.59, AUROC: 77.06 AUPR_IN: 76.79, AUPR_OUT: 73.75\n",
      "CCR: 0.01, 0.02, 9.41, 41.89, ACC: 75.03\n",
      "\n",
      "Running model: models/cifar_resnet50_odin_relu_Adam_2.pkl...\n",
      "Getting optimizer for type: Adam...\n",
      "Training epoch: 0\n",
      "idx: 0, loss: 2.6199276447296143 time take: 0.2744026184082031\n",
      "idx: 100, loss: 2.2785723209381104 time take: 6.590246200561523\n",
      "idx: 200, loss: 2.351520299911499 time take: 6.7339959144592285\n",
      "idx: 300, loss: 2.108813762664795 time take: 6.777331590652466\n",
      "epoch 0 time taken: 26.446737051010132s\n",
      "Training epoch: 1\n",
      "idx: 0, loss: 2.084507465362549 time take: 0.26970887184143066\n",
      "idx: 100, loss: 1.8693965673446655 time take: 6.609508037567139\n",
      "idx: 200, loss: 1.8586676120758057 time take: 6.58804988861084\n",
      "idx: 300, loss: 1.8039742708206177 time take: 6.578991413116455\n",
      "epoch 1 time taken: 26.014320135116577s\n",
      "Training epoch: 2\n",
      "idx: 0, loss: 1.8414390087127686 time take: 0.27604222297668457\n",
      "idx: 100, loss: 1.6675299406051636 time take: 6.699211835861206\n",
      "idx: 200, loss: 1.8091363906860352 time take: 6.720189094543457\n",
      "idx: 300, loss: 1.6765248775482178 time take: 6.668798446655273\n",
      "epoch 2 time taken: 26.328315019607544s\n",
      "Training epoch: 3\n",
      "idx: 0, loss: 1.6884479522705078 time take: 0.24819135665893555\n",
      "idx: 100, loss: 1.5099881887435913 time take: 6.612981081008911\n",
      "idx: 200, loss: 1.5293101072311401 time take: 6.578008651733398\n",
      "idx: 300, loss: 1.5170443058013916 time take: 6.582707405090332\n",
      "epoch 3 time taken: 25.98701286315918s\n",
      "Training epoch: 4\n",
      "idx: 0, loss: 1.504440188407898 time take: 0.24583673477172852\n",
      "idx: 100, loss: 1.3974394798278809 time take: 6.601762294769287\n",
      "idx: 200, loss: 1.4646981954574585 time take: 6.586719989776611\n",
      "idx: 300, loss: 1.4207403659820557 time take: 6.583472013473511\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 4 time taken: 26.045965909957886s\n",
      "Training epoch: 5\n",
      "idx: 0, loss: 1.418537974357605 time take: 0.25160694122314453\n",
      "idx: 100, loss: 1.340538501739502 time take: 6.595491170883179\n",
      "idx: 200, loss: 1.34032142162323 time take: 6.584538459777832\n",
      "idx: 300, loss: 1.3569982051849365 time take: 6.582293510437012\n",
      "epoch 5 time taken: 25.981970071792603s\n",
      "Training epoch: 6\n",
      "idx: 0, loss: 1.370997667312622 time take: 0.2662355899810791\n",
      "idx: 100, loss: 1.27835214138031 time take: 6.605718374252319\n",
      "idx: 200, loss: 1.3348937034606934 time take: 6.582807302474976\n",
      "idx: 300, loss: 1.2628141641616821 time take: 6.581418037414551\n",
      "epoch 6 time taken: 26.008046627044678s\n",
      "Training epoch: 7\n",
      "idx: 0, loss: 1.2738956212997437 time take: 0.26305389404296875\n",
      "idx: 100, loss: 1.1675077676773071 time take: 6.639991521835327\n",
      "idx: 200, loss: 1.228621482849121 time take: 6.5817954540252686\n",
      "idx: 300, loss: 1.1231369972229004 time take: 6.5856122970581055\n",
      "epoch 7 time taken: 26.040780067443848s\n",
      "Training epoch: 8\n",
      "idx: 0, loss: 1.145025610923767 time take: 0.24323344230651855\n",
      "idx: 100, loss: 1.058472990989685 time take: 6.617619514465332\n",
      "idx: 200, loss: 1.1832698583602905 time take: 6.585466623306274\n",
      "idx: 300, loss: 1.129667043685913 time take: 6.591055870056152\n",
      "epoch 8 time taken: 26.005290031433105s\n",
      "Training epoch: 9\n",
      "idx: 0, loss: 1.1810812950134277 time take: 0.2675034999847412\n",
      "idx: 100, loss: 1.0167471170425415 time take: 6.598749399185181\n",
      "idx: 200, loss: 1.059170126914978 time take: 6.631219387054443\n",
      "idx: 300, loss: 1.0131149291992188 time take: 6.611880540847778\n",
      "epoch 9 time taken: 26.081197023391724s\n",
      "Training epoch: 10\n",
      "idx: 0, loss: 1.1676262617111206 time take: 0.2686896324157715\n",
      "idx: 100, loss: 1.0587888956069946 time take: 6.595606327056885\n",
      "idx: 200, loss: 1.0910847187042236 time take: 6.584130525588989\n",
      "idx: 300, loss: 1.0110499858856201 time take: 6.587368965148926\n",
      "epoch 10 time taken: 26.004345655441284s\n",
      "Training epoch: 11\n",
      "idx: 0, loss: 1.0933911800384521 time take: 0.2564578056335449\n",
      "idx: 100, loss: 0.95315021276474 time take: 6.589780330657959\n",
      "idx: 200, loss: 0.9067949652671814 time take: 6.5861992835998535\n",
      "idx: 300, loss: 0.9087072014808655 time take: 6.603991746902466\n",
      "epoch 11 time taken: 26.047030925750732s\n",
      "Training epoch: 12\n",
      "idx: 0, loss: 0.8427878022193909 time take: 0.26241207122802734\n",
      "idx: 100, loss: 0.8510333299636841 time take: 6.653893232345581\n",
      "idx: 200, loss: 0.8604511022567749 time take: 6.586203098297119\n",
      "idx: 300, loss: 0.7850988507270813 time take: 6.586439371109009\n",
      "epoch 12 time taken: 26.05923366546631s\n",
      "Training epoch: 13\n",
      "idx: 0, loss: 0.7864624261856079 time take: 0.27504873275756836\n",
      "idx: 100, loss: 0.8405060172080994 time take: 6.608395576477051\n",
      "idx: 200, loss: 0.8748389482498169 time take: 6.586399793624878\n",
      "idx: 300, loss: 0.7847476005554199 time take: 6.681811809539795\n",
      "epoch 13 time taken: 26.249743461608887s\n",
      "Training epoch: 14\n",
      "idx: 0, loss: 0.8050721883773804 time take: 0.255570650100708\n",
      "idx: 100, loss: 0.8403739929199219 time take: 6.686044692993164\n",
      "idx: 200, loss: 0.8551084399223328 time take: 6.673951148986816\n",
      "idx: 300, loss: 0.8268411755561829 time take: 6.682414293289185\n",
      "epoch 14 time taken: 26.36102056503296s\n",
      "Training epoch: 15\n",
      "idx: 0, loss: 0.8150562047958374 time take: 0.24090051651000977\n",
      "idx: 100, loss: 0.8490387797355652 time take: 6.693053483963013\n",
      "idx: 200, loss: 0.8667108416557312 time take: 6.589867830276489\n",
      "idx: 300, loss: 0.7883124947547913 time take: 6.5843186378479\n",
      "epoch 15 time taken: 26.08178973197937s\n",
      "Training epoch: 16\n",
      "idx: 0, loss: 0.9458051919937134 time take: 0.2699146270751953\n",
      "idx: 100, loss: 0.954365611076355 time take: 6.697362899780273\n",
      "idx: 200, loss: 0.9140809178352356 time take: 6.6312971115112305\n",
      "idx: 300, loss: 0.7560561299324036 time take: 6.581640958786011\n",
      "epoch 16 time taken: 26.15155863761902s\n",
      "Training epoch: 17\n",
      "idx: 0, loss: 0.6736851334571838 time take: 0.2507975101470947\n",
      "idx: 100, loss: 0.6976089477539062 time take: 6.597034215927124\n",
      "idx: 200, loss: 0.7962995767593384 time take: 6.583250999450684\n",
      "idx: 300, loss: 0.7298721671104431 time take: 6.58870792388916\n",
      "epoch 17 time taken: 25.99234175682068s\n",
      "Training epoch: 18\n",
      "idx: 0, loss: 0.6248064637184143 time take: 0.2444150447845459\n",
      "idx: 100, loss: 0.6495203971862793 time take: 6.598566055297852\n",
      "idx: 200, loss: 0.7167331576347351 time take: 6.591463804244995\n",
      "idx: 300, loss: 0.6064929366111755 time take: 6.61636209487915\n",
      "epoch 18 time taken: 26.018917322158813s\n",
      "Training epoch: 19\n",
      "idx: 0, loss: 0.6637333631515503 time take: 0.23645925521850586\n",
      "idx: 100, loss: 0.7263404726982117 time take: 6.604332685470581\n",
      "idx: 200, loss: 0.7137792706489563 time take: 6.715222120285034\n",
      "idx: 300, loss: 0.7179684042930603 time take: 6.589685916900635\n",
      "epoch 19 time taken: 26.11726665496826s\n",
      "Training epoch: 20\n",
      "idx: 0, loss: 0.6910286545753479 time take: 0.255993127822876\n",
      "idx: 100, loss: 0.7231791615486145 time take: 6.6702165603637695\n",
      "idx: 200, loss: 0.6900287866592407 time take: 6.591917037963867\n",
      "idx: 300, loss: 0.6262456178665161 time take: 6.587618589401245\n",
      "epoch 20 time taken: 26.111631393432617s\n",
      "Training epoch: 21\n",
      "idx: 0, loss: 0.563429594039917 time take: 0.39414024353027344\n",
      "idx: 100, loss: 0.5639657974243164 time take: 6.611651182174683\n",
      "idx: 200, loss: 0.6667223572731018 time take: 6.650075912475586\n",
      "idx: 300, loss: 0.6169822812080383 time take: 6.613229036331177\n",
      "epoch 21 time taken: 26.24031639099121s\n",
      "Training epoch: 22\n",
      "idx: 0, loss: 0.48015764355659485 time take: 0.2477884292602539\n",
      "idx: 100, loss: 0.4940029978752136 time take: 6.597732305526733\n",
      "idx: 200, loss: 0.6676681041717529 time take: 6.595154762268066\n",
      "idx: 300, loss: 0.515169084072113 time take: 6.585956811904907\n",
      "epoch 22 time taken: 25.997398853302002s\n",
      "Training epoch: 23\n",
      "idx: 0, loss: 0.6179232597351074 time take: 0.23171162605285645\n",
      "idx: 100, loss: 0.6594253182411194 time take: 6.598787069320679\n",
      "idx: 200, loss: 0.6525920033454895 time take: 6.665456533432007\n",
      "idx: 300, loss: 0.5761199593544006 time take: 6.608268737792969\n",
      "epoch 23 time taken: 26.0727219581604s\n",
      "Training epoch: 24\n",
      "idx: 0, loss: 0.48367583751678467 time take: 0.24490714073181152\n",
      "idx: 100, loss: 0.578458309173584 time take: 6.600116014480591\n",
      "idx: 200, loss: 0.6154850721359253 time take: 6.5880446434021\n",
      "idx: 300, loss: 0.5491248965263367 time take: 6.590438604354858\n",
      "epoch 24 time taken: 26.00071668624878s\n",
      "Training epoch: 25\n",
      "idx: 0, loss: 0.5409037470817566 time take: 0.24890756607055664\n",
      "idx: 100, loss: 0.4479415714740753 time take: 6.596258878707886\n",
      "idx: 200, loss: 0.6778849363327026 time take: 6.58976149559021\n",
      "idx: 300, loss: 0.46193015575408936 time take: 6.615347862243652\n",
      "epoch 25 time taken: 26.02427649497986s\n",
      "Training epoch: 26\n",
      "idx: 0, loss: 0.4917287230491638 time take: 0.23252415657043457\n",
      "idx: 100, loss: 0.5812281966209412 time take: 6.6025941371917725\n",
      "idx: 200, loss: 0.5661433935165405 time take: 6.588439226150513\n",
      "idx: 300, loss: 0.5350257158279419 time take: 6.587568759918213\n",
      "epoch 26 time taken: 26.041205406188965s\n",
      "Training epoch: 27\n",
      "idx: 0, loss: 1.166487216949463 time take: 0.2334895133972168\n",
      "idx: 100, loss: 0.5218550562858582 time take: 6.659135103225708\n",
      "idx: 200, loss: 0.691563606262207 time take: 6.622546434402466\n",
      "idx: 300, loss: 0.5572612881660461 time take: 6.628658294677734\n",
      "epoch 27 time taken: 26.199742317199707s\n",
      "Training epoch: 28\n",
      "idx: 0, loss: 0.5249271392822266 time take: 0.23379087448120117\n",
      "idx: 100, loss: 0.5316700339317322 time take: 6.670206785202026\n",
      "idx: 200, loss: 0.5937238931655884 time take: 6.591276407241821\n",
      "idx: 300, loss: 0.5200361013412476 time take: 6.603331565856934\n",
      "epoch 28 time taken: 26.131136178970337s\n",
      "Training epoch: 29\n",
      "idx: 0, loss: 0.32780084013938904 time take: 0.2565040588378906\n",
      "idx: 100, loss: 0.39886900782585144 time take: 6.771920442581177\n",
      "idx: 200, loss: 0.6173363924026489 time take: 6.59573221206665\n",
      "idx: 300, loss: 0.45156440138816833 time take: 6.594140291213989\n",
      "epoch 29 time taken: 26.194810390472412s\n",
      "Training epoch: 30\n",
      "idx: 0, loss: 0.4030393958091736 time take: 0.24105024337768555\n",
      "idx: 100, loss: 0.5104932188987732 time take: 6.68837833404541\n",
      "idx: 200, loss: 0.4809000492095947 time take: 6.624927282333374\n",
      "idx: 300, loss: 0.5875185132026672 time take: 6.595284461975098\n",
      "epoch 30 time taken: 26.125375509262085s\n",
      "Training epoch: 31\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "idx: 0, loss: 0.3683387339115143 time take: 0.260467529296875\n",
      "idx: 100, loss: 0.4372905492782593 time take: 6.616334438323975\n",
      "idx: 200, loss: 0.5869937539100647 time take: 6.593849420547485\n",
      "idx: 300, loss: 0.5844462513923645 time take: 6.597427606582642\n",
      "epoch 31 time taken: 26.043166637420654s\n",
      "Training epoch: 32\n",
      "idx: 0, loss: 0.5211504697799683 time take: 0.23636245727539062\n",
      "idx: 100, loss: 0.4015485644340515 time take: 6.608212232589722\n",
      "idx: 200, loss: 0.5532274842262268 time take: 6.615742444992065\n",
      "idx: 300, loss: 0.41155144572257996 time take: 6.595170259475708\n",
      "epoch 32 time taken: 26.038853406906128s\n",
      "Training epoch: 33\n",
      "idx: 0, loss: 0.3876838684082031 time take: 0.24454259872436523\n",
      "idx: 100, loss: 0.406494140625 time take: 6.612250566482544\n",
      "idx: 200, loss: 0.5751639604568481 time take: 6.598246097564697\n",
      "idx: 300, loss: 0.4406026601791382 time take: 6.598705053329468\n",
      "epoch 33 time taken: 26.092898845672607s\n",
      "Training epoch: 34\n",
      "idx: 0, loss: 0.3477293848991394 time take: 0.2632124423980713\n",
      "idx: 100, loss: 0.49574822187423706 time take: 6.623447895050049\n",
      "idx: 200, loss: 0.4588337242603302 time take: 6.609132528305054\n",
      "idx: 300, loss: 0.35898271203041077 time take: 6.631465673446655\n",
      "epoch 34 time taken: 26.20932650566101s\n",
      "Training epoch: 35\n",
      "idx: 0, loss: 0.3403190076351166 time take: 0.2599751949310303\n",
      "idx: 100, loss: 0.3470118045806885 time take: 6.622960567474365\n",
      "idx: 200, loss: 1.3995444774627686 time take: 6.596842050552368\n",
      "idx: 300, loss: 0.602086067199707 time take: 6.594193458557129\n",
      "epoch 35 time taken: 26.052688598632812s\n",
      "Training epoch: 36\n",
      "idx: 0, loss: 0.5616446733474731 time take: 0.24011826515197754\n",
      "idx: 100, loss: 0.37744200229644775 time take: 6.687544107437134\n",
      "idx: 200, loss: 0.5082417130470276 time take: 6.595255374908447\n",
      "idx: 300, loss: 0.3535677194595337 time take: 6.602815628051758\n",
      "epoch 36 time taken: 26.121028423309326s\n",
      "Training epoch: 37\n",
      "idx: 0, loss: 0.3676595687866211 time take: 0.23990845680236816\n",
      "idx: 100, loss: 0.3913896083831787 time take: 6.6884729862213135\n",
      "idx: 200, loss: 0.46164241433143616 time take: 6.60779333114624\n",
      "idx: 300, loss: 0.4366370439529419 time take: 6.6975438594818115\n",
      "epoch 37 time taken: 26.321223974227905s\n",
      "Training epoch: 38\n",
      "idx: 0, loss: 0.4060460329055786 time take: 0.25836849212646484\n",
      "idx: 100, loss: 0.35729384422302246 time take: 6.609282970428467\n",
      "idx: 200, loss: 0.4635877013206482 time take: 6.6643595695495605\n",
      "idx: 300, loss: 0.4433344304561615 time take: 6.6899025440216064\n",
      "epoch 38 time taken: 26.26626443862915s\n",
      "Training epoch: 39\n",
      "idx: 0, loss: 0.350249707698822 time take: 0.22706246376037598\n",
      "idx: 100, loss: 0.36141031980514526 time take: 6.648633718490601\n",
      "idx: 200, loss: 0.4138343632221222 time take: 6.751678943634033\n",
      "idx: 300, loss: 0.344044029712677 time take: 6.6674113273620605\n",
      "epoch 39 time taken: 26.389896154403687s\n",
      "Training epoch: 40\n",
      "idx: 0, loss: 0.3522908389568329 time take: 0.252791166305542\n",
      "idx: 100, loss: 0.34068241715431213 time take: 6.63028359413147\n",
      "idx: 200, loss: 0.4501461386680603 time take: 6.710837364196777\n",
      "idx: 300, loss: 0.429312139749527 time take: 6.613907337188721\n",
      "epoch 40 time taken: 26.57994532585144s\n",
      "Training epoch: 41\n",
      "idx: 0, loss: 0.4336991310119629 time take: 0.25684189796447754\n",
      "idx: 100, loss: 0.28076162934303284 time take: 6.681890249252319\n",
      "idx: 200, loss: 0.4213200509548187 time take: 6.679862976074219\n",
      "idx: 300, loss: 0.5187010169029236 time take: 6.713337659835815\n",
      "epoch 41 time taken: 26.43302083015442s\n",
      "Training epoch: 42\n",
      "idx: 0, loss: 0.3269202709197998 time take: 0.2481670379638672\n",
      "idx: 100, loss: 0.34410789608955383 time take: 6.687138319015503\n",
      "idx: 200, loss: 0.4139612913131714 time take: 6.607534885406494\n",
      "idx: 300, loss: 0.3476918339729309 time take: 6.6102001667022705\n",
      "epoch 42 time taken: 33.45187973976135s\n",
      "Training epoch: 43\n",
      "idx: 0, loss: 0.32245805859565735 time take: 0.35777878761291504\n",
      "idx: 100, loss: 0.3506705164909363 time take: 15.681503295898438\n",
      "idx: 200, loss: 0.40301796793937683 time take: 6.641735315322876\n",
      "idx: 300, loss: 0.3596523106098175 time take: 6.614088535308838\n",
      "epoch 43 time taken: 35.28919315338135s\n",
      "Training epoch: 44\n",
      "idx: 0, loss: 0.2672756612300873 time take: 0.25303101539611816\n",
      "idx: 100, loss: 0.3505040109157562 time take: 6.62066650390625\n",
      "idx: 200, loss: 0.41283559799194336 time take: 6.607814788818359\n",
      "idx: 300, loss: 0.3671554625034332 time take: 6.607032537460327\n",
      "epoch 44 time taken: 26.078770399093628s\n",
      "Training epoch: 45\n",
      "idx: 0, loss: 0.4255983829498291 time take: 0.23955321311950684\n",
      "idx: 100, loss: 0.24021700024604797 time take: 6.621504545211792\n",
      "idx: 200, loss: 0.39673298597335815 time take: 6.669970750808716\n",
      "idx: 300, loss: 0.3648182451725006 time take: 6.705946922302246\n",
      "epoch 45 time taken: 26.227461099624634s\n",
      "Training epoch: 46\n",
      "idx: 0, loss: 0.2688111960887909 time take: 0.28014326095581055\n",
      "idx: 100, loss: 0.26218727231025696 time take: 6.621070623397827\n",
      "idx: 200, loss: 1.0372323989868164 time take: 6.640740871429443\n",
      "idx: 300, loss: 1.05326247215271 time take: 6.639051675796509\n",
      "epoch 46 time taken: 26.17729616165161s\n",
      "Training epoch: 47\n",
      "idx: 0, loss: 0.6640519499778748 time take: 0.26264524459838867\n",
      "idx: 100, loss: 0.4449740946292877 time take: 6.618468761444092\n",
      "idx: 200, loss: 0.6678920388221741 time take: 6.619054794311523\n",
      "idx: 300, loss: 0.47516199946403503 time take: 6.626344203948975\n",
      "epoch 47 time taken: 26.140732765197754s\n",
      "Training epoch: 48\n",
      "idx: 0, loss: 0.29375937581062317 time take: 0.2539396286010742\n",
      "idx: 100, loss: 0.3273160755634308 time take: 6.650004625320435\n",
      "idx: 200, loss: 0.4561942219734192 time take: 6.607556104660034\n",
      "idx: 300, loss: 0.32956573367118835 time take: 6.611997365951538\n",
      "epoch 48 time taken: 26.11858868598938s\n",
      "Training epoch: 49\n",
      "idx: 0, loss: 0.2928135097026825 time take: 0.261826753616333\n",
      "idx: 100, loss: 0.2954171895980835 time take: 6.660008668899536\n",
      "idx: 200, loss: 0.3198866844177246 time take: 6.675718545913696\n",
      "idx: 300, loss: 0.3302515745162964 time take: 6.616478443145752\n",
      "epoch 49 time taken: 26.21184253692627s\n",
      "Training epoch: 50\n",
      "idx: 0, loss: 0.28693729639053345 time take: 0.26923155784606934\n",
      "idx: 100, loss: 0.256462961435318 time take: 6.671637058258057\n",
      "idx: 200, loss: 0.3971007466316223 time take: 6.707982063293457\n",
      "idx: 300, loss: 0.2316141128540039 time take: 6.727630853652954\n",
      "epoch 50 time taken: 26.373127222061157s\n",
      "Training epoch: 51\n",
      "idx: 0, loss: 0.29360097646713257 time take: 0.2573857307434082\n",
      "idx: 100, loss: 0.2367170751094818 time take: 6.623809814453125\n",
      "idx: 200, loss: 0.3458486795425415 time take: 6.672062635421753\n",
      "idx: 300, loss: 0.29315346479415894 time take: 6.737456560134888\n",
      "epoch 51 time taken: 26.360562801361084s\n",
      "Training epoch: 52\n",
      "idx: 0, loss: 0.17926503717899323 time take: 0.26741600036621094\n",
      "idx: 100, loss: 0.14997920393943787 time take: 6.6241984367370605\n",
      "idx: 200, loss: 0.4023507237434387 time take: 6.647908687591553\n",
      "idx: 300, loss: 0.32762622833251953 time take: 14.152434825897217\n",
      "epoch 52 time taken: 43.62803602218628s\n",
      "Training epoch: 53\n",
      "idx: 0, loss: 0.3215116858482361 time take: 0.34834814071655273\n",
      "idx: 100, loss: 0.16506528854370117 time take: 17.527028560638428\n",
      "idx: 200, loss: 0.40274009108543396 time take: 17.54925799369812\n",
      "idx: 300, loss: 0.314870148897171 time take: 17.525567770004272\n",
      "epoch 53 time taken: 68.54214668273926s\n",
      "Training epoch: 54\n",
      "idx: 0, loss: 0.20738111436367035 time take: 0.29877662658691406\n",
      "idx: 100, loss: 0.24627216160297394 time take: 17.523497581481934\n",
      "idx: 200, loss: 0.3538157045841217 time take: 17.527230739593506\n",
      "idx: 300, loss: 0.2256830632686615 time take: 17.476582050323486\n",
      "epoch 54 time taken: 68.73735070228577s\n",
      "Training epoch: 55\n",
      "idx: 0, loss: 0.2000608742237091 time take: 0.3272688388824463\n",
      "idx: 100, loss: 0.20706085860729218 time take: 7.168872594833374\n",
      "idx: 200, loss: 0.3573784828186035 time take: 6.6996376514434814\n",
      "idx: 300, loss: 0.2811679244041443 time take: 6.615024566650391\n",
      "epoch 55 time taken: 26.801101207733154s\n",
      "Training epoch: 56\n",
      "idx: 0, loss: 0.19521889090538025 time take: 0.25601744651794434\n",
      "idx: 100, loss: 0.17116917669773102 time take: 6.619922637939453\n",
      "idx: 200, loss: 0.28408557176589966 time take: 6.615400314331055\n",
      "idx: 300, loss: 0.24583493173122406 time take: 6.612441062927246\n",
      "epoch 56 time taken: 26.11188530921936s\n",
      "Training epoch: 57\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "idx: 0, loss: 0.18580280244350433 time take: 0.2576570510864258\n",
      "idx: 100, loss: 0.28699538111686707 time take: 6.617734909057617\n",
      "idx: 200, loss: 0.3588714599609375 time take: 6.610241889953613\n",
      "idx: 300, loss: 0.3063720166683197 time take: 6.660557985305786\n",
      "epoch 57 time taken: 26.143787384033203s\n",
      "Training epoch: 58\n",
      "idx: 0, loss: 0.19715920090675354 time take: 0.25107359886169434\n",
      "idx: 100, loss: 0.21232835948467255 time take: 6.619342565536499\n",
      "idx: 200, loss: 0.3535938262939453 time take: 6.61928129196167\n",
      "idx: 300, loss: 0.28335851430892944 time take: 6.613996267318726\n",
      "epoch 58 time taken: 26.09619450569153s\n",
      "Training epoch: 59\n",
      "idx: 0, loss: 0.25357508659362793 time take: 0.25415706634521484\n",
      "idx: 100, loss: 0.16154161095619202 time take: 6.747373580932617\n",
      "idx: 200, loss: 0.36901170015335083 time take: 6.7278053760528564\n",
      "idx: 300, loss: 0.170962855219841 time take: 6.615602254867554\n",
      "epoch 59 time taken: 26.36773443222046s\n",
      "Training epoch: 60\n",
      "idx: 0, loss: 0.22231513261795044 time take: 0.2625584602355957\n",
      "idx: 100, loss: 0.19031038880348206 time take: 6.6225175857543945\n",
      "idx: 200, loss: 0.23145151138305664 time take: 6.6111485958099365\n",
      "idx: 300, loss: 0.261931449174881 time take: 6.611750602722168\n",
      "epoch 60 time taken: 26.099889755249023s\n",
      "Training epoch: 61\n",
      "idx: 0, loss: 0.13662511110305786 time take: 0.25574612617492676\n",
      "idx: 100, loss: 0.24031899869441986 time take: 6.628233909606934\n",
      "idx: 200, loss: 0.2943589687347412 time take: 6.611932277679443\n",
      "idx: 300, loss: 0.21700231730937958 time take: 6.610393762588501\n",
      "epoch 61 time taken: 26.123538970947266s\n",
      "Training epoch: 62\n",
      "idx: 0, loss: 0.2570933401584625 time take: 0.257129430770874\n",
      "idx: 100, loss: 0.16332945227622986 time take: 6.706826686859131\n",
      "idx: 200, loss: 0.3487362861633301 time take: 6.634958982467651\n",
      "idx: 300, loss: 0.27528291940689087 time take: 6.61846137046814\n",
      "epoch 62 time taken: 26.209977388381958s\n",
      "Training epoch: 63\n",
      "idx: 0, loss: 0.23866258561611176 time take: 0.23647499084472656\n",
      "idx: 100, loss: 0.2195155769586563 time take: 6.679747581481934\n",
      "idx: 200, loss: 0.28237184882164 time take: 6.611871719360352\n",
      "idx: 300, loss: 0.21487048268318176 time take: 6.664887428283691\n",
      "epoch 63 time taken: 26.1890766620636s\n",
      "Training epoch: 64\n",
      "idx: 0, loss: 0.18519553542137146 time take: 0.24261713027954102\n",
      "idx: 100, loss: 0.191863015294075 time take: 6.627302885055542\n",
      "idx: 200, loss: 0.22851882874965668 time take: 6.615858316421509\n",
      "idx: 300, loss: 0.20564663410186768 time take: 6.642311334609985\n",
      "epoch 64 time taken: 26.128687858581543s\n",
      "Training epoch: 65\n",
      "idx: 0, loss: 0.15643109381198883 time take: 0.2750585079193115\n",
      "idx: 100, loss: 0.13463366031646729 time take: 6.625581741333008\n",
      "idx: 200, loss: 0.6712223291397095 time take: 6.610966444015503\n",
      "idx: 300, loss: 0.3169785439968109 time take: 6.609644651412964\n",
      "epoch 65 time taken: 26.11605715751648s\n",
      "Training epoch: 66\n",
      "idx: 0, loss: 0.29398179054260254 time take: 0.2672007083892822\n",
      "idx: 100, loss: 0.2181089073419571 time take: 6.630081415176392\n",
      "idx: 200, loss: 0.2700250744819641 time take: 6.6075663566589355\n",
      "idx: 300, loss: 0.16710616648197174 time take: 6.686273813247681\n",
      "epoch 66 time taken: 26.32972741127014s\n",
      "Training epoch: 67\n",
      "idx: 0, loss: 1.507110834121704 time take: 0.2629082202911377\n",
      "idx: 100, loss: 0.7017972469329834 time take: 6.6872639656066895\n",
      "idx: 200, loss: 0.7290445566177368 time take: 6.6750195026397705\n",
      "idx: 300, loss: 0.4436647593975067 time take: 6.648292779922485\n",
      "epoch 67 time taken: 26.27945613861084s\n",
      "Training epoch: 68\n",
      "idx: 0, loss: 0.36211779713630676 time take: 0.25071001052856445\n",
      "idx: 100, loss: 0.31833401322364807 time take: 6.624877691268921\n",
      "idx: 200, loss: 0.29204699397087097 time take: 6.657284259796143\n",
      "idx: 300, loss: 0.32062527537345886 time take: 6.614765405654907\n",
      "epoch 68 time taken: 26.141265153884888s\n",
      "Training epoch: 69\n",
      "idx: 0, loss: 0.32644087076187134 time take: 0.24842548370361328\n",
      "idx: 100, loss: 0.30396008491516113 time take: 6.688153028488159\n",
      "idx: 200, loss: 0.28652241826057434 time take: 6.616018295288086\n",
      "idx: 300, loss: 0.2767786681652069 time take: 6.6127729415893555\n",
      "epoch 69 time taken: 26.157516956329346s\n",
      "Training epoch: 70\n",
      "idx: 0, loss: 0.2262272834777832 time take: 0.24966096878051758\n",
      "idx: 100, loss: 0.1506935954093933 time take: 6.720314979553223\n",
      "idx: 200, loss: 0.3071294128894806 time take: 6.618180751800537\n",
      "idx: 300, loss: 0.25838273763656616 time take: 6.619976282119751\n",
      "epoch 70 time taken: 26.20356011390686s\n",
      "Training epoch: 71\n",
      "idx: 0, loss: 0.15554936230182648 time take: 0.2590348720550537\n",
      "idx: 100, loss: 0.16031649708747864 time take: 6.6289472579956055\n",
      "idx: 200, loss: 0.23671169579029083 time take: 6.639573097229004\n",
      "idx: 300, loss: 0.24934886395931244 time take: 6.609582901000977\n",
      "epoch 71 time taken: 26.13028836250305s\n",
      "Training epoch: 72\n",
      "idx: 0, loss: 0.1270749270915985 time take: 0.2567417621612549\n",
      "idx: 100, loss: 0.130496084690094 time take: 6.641103029251099\n",
      "idx: 200, loss: 0.27622950077056885 time take: 6.6087846755981445\n",
      "idx: 300, loss: 0.1206182911992073 time take: 6.608128547668457\n",
      "epoch 72 time taken: 26.108170986175537s\n",
      "Training epoch: 73\n",
      "idx: 0, loss: 0.2116921991109848 time take: 0.2670013904571533\n",
      "idx: 100, loss: 0.15373943746089935 time take: 6.620038747787476\n",
      "idx: 200, loss: 0.24955613911151886 time take: 6.706679821014404\n",
      "idx: 300, loss: 0.24223199486732483 time take: 6.763200521469116\n",
      "epoch 73 time taken: 26.35456919670105s\n",
      "Training epoch: 74\n",
      "idx: 0, loss: 0.17012929916381836 time take: 0.25749897956848145\n",
      "idx: 100, loss: 0.18181245028972626 time take: 6.631195783615112\n",
      "idx: 200, loss: 0.20703451335430145 time take: 6.609373569488525\n",
      "idx: 300, loss: 0.20263217389583588 time take: 6.63801646232605\n",
      "epoch 74 time taken: 26.13243269920349s\n",
      "Training epoch: 75\n",
      "idx: 0, loss: 0.2531682550907135 time take: 0.26336050033569336\n",
      "idx: 100, loss: 0.13074654340744019 time take: 6.697599411010742\n",
      "idx: 200, loss: 0.2522774040699005 time take: 6.697751045227051\n",
      "idx: 300, loss: 0.2486511915922165 time take: 6.61953067779541\n",
      "epoch 75 time taken: 26.27072787284851s\n",
      "Training epoch: 76\n",
      "idx: 0, loss: 0.15400142967700958 time take: 0.44000244140625\n",
      "idx: 100, loss: 0.0866314098238945 time take: 6.657323360443115\n",
      "idx: 200, loss: 0.2296595424413681 time take: 6.639034271240234\n",
      "idx: 300, loss: 0.13243810832500458 time take: 6.651779651641846\n",
      "epoch 76 time taken: 26.4182071685791s\n",
      "Training epoch: 77\n",
      "idx: 0, loss: 0.16572703421115875 time take: 0.23771429061889648\n",
      "idx: 100, loss: 0.1491883099079132 time take: 6.6302878856658936\n",
      "idx: 200, loss: 0.2626037895679474 time take: 6.611677885055542\n",
      "idx: 300, loss: 0.21981702744960785 time take: 6.629506587982178\n",
      "epoch 77 time taken: 26.10117769241333s\n",
      "Training epoch: 78\n",
      "idx: 0, loss: 0.19479426741600037 time take: 0.2592346668243408\n",
      "idx: 100, loss: 0.1918206661939621 time take: 6.63287353515625\n",
      "idx: 200, loss: 0.1971704661846161 time take: 6.64197301864624\n",
      "idx: 300, loss: 0.24517974257469177 time take: 6.611423492431641\n",
      "epoch 78 time taken: 26.13486886024475s\n",
      "Training epoch: 79\n",
      "idx: 0, loss: 0.19515712559223175 time take: 0.2517573833465576\n",
      "idx: 100, loss: 0.1640247404575348 time take: 6.621139049530029\n",
      "idx: 200, loss: 0.21120190620422363 time take: 6.608715295791626\n",
      "idx: 300, loss: 0.18992945551872253 time take: 6.618062496185303\n",
      "epoch 79 time taken: 26.09050703048706s\n",
      "Training epoch: 80\n",
      "idx: 0, loss: 0.14332929253578186 time take: 0.24528002738952637\n",
      "idx: 100, loss: 0.11746574193239212 time take: 6.620067834854126\n",
      "idx: 200, loss: 0.20021910965442657 time take: 6.611830949783325\n",
      "idx: 300, loss: 0.16614274680614471 time take: 6.644617557525635\n",
      "epoch 80 time taken: 26.110380172729492s\n",
      "Training epoch: 81\n",
      "idx: 0, loss: 0.09944973140954971 time take: 0.2500433921813965\n",
      "idx: 100, loss: 0.06204589456319809 time take: 6.61716890335083\n",
      "idx: 200, loss: 0.19817936420440674 time take: 6.6155455112457275\n",
      "idx: 300, loss: 0.13648445904254913 time take: 6.611479759216309\n",
      "epoch 81 time taken: 26.08956813812256s\n",
      "Training epoch: 82\n",
      "idx: 0, loss: 0.2047221064567566 time take: 0.24709630012512207\n",
      "idx: 100, loss: 0.13162840902805328 time take: 6.6194071769714355\n",
      "idx: 200, loss: 0.29524198174476624 time take: 6.610655307769775\n",
      "idx: 300, loss: 0.266736775636673 time take: 6.612047433853149\n",
      "epoch 82 time taken: 26.109572887420654s\n",
      "Training epoch: 83\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "idx: 0, loss: 0.17460007965564728 time take: 0.25932788848876953\n",
      "idx: 100, loss: 0.13622137904167175 time take: 6.632730960845947\n",
      "idx: 200, loss: 0.18141227960586548 time take: 6.61474871635437\n",
      "idx: 300, loss: 0.38020291924476624 time take: 6.610538005828857\n",
      "epoch 83 time taken: 26.12343430519104s\n",
      "Training epoch: 84\n",
      "idx: 0, loss: 0.22359351813793182 time take: 0.2522265911102295\n",
      "idx: 100, loss: 0.10664388537406921 time take: 6.626541376113892\n",
      "idx: 200, loss: 0.23136796057224274 time take: 6.726781606674194\n",
      "idx: 300, loss: 0.20070664584636688 time take: 6.621631622314453\n",
      "epoch 84 time taken: 26.217286586761475s\n",
      "Training epoch: 85\n",
      "idx: 0, loss: 0.08223766833543777 time take: 0.2227795124053955\n",
      "idx: 100, loss: 0.09068890661001205 time take: 6.72458291053772\n",
      "idx: 200, loss: 0.17354312539100647 time take: 6.652517318725586\n",
      "idx: 300, loss: 0.20919522643089294 time take: 6.623441934585571\n",
      "epoch 85 time taken: 26.27639412879944s\n",
      "Training epoch: 86\n",
      "idx: 0, loss: 0.23266887664794922 time take: 0.2532341480255127\n",
      "idx: 100, loss: 0.10581979155540466 time take: 6.619379281997681\n",
      "idx: 200, loss: 0.21725478768348694 time take: 6.614207983016968\n",
      "idx: 300, loss: 0.1757965385913849 time take: 6.67592191696167\n",
      "epoch 86 time taken: 26.252386569976807s\n",
      "Training epoch: 87\n",
      "idx: 0, loss: 0.12278569489717484 time take: 0.2413938045501709\n",
      "idx: 100, loss: 0.10609926283359528 time take: 6.621859312057495\n",
      "idx: 200, loss: 0.18399660289287567 time take: 6.65203857421875\n",
      "idx: 300, loss: 0.1741892546415329 time take: 6.627152442932129\n",
      "epoch 87 time taken: 26.132957220077515s\n",
      "Training epoch: 88\n",
      "idx: 0, loss: 0.14651383459568024 time take: 0.23236727714538574\n",
      "idx: 100, loss: 0.1169351115822792 time take: 6.687408685684204\n",
      "idx: 200, loss: 0.13942773640155792 time take: 6.623552560806274\n",
      "idx: 300, loss: 0.170399010181427 time take: 6.610662937164307\n",
      "epoch 88 time taken: 26.149348974227905s\n",
      "Training epoch: 89\n",
      "idx: 0, loss: 0.13961444795131683 time take: 0.24858975410461426\n",
      "idx: 100, loss: 0.06898178160190582 time take: 6.629740238189697\n",
      "idx: 200, loss: 0.1887272149324417 time take: 6.609286785125732\n",
      "idx: 300, loss: 0.0817916989326477 time take: 6.612852573394775\n",
      "epoch 89 time taken: 26.182472229003906s\n",
      "Training epoch: 90\n",
      "idx: 0, loss: 0.04349503293633461 time take: 0.26471734046936035\n",
      "idx: 100, loss: 0.12781205773353577 time take: 6.680064916610718\n",
      "idx: 200, loss: 0.17549072206020355 time take: 6.673991680145264\n",
      "idx: 300, loss: 0.21397344768047333 time take: 6.689834833145142\n",
      "epoch 90 time taken: 26.299994230270386s\n",
      "Training epoch: 91\n",
      "idx: 0, loss: 0.20128470659255981 time take: 0.2396540641784668\n",
      "idx: 100, loss: 0.21519218385219574 time take: 6.6400017738342285\n",
      "idx: 200, loss: 0.2044636607170105 time take: 6.611278772354126\n",
      "idx: 300, loss: 0.137803852558136 time take: 6.6118974685668945\n",
      "epoch 91 time taken: 26.09487295150757s\n",
      "Training epoch: 92\n",
      "idx: 0, loss: 0.08279184252023697 time take: 0.237823486328125\n",
      "idx: 100, loss: 0.15302520990371704 time take: 6.663848400115967\n",
      "idx: 200, loss: 0.1754172295331955 time take: 6.624801158905029\n",
      "idx: 300, loss: 0.16351662576198578 time take: 6.607797384262085\n",
      "epoch 92 time taken: 26.12462878227234s\n",
      "Training epoch: 93\n",
      "idx: 0, loss: 0.1732531040906906 time take: 0.2690927982330322\n",
      "idx: 100, loss: 0.09056001901626587 time take: 6.633643388748169\n",
      "idx: 200, loss: 0.18728335201740265 time take: 6.607459783554077\n",
      "idx: 300, loss: 0.16201788187026978 time take: 6.668169736862183\n",
      "epoch 93 time taken: 26.170068502426147s\n",
      "Training epoch: 94\n",
      "idx: 0, loss: 0.1207488402724266 time take: 0.2690439224243164\n",
      "idx: 100, loss: 0.15314383804798126 time take: 6.634437561035156\n",
      "idx: 200, loss: 0.1441633403301239 time take: 6.643316030502319\n",
      "idx: 300, loss: 0.17400702834129333 time take: 6.607161283493042\n",
      "epoch 94 time taken: 26.15932059288025s\n",
      "Training epoch: 95\n",
      "idx: 0, loss: 0.19365981221199036 time take: 0.25929880142211914\n",
      "idx: 100, loss: 0.10309228301048279 time take: 6.630201816558838\n",
      "idx: 200, loss: 0.197240948677063 time take: 6.606446981430054\n",
      "idx: 300, loss: 0.06759358197450638 time take: 6.6080687046051025\n",
      "epoch 95 time taken: 26.094766855239868s\n",
      "Training epoch: 96\n",
      "idx: 0, loss: 0.09649601578712463 time take: 0.26926493644714355\n",
      "idx: 100, loss: 0.1174526959657669 time take: 6.623340368270874\n",
      "idx: 200, loss: 0.16705182194709778 time take: 6.608080148696899\n",
      "idx: 300, loss: 0.10481617599725723 time take: 6.636598348617554\n",
      "epoch 96 time taken: 26.139830112457275s\n",
      "Training epoch: 97\n",
      "idx: 0, loss: 0.0889982208609581 time take: 0.2567017078399658\n",
      "idx: 100, loss: 0.06333985924720764 time take: 6.6206841468811035\n",
      "idx: 200, loss: 0.1779634803533554 time take: 6.60631251335144\n",
      "idx: 300, loss: 0.09992562234401703 time take: 6.626992225646973\n",
      "epoch 97 time taken: 26.102379083633423s\n",
      "Training epoch: 98\n",
      "idx: 0, loss: 0.10301081836223602 time take: 0.2380068302154541\n",
      "idx: 100, loss: 0.07363186031579971 time take: 6.6236419677734375\n",
      "idx: 200, loss: 0.17202377319335938 time take: 6.620663642883301\n",
      "idx: 300, loss: 0.17418172955513 time take: 6.608515977859497\n",
      "epoch 98 time taken: 26.142364740371704s\n",
      "Training epoch: 99\n",
      "idx: 0, loss: 0.07064005732536316 time take: 0.244232177734375\n",
      "idx: 100, loss: 0.11718017607927322 time take: 6.627807855606079\n",
      "idx: 200, loss: 0.21243280172348022 time take: 6.607098579406738\n",
      "idx: 300, loss: 0.13366499543190002 time take: 6.60758638381958\n",
      "epoch 99 time taken: 26.074753522872925s\n",
      "Performing inference on batch: 0\n",
      "Performing inference on batch: 50\n",
      "Performing inference on batch: 0\n",
      "Performing inference on batch: 50\n",
      "FPR@95: 74.17, AUROC: 81.73 AUPR_IN: 83.12, AUPR_OUT: 78.55\n",
      "CCR: 2.71, 4.16, 18.66, 54.58, ACC: 84.94\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{0: {'dataset': 'cifar',\n",
       "  'FPR@95': '74.84',\n",
       "  'AUROC': '82.09',\n",
       "  'AUPR_IN': '83.53',\n",
       "  'AUPR_OUT': '78.47',\n",
       "  'CCR_4': '0.15',\n",
       "  'CCR_3': '3.41',\n",
       "  'CCR_2': '20.23',\n",
       "  'CCR_1': '55.44',\n",
       "  'ACC': '85.13',\n",
       "  'optimizer_type': 'Adam',\n",
       "  'activation_function_type': 'relu',\n",
       "  'postprocessor_type': 'odin'},\n",
       " 1: {'dataset': 'cifar',\n",
       "  'FPR@95': '79.59',\n",
       "  'AUROC': '77.06',\n",
       "  'AUPR_IN': '76.79',\n",
       "  'AUPR_OUT': '73.75',\n",
       "  'CCR_4': '0.01',\n",
       "  'CCR_3': '0.02',\n",
       "  'CCR_2': '9.41',\n",
       "  'CCR_1': '41.89',\n",
       "  'ACC': '75.03',\n",
       "  'optimizer_type': 'Adam',\n",
       "  'activation_function_type': 'relu',\n",
       "  'postprocessor_type': 'odin'},\n",
       " 2: {'dataset': 'cifar',\n",
       "  'FPR@95': '74.17',\n",
       "  'AUROC': '81.73',\n",
       "  'AUPR_IN': '83.12',\n",
       "  'AUPR_OUT': '78.55',\n",
       "  'CCR_4': '2.71',\n",
       "  'CCR_3': '4.16',\n",
       "  'CCR_2': '18.66',\n",
       "  'CCR_1': '54.58',\n",
       "  'ACC': '84.94',\n",
       "  'optimizer_type': 'Adam',\n",
       "  'activation_function_type': 'relu',\n",
       "  'postprocessor_type': 'odin'}}"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "config_cifar_adam_relu_odin = {\n",
    "    \"batch_size\": 128,\n",
    "    \"n_classes\": 10,\n",
    "    \"dataset_name\": \"cifar\",\n",
    "    \"epochs\": 100,\n",
    "    \"version\": time.time(),\n",
    "    \"lr\": 0.01,\n",
    "    \"momentum\": 0.9,\n",
    "    \"weight_decay\": 0.0005,\n",
    "    \"optimizer_type\": \"Adam\",\n",
    "    \"activation_function_type\": \"relu\",\n",
    "    \"network\": \"resnet50\",\n",
    "    \"postprocessor_type\": \"odin\",\n",
    "    \"trials\": 3,\n",
    "    \"dataset_type\": \"cifar\",\n",
    "    \"results_dir\": \"cifar10-study\",\n",
    "    \"pretrained\": False\n",
    "} \n",
    "config_cifar_adam_relu_odin[\"data_loaders\"] = get_data_loaders(config_cifar_adam_relu_odin)\n",
    "run_full_oodn_pipeline(config_cifar_adam_relu_odin)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Study 2 (b.) Adam + Softplus + odin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "Running model: models/cifar_resnet50_odin_softplus_Adam_0.pkl...\n",
      "Getting optimizer for type: Adam...\n",
      "Training epoch: 0\n",
      "idx: 0, loss: 2.5337820053100586 time take: 0.2714509963989258\n",
      "idx: 100, loss: 3.479654312133789 time take: 6.675965785980225\n",
      "idx: 200, loss: 3.0372395515441895 time take: 6.696977138519287\n",
      "idx: 300, loss: 2.558212995529175 time take: 6.654980897903442\n",
      "epoch 0 time taken: 26.292356967926025s\n",
      "Training epoch: 1\n",
      "idx: 0, loss: 3.0308470726013184 time take: 0.24722886085510254\n",
      "idx: 100, loss: 2.7717363834381104 time take: 6.645073890686035\n",
      "idx: 200, loss: 2.4414756298065186 time take: 6.613676309585571\n",
      "idx: 300, loss: 2.1312203407287598 time take: 6.613912582397461\n",
      "epoch 1 time taken: 26.11988925933838s\n",
      "Training epoch: 2\n",
      "idx: 0, loss: 1.9130369424819946 time take: 0.23324036598205566\n",
      "idx: 100, loss: 2.139862298965454 time take: 6.635451078414917\n",
      "idx: 200, loss: 2.030539035797119 time take: 6.609519958496094\n",
      "idx: 300, loss: 1.7827948331832886 time take: 6.6143083572387695\n",
      "epoch 2 time taken: 26.113044261932373s\n",
      "Training epoch: 3\n",
      "idx: 0, loss: 2.000739574432373 time take: 0.26389193534851074\n",
      "idx: 100, loss: 1.7056196928024292 time take: 6.631065607070923\n",
      "idx: 200, loss: 1.7448055744171143 time take: 6.630488157272339\n",
      "idx: 300, loss: 1.7266533374786377 time take: 6.619263172149658\n",
      "epoch 3 time taken: 26.136690855026245s\n",
      "Training epoch: 4\n",
      "idx: 0, loss: 1.865349531173706 time take: 0.24789166450500488\n",
      "idx: 100, loss: 1.6135153770446777 time take: 6.619693994522095\n",
      "idx: 200, loss: 1.5041649341583252 time take: 6.616060495376587\n",
      "idx: 300, loss: 1.6515392065048218 time take: 6.616199493408203\n",
      "epoch 4 time taken: 26.094090700149536s\n",
      "Training epoch: 5\n",
      "idx: 0, loss: 1.6178436279296875 time take: 0.2385706901550293\n",
      "idx: 100, loss: 1.5023491382598877 time take: 6.739067077636719\n",
      "idx: 200, loss: 1.4529216289520264 time take: 6.61670994758606\n",
      "idx: 300, loss: 1.4404101371765137 time take: 6.613610029220581\n",
      "epoch 5 time taken: 26.203932523727417s\n",
      "Training epoch: 6\n",
      "idx: 0, loss: 1.3738272190093994 time take: 0.26149964332580566\n",
      "idx: 100, loss: 1.3587639331817627 time take: 6.616822957992554\n",
      "idx: 200, loss: 1.3444876670837402 time take: 6.611037969589233\n",
      "idx: 300, loss: 1.40208101272583 time take: 6.614886522293091\n",
      "epoch 6 time taken: 26.099860668182373s\n",
      "Training epoch: 7\n",
      "idx: 0, loss: 1.4197969436645508 time take: 0.24959444999694824\n",
      "idx: 100, loss: 1.257630467414856 time take: 6.623183965682983\n",
      "idx: 200, loss: 1.4316259622573853 time take: 6.637074947357178\n",
      "idx: 300, loss: 1.2388274669647217 time take: 6.610892057418823\n",
      "epoch 7 time taken: 26.11568307876587s\n",
      "Training epoch: 8\n",
      "idx: 0, loss: 1.2658820152282715 time take: 0.24915099143981934\n",
      "idx: 100, loss: 1.0970940589904785 time take: 6.721757173538208\n",
      "idx: 200, loss: 1.2904810905456543 time take: 6.629875421524048\n",
      "idx: 300, loss: 1.0839519500732422 time take: 6.614002227783203\n",
      "epoch 8 time taken: 26.222565174102783s\n",
      "Training epoch: 9\n",
      "idx: 0, loss: 1.3278424739837646 time take: 0.25728392601013184\n",
      "idx: 100, loss: 0.992273211479187 time take: 6.630449533462524\n",
      "idx: 200, loss: 1.170706033706665 time take: 6.611372709274292\n",
      "idx: 300, loss: 0.971146821975708 time take: 6.685468435287476\n",
      "epoch 9 time taken: 26.213053464889526s\n",
      "Training epoch: 10\n",
      "idx: 0, loss: 1.1150543689727783 time take: 0.24602007865905762\n",
      "idx: 100, loss: 0.9572055339813232 time take: 6.669904947280884\n",
      "idx: 200, loss: 1.104205846786499 time take: 6.614551544189453\n",
      "idx: 300, loss: 0.9558696746826172 time take: 6.6213836669921875\n",
      "epoch 10 time taken: 26.15571928024292s\n",
      "Training epoch: 11\n",
      "idx: 0, loss: 1.0341486930847168 time take: 0.2676048278808594\n",
      "idx: 100, loss: 0.8750191926956177 time take: 6.626330137252808\n",
      "idx: 200, loss: 1.0625011920928955 time take: 6.610962629318237\n",
      "idx: 300, loss: 0.8959131240844727 time take: 6.6138153076171875\n",
      "epoch 11 time taken: 26.12874698638916s\n",
      "Training epoch: 12\n",
      "idx: 0, loss: 0.9223577976226807 time take: 0.35022401809692383\n",
      "idx: 100, loss: 0.9007600545883179 time take: 6.621829271316528\n",
      "idx: 200, loss: 0.9982092380523682 time take: 6.613717555999756\n",
      "idx: 300, loss: 0.8608249425888062 time take: 6.617115020751953\n",
      "epoch 12 time taken: 26.199324369430542s\n",
      "Training epoch: 13\n",
      "idx: 0, loss: 0.9199763536453247 time take: 0.27689027786254883\n",
      "idx: 100, loss: 0.8462101221084595 time take: 6.690558433532715\n",
      "idx: 200, loss: 0.8389083743095398 time take: 6.65355658531189\n",
      "idx: 300, loss: 0.8104344010353088 time take: 6.70699143409729\n",
      "epoch 13 time taken: 26.427042722702026s\n",
      "Training epoch: 14\n",
      "idx: 0, loss: 0.8494608402252197 time take: 0.2508580684661865\n",
      "idx: 100, loss: 0.8720282316207886 time take: 6.633373975753784\n",
      "idx: 200, loss: 0.9489806294441223 time take: 6.622230768203735\n",
      "idx: 300, loss: 0.7500665783882141 time take: 6.613571643829346\n",
      "epoch 14 time taken: 26.116705417633057s\n",
      "Training epoch: 15\n",
      "idx: 0, loss: 0.7592484951019287 time take: 0.2602071762084961\n",
      "idx: 100, loss: 0.8483332395553589 time take: 6.626134634017944\n",
      "idx: 200, loss: 0.8535336852073669 time take: 6.619571924209595\n",
      "idx: 300, loss: 0.8571348786354065 time take: 6.614169597625732\n",
      "epoch 15 time taken: 26.114551067352295s\n",
      "Training epoch: 16\n",
      "idx: 0, loss: 0.7993550300598145 time take: 0.2536311149597168\n",
      "idx: 100, loss: 0.7250540852546692 time take: 6.645718812942505\n",
      "idx: 200, loss: 0.8741710186004639 time take: 6.613500118255615\n",
      "idx: 300, loss: 0.7727760076522827 time take: 6.6987223625183105\n",
      "epoch 16 time taken: 26.229690551757812s\n",
      "Training epoch: 17\n",
      "idx: 0, loss: 0.775537371635437 time take: 0.2707986831665039\n",
      "idx: 100, loss: 0.7530534863471985 time take: 6.616795063018799\n",
      "idx: 200, loss: 0.8367842435836792 time take: 6.615792512893677\n",
      "idx: 300, loss: 0.7550581693649292 time take: 6.610321283340454\n",
      "epoch 17 time taken: 26.15179204940796s\n",
      "Training epoch: 18\n",
      "idx: 0, loss: 0.5970481634140015 time take: 0.23825836181640625\n",
      "idx: 100, loss: 0.7698363065719604 time take: 6.6198015213012695\n",
      "idx: 200, loss: 0.7675671577453613 time take: 6.610925912857056\n",
      "idx: 300, loss: 0.6509543061256409 time take: 6.6087610721588135\n",
      "epoch 18 time taken: 26.13937497138977s\n",
      "Training epoch: 19\n",
      "idx: 0, loss: 0.5147296190261841 time take: 0.23521971702575684\n",
      "idx: 100, loss: 0.7745805978775024 time take: 6.6326658725738525\n",
      "idx: 200, loss: 0.7136280536651611 time take: 6.619650602340698\n",
      "idx: 300, loss: 0.6440694332122803 time take: 6.611291408538818\n",
      "epoch 19 time taken: 26.096399307250977s\n",
      "Training epoch: 20\n",
      "idx: 0, loss: 0.6568130254745483 time take: 0.24797868728637695\n",
      "idx: 100, loss: 0.6440338492393494 time take: 6.6204564571380615\n",
      "idx: 200, loss: 0.7230556011199951 time take: 6.610400676727295\n",
      "idx: 300, loss: 0.692438006401062 time take: 6.613030195236206\n",
      "epoch 20 time taken: 26.087251901626587s\n",
      "Training epoch: 21\n",
      "idx: 0, loss: 0.6437469720840454 time take: 0.2617924213409424\n",
      "idx: 100, loss: 0.6478568315505981 time take: 6.743315935134888\n",
      "idx: 200, loss: 0.6738187074661255 time take: 6.613363742828369\n",
      "idx: 300, loss: 0.6214375495910645 time take: 6.610653400421143\n",
      "epoch 21 time taken: 26.221435546875s\n",
      "Training epoch: 22\n",
      "idx: 0, loss: 0.5195341110229492 time take: 0.26102304458618164\n",
      "idx: 100, loss: 0.5007795095443726 time take: 6.624781608581543\n",
      "idx: 200, loss: 0.6947864890098572 time take: 6.613529682159424\n",
      "idx: 300, loss: 0.6834748983383179 time take: 6.613321781158447\n",
      "epoch 22 time taken: 26.103970527648926s\n",
      "Training epoch: 23\n",
      "idx: 0, loss: 0.5910612940788269 time take: 0.23528194427490234\n",
      "idx: 100, loss: 0.5790607929229736 time take: 6.6714558601379395\n",
      "idx: 200, loss: 0.7212347388267517 time take: 6.661388158798218\n",
      "idx: 300, loss: 0.5378901958465576 time take: 6.707054138183594\n",
      "epoch 23 time taken: 26.270623683929443s\n",
      "Training epoch: 24\n",
      "idx: 0, loss: 0.5232217907905579 time take: 0.23836016654968262\n",
      "idx: 100, loss: 0.5991681814193726 time take: 6.6192076206207275\n",
      "idx: 200, loss: 0.5977595448493958 time take: 6.61214017868042\n",
      "idx: 300, loss: 0.48883765935897827 time take: 6.611943244934082\n",
      "epoch 24 time taken: 26.0736083984375s\n",
      "Training epoch: 25\n",
      "idx: 0, loss: 0.5576886534690857 time take: 0.26270103454589844\n",
      "idx: 100, loss: 0.4971746802330017 time take: 6.648159503936768\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "idx: 200, loss: 0.6064569354057312 time take: 6.618139028549194\n",
      "idx: 300, loss: 0.495060533285141 time take: 6.640892028808594\n",
      "epoch 25 time taken: 26.242170333862305s\n",
      "Training epoch: 26\n",
      "idx: 0, loss: 0.441956490278244 time take: 0.25998806953430176\n",
      "idx: 100, loss: 0.511660635471344 time take: 6.6779091358184814\n",
      "idx: 200, loss: 0.6620965003967285 time take: 6.609328985214233\n",
      "idx: 300, loss: 0.48995476961135864 time take: 6.6252381801605225\n",
      "epoch 26 time taken: 26.173784255981445s\n",
      "Training epoch: 27\n",
      "idx: 0, loss: 0.4562523066997528 time take: 0.244065523147583\n",
      "idx: 100, loss: 0.3325934112071991 time take: 6.6302971839904785\n",
      "idx: 200, loss: 0.6206389665603638 time take: 6.615665674209595\n",
      "idx: 300, loss: 0.5455806255340576 time take: 6.609037637710571\n",
      "epoch 27 time taken: 26.11711287498474s\n",
      "Training epoch: 28\n",
      "idx: 0, loss: 0.5060380101203918 time take: 0.30780720710754395\n",
      "idx: 100, loss: 0.44938430190086365 time take: 16.358985662460327\n",
      "idx: 200, loss: 0.5723460912704468 time take: 13.47132658958435\n",
      "idx: 300, loss: 0.5359789729118347 time take: 6.616900444030762\n",
      "epoch 28 time taken: 42.751105546951294s\n",
      "Training epoch: 29\n",
      "idx: 0, loss: 0.4456864297389984 time take: 0.23231816291809082\n",
      "idx: 100, loss: 0.40063002705574036 time take: 6.626840114593506\n",
      "idx: 200, loss: 0.6054561138153076 time take: 11.798635244369507\n",
      "idx: 300, loss: 0.4372752010822296 time take: 16.296184539794922\n",
      "epoch 29 time taken: 49.75829219818115s\n",
      "Training epoch: 30\n",
      "idx: 0, loss: 0.4483258128166199 time take: 0.34815192222595215\n",
      "idx: 100, loss: 0.3961108326911926 time take: 17.43423867225647\n",
      "idx: 200, loss: 0.5699611902236938 time take: 17.487462282180786\n",
      "idx: 300, loss: 0.4241351783275604 time take: 17.413776397705078\n",
      "epoch 30 time taken: 68.5090799331665s\n",
      "Training epoch: 31\n",
      "idx: 0, loss: 0.3550596833229065 time take: 0.3145296573638916\n",
      "idx: 100, loss: 0.38195112347602844 time take: 17.103251457214355\n",
      "idx: 200, loss: 0.4828624427318573 time take: 17.423193216323853\n",
      "idx: 300, loss: 0.43713170289993286 time take: 17.454599618911743\n",
      "epoch 31 time taken: 68.12186312675476s\n",
      "Training epoch: 32\n",
      "idx: 0, loss: 0.5116133093833923 time take: 0.3122696876525879\n",
      "idx: 100, loss: 0.3621714413166046 time take: 17.443936347961426\n",
      "idx: 200, loss: 0.5055630803108215 time take: 7.3240602016448975\n",
      "idx: 300, loss: 0.4686279296875 time take: 6.628752708435059\n",
      "epoch 32 time taken: 37.704506158828735s\n",
      "Training epoch: 33\n",
      "idx: 0, loss: 0.3447061777114868 time take: 0.2561933994293213\n",
      "idx: 100, loss: 0.5201072096824646 time take: 6.648970365524292\n",
      "idx: 200, loss: 0.5204027891159058 time take: 6.616997957229614\n",
      "idx: 300, loss: 0.448394238948822 time take: 6.614622592926025\n",
      "epoch 33 time taken: 26.1381995677948s\n",
      "Training epoch: 34\n",
      "idx: 0, loss: 0.4152921438217163 time take: 0.26959776878356934\n",
      "idx: 100, loss: 0.27645909786224365 time take: 6.6268181800842285\n",
      "idx: 200, loss: 0.5387685894966125 time take: 6.651915550231934\n",
      "idx: 300, loss: 0.41343554854393005 time take: 6.643365144729614\n",
      "epoch 34 time taken: 26.213053941726685s\n",
      "Training epoch: 35\n",
      "idx: 0, loss: 0.2983792722225189 time take: 0.2632622718811035\n",
      "idx: 100, loss: 0.3410288095474243 time take: 6.62342643737793\n",
      "idx: 200, loss: 0.3814883232116699 time take: 6.639675617218018\n",
      "idx: 300, loss: 0.3804129958152771 time take: 6.695878982543945\n",
      "epoch 35 time taken: 26.22203540802002s\n",
      "Training epoch: 36\n",
      "idx: 0, loss: 0.3754795491695404 time take: 0.25545454025268555\n",
      "idx: 100, loss: 0.23451471328735352 time take: 6.629816770553589\n",
      "idx: 200, loss: 0.40782660245895386 time take: 6.617567300796509\n",
      "idx: 300, loss: 0.3368891775608063 time take: 6.6582465171813965\n",
      "epoch 36 time taken: 26.1580228805542s\n",
      "Training epoch: 37\n",
      "idx: 0, loss: 0.30807551741600037 time take: 0.26488828659057617\n",
      "idx: 100, loss: 0.2955222725868225 time take: 6.629963636398315\n",
      "idx: 200, loss: 0.4856386184692383 time take: 6.625030517578125\n",
      "idx: 300, loss: 0.44435086846351624 time take: 6.701070785522461\n",
      "epoch 37 time taken: 26.30654788017273s\n",
      "Training epoch: 38\n",
      "idx: 0, loss: 0.29218608140945435 time take: 0.25420117378234863\n",
      "idx: 100, loss: 0.3220592141151428 time take: 6.6367340087890625\n",
      "idx: 200, loss: 0.4930388927459717 time take: 6.625265598297119\n",
      "idx: 300, loss: 0.4295986592769623 time take: 6.725250482559204\n",
      "epoch 38 time taken: 26.372204303741455s\n",
      "Training epoch: 39\n",
      "idx: 0, loss: 0.2765284478664398 time take: 0.25817108154296875\n",
      "idx: 100, loss: 0.3054710328578949 time take: 6.686743497848511\n",
      "idx: 200, loss: 0.4784299433231354 time take: 6.622495174407959\n",
      "idx: 300, loss: 0.46211734414100647 time take: 6.625314235687256\n",
      "epoch 39 time taken: 26.191117763519287s\n",
      "Training epoch: 40\n",
      "idx: 0, loss: 0.2750159204006195 time take: 0.23546934127807617\n",
      "idx: 100, loss: 0.2223212867975235 time take: 6.638723850250244\n",
      "idx: 200, loss: 0.521937906742096 time take: 6.618609428405762\n",
      "idx: 300, loss: 0.38459089398384094 time take: 6.613751411437988\n",
      "epoch 40 time taken: 26.144050359725952s\n",
      "Training epoch: 41\n",
      "idx: 0, loss: 0.2560616433620453 time take: 0.26183176040649414\n",
      "idx: 100, loss: 0.2589832842350006 time take: 6.7470927238464355\n",
      "idx: 200, loss: 0.45780840516090393 time take: 6.623299837112427\n",
      "idx: 300, loss: 0.2976865768432617 time take: 6.619166135787964\n",
      "epoch 41 time taken: 26.25132179260254s\n",
      "Training epoch: 42\n",
      "idx: 0, loss: 0.2808627486228943 time take: 0.24786734580993652\n",
      "idx: 100, loss: 0.3548651933670044 time take: 6.627880334854126\n",
      "idx: 200, loss: 0.42353102564811707 time take: 6.615902900695801\n",
      "idx: 300, loss: 0.448368638753891 time take: 6.61384391784668\n",
      "epoch 42 time taken: 26.099265098571777s\n",
      "Training epoch: 43\n",
      "idx: 0, loss: 0.2454940378665924 time take: 0.2390432357788086\n",
      "idx: 100, loss: 0.2554030120372772 time take: 6.637482643127441\n",
      "idx: 200, loss: 0.4129476249217987 time take: 6.6936235427856445\n",
      "idx: 300, loss: 0.4142565429210663 time take: 6.625783205032349\n",
      "epoch 43 time taken: 26.189773321151733s\n",
      "Training epoch: 44\n",
      "idx: 0, loss: 0.18520930409431458 time take: 0.23229527473449707\n",
      "idx: 100, loss: 0.17697153985500336 time take: 6.62475323677063\n",
      "idx: 200, loss: 0.49054253101348877 time take: 6.613985061645508\n",
      "idx: 300, loss: 0.34677788615226746 time take: 6.613646030426025\n",
      "epoch 44 time taken: 26.08303928375244s\n",
      "Training epoch: 45\n",
      "idx: 0, loss: 0.300976037979126 time take: 0.2565042972564697\n",
      "idx: 100, loss: 0.24798983335494995 time take: 6.63606333732605\n",
      "idx: 200, loss: 0.3668137788772583 time take: 6.61874532699585\n",
      "idx: 300, loss: 0.26041799783706665 time take: 6.658437252044678\n",
      "epoch 45 time taken: 26.22991180419922s\n",
      "Training epoch: 46\n",
      "idx: 0, loss: 0.2469600886106491 time take: 0.22748136520385742\n",
      "idx: 100, loss: 0.28175467252731323 time take: 6.625455617904663\n",
      "idx: 200, loss: 0.3872174918651581 time take: 6.618747711181641\n",
      "idx: 300, loss: 0.3553907573223114 time take: 6.613723278045654\n",
      "epoch 46 time taken: 26.080249309539795s\n",
      "Training epoch: 47\n",
      "idx: 0, loss: 0.19900555908679962 time take: 0.24411821365356445\n",
      "idx: 100, loss: 0.20315347611904144 time take: 6.695572853088379\n",
      "idx: 200, loss: 0.2997500002384186 time take: 6.615445613861084\n",
      "idx: 300, loss: 0.3502741754055023 time take: 6.616396188735962\n",
      "epoch 47 time taken: 26.172187328338623s\n",
      "Training epoch: 48\n",
      "idx: 0, loss: 0.24245679378509521 time take: 0.24500536918640137\n",
      "idx: 100, loss: 0.27931898832321167 time take: 6.738494873046875\n",
      "idx: 200, loss: 0.3943766951560974 time take: 6.686050176620483\n",
      "idx: 300, loss: 0.2869988977909088 time take: 6.646795034408569\n",
      "epoch 48 time taken: 26.315868139266968s\n",
      "Training epoch: 49\n",
      "idx: 0, loss: 0.2384132444858551 time take: 0.24807119369506836\n",
      "idx: 100, loss: 0.21430310606956482 time take: 6.628903865814209\n",
      "idx: 200, loss: 0.3165075480937958 time take: 6.612971782684326\n",
      "idx: 300, loss: 0.24305732548236847 time take: 6.61179256439209\n",
      "epoch 49 time taken: 26.09700298309326s\n",
      "Training epoch: 50\n",
      "idx: 0, loss: 0.23085695505142212 time take: 0.26500844955444336\n",
      "idx: 100, loss: 0.17560863494873047 time take: 6.62311315536499\n",
      "idx: 200, loss: 0.29256173968315125 time take: 6.657616138458252\n",
      "idx: 300, loss: 0.28852835297584534 time take: 6.61310076713562\n",
      "epoch 50 time taken: 26.156593084335327s\n",
      "Training epoch: 51\n",
      "idx: 0, loss: 0.2333908975124359 time take: 0.24429774284362793\n",
      "idx: 100, loss: 0.2586112320423126 time take: 6.741983890533447\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "idx: 200, loss: 0.31630343198776245 time take: 6.704124689102173\n",
      "idx: 300, loss: 0.2205219268798828 time take: 6.7269980907440186\n",
      "epoch 51 time taken: 26.419057607650757s\n",
      "Training epoch: 52\n",
      "idx: 0, loss: 0.19029900431632996 time take: 0.22911357879638672\n",
      "idx: 100, loss: 0.14726689457893372 time take: 6.63547158241272\n",
      "idx: 200, loss: 0.23855534195899963 time take: 6.621695280075073\n",
      "idx: 300, loss: 0.21549226343631744 time take: 6.650598526000977\n",
      "epoch 52 time taken: 26.155381441116333s\n",
      "Training epoch: 53\n",
      "idx: 0, loss: 0.18259534239768982 time take: 0.26244068145751953\n",
      "idx: 100, loss: 0.1870933622121811 time take: 6.681147813796997\n",
      "idx: 200, loss: 0.27151888608932495 time take: 6.625962018966675\n",
      "idx: 300, loss: 0.24140478670597076 time take: 6.613759517669678\n",
      "epoch 53 time taken: 26.179369688034058s\n",
      "Training epoch: 54\n",
      "idx: 0, loss: 0.14228695631027222 time take: 0.24442529678344727\n",
      "idx: 100, loss: 0.25541624426841736 time take: 6.639346122741699\n",
      "idx: 200, loss: 0.28225845098495483 time take: 6.631605625152588\n",
      "idx: 300, loss: 0.24693122506141663 time take: 6.632909536361694\n",
      "epoch 54 time taken: 26.194764614105225s\n",
      "Training epoch: 55\n",
      "idx: 0, loss: 0.24617381393909454 time take: 0.255382776260376\n",
      "idx: 100, loss: 0.1906365603208542 time take: 6.626510858535767\n",
      "idx: 200, loss: 0.31742626428604126 time take: 6.6126463413238525\n",
      "idx: 300, loss: 0.22401849925518036 time take: 6.613767385482788\n",
      "epoch 55 time taken: 26.101189851760864s\n",
      "Training epoch: 56\n",
      "idx: 0, loss: 0.24757033586502075 time take: 0.25211548805236816\n",
      "idx: 100, loss: 0.08345536887645721 time take: 6.632253885269165\n",
      "idx: 200, loss: 0.338440865278244 time take: 6.616513013839722\n",
      "idx: 300, loss: 0.2894200086593628 time take: 6.614062070846558\n",
      "epoch 56 time taken: 26.111173391342163s\n",
      "Training epoch: 57\n",
      "idx: 0, loss: 0.223496675491333 time take: 0.2374565601348877\n",
      "idx: 100, loss: 0.194207563996315 time take: 6.68700909614563\n",
      "idx: 200, loss: 0.17788347601890564 time take: 6.616779565811157\n",
      "idx: 300, loss: 0.2441934198141098 time take: 6.617700815200806\n",
      "epoch 57 time taken: 26.156668186187744s\n",
      "Training epoch: 58\n",
      "idx: 0, loss: 0.20996218919754028 time take: 0.24557852745056152\n",
      "idx: 100, loss: 0.1921767294406891 time take: 6.641932725906372\n",
      "idx: 200, loss: 0.23175857961177826 time take: 6.624966859817505\n",
      "idx: 300, loss: 0.34315547347068787 time take: 6.615081787109375\n",
      "epoch 58 time taken: 26.1261043548584s\n",
      "Training epoch: 59\n",
      "idx: 0, loss: 0.1260104477405548 time take: 0.24420523643493652\n",
      "idx: 100, loss: 0.12700137495994568 time take: 6.625165224075317\n",
      "idx: 200, loss: 0.2650372087955475 time take: 6.613147020339966\n",
      "idx: 300, loss: 0.2159343957901001 time take: 6.677416086196899\n",
      "epoch 59 time taken: 26.183494091033936s\n",
      "Training epoch: 60\n",
      "idx: 0, loss: 0.1726836860179901 time take: 0.2487349510192871\n",
      "idx: 100, loss: 0.1338229775428772 time take: 6.62903094291687\n",
      "idx: 200, loss: 0.2595454454421997 time take: 6.615327596664429\n",
      "idx: 300, loss: 0.19759641587734222 time take: 6.613444566726685\n",
      "epoch 60 time taken: 26.141919374465942s\n",
      "Training epoch: 61\n",
      "idx: 0, loss: 0.22774168848991394 time take: 0.24459147453308105\n",
      "idx: 100, loss: 0.12952737510204315 time take: 6.624481916427612\n",
      "idx: 200, loss: 0.2845986783504486 time take: 6.631589651107788\n",
      "idx: 300, loss: 0.22517289221286774 time take: 6.612287521362305\n",
      "epoch 61 time taken: 26.143094062805176s\n",
      "Training epoch: 62\n",
      "idx: 0, loss: 0.18797336518764496 time take: 0.2733132839202881\n",
      "idx: 100, loss: 0.21791577339172363 time take: 6.678402423858643\n",
      "idx: 200, loss: 0.20280714333057404 time take: 6.704560279846191\n",
      "idx: 300, loss: 0.1399155855178833 time take: 6.627616882324219\n",
      "epoch 62 time taken: 26.281750679016113s\n",
      "Training epoch: 63\n",
      "idx: 0, loss: 0.20904844999313354 time take: 0.22539448738098145\n",
      "idx: 100, loss: 0.17296193540096283 time take: 6.677087306976318\n",
      "idx: 200, loss: 0.20442341268062592 time take: 6.686342477798462\n",
      "idx: 300, loss: 0.27780428528785706 time take: 6.706920146942139\n",
      "epoch 63 time taken: 26.356801986694336s\n",
      "Training epoch: 64\n",
      "idx: 0, loss: 0.19369961321353912 time take: 0.26728129386901855\n",
      "idx: 100, loss: 0.15244433283805847 time take: 6.637664794921875\n",
      "idx: 200, loss: 0.2249746024608612 time take: 6.618008613586426\n",
      "idx: 300, loss: 0.22423772513866425 time take: 6.614980220794678\n",
      "epoch 64 time taken: 26.132793426513672s\n",
      "Training epoch: 65\n",
      "idx: 0, loss: 0.1519346982240677 time take: 0.2453906536102295\n",
      "idx: 100, loss: 0.19308686256408691 time take: 6.623851776123047\n",
      "idx: 200, loss: 0.1940927356481552 time take: 6.629107713699341\n",
      "idx: 300, loss: 0.25326526165008545 time take: 6.6141064167022705\n",
      "epoch 65 time taken: 26.11064624786377s\n",
      "Training epoch: 66\n",
      "idx: 0, loss: 0.2565290629863739 time take: 0.2230052947998047\n",
      "idx: 100, loss: 0.13571543991565704 time take: 6.6514434814453125\n",
      "idx: 200, loss: 0.18494506180286407 time take: 6.709042549133301\n",
      "idx: 300, loss: 0.19917425513267517 time take: 6.684068202972412\n",
      "epoch 66 time taken: 26.26052212715149s\n",
      "Training epoch: 67\n",
      "idx: 0, loss: 0.2671307325363159 time take: 0.25917887687683105\n",
      "idx: 100, loss: 0.1993664652109146 time take: 6.702357053756714\n",
      "idx: 200, loss: 0.23778484761714935 time take: 6.701822996139526\n",
      "idx: 300, loss: 0.2836872935295105 time take: 6.6892547607421875\n",
      "epoch 67 time taken: 26.345604181289673s\n",
      "Training epoch: 68\n",
      "idx: 0, loss: 0.10934586822986603 time take: 0.25612616539001465\n",
      "idx: 100, loss: 0.13965943455696106 time take: 6.689351320266724\n",
      "idx: 200, loss: 0.1720024198293686 time take: 6.6429829597473145\n",
      "idx: 300, loss: 0.14947588741779327 time take: 6.692030906677246\n",
      "epoch 68 time taken: 26.273982524871826s\n",
      "Training epoch: 69\n",
      "idx: 0, loss: 0.14511717855930328 time take: 0.23488283157348633\n",
      "idx: 100, loss: 0.09472925961017609 time take: 6.637347936630249\n",
      "idx: 200, loss: 0.19549356400966644 time take: 6.642009735107422\n",
      "idx: 300, loss: 0.20824013650417328 time take: 6.644009590148926\n",
      "epoch 69 time taken: 26.178218126296997s\n",
      "Training epoch: 70\n",
      "idx: 0, loss: 0.11366602778434753 time take: 0.24956917762756348\n",
      "idx: 100, loss: 0.12916144728660583 time take: 6.620359182357788\n",
      "idx: 200, loss: 0.28732410073280334 time take: 6.61393928527832\n",
      "idx: 300, loss: 0.22461266815662384 time take: 6.654641389846802\n",
      "epoch 70 time taken: 26.210697650909424s\n",
      "Training epoch: 71\n",
      "idx: 0, loss: 0.13845908641815186 time take: 0.2551727294921875\n",
      "idx: 100, loss: 0.09517832100391388 time take: 6.622192859649658\n",
      "idx: 200, loss: 0.2348918467760086 time take: 6.615525484085083\n",
      "idx: 300, loss: 0.1250527799129486 time take: 6.612462282180786\n",
      "epoch 71 time taken: 26.09980869293213s\n",
      "Training epoch: 72\n",
      "idx: 0, loss: 0.1450730711221695 time take: 0.24365806579589844\n",
      "idx: 100, loss: 0.09626860916614532 time take: 6.658692836761475\n",
      "idx: 200, loss: 0.17156697809696198 time take: 6.6112024784088135\n",
      "idx: 300, loss: 0.27356648445129395 time take: 6.613512277603149\n",
      "epoch 72 time taken: 26.124407291412354s\n",
      "Training epoch: 73\n",
      "idx: 0, loss: 0.11098398268222809 time take: 0.24938416481018066\n",
      "idx: 100, loss: 0.13534560799598694 time take: 6.733146667480469\n",
      "idx: 200, loss: 0.2376411408185959 time take: 6.6159703731536865\n",
      "idx: 300, loss: 0.17412522435188293 time take: 6.612737417221069\n",
      "epoch 73 time taken: 26.20558214187622s\n",
      "Training epoch: 74\n",
      "idx: 0, loss: 0.20639415085315704 time take: 0.23848843574523926\n",
      "idx: 100, loss: 0.20524582266807556 time take: 6.625914812088013\n",
      "idx: 200, loss: 0.17361998558044434 time take: 6.616585731506348\n",
      "idx: 300, loss: 0.14797836542129517 time take: 6.614223003387451\n",
      "epoch 74 time taken: 26.086726903915405s\n",
      "Training epoch: 75\n",
      "idx: 0, loss: 0.19089342653751373 time take: 0.2601454257965088\n",
      "idx: 100, loss: 0.08459270000457764 time take: 6.624232292175293\n",
      "idx: 200, loss: 0.16002678871154785 time take: 6.611395597457886\n",
      "idx: 300, loss: 0.16557584702968597 time take: 6.685197591781616\n",
      "epoch 75 time taken: 26.175349235534668s\n",
      "Training epoch: 76\n",
      "idx: 0, loss: 0.23193815350532532 time take: 0.2457561492919922\n",
      "idx: 100, loss: 0.10313305258750916 time take: 6.6301350593566895\n",
      "idx: 200, loss: 0.12799502909183502 time take: 6.651790618896484\n",
      "idx: 300, loss: 0.15319512784481049 time take: 6.682572364807129\n",
      "epoch 76 time taken: 26.252668619155884s\n",
      "Training epoch: 77\n",
      "idx: 0, loss: 0.1457175612449646 time take: 0.2217259407043457\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "idx: 100, loss: 0.13588443398475647 time take: 6.622119426727295\n",
      "idx: 200, loss: 0.2570956349372864 time take: 6.611584424972534\n",
      "idx: 300, loss: 0.14335092902183533 time take: 6.614312410354614\n",
      "epoch 77 time taken: 26.122233629226685s\n",
      "Training epoch: 78\n",
      "idx: 0, loss: 0.09631645679473877 time take: 0.24411225318908691\n",
      "idx: 100, loss: 0.06118485704064369 time take: 6.6219470500946045\n",
      "idx: 200, loss: 0.21508173644542694 time take: 6.6093573570251465\n",
      "idx: 300, loss: 0.19602982699871063 time take: 6.613054513931274\n",
      "epoch 78 time taken: 26.08490252494812s\n",
      "Training epoch: 79\n",
      "idx: 0, loss: 0.11522193998098373 time take: 0.24671530723571777\n",
      "idx: 100, loss: 0.07653247565031052 time take: 6.651439666748047\n",
      "idx: 200, loss: 0.12243413180112839 time take: 6.61201548576355\n",
      "idx: 300, loss: 0.09151208400726318 time take: 6.61209511756897\n",
      "epoch 79 time taken: 26.11755895614624s\n",
      "Training epoch: 80\n",
      "idx: 0, loss: 0.16937515139579773 time take: 0.2577834129333496\n",
      "idx: 100, loss: 0.14408943057060242 time take: 6.712240219116211\n",
      "idx: 200, loss: 0.24638479948043823 time take: 6.612234115600586\n",
      "idx: 300, loss: 0.17029033601284027 time take: 6.610184192657471\n",
      "epoch 80 time taken: 26.184489488601685s\n",
      "Training epoch: 81\n",
      "idx: 0, loss: 0.1842426359653473 time take: 0.26358842849731445\n",
      "idx: 100, loss: 0.18970218300819397 time take: 6.6283111572265625\n",
      "idx: 200, loss: 0.2180848866701126 time take: 6.627009153366089\n",
      "idx: 300, loss: 0.10429423302412033 time take: 6.663130760192871\n",
      "epoch 81 time taken: 26.17221999168396s\n",
      "Training epoch: 82\n",
      "idx: 0, loss: 0.1445140540599823 time take: 0.258817195892334\n",
      "idx: 100, loss: 0.10079219192266464 time take: 6.627773761749268\n",
      "idx: 200, loss: 0.14140331745147705 time take: 6.6501195430755615\n",
      "idx: 300, loss: 0.18106217682361603 time take: 6.630199670791626\n",
      "epoch 82 time taken: 26.18726396560669s\n",
      "Training epoch: 83\n",
      "idx: 0, loss: 0.07641959190368652 time take: 0.2563354969024658\n",
      "idx: 100, loss: 0.11811482906341553 time take: 6.631137371063232\n",
      "idx: 200, loss: 0.12452750653028488 time take: 6.6431519985198975\n",
      "idx: 300, loss: 0.1513700932264328 time take: 6.674258470535278\n",
      "epoch 83 time taken: 26.221820831298828s\n",
      "Training epoch: 84\n",
      "idx: 0, loss: 0.07113765925168991 time take: 0.2464919090270996\n",
      "idx: 100, loss: 0.07201950252056122 time take: 6.622232437133789\n",
      "idx: 200, loss: 0.18231409788131714 time take: 6.624218463897705\n",
      "idx: 300, loss: 0.13492581248283386 time take: 6.667965412139893\n",
      "epoch 84 time taken: 26.15373706817627s\n",
      "Training epoch: 85\n",
      "idx: 0, loss: 0.1317068487405777 time take: 0.24737858772277832\n",
      "idx: 100, loss: 0.20822349190711975 time take: 6.645784378051758\n",
      "idx: 200, loss: 0.1679283082485199 time take: 6.61325216293335\n",
      "idx: 300, loss: 0.07601883262395859 time take: 6.659766674041748\n",
      "epoch 85 time taken: 26.177620887756348s\n",
      "Training epoch: 86\n",
      "idx: 0, loss: 0.22715479135513306 time take: 0.24417424201965332\n",
      "idx: 100, loss: 0.0807063952088356 time take: 6.626496076583862\n",
      "idx: 200, loss: 0.20277687907218933 time take: 6.638570308685303\n",
      "idx: 300, loss: 0.1095491573214531 time take: 6.69557523727417\n",
      "epoch 86 time taken: 27.76706290245056s\n",
      "Training epoch: 87\n",
      "idx: 0, loss: 0.12183474004268646 time take: 0.33830976486206055\n",
      "idx: 100, loss: 0.23099642992019653 time take: 9.811689138412476\n",
      "idx: 200, loss: 0.1934429109096527 time take: 9.206539869308472\n",
      "idx: 300, loss: 0.16717900335788727 time take: 9.376386165618896\n",
      "epoch 87 time taken: 37.49561405181885s\n",
      "Training epoch: 88\n",
      "idx: 0, loss: 0.10687990486621857 time take: 0.36283254623413086\n",
      "idx: 100, loss: 0.07644511014223099 time take: 12.648298978805542\n",
      "idx: 200, loss: 0.21813087165355682 time take: 16.463671684265137\n",
      "idx: 300, loss: 0.11820239573717117 time take: 16.224794149398804\n",
      "epoch 88 time taken: 61.52670741081238s\n",
      "Training epoch: 89\n",
      "idx: 0, loss: 0.05899634584784508 time take: 0.32557082176208496\n",
      "idx: 100, loss: 0.07873092591762543 time take: 17.43282914161682\n",
      "idx: 200, loss: 0.08496202528476715 time take: 17.453524351119995\n",
      "idx: 300, loss: 0.1477523148059845 time take: 17.43505883216858\n",
      "epoch 89 time taken: 68.07870841026306s\n",
      "Training epoch: 90\n",
      "idx: 0, loss: 0.03599690645933151 time take: 0.31668663024902344\n",
      "idx: 100, loss: 0.09689842164516449 time take: 17.42711329460144\n",
      "idx: 200, loss: 0.12811869382858276 time take: 17.456071376800537\n",
      "idx: 300, loss: 0.14146532118320465 time take: 17.458107948303223\n",
      "epoch 90 time taken: 68.48840045928955s\n",
      "Training epoch: 91\n",
      "idx: 0, loss: 0.16159160435199738 time take: 0.3202939033508301\n",
      "idx: 100, loss: 0.08266151696443558 time take: 13.877629518508911\n",
      "idx: 200, loss: 0.14540840685367584 time take: 16.38912010192871\n",
      "idx: 300, loss: 0.16004733741283417 time take: 16.39387011528015\n",
      "epoch 91 time taken: 62.79941439628601s\n",
      "Training epoch: 92\n",
      "idx: 0, loss: 0.12363989651203156 time take: 0.28840017318725586\n",
      "idx: 100, loss: 0.14474909007549286 time take: 17.437705755233765\n",
      "idx: 200, loss: 0.1488042026758194 time take: 17.455172061920166\n",
      "idx: 300, loss: 0.1483130156993866 time take: 17.43217396736145\n",
      "epoch 92 time taken: 68.1291754245758s\n",
      "Training epoch: 93\n",
      "idx: 0, loss: 0.10467672348022461 time take: 0.33832454681396484\n",
      "idx: 100, loss: 0.043346669524908066 time take: 17.464873552322388\n",
      "idx: 200, loss: 0.09480565786361694 time take: 17.444013118743896\n",
      "idx: 300, loss: 0.07667455077171326 time take: 17.451739072799683\n",
      "epoch 93 time taken: 68.43851566314697s\n",
      "Training epoch: 94\n",
      "idx: 0, loss: 0.03058449923992157 time take: 0.383786678314209\n",
      "idx: 100, loss: 0.09083851426839828 time take: 9.285919904708862\n",
      "idx: 200, loss: 0.1333135962486267 time take: 9.488239765167236\n",
      "idx: 300, loss: 0.14252781867980957 time take: 11.946449279785156\n",
      "epoch 94 time taken: 45.740084648132324s\n",
      "Training epoch: 95\n",
      "idx: 0, loss: 0.07373266667127609 time take: 0.34723544120788574\n",
      "idx: 100, loss: 0.059954628348350525 time take: 16.212181568145752\n",
      "idx: 200, loss: 0.10695955157279968 time take: 17.428386926651\n",
      "idx: 300, loss: 0.07408245652914047 time take: 17.432000398635864\n",
      "epoch 95 time taken: 67.22660112380981s\n",
      "Training epoch: 96\n",
      "idx: 0, loss: 0.11076217144727707 time take: 0.290485143661499\n",
      "idx: 100, loss: 0.15761125087738037 time take: 17.4191837310791\n",
      "idx: 200, loss: 0.16043207049369812 time take: 17.01703143119812\n",
      "idx: 300, loss: 0.1319606453180313 time take: 17.47193670272827\n",
      "epoch 96 time taken: 67.99361991882324s\n",
      "Training epoch: 97\n",
      "idx: 0, loss: 0.1442994624376297 time take: 0.3251218795776367\n",
      "idx: 100, loss: 0.09996721148490906 time take: 17.433911323547363\n",
      "idx: 200, loss: 0.12145020067691803 time take: 17.425600290298462\n",
      "idx: 300, loss: 0.06559643149375916 time take: 11.852004289627075\n",
      "epoch 97 time taken: 55.98863935470581s\n",
      "Training epoch: 98\n",
      "idx: 0, loss: 0.1272280067205429 time take: 0.35398054122924805\n",
      "idx: 100, loss: 0.05632242187857628 time take: 9.306841850280762\n",
      "idx: 200, loss: 0.11274483054876328 time take: 9.650526523590088\n",
      "idx: 300, loss: 0.12036711722612381 time take: 16.304903745651245\n",
      "epoch 98 time taken: 50.17407584190369s\n",
      "Training epoch: 99\n",
      "idx: 0, loss: 0.07868518680334091 time take: 0.28357982635498047\n",
      "idx: 100, loss: 0.08446959406137466 time take: 17.482487201690674\n",
      "idx: 200, loss: 0.09730395674705505 time take: 17.420372486114502\n",
      "idx: 300, loss: 0.1138409972190857 time take: 17.436471939086914\n",
      "epoch 99 time taken: 68.49619889259338s\n",
      "Performing inference on batch: 0\n",
      "Performing inference on batch: 50\n",
      "Performing inference on batch: 0\n",
      "Performing inference on batch: 50\n",
      "FPR@95: 75.67, AUROC: 81.23 AUPR_IN: 82.73, AUPR_OUT: 77.64\n",
      "CCR: 0.08, 1.76, 20.75, 54.69, ACC: 85.32\n",
      "\n",
      "Running model: models/cifar_resnet50_odin_softplus_Adam_1.pkl...\n",
      "Getting optimizer for type: Adam...\n",
      "Training epoch: 0\n",
      "idx: 0, loss: 3.080024242401123 time take: 0.32479262351989746\n",
      "idx: 100, loss: 3.0885157585144043 time take: 17.473212480545044\n",
      "idx: 200, loss: 3.563685655593872 time take: 17.424672603607178\n",
      "idx: 300, loss: 3.326247215270996 time take: 17.449357986450195\n",
      "epoch 0 time taken: 65.00812816619873s\n",
      "Training epoch: 1\n",
      "idx: 0, loss: 2.4415628910064697 time take: 0.3240664005279541\n",
      "idx: 100, loss: 2.221106767654419 time take: 9.86282467842102\n",
      "idx: 200, loss: 2.5383987426757812 time take: 9.898144245147705\n",
      "idx: 300, loss: 2.3492095470428467 time take: 9.27272343635559\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 1 time taken: 37.970566749572754s\n",
      "Training epoch: 2\n",
      "idx: 0, loss: 2.0488224029541016 time take: 0.4266514778137207\n",
      "idx: 100, loss: 1.9244788885116577 time take: 11.499085664749146\n",
      "idx: 200, loss: 1.9873977899551392 time take: 16.24790120124817\n",
      "idx: 300, loss: 1.9369984865188599 time take: 16.11076807975769\n",
      "epoch 2 time taken: 60.09878134727478s\n",
      "Training epoch: 3\n",
      "idx: 0, loss: 2.0564136505126953 time take: 0.3454399108886719\n",
      "idx: 100, loss: 1.6248329877853394 time take: 17.435948610305786\n",
      "idx: 200, loss: 1.623598337173462 time take: 17.435144424438477\n",
      "idx: 300, loss: 1.790894865989685 time take: 17.470246076583862\n",
      "epoch 3 time taken: 68.08431649208069s\n",
      "Training epoch: 4\n",
      "idx: 0, loss: 1.759663701057434 time take: 0.3084444999694824\n",
      "idx: 100, loss: 1.5608335733413696 time take: 17.462621688842773\n",
      "idx: 200, loss: 1.425879955291748 time take: 17.448249101638794\n",
      "idx: 300, loss: 1.6865845918655396 time take: 17.416495084762573\n",
      "epoch 4 time taken: 68.46527147293091s\n",
      "Training epoch: 5\n",
      "idx: 0, loss: 1.5961453914642334 time take: 0.345306396484375\n",
      "idx: 100, loss: 1.450329065322876 time take: 11.725518226623535\n",
      "idx: 200, loss: 1.4914368391036987 time take: 9.55864405632019\n",
      "idx: 300, loss: 1.5067254304885864 time take: 14.78442931175232\n",
      "epoch 5 time taken: 50.99741244316101s\n",
      "Training epoch: 6\n",
      "idx: 0, loss: 1.4457343816757202 time take: 0.3327066898345947\n",
      "idx: 100, loss: 1.4210976362228394 time take: 17.39927577972412\n",
      "idx: 200, loss: 1.4680500030517578 time take: 17.46320867538452\n",
      "idx: 300, loss: 1.3622865676879883 time take: 17.429795026779175\n",
      "epoch 6 time taken: 68.45457005500793s\n",
      "Training epoch: 7\n",
      "idx: 0, loss: 1.4115031957626343 time take: 0.31687045097351074\n",
      "idx: 100, loss: 1.2317428588867188 time take: 17.036049365997314\n",
      "idx: 200, loss: 1.2837694883346558 time take: 17.41804051399231\n",
      "idx: 300, loss: 1.1711727380752563 time take: 17.429776430130005\n",
      "epoch 7 time taken: 68.00726771354675s\n",
      "Training epoch: 8\n",
      "idx: 0, loss: 1.2604057788848877 time take: 0.2885575294494629\n",
      "idx: 100, loss: 1.1299623250961304 time take: 17.436018466949463\n",
      "idx: 200, loss: 1.1923984289169312 time take: 15.927081108093262\n",
      "idx: 300, loss: 1.1392565965652466 time take: 9.142089128494263\n",
      "epoch 8 time taken: 57.48456430435181s\n",
      "Training epoch: 9\n",
      "idx: 0, loss: 1.1500073671340942 time take: 0.37452244758605957\n",
      "idx: 100, loss: 1.0021566152572632 time take: 15.68402361869812\n",
      "idx: 200, loss: 1.1174407005310059 time take: 17.438599348068237\n",
      "idx: 300, loss: 1.1079009771347046 time take: 17.438400506973267\n",
      "epoch 9 time taken: 66.73610782623291s\n",
      "Training epoch: 10\n",
      "idx: 0, loss: 1.0873324871063232 time take: 0.33944058418273926\n",
      "idx: 100, loss: 0.9677886366844177 time take: 17.476626873016357\n",
      "idx: 200, loss: 1.0420860052108765 time take: 16.999913930892944\n",
      "idx: 300, loss: 0.9383084774017334 time take: 17.446501970291138\n",
      "epoch 10 time taken: 68.0931966304779s\n",
      "Training epoch: 11\n",
      "idx: 0, loss: 1.09388267993927 time take: 0.31664133071899414\n",
      "idx: 100, loss: 0.9650335907936096 time take: 17.449843645095825\n",
      "idx: 200, loss: 1.0679644346237183 time take: 17.438753604888916\n",
      "idx: 300, loss: 0.9780204892158508 time take: 14.393386125564575\n",
      "epoch 11 time taken: 58.47321653366089s\n",
      "Training epoch: 12\n",
      "idx: 0, loss: 0.8968241214752197 time take: 0.3446638584136963\n",
      "idx: 100, loss: 0.879662811756134 time take: 8.062761783599854\n",
      "idx: 200, loss: 0.9754624962806702 time take: 6.6360085010528564\n",
      "idx: 300, loss: 0.8913906812667847 time take: 6.623880863189697\n",
      "epoch 12 time taken: 27.667929887771606s\n",
      "Training epoch: 13\n",
      "idx: 0, loss: 0.8644862771034241 time take: 0.2602841854095459\n",
      "idx: 100, loss: 0.8035236597061157 time take: 6.7227396965026855\n",
      "idx: 200, loss: 0.9102202653884888 time take: 6.620457887649536\n",
      "idx: 300, loss: 0.8933589458465576 time take: 6.615783452987671\n",
      "epoch 13 time taken: 26.21680235862732s\n",
      "Training epoch: 14\n",
      "idx: 0, loss: 0.8800194263458252 time take: 0.2640676498413086\n",
      "idx: 100, loss: 0.8712490797042847 time take: 6.666415452957153\n",
      "idx: 200, loss: 0.8975590467453003 time take: 6.61424446105957\n",
      "idx: 300, loss: 0.8025012016296387 time take: 6.619927644729614\n",
      "epoch 14 time taken: 26.161930799484253s\n",
      "Training epoch: 15\n",
      "idx: 0, loss: 0.8032218813896179 time take: 0.2500901222229004\n",
      "idx: 100, loss: 0.7950735688209534 time take: 6.63720703125\n",
      "idx: 200, loss: 0.8748730421066284 time take: 6.625513553619385\n",
      "idx: 300, loss: 0.8948058485984802 time take: 6.62028694152832\n",
      "epoch 15 time taken: 26.129634618759155s\n",
      "Training epoch: 16\n",
      "idx: 0, loss: 0.8485928177833557 time take: 0.2620964050292969\n",
      "idx: 100, loss: 0.8218162059783936 time take: 6.634901285171509\n",
      "idx: 200, loss: 0.8607395887374878 time take: 6.641065835952759\n",
      "idx: 300, loss: 0.6944175958633423 time take: 6.612650394439697\n",
      "epoch 16 time taken: 26.143165349960327s\n",
      "Training epoch: 17\n",
      "idx: 0, loss: 0.7970943450927734 time take: 0.2567787170410156\n",
      "idx: 100, loss: 0.7356774210929871 time take: 6.641028881072998\n",
      "idx: 200, loss: 0.8292143940925598 time take: 6.644258499145508\n",
      "idx: 300, loss: 0.7726836800575256 time take: 6.6242663860321045\n",
      "epoch 17 time taken: 26.176021575927734s\n",
      "Training epoch: 18\n",
      "idx: 0, loss: 0.7083632946014404 time take: 0.24517226219177246\n",
      "idx: 100, loss: 0.7421236634254456 time take: 6.660504579544067\n",
      "idx: 200, loss: 0.8249601125717163 time take: 6.615030765533447\n",
      "idx: 300, loss: 0.6998124122619629 time take: 6.6403913497924805\n",
      "epoch 18 time taken: 26.153581619262695s\n",
      "Training epoch: 19\n",
      "idx: 0, loss: 0.750389039516449 time take: 0.21450233459472656\n",
      "idx: 100, loss: 0.7801550626754761 time take: 6.710739612579346\n",
      "idx: 200, loss: 0.7018424868583679 time take: 6.641789674758911\n",
      "idx: 300, loss: 0.7246426939964294 time take: 6.620779514312744\n",
      "epoch 19 time taken: 26.26272177696228s\n",
      "Training epoch: 20\n",
      "idx: 0, loss: 0.6852206587791443 time take: 0.2544829845428467\n",
      "idx: 100, loss: 0.6220583915710449 time take: 6.6255576610565186\n",
      "idx: 200, loss: 0.7366030216217041 time take: 6.629009962081909\n",
      "idx: 300, loss: 0.6977331638336182 time take: 6.735608339309692\n",
      "epoch 20 time taken: 26.2719988822937s\n",
      "Training epoch: 21\n",
      "idx: 0, loss: 0.6745073199272156 time take: 0.2435288429260254\n",
      "idx: 100, loss: 0.6232757568359375 time take: 6.627338409423828\n",
      "idx: 200, loss: 0.8101760745048523 time take: 6.613332986831665\n",
      "idx: 300, loss: 0.7206361889839172 time take: 6.637965440750122\n",
      "epoch 21 time taken: 26.157023191452026s\n",
      "Training epoch: 22\n",
      "idx: 0, loss: 0.6325517892837524 time take: 0.26883816719055176\n",
      "idx: 100, loss: 0.6017137765884399 time take: 6.683215141296387\n",
      "idx: 200, loss: 0.6992563009262085 time take: 6.631173849105835\n",
      "idx: 300, loss: 0.5581586360931396 time take: 6.614165306091309\n",
      "epoch 22 time taken: 26.193094491958618s\n",
      "Training epoch: 23\n",
      "idx: 0, loss: 0.5963260531425476 time take: 0.2483069896697998\n",
      "idx: 100, loss: 0.5928495526313782 time take: 6.6465208530426025\n",
      "idx: 200, loss: 0.7108266353607178 time take: 6.6235878467559814\n",
      "idx: 300, loss: 0.6128948330879211 time take: 6.6235997676849365\n",
      "epoch 23 time taken: 26.13756775856018s\n",
      "Training epoch: 24\n",
      "idx: 0, loss: 0.6866241097450256 time take: 0.23497343063354492\n",
      "idx: 100, loss: 0.5278669595718384 time take: 6.622329950332642\n",
      "idx: 200, loss: 0.7143815755844116 time take: 6.615570783615112\n",
      "idx: 300, loss: 0.5317836999893188 time take: 6.617166996002197\n",
      "epoch 24 time taken: 26.086774826049805s\n",
      "Training epoch: 25\n",
      "idx: 0, loss: 0.4964327812194824 time take: 0.23093390464782715\n",
      "idx: 100, loss: 0.4907410144805908 time take: 6.623046875\n",
      "idx: 200, loss: 0.7769877910614014 time take: 6.61320161819458\n",
      "idx: 300, loss: 0.5366113185882568 time take: 6.6400885581970215\n",
      "epoch 25 time taken: 26.119064331054688s\n",
      "Training epoch: 26\n",
      "idx: 0, loss: 0.4788629710674286 time take: 0.25186657905578613\n",
      "idx: 100, loss: 0.41127434372901917 time take: 6.627366065979004\n",
      "idx: 200, loss: 0.573214590549469 time take: 6.615826606750488\n",
      "idx: 300, loss: 0.5886942744255066 time take: 6.613809108734131\n",
      "epoch 26 time taken: 26.143553972244263s\n",
      "Training epoch: 27\n",
      "idx: 0, loss: 0.6207281351089478 time take: 0.25781679153442383\n",
      "idx: 100, loss: 0.45212122797966003 time take: 6.682158470153809\n",
      "idx: 200, loss: 0.5875495672225952 time take: 6.660121917724609\n",
      "idx: 300, loss: 0.4624914228916168 time take: 6.612339496612549\n",
      "epoch 27 time taken: 26.240067958831787s\n",
      "Training epoch: 28\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "idx: 0, loss: 0.4421517252922058 time take: 0.24152827262878418\n",
      "idx: 100, loss: 0.4549048840999603 time take: 6.629119873046875\n",
      "idx: 200, loss: 0.6421298980712891 time take: 6.614649057388306\n",
      "idx: 300, loss: 0.573917031288147 time take: 6.614962339401245\n",
      "epoch 28 time taken: 26.095964908599854s\n",
      "Training epoch: 29\n",
      "idx: 0, loss: 0.5052249431610107 time take: 0.24231767654418945\n",
      "idx: 100, loss: 0.4861232042312622 time take: 6.627577066421509\n",
      "idx: 200, loss: 0.6224702000617981 time take: 6.616735219955444\n",
      "idx: 300, loss: 0.5747985243797302 time take: 6.614736080169678\n",
      "epoch 29 time taken: 26.095654010772705s\n",
      "Training epoch: 30\n",
      "idx: 0, loss: 0.5002521872520447 time take: 0.2434849739074707\n",
      "idx: 100, loss: 0.5111833810806274 time take: 6.691584825515747\n",
      "idx: 200, loss: 0.6427602171897888 time take: 6.6386449337005615\n",
      "idx: 300, loss: 0.42303481698036194 time take: 6.61634087562561\n",
      "epoch 30 time taken: 26.188615560531616s\n",
      "Training epoch: 31\n",
      "idx: 0, loss: 0.4584808051586151 time take: 0.25037121772766113\n",
      "idx: 100, loss: 0.3955227732658386 time take: 6.648789882659912\n",
      "idx: 200, loss: 0.5524351000785828 time take: 6.626855373382568\n",
      "idx: 300, loss: 0.43808314204216003 time take: 6.616729497909546\n",
      "epoch 31 time taken: 26.136910438537598s\n",
      "Training epoch: 32\n",
      "idx: 0, loss: 0.4957510232925415 time take: 0.26055192947387695\n",
      "idx: 100, loss: 0.41893139481544495 time take: 6.62512993812561\n",
      "idx: 200, loss: 0.5014581680297852 time take: 6.666611433029175\n",
      "idx: 300, loss: 0.4271189272403717 time take: 6.67277717590332\n",
      "epoch 32 time taken: 26.222938299179077s\n",
      "Training epoch: 33\n",
      "idx: 0, loss: 0.46719783544540405 time take: 0.22419190406799316\n",
      "idx: 100, loss: 0.4990246593952179 time take: 6.626870155334473\n",
      "idx: 200, loss: 0.5781559944152832 time take: 6.6139326095581055\n",
      "idx: 300, loss: 0.4996938109397888 time take: 6.612385988235474\n",
      "epoch 33 time taken: 26.072112321853638s\n",
      "Training epoch: 34\n",
      "idx: 0, loss: 0.33527445793151855 time take: 0.23799920082092285\n",
      "idx: 100, loss: 0.38030117750167847 time take: 6.629865884780884\n",
      "idx: 200, loss: 0.6708273887634277 time take: 6.637126684188843\n",
      "idx: 300, loss: 0.38981521129608154 time take: 6.70842719078064\n",
      "epoch 34 time taken: 26.21322727203369s\n",
      "Training epoch: 35\n",
      "idx: 0, loss: 0.41540268063545227 time take: 0.2515263557434082\n",
      "idx: 100, loss: 0.3944757282733917 time take: 6.625444650650024\n",
      "idx: 200, loss: 0.4389868676662445 time take: 6.621331691741943\n",
      "idx: 300, loss: 0.44615477323532104 time take: 6.612233638763428\n",
      "epoch 35 time taken: 26.104318380355835s\n",
      "Training epoch: 36\n",
      "idx: 0, loss: 0.341847687959671 time take: 0.2572817802429199\n",
      "idx: 100, loss: 0.3965063989162445 time take: 6.6184258460998535\n",
      "idx: 200, loss: 0.5949057340621948 time take: 6.619846343994141\n",
      "idx: 300, loss: 0.3599525988101959 time take: 6.612234354019165\n",
      "epoch 36 time taken: 26.132461071014404s\n",
      "Training epoch: 37\n",
      "idx: 0, loss: 0.3461206555366516 time take: 0.3420991897583008\n",
      "idx: 100, loss: 0.4321760833263397 time take: 6.644150257110596\n",
      "idx: 200, loss: 0.4881882667541504 time take: 6.622605323791504\n",
      "idx: 300, loss: 0.32225972414016724 time take: 6.61737585067749\n",
      "epoch 37 time taken: 26.224351167678833s\n",
      "Training epoch: 38\n",
      "idx: 0, loss: 0.36691173911094666 time take: 0.24385690689086914\n",
      "idx: 100, loss: 0.5094876289367676 time take: 6.642542123794556\n",
      "idx: 200, loss: 0.5104607939720154 time take: 6.639397621154785\n",
      "idx: 300, loss: 0.2752944827079773 time take: 6.638147592544556\n",
      "epoch 38 time taken: 26.15892720222473s\n",
      "Training epoch: 39\n",
      "idx: 0, loss: 0.32803815603256226 time take: 0.25574183464050293\n",
      "idx: 100, loss: 0.3511667847633362 time take: 6.619034290313721\n",
      "idx: 200, loss: 0.37821194529533386 time take: 6.670108318328857\n",
      "idx: 300, loss: 0.3628235459327698 time take: 6.665527105331421\n",
      "epoch 39 time taken: 26.24809432029724s\n",
      "Training epoch: 40\n",
      "idx: 0, loss: 0.4552222490310669 time take: 0.2841517925262451\n",
      "idx: 100, loss: 0.36885201930999756 time take: 6.627193927764893\n",
      "idx: 200, loss: 0.5351002812385559 time take: 6.611966371536255\n",
      "idx: 300, loss: 0.36100754141807556 time take: 6.637195825576782\n",
      "epoch 40 time taken: 26.22659730911255s\n",
      "Training epoch: 41\n",
      "idx: 0, loss: 0.321048378944397 time take: 0.24283528327941895\n",
      "idx: 100, loss: 0.2610968053340912 time take: 6.6233110427856445\n",
      "idx: 200, loss: 0.45842400193214417 time take: 6.6124348640441895\n",
      "idx: 300, loss: 0.37675872445106506 time take: 6.716851472854614\n",
      "epoch 41 time taken: 26.190614461898804s\n",
      "Training epoch: 42\n",
      "idx: 0, loss: 0.384543240070343 time take: 0.24889326095581055\n",
      "idx: 100, loss: 0.27232417464256287 time take: 6.6676061153411865\n",
      "idx: 200, loss: 0.43489575386047363 time take: 6.629211187362671\n",
      "idx: 300, loss: 0.3932250440120697 time take: 6.670472621917725\n",
      "epoch 42 time taken: 26.22242569923401s\n",
      "Training epoch: 43\n",
      "idx: 0, loss: 0.3098047375679016 time take: 0.24177289009094238\n",
      "idx: 100, loss: 0.3460023105144501 time take: 6.619611978530884\n",
      "idx: 200, loss: 0.4779403805732727 time take: 6.6164164543151855\n",
      "idx: 300, loss: 0.355288565158844 time take: 6.70214056968689\n",
      "epoch 43 time taken: 26.268035888671875s\n",
      "Training epoch: 44\n",
      "idx: 0, loss: 0.2718735933303833 time take: 0.2580850124359131\n",
      "idx: 100, loss: 0.22412078082561493 time take: 6.656264781951904\n",
      "idx: 200, loss: 0.4914831519126892 time take: 6.663180112838745\n",
      "idx: 300, loss: 0.37138813734054565 time take: 6.66663932800293\n",
      "epoch 44 time taken: 26.248981952667236s\n",
      "Training epoch: 45\n",
      "idx: 0, loss: 0.3916797637939453 time take: 0.25768303871154785\n",
      "idx: 100, loss: 0.3233180046081543 time take: 6.623791933059692\n",
      "idx: 200, loss: 0.49189305305480957 time take: 6.612897872924805\n",
      "idx: 300, loss: 0.2979215085506439 time take: 6.611889600753784\n",
      "epoch 45 time taken: 26.10068392753601s\n",
      "Training epoch: 46\n",
      "idx: 0, loss: 0.3156956434249878 time take: 0.25899219512939453\n",
      "idx: 100, loss: 0.26203808188438416 time take: 6.694339275360107\n",
      "idx: 200, loss: 0.39283981919288635 time take: 6.611118316650391\n",
      "idx: 300, loss: 0.27516910433769226 time take: 6.613841533660889\n",
      "epoch 46 time taken: 26.173428058624268s\n",
      "Training epoch: 47\n",
      "idx: 0, loss: 0.34018972516059875 time take: 0.25432419776916504\n",
      "idx: 100, loss: 0.23508737981319427 time take: 6.629854679107666\n",
      "idx: 200, loss: 0.4012228548526764 time take: 6.610320568084717\n",
      "idx: 300, loss: 0.24994567036628723 time take: 6.613187551498413\n",
      "epoch 47 time taken: 26.102014303207397s\n",
      "Training epoch: 48\n",
      "idx: 0, loss: 0.217000350356102 time take: 0.2612621784210205\n",
      "idx: 100, loss: 0.2030988335609436 time take: 6.618124961853027\n",
      "idx: 200, loss: 0.3062245845794678 time take: 6.645007610321045\n",
      "idx: 300, loss: 0.2721070647239685 time take: 6.618633508682251\n",
      "epoch 48 time taken: 26.135598182678223s\n",
      "Training epoch: 49\n",
      "idx: 0, loss: 0.3028385043144226 time take: 0.23470735549926758\n",
      "idx: 100, loss: 0.24923205375671387 time take: 6.6244471073150635\n",
      "idx: 200, loss: 0.34114015102386475 time take: 6.614105939865112\n",
      "idx: 300, loss: 0.2865927815437317 time take: 6.613980293273926\n",
      "epoch 49 time taken: 26.078379154205322s\n",
      "Training epoch: 50\n",
      "idx: 0, loss: 0.2619915008544922 time take: 0.26657938957214355\n",
      "idx: 100, loss: 0.22539997100830078 time take: 6.6748576164245605\n",
      "idx: 200, loss: 0.3380301594734192 time take: 6.6163246631622314\n",
      "idx: 300, loss: 0.24995741248130798 time take: 6.648474454879761\n",
      "epoch 50 time taken: 26.265777587890625s\n",
      "Training epoch: 51\n",
      "idx: 0, loss: 0.2476966381072998 time take: 0.25002217292785645\n",
      "idx: 100, loss: 0.20972342789173126 time take: 6.650772333145142\n",
      "idx: 200, loss: 0.3064689338207245 time take: 6.664982080459595\n",
      "idx: 300, loss: 0.19428983330726624 time take: 6.625184535980225\n",
      "epoch 51 time taken: 26.204915285110474s\n",
      "Training epoch: 52\n",
      "idx: 0, loss: 0.25609496235847473 time take: 0.2514791488647461\n",
      "idx: 100, loss: 0.25438857078552246 time take: 6.6663219928741455\n",
      "idx: 200, loss: 0.3803180456161499 time take: 6.611904859542847\n",
      "idx: 300, loss: 0.22754189372062683 time take: 6.615559816360474\n",
      "epoch 52 time taken: 26.140570402145386s\n",
      "Training epoch: 53\n",
      "idx: 0, loss: 0.25517505407333374 time take: 0.25723814964294434\n",
      "idx: 100, loss: 0.16930651664733887 time take: 6.669295072555542\n",
      "idx: 200, loss: 0.3980185091495514 time take: 6.620535850524902\n",
      "idx: 300, loss: 0.23787803947925568 time take: 6.613835334777832\n",
      "epoch 53 time taken: 26.15247392654419s\n",
      "Training epoch: 54\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "idx: 0, loss: 0.33583879470825195 time take: 0.2572667598724365\n",
      "idx: 100, loss: 0.271762877702713 time take: 6.617304801940918\n",
      "idx: 200, loss: 0.3425196707248688 time take: 6.668344497680664\n",
      "idx: 300, loss: 0.23894907534122467 time take: 6.619114637374878\n",
      "epoch 54 time taken: 26.15724468231201s\n",
      "Training epoch: 55\n",
      "idx: 0, loss: 0.20688733458518982 time take: 0.24809861183166504\n",
      "idx: 100, loss: 0.21818581223487854 time take: 6.621826171875\n",
      "idx: 200, loss: 0.2712675631046295 time take: 6.693837642669678\n",
      "idx: 300, loss: 0.27271249890327454 time take: 6.656576633453369\n",
      "epoch 55 time taken: 26.21820569038391s\n",
      "Training epoch: 56\n",
      "idx: 0, loss: 0.21178734302520752 time take: 0.23725652694702148\n",
      "idx: 100, loss: 0.11650153994560242 time take: 6.624606132507324\n",
      "idx: 200, loss: 0.3136546313762665 time take: 6.612377405166626\n",
      "idx: 300, loss: 0.1502830982208252 time take: 6.614327907562256\n",
      "epoch 56 time taken: 26.08275008201599s\n",
      "Training epoch: 57\n",
      "idx: 0, loss: 0.24572600424289703 time take: 0.2638514041900635\n",
      "idx: 100, loss: 0.19909660518169403 time take: 6.691059112548828\n",
      "idx: 200, loss: 0.2408919334411621 time take: 6.712738037109375\n",
      "idx: 300, loss: 0.33249256014823914 time take: 6.714545965194702\n",
      "epoch 57 time taken: 26.376018047332764s\n",
      "Training epoch: 58\n",
      "idx: 0, loss: 0.15956126153469086 time take: 0.24176025390625\n",
      "idx: 100, loss: 0.23288443684577942 time take: 6.6230199337005615\n",
      "idx: 200, loss: 0.30068808794021606 time take: 6.6130876541137695\n",
      "idx: 300, loss: 0.24242514371871948 time take: 6.6115193367004395\n",
      "epoch 58 time taken: 26.123657703399658s\n",
      "Training epoch: 59\n",
      "idx: 0, loss: 0.38142794370651245 time take: 0.2212817668914795\n",
      "idx: 100, loss: 0.20435433089733124 time take: 6.685133218765259\n",
      "idx: 200, loss: 0.2881074845790863 time take: 6.673444032669067\n",
      "idx: 300, loss: 0.18368111550807953 time take: 6.6637818813323975\n",
      "epoch 59 time taken: 26.277421474456787s\n",
      "Training epoch: 60\n",
      "idx: 0, loss: 0.1750156283378601 time take: 0.24302935600280762\n",
      "idx: 100, loss: 0.13911819458007812 time take: 6.61638331413269\n",
      "idx: 200, loss: 0.18894508481025696 time take: 6.6120991706848145\n",
      "idx: 300, loss: 0.2096095085144043 time take: 6.611961841583252\n",
      "epoch 60 time taken: 26.076979875564575s\n",
      "Training epoch: 61\n",
      "idx: 0, loss: 0.2476416677236557 time take: 0.23783612251281738\n",
      "idx: 100, loss: 0.18507491052150726 time take: 6.673610687255859\n",
      "idx: 200, loss: 0.2815980017185211 time take: 6.653984069824219\n",
      "idx: 300, loss: 0.14961102604866028 time take: 6.651808023452759\n",
      "epoch 61 time taken: 26.211899280548096s\n",
      "Training epoch: 62\n",
      "idx: 0, loss: 0.21217255294322968 time take: 0.2542552947998047\n",
      "idx: 100, loss: 0.16754458844661713 time take: 6.691111326217651\n",
      "idx: 200, loss: 0.2327878326177597 time take: 6.627046823501587\n",
      "idx: 300, loss: 0.2236804962158203 time take: 6.610712766647339\n",
      "epoch 62 time taken: 26.178053379058838s\n",
      "Training epoch: 63\n",
      "idx: 0, loss: 0.23600561916828156 time take: 0.2576136589050293\n",
      "idx: 100, loss: 0.09493151307106018 time take: 6.64512825012207\n",
      "idx: 200, loss: 0.3274126350879669 time take: 6.6254212856292725\n",
      "idx: 300, loss: 0.1783328503370285 time take: 6.614240407943726\n",
      "epoch 63 time taken: 26.138197660446167s\n",
      "Training epoch: 64\n",
      "idx: 0, loss: 0.20436084270477295 time take: 0.23012971878051758\n",
      "idx: 100, loss: 0.1396518051624298 time take: 6.6274871826171875\n",
      "idx: 200, loss: 0.344085156917572 time take: 6.719433546066284\n",
      "idx: 300, loss: 0.15986809134483337 time take: 6.631487846374512\n",
      "epoch 64 time taken: 26.224817514419556s\n",
      "Training epoch: 65\n",
      "idx: 0, loss: 0.21400178968906403 time take: 0.263077974319458\n",
      "idx: 100, loss: 0.15210889279842377 time take: 6.647156715393066\n",
      "idx: 200, loss: 0.23744748532772064 time take: 6.613520622253418\n",
      "idx: 300, loss: 0.15726831555366516 time take: 6.61611270904541\n",
      "epoch 65 time taken: 26.234437942504883s\n",
      "Training epoch: 66\n",
      "idx: 0, loss: 0.21746911108493805 time take: 0.259077787399292\n",
      "idx: 100, loss: 0.17190399765968323 time take: 6.681955575942993\n",
      "idx: 200, loss: 0.19754013419151306 time take: 6.6154961585998535\n",
      "idx: 300, loss: 0.12388519942760468 time take: 6.6145100593566895\n",
      "epoch 66 time taken: 26.217647552490234s\n",
      "Training epoch: 67\n",
      "idx: 0, loss: 0.14601364731788635 time take: 0.23552298545837402\n",
      "idx: 100, loss: 0.11508876085281372 time take: 6.629778146743774\n",
      "idx: 200, loss: 0.2535085380077362 time take: 6.611845970153809\n",
      "idx: 300, loss: 0.12517507374286652 time take: 6.615339756011963\n",
      "epoch 67 time taken: 26.086867570877075s\n",
      "Training epoch: 68\n",
      "idx: 0, loss: 0.12577497959136963 time take: 0.2609288692474365\n",
      "idx: 100, loss: 0.09960896521806717 time take: 6.65304160118103\n",
      "idx: 200, loss: 0.24971430003643036 time take: 6.611920356750488\n",
      "idx: 300, loss: 0.12550877034664154 time take: 6.6157941818237305\n",
      "epoch 68 time taken: 26.14033007621765s\n",
      "Training epoch: 69\n",
      "idx: 0, loss: 0.21080750226974487 time take: 0.2810029983520508\n",
      "idx: 100, loss: 0.1434357762336731 time take: 6.723507881164551\n",
      "idx: 200, loss: 0.2159160077571869 time take: 6.6116790771484375\n",
      "idx: 300, loss: 0.1484806388616562 time take: 6.622931957244873\n",
      "epoch 69 time taken: 26.231701374053955s\n",
      "Training epoch: 70\n",
      "idx: 0, loss: 0.21999412775039673 time take: 0.24189233779907227\n",
      "idx: 100, loss: 0.176737442612648 time take: 6.630833864212036\n",
      "idx: 200, loss: 0.24030698835849762 time take: 6.61406397819519\n",
      "idx: 300, loss: 0.18578538298606873 time take: 6.619234323501587\n",
      "epoch 70 time taken: 26.10167098045349s\n",
      "Training epoch: 71\n",
      "idx: 0, loss: 0.19284917414188385 time take: 0.24634623527526855\n",
      "idx: 100, loss: 0.18094581365585327 time take: 6.627909183502197\n",
      "idx: 200, loss: 0.24219559133052826 time take: 6.6611573696136475\n",
      "idx: 300, loss: 0.16883787512779236 time take: 6.612593173980713\n",
      "epoch 71 time taken: 26.16166663169861s\n",
      "Training epoch: 72\n",
      "idx: 0, loss: 0.2032136619091034 time take: 0.25380611419677734\n",
      "idx: 100, loss: 0.20248070359230042 time take: 6.645547389984131\n",
      "idx: 200, loss: 0.17697858810424805 time take: 6.649392127990723\n",
      "idx: 300, loss: 0.14537246525287628 time take: 6.612747430801392\n",
      "epoch 72 time taken: 26.15943694114685s\n",
      "Training epoch: 73\n",
      "idx: 0, loss: 0.23570555448532104 time take: 0.22391295433044434\n",
      "idx: 100, loss: 0.10525877773761749 time take: 6.6315014362335205\n",
      "idx: 200, loss: 0.14900003373622894 time take: 6.613152980804443\n",
      "idx: 300, loss: 0.14029459655284882 time take: 6.656989336013794\n",
      "epoch 73 time taken: 26.120089769363403s\n",
      "Training epoch: 74\n",
      "idx: 0, loss: 0.16972535848617554 time take: 0.2639446258544922\n",
      "idx: 100, loss: 0.08505389094352722 time take: 6.6271374225616455\n",
      "idx: 200, loss: 0.3225693702697754 time take: 6.607337951660156\n",
      "idx: 300, loss: 0.07497308403253555 time take: 6.612594366073608\n",
      "epoch 74 time taken: 26.106186151504517s\n",
      "Training epoch: 75\n",
      "idx: 0, loss: 0.10118135064840317 time take: 0.25415897369384766\n",
      "idx: 100, loss: 0.0708455815911293 time take: 6.63390851020813\n",
      "idx: 200, loss: 0.18823887407779694 time take: 6.609456539154053\n",
      "idx: 300, loss: 0.15038907527923584 time take: 6.659924745559692\n",
      "epoch 75 time taken: 26.237616539001465s\n",
      "Training epoch: 76\n",
      "idx: 0, loss: 0.08294303715229034 time take: 0.23344016075134277\n",
      "idx: 100, loss: 0.21622329950332642 time take: 6.624529838562012\n",
      "idx: 200, loss: 0.13966487348079681 time take: 6.628533840179443\n",
      "idx: 300, loss: 0.1849343180656433 time take: 6.635612487792969\n",
      "epoch 76 time taken: 26.139601469039917s\n",
      "Training epoch: 77\n",
      "idx: 0, loss: 0.09517493844032288 time take: 0.2568857669830322\n",
      "idx: 100, loss: 0.11704104393720627 time take: 6.634435176849365\n",
      "idx: 200, loss: 0.16284087300300598 time take: 6.61134934425354\n",
      "idx: 300, loss: 0.12162736058235168 time take: 6.623314142227173\n",
      "epoch 77 time taken: 26.14048457145691s\n",
      "Training epoch: 78\n",
      "idx: 0, loss: 0.1590815633535385 time take: 0.25417613983154297\n",
      "idx: 100, loss: 0.0978819951415062 time take: 6.661964654922485\n",
      "idx: 200, loss: 0.19456025958061218 time take: 6.6384971141815186\n",
      "idx: 300, loss: 0.15447258949279785 time take: 6.614571571350098\n",
      "epoch 78 time taken: 26.184823751449585s\n",
      "Training epoch: 79\n",
      "idx: 0, loss: 0.099999338388443 time take: 0.31737208366394043\n",
      "idx: 100, loss: 0.062208984047174454 time take: 7.871239900588989\n",
      "idx: 200, loss: 0.18231435120105743 time take: 6.722893238067627\n",
      "idx: 300, loss: 0.15488773584365845 time take: 9.23475432395935\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 79 time taken: 38.95448398590088s\n",
      "Training epoch: 80\n",
      "idx: 0, loss: 0.1085602194070816 time take: 0.32114720344543457\n",
      "idx: 100, loss: 0.1230112761259079 time take: 15.786655902862549\n",
      "idx: 200, loss: 0.21541698276996613 time take: 17.449607849121094\n",
      "idx: 300, loss: 0.19706372916698456 time take: 17.468252897262573\n",
      "epoch 80 time taken: 66.85022187232971s\n",
      "Training epoch: 81\n",
      "idx: 0, loss: 0.2551638185977936 time take: 0.30420899391174316\n",
      "idx: 100, loss: 0.07676795870065689 time take: 17.473079681396484\n",
      "idx: 200, loss: 0.2054833173751831 time take: 17.051029205322266\n",
      "idx: 300, loss: 0.15368445217609406 time take: 17.434929370880127\n",
      "epoch 81 time taken: 68.12181353569031s\n",
      "Training epoch: 82\n",
      "idx: 0, loss: 0.13065050542354584 time take: 0.32121944427490234\n",
      "idx: 100, loss: 0.15208721160888672 time take: 17.441019773483276\n",
      "idx: 200, loss: 0.10273505002260208 time take: 17.43311047554016\n",
      "idx: 300, loss: 0.20175638794898987 time take: 14.056542158126831\n",
      "epoch 82 time taken: 63.99685549736023s\n",
      "Training epoch: 83\n",
      "idx: 0, loss: 0.14899834990501404 time take: 0.3653678894042969\n",
      "idx: 100, loss: 0.0746479257941246 time take: 15.976196050643921\n",
      "idx: 200, loss: 0.12897422909736633 time take: 17.4438579082489\n",
      "idx: 300, loss: 0.11412519961595535 time take: 17.439847946166992\n",
      "epoch 83 time taken: 67.03125500679016s\n",
      "Training epoch: 84\n",
      "idx: 0, loss: 0.13527101278305054 time take: 0.3104426860809326\n",
      "idx: 100, loss: 0.07722640037536621 time take: 17.445411920547485\n",
      "idx: 200, loss: 0.12208781391382217 time take: 17.131535053253174\n",
      "idx: 300, loss: 0.14817604422569275 time take: 17.433794498443604\n",
      "epoch 84 time taken: 68.17781209945679s\n",
      "Training epoch: 85\n",
      "idx: 0, loss: 0.17434635758399963 time take: 0.32788515090942383\n",
      "idx: 100, loss: 0.09487516433000565 time take: 17.45333242416382\n",
      "idx: 200, loss: 0.2341768592596054 time take: 17.436908960342407\n",
      "idx: 300, loss: 0.12045759707689285 time take: 12.695642948150635\n",
      "epoch 85 time taken: 56.71182680130005s\n",
      "Training epoch: 86\n",
      "idx: 0, loss: 0.1229512095451355 time take: 0.3555271625518799\n",
      "idx: 100, loss: 0.06811653077602386 time take: 9.443614482879639\n",
      "idx: 200, loss: 0.12250270694494247 time take: 14.822142839431763\n",
      "idx: 300, loss: 0.13605159521102905 time take: 15.307679891586304\n",
      "epoch 86 time taken: 55.77416133880615s\n",
      "Training epoch: 87\n",
      "idx: 0, loss: 0.07684486359357834 time take: 0.32981300354003906\n",
      "idx: 100, loss: 0.08688131719827652 time take: 17.44662594795227\n",
      "idx: 200, loss: 0.17426402866840363 time take: 17.427486896514893\n",
      "idx: 300, loss: 0.15425550937652588 time take: 17.428536653518677\n",
      "epoch 87 time taken: 68.27243614196777s\n",
      "Training epoch: 88\n",
      "idx: 0, loss: 0.08108019828796387 time take: 0.369687557220459\n",
      "idx: 100, loss: 0.07300903648138046 time take: 17.45664668083191\n",
      "idx: 200, loss: 0.11369297653436661 time take: 17.430473804473877\n",
      "idx: 300, loss: 0.05020575970411301 time take: 17.42419147491455\n",
      "epoch 88 time taken: 68.49808263778687s\n",
      "Training epoch: 89\n",
      "idx: 0, loss: 0.12132810056209564 time take: 0.29214954376220703\n",
      "idx: 100, loss: 0.13409456610679626 time take: 16.31394863128662\n",
      "idx: 200, loss: 0.17396597564220428 time take: 9.337883710861206\n",
      "idx: 300, loss: 0.14661972224712372 time take: 10.76671028137207\n",
      "epoch 89 time taken: 51.48541712760925s\n",
      "Training epoch: 90\n",
      "idx: 0, loss: 0.06536038219928741 time take: 0.329143762588501\n",
      "idx: 100, loss: 0.05643663555383682 time take: 16.082220315933228\n",
      "idx: 200, loss: 0.1348484456539154 time take: 17.425918102264404\n",
      "idx: 300, loss: 0.14876259863376617 time take: 17.442523956298828\n",
      "epoch 90 time taken: 67.09089303016663s\n",
      "Training epoch: 91\n",
      "idx: 0, loss: 0.1733323484659195 time take: 0.35518431663513184\n",
      "idx: 100, loss: 0.145977184176445 time take: 17.44803524017334\n",
      "idx: 200, loss: 0.20521698892116547 time take: 17.083705186843872\n",
      "idx: 300, loss: 0.09355708956718445 time take: 17.458425283432007\n",
      "epoch 91 time taken: 68.17682194709778s\n",
      "Training epoch: 92\n",
      "idx: 0, loss: 0.05530783161520958 time take: 0.28675246238708496\n",
      "idx: 100, loss: 0.06432657688856125 time take: 17.440743923187256\n",
      "idx: 200, loss: 0.2749563157558441 time take: 17.43693494796753\n",
      "idx: 300, loss: 0.0818578377366066 time take: 11.947372674942017\n",
      "epoch 92 time taken: 56.064149379730225s\n",
      "Training epoch: 93\n",
      "idx: 0, loss: 0.1547546535730362 time take: 0.3131368160247803\n",
      "idx: 100, loss: 0.07955336570739746 time take: 9.36229658126831\n",
      "idx: 200, loss: 0.10154075920581818 time take: 9.511102676391602\n",
      "idx: 300, loss: 0.09809447079896927 time take: 16.354684591293335\n",
      "epoch 93 time taken: 49.970112562179565s\n",
      "Training epoch: 94\n",
      "idx: 0, loss: 0.08841606229543686 time take: 0.28740715980529785\n",
      "idx: 100, loss: 0.09742777049541473 time take: 17.448816776275635\n",
      "idx: 200, loss: 0.15680912137031555 time take: 17.455372095108032\n",
      "idx: 300, loss: 0.12089624255895615 time take: 17.411995887756348\n",
      "epoch 94 time taken: 68.41745281219482s\n",
      "Training epoch: 95\n",
      "idx: 0, loss: 0.16155675053596497 time take: 0.35068249702453613\n",
      "idx: 100, loss: 0.17994391918182373 time take: 17.138733863830566\n",
      "idx: 200, loss: 0.1630629003047943 time take: 17.425473928451538\n",
      "idx: 300, loss: 0.14658667147159576 time take: 17.42028260231018\n",
      "epoch 95 time taken: 68.17151927947998s\n",
      "Training epoch: 96\n",
      "idx: 0, loss: 0.08442819863557816 time take: 0.29383111000061035\n",
      "idx: 100, loss: 0.05593126267194748 time take: 17.4662127494812\n",
      "idx: 200, loss: 0.11905614286661148 time take: 14.1964750289917\n",
      "idx: 300, loss: 0.11565805971622467 time take: 16.296782732009888\n",
      "epoch 96 time taken: 62.64651012420654s\n",
      "Training epoch: 97\n",
      "idx: 0, loss: 0.0659990906715393 time take: 0.31690049171447754\n",
      "idx: 100, loss: 0.11445952206850052 time take: 17.461618185043335\n",
      "idx: 200, loss: 0.11384046077728271 time take: 17.42352795600891\n",
      "idx: 300, loss: 0.10986108332872391 time take: 17.431098222732544\n",
      "epoch 97 time taken: 68.4910295009613s\n",
      "Training epoch: 98\n",
      "idx: 0, loss: 0.11059451103210449 time take: 0.3172030448913574\n",
      "idx: 100, loss: 0.04510937258601189 time take: 17.0839421749115\n",
      "idx: 200, loss: 0.10308615863323212 time take: 17.439679861068726\n",
      "idx: 300, loss: 0.08576073497533798 time take: 17.39054584503174\n",
      "epoch 98 time taken: 68.05199694633484s\n",
      "Training epoch: 99\n",
      "idx: 0, loss: 0.16147802770137787 time take: 0.28354716300964355\n",
      "idx: 100, loss: 0.05662910267710686 time take: 17.44237184524536\n",
      "idx: 200, loss: 0.06651042401790619 time take: 13.933221578598022\n",
      "idx: 300, loss: 0.09087804704904556 time take: 16.26495885848999\n",
      "epoch 99 time taken: 62.345608711242676s\n",
      "Performing inference on batch: 0\n",
      "Performing inference on batch: 50\n",
      "Performing inference on batch: 0\n",
      "Performing inference on batch: 50\n",
      "FPR@95: 76.39, AUROC: 79.75 AUPR_IN: 80.72, AUPR_OUT: 76.66\n",
      "CCR: 0.00, 0.12, 13.99, 49.26, ACC: 83.59\n",
      "\n",
      "Running model: models/cifar_resnet50_odin_softplus_Adam_2.pkl...\n",
      "Getting optimizer for type: Adam...\n",
      "Training epoch: 0\n",
      "idx: 0, loss: 2.9189655780792236 time take: 0.342562198638916\n",
      "idx: 100, loss: 2.9142212867736816 time take: 17.392356395721436\n",
      "idx: 200, loss: 3.893366575241089 time take: 17.440255641937256\n",
      "idx: 300, loss: 2.8786227703094482 time take: 17.08820652961731\n",
      "epoch 0 time taken: 68.0590283870697s\n",
      "Training epoch: 1\n",
      "idx: 0, loss: 2.835697889328003 time take: 0.3092916011810303\n",
      "idx: 100, loss: 2.3777856826782227 time take: 17.413147449493408\n",
      "idx: 200, loss: 2.315714120864868 time take: 17.41897201538086\n",
      "idx: 300, loss: 1.944800853729248 time take: 17.420589208602905\n",
      "epoch 1 time taken: 65.6880145072937s\n",
      "Training epoch: 2\n",
      "idx: 0, loss: 2.0996744632720947 time take: 0.428560733795166\n",
      "idx: 100, loss: 2.129795789718628 time take: 9.746025085449219\n",
      "idx: 200, loss: 1.9008262157440186 time take: 7.894948482513428\n",
      "idx: 300, loss: 1.8630082607269287 time take: 6.630573987960815\n",
      "epoch 2 time taken: 30.696839809417725s\n",
      "Training epoch: 3\n",
      "idx: 0, loss: 1.9494047164916992 time take: 0.24803900718688965\n",
      "idx: 100, loss: 1.5643301010131836 time take: 6.633846998214722\n",
      "idx: 200, loss: 1.6273548603057861 time take: 6.617162704467773\n",
      "idx: 300, loss: 1.7164928913116455 time take: 6.617246150970459\n",
      "epoch 3 time taken: 26.115423679351807s\n",
      "Training epoch: 4\n",
      "idx: 0, loss: 1.7046865224838257 time take: 0.24463415145874023\n",
      "idx: 100, loss: 1.515860915184021 time take: 6.681027173995972\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "idx: 200, loss: 1.4984065294265747 time take: 6.61432409286499\n",
      "idx: 300, loss: 1.503967046737671 time take: 6.629724502563477\n",
      "epoch 4 time taken: 26.187664031982422s\n",
      "Training epoch: 5\n",
      "idx: 0, loss: 1.4906679391860962 time take: 0.23058271408081055\n",
      "idx: 100, loss: 1.432595133781433 time take: 6.624086618423462\n",
      "idx: 200, loss: 1.3607155084609985 time take: 6.612660884857178\n",
      "idx: 300, loss: 1.4277511835098267 time take: 6.621292352676392\n",
      "epoch 5 time taken: 26.087666749954224s\n",
      "Training epoch: 6\n",
      "idx: 0, loss: 1.429185390472412 time take: 0.23420476913452148\n",
      "idx: 100, loss: 1.2645304203033447 time take: 6.685285329818726\n",
      "idx: 200, loss: 1.4254693984985352 time take: 6.712737560272217\n",
      "idx: 300, loss: 1.2264225482940674 time take: 6.617182970046997\n",
      "epoch 6 time taken: 26.24608612060547s\n",
      "Training epoch: 7\n",
      "idx: 0, loss: 1.2745002508163452 time take: 0.26207756996154785\n",
      "idx: 100, loss: 1.200764775276184 time take: 6.624682188034058\n",
      "idx: 200, loss: 1.3311946392059326 time take: 6.616963624954224\n",
      "idx: 300, loss: 1.0328295230865479 time take: 6.615906000137329\n",
      "epoch 7 time taken: 26.1325523853302s\n",
      "Training epoch: 8\n",
      "idx: 0, loss: 1.2026108503341675 time take: 0.23179936408996582\n",
      "idx: 100, loss: 0.9972469210624695 time take: 6.6260294914245605\n",
      "idx: 200, loss: 1.2161858081817627 time take: 6.613807916641235\n",
      "idx: 300, loss: 1.0537670850753784 time take: 6.707323789596558\n",
      "epoch 8 time taken: 26.182918071746826s\n",
      "Training epoch: 9\n",
      "idx: 0, loss: 1.0913658142089844 time take: 0.25412869453430176\n",
      "idx: 100, loss: 0.9087473154067993 time take: 6.632330656051636\n",
      "idx: 200, loss: 1.058249592781067 time take: 6.619677305221558\n",
      "idx: 300, loss: 0.9319172501564026 time take: 6.615697622299194\n",
      "epoch 9 time taken: 26.118236303329468s\n",
      "Training epoch: 10\n",
      "idx: 0, loss: 1.0185191631317139 time take: 0.23807930946350098\n",
      "idx: 100, loss: 0.884259819984436 time take: 6.6214985847473145\n",
      "idx: 200, loss: 1.0875240564346313 time take: 6.616051435470581\n",
      "idx: 300, loss: 0.8805657029151917 time take: 6.614243984222412\n",
      "epoch 10 time taken: 26.110048294067383s\n",
      "Training epoch: 11\n",
      "idx: 0, loss: 0.8706297278404236 time take: 0.2408599853515625\n",
      "idx: 100, loss: 0.8813894391059875 time take: 6.626596212387085\n",
      "idx: 200, loss: 0.9463974833488464 time take: 6.614041805267334\n",
      "idx: 300, loss: 0.9286319613456726 time take: 6.613783359527588\n",
      "epoch 11 time taken: 26.09457540512085s\n",
      "Training epoch: 12\n",
      "idx: 0, loss: 0.9057929515838623 time take: 0.26709771156311035\n",
      "idx: 100, loss: 0.7731611132621765 time take: 6.679210424423218\n",
      "idx: 200, loss: 0.9456193447113037 time take: 6.65235447883606\n",
      "idx: 300, loss: 0.866696298122406 time take: 6.616328001022339\n",
      "epoch 12 time taken: 26.23248529434204s\n",
      "Training epoch: 13\n",
      "idx: 0, loss: 0.8262315392494202 time take: 0.2546699047088623\n",
      "idx: 100, loss: 0.7727596163749695 time take: 6.622128963470459\n",
      "idx: 200, loss: 0.9083189368247986 time take: 6.635563611984253\n",
      "idx: 300, loss: 0.7117003798484802 time take: 6.6842615604400635\n",
      "epoch 13 time taken: 26.195195198059082s\n",
      "Training epoch: 14\n",
      "idx: 0, loss: 0.6847462058067322 time take: 0.23687171936035156\n",
      "idx: 100, loss: 0.7488117218017578 time take: 6.632684707641602\n",
      "idx: 200, loss: 0.8436902761459351 time take: 6.6403772830963135\n",
      "idx: 300, loss: 0.7419024705886841 time take: 6.613937616348267\n",
      "epoch 14 time taken: 26.134844541549683s\n",
      "Training epoch: 15\n",
      "idx: 0, loss: 0.6547906994819641 time take: 0.23346376419067383\n",
      "idx: 100, loss: 0.6615787744522095 time take: 6.645611524581909\n",
      "idx: 200, loss: 0.7333711385726929 time take: 6.616797924041748\n",
      "idx: 300, loss: 0.6594241261482239 time take: 6.682103872299194\n",
      "epoch 15 time taken: 26.211968421936035s\n",
      "Training epoch: 16\n",
      "idx: 0, loss: 0.757889986038208 time take: 0.24243974685668945\n",
      "idx: 100, loss: 0.7182134985923767 time take: 6.634214162826538\n",
      "idx: 200, loss: 0.7917059659957886 time take: 6.6153037548065186\n",
      "idx: 300, loss: 0.6552636623382568 time take: 6.6128246784210205\n",
      "epoch 16 time taken: 26.103873014450073s\n",
      "Training epoch: 17\n",
      "idx: 0, loss: 0.6116059422492981 time take: 0.2532341480255127\n",
      "idx: 100, loss: 0.6633644700050354 time take: 6.627509593963623\n",
      "idx: 200, loss: 0.725389838218689 time take: 6.625767707824707\n",
      "idx: 300, loss: 0.6428623795509338 time take: 6.622871398925781\n",
      "epoch 17 time taken: 26.163733959197998s\n",
      "Training epoch: 18\n",
      "idx: 0, loss: 0.6130440831184387 time take: 0.24806499481201172\n",
      "idx: 100, loss: 0.6065511107444763 time take: 6.637454271316528\n",
      "idx: 200, loss: 0.7871547937393188 time take: 6.614628314971924\n",
      "idx: 300, loss: 0.5484086275100708 time take: 6.61558198928833\n",
      "epoch 18 time taken: 26.112366676330566s\n",
      "Training epoch: 19\n",
      "idx: 0, loss: 0.6319643259048462 time take: 0.2572968006134033\n",
      "idx: 100, loss: 0.5772534012794495 time take: 6.625563859939575\n",
      "idx: 200, loss: 0.7451311945915222 time take: 6.647289037704468\n",
      "idx: 300, loss: 0.5870264172554016 time take: 6.61415696144104\n",
      "epoch 19 time taken: 26.143195867538452s\n",
      "Training epoch: 20\n",
      "idx: 0, loss: 0.6307536363601685 time take: 0.23409485816955566\n",
      "idx: 100, loss: 0.542372465133667 time take: 6.675511837005615\n",
      "idx: 200, loss: 0.7090516686439514 time take: 6.617275953292847\n",
      "idx: 300, loss: 0.5148116946220398 time take: 6.616297245025635\n",
      "epoch 20 time taken: 26.13901996612549s\n",
      "Training epoch: 21\n",
      "idx: 0, loss: 0.5492615699768066 time take: 0.24554753303527832\n",
      "idx: 100, loss: 0.4701926112174988 time take: 6.650695562362671\n",
      "idx: 200, loss: 0.6822080612182617 time take: 6.614371061325073\n",
      "idx: 300, loss: 0.5620332360267639 time take: 6.6216652393341064\n",
      "epoch 21 time taken: 26.14570426940918s\n",
      "Training epoch: 22\n",
      "idx: 0, loss: 0.5462998151779175 time take: 0.24657130241394043\n",
      "idx: 100, loss: 0.5444594025611877 time take: 6.623316764831543\n",
      "idx: 200, loss: 0.6790940761566162 time take: 6.651778697967529\n",
      "idx: 300, loss: 0.4541843831539154 time take: 6.612342834472656\n",
      "epoch 22 time taken: 26.131627321243286s\n",
      "Training epoch: 23\n",
      "idx: 0, loss: 0.5033591985702515 time take: 0.24961137771606445\n",
      "idx: 100, loss: 0.44906333088874817 time take: 6.625745058059692\n",
      "idx: 200, loss: 0.6518629789352417 time take: 6.613927602767944\n",
      "idx: 300, loss: 0.47863760590553284 time take: 6.614927768707275\n",
      "epoch 23 time taken: 26.100367546081543s\n",
      "Training epoch: 24\n",
      "idx: 0, loss: 0.43632590770721436 time take: 0.26134347915649414\n",
      "idx: 100, loss: 0.47811925411224365 time take: 6.673971176147461\n",
      "idx: 200, loss: 0.6733331680297852 time take: 6.725953817367554\n",
      "idx: 300, loss: 0.544237494468689 time take: 6.658639907836914\n",
      "epoch 24 time taken: 26.315340518951416s\n",
      "Training epoch: 25\n",
      "idx: 0, loss: 0.45456722378730774 time take: 0.24732208251953125\n",
      "idx: 100, loss: 0.35874444246292114 time take: 6.6294846534729\n",
      "idx: 200, loss: 0.5974826216697693 time take: 6.60973596572876\n",
      "idx: 300, loss: 0.4778468906879425 time take: 6.613164663314819\n",
      "epoch 25 time taken: 26.0959689617157s\n",
      "Training epoch: 26\n",
      "idx: 0, loss: 0.3696569502353668 time take: 0.25139617919921875\n",
      "idx: 100, loss: 0.4622423052787781 time take: 6.629400968551636\n",
      "idx: 200, loss: 0.5585065484046936 time take: 6.6150970458984375\n",
      "idx: 300, loss: 0.3637930750846863 time take: 6.654131650924683\n",
      "epoch 26 time taken: 26.21321392059326s\n",
      "Training epoch: 27\n",
      "idx: 0, loss: 0.35587215423583984 time take: 0.2602055072784424\n",
      "idx: 100, loss: 0.38888290524482727 time take: 6.736273288726807\n",
      "idx: 200, loss: 0.5606694221496582 time take: 6.714474439620972\n",
      "idx: 300, loss: 0.3852460980415344 time take: 6.618587017059326\n",
      "epoch 27 time taken: 26.375215768814087s\n",
      "Training epoch: 28\n",
      "idx: 0, loss: 0.37097805738449097 time take: 0.23645591735839844\n",
      "idx: 100, loss: 0.41502484679222107 time take: 6.6362693309783936\n",
      "idx: 200, loss: 0.49545803666114807 time take: 6.613941431045532\n",
      "idx: 300, loss: 0.4376203417778015 time take: 6.614092826843262\n",
      "epoch 28 time taken: 26.100140810012817s\n",
      "Training epoch: 29\n",
      "idx: 0, loss: 0.4468855857849121 time take: 0.24017691612243652\n",
      "idx: 100, loss: 0.37791624665260315 time take: 6.678879976272583\n",
      "idx: 200, loss: 0.6108678579330444 time take: 6.654592275619507\n",
      "idx: 300, loss: 0.3705507814884186 time take: 6.6132097244262695\n",
      "epoch 29 time taken: 26.18492293357849s\n",
      "Training epoch: 30\n",
      "idx: 0, loss: 0.3808824121952057 time take: 0.24386000633239746\n",
      "idx: 100, loss: 0.3983234167098999 time take: 6.624064207077026\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "idx: 200, loss: 0.5546537041664124 time take: 6.643129110336304\n",
      "idx: 300, loss: 0.4124358594417572 time take: 6.632961988449097\n",
      "epoch 30 time taken: 26.18768572807312s\n",
      "Training epoch: 31\n",
      "idx: 0, loss: 0.3269745707511902 time take: 0.2265770435333252\n",
      "idx: 100, loss: 0.3166235089302063 time take: 6.628132104873657\n",
      "idx: 200, loss: 0.5359580516815186 time take: 6.614710569381714\n",
      "idx: 300, loss: 0.3869037926197052 time take: 6.6439878940582275\n",
      "epoch 31 time taken: 26.127283811569214s\n",
      "Training epoch: 32\n",
      "idx: 0, loss: 0.32809117436408997 time take: 0.24917221069335938\n",
      "idx: 100, loss: 0.31216713786125183 time take: 6.6151440143585205\n",
      "idx: 200, loss: 0.5158452391624451 time take: 6.61550498008728\n",
      "idx: 300, loss: 0.2816767394542694 time take: 6.613265752792358\n",
      "epoch 32 time taken: 26.093472957611084s\n",
      "Training epoch: 33\n",
      "idx: 0, loss: 0.3418561816215515 time take: 0.23473906517028809\n",
      "idx: 100, loss: 0.283948689699173 time take: 6.67553448677063\n",
      "idx: 200, loss: 0.4619256854057312 time take: 6.731452941894531\n",
      "idx: 300, loss: 0.3513681888580322 time take: 6.614871501922607\n",
      "epoch 33 time taken: 26.27964425086975s\n",
      "Training epoch: 34\n",
      "idx: 0, loss: 0.2796860337257385 time take: 0.2432856559753418\n",
      "idx: 100, loss: 0.2562200427055359 time take: 6.627143859863281\n",
      "idx: 200, loss: 0.412623792886734 time take: 6.616382598876953\n",
      "idx: 300, loss: 0.324137419462204 time take: 6.611732482910156\n",
      "epoch 34 time taken: 26.093093395233154s\n",
      "Training epoch: 35\n",
      "idx: 0, loss: 0.29443439841270447 time take: 0.2624630928039551\n",
      "idx: 100, loss: 0.35331597924232483 time take: 6.624241828918457\n",
      "idx: 200, loss: 0.4760781228542328 time take: 6.616924524307251\n",
      "idx: 300, loss: 0.3025858700275421 time take: 6.640990495681763\n",
      "epoch 35 time taken: 26.151028871536255s\n",
      "Training epoch: 36\n",
      "idx: 0, loss: 0.26218706369400024 time take: 0.24293112754821777\n",
      "idx: 100, loss: 0.3327525854110718 time take: 6.685412645339966\n",
      "idx: 200, loss: 0.382495254278183 time take: 6.683813095092773\n",
      "idx: 300, loss: 0.279411643743515 time take: 6.615193605422974\n",
      "epoch 36 time taken: 26.223783493041992s\n",
      "Training epoch: 37\n",
      "idx: 0, loss: 0.3350690007209778 time take: 0.2488536834716797\n",
      "idx: 100, loss: 0.25289326906204224 time take: 6.63439154624939\n",
      "idx: 200, loss: 0.36446285247802734 time take: 6.612039566040039\n",
      "idx: 300, loss: 0.2647366523742676 time take: 6.654285192489624\n",
      "epoch 37 time taken: 26.145226001739502s\n",
      "Training epoch: 38\n",
      "idx: 0, loss: 0.3518001139163971 time take: 0.23572039604187012\n",
      "idx: 100, loss: 0.19083234667778015 time take: 6.623893976211548\n",
      "idx: 200, loss: 0.438352108001709 time take: 6.639066457748413\n",
      "idx: 300, loss: 0.3647494614124298 time take: 6.6257078647613525\n",
      "epoch 38 time taken: 26.1203396320343s\n",
      "Training epoch: 39\n",
      "idx: 0, loss: 0.2767430543899536 time take: 0.2702300548553467\n",
      "idx: 100, loss: 0.22789889574050903 time take: 6.626993417739868\n",
      "idx: 200, loss: 0.3957182765007019 time take: 6.613933086395264\n",
      "idx: 300, loss: 0.31334561109542847 time take: 6.612319469451904\n",
      "epoch 39 time taken: 26.118738412857056s\n",
      "Training epoch: 40\n",
      "idx: 0, loss: 0.3125230669975281 time take: 0.24069452285766602\n",
      "idx: 100, loss: 0.24339313805103302 time take: 6.680509567260742\n",
      "idx: 200, loss: 0.3426542282104492 time take: 6.624966382980347\n",
      "idx: 300, loss: 0.3112686574459076 time take: 6.614659547805786\n",
      "epoch 40 time taken: 26.170233726501465s\n",
      "Training epoch: 41\n",
      "idx: 0, loss: 0.21214385330677032 time take: 0.24620270729064941\n",
      "idx: 100, loss: 0.3585427403450012 time take: 6.627067804336548\n",
      "idx: 200, loss: 0.3279576897621155 time take: 6.615745544433594\n",
      "idx: 300, loss: 0.24363486468791962 time take: 6.61521577835083\n",
      "epoch 41 time taken: 26.098006010055542s\n",
      "Training epoch: 42\n",
      "idx: 0, loss: 0.1733655333518982 time take: 0.2401266098022461\n",
      "idx: 100, loss: 0.29879429936408997 time take: 6.628484010696411\n",
      "idx: 200, loss: 0.43883389234542847 time take: 6.6128058433532715\n",
      "idx: 300, loss: 0.27439239621162415 time take: 6.612687110900879\n",
      "epoch 42 time taken: 26.089183807373047s\n",
      "Training epoch: 43\n",
      "idx: 0, loss: 0.26690155267715454 time take: 0.23329734802246094\n",
      "idx: 100, loss: 0.29696834087371826 time take: 6.677825212478638\n",
      "idx: 200, loss: 0.40884071588516235 time take: 6.614545822143555\n",
      "idx: 300, loss: 0.2861602306365967 time take: 6.6359031200408936\n",
      "epoch 43 time taken: 26.18927812576294s\n",
      "Training epoch: 44\n",
      "idx: 0, loss: 0.23331046104431152 time take: 0.22686004638671875\n",
      "idx: 100, loss: 0.16938133537769318 time take: 6.626739740371704\n",
      "idx: 200, loss: 0.27586573362350464 time take: 6.611763954162598\n",
      "idx: 300, loss: 0.2409021258354187 time take: 6.612810373306274\n",
      "epoch 44 time taken: 26.085136890411377s\n",
      "Training epoch: 45\n",
      "idx: 0, loss: 0.2649780809879303 time take: 0.2581150531768799\n",
      "idx: 100, loss: 0.19221583008766174 time take: 6.686345338821411\n",
      "idx: 200, loss: 0.3087102770805359 time take: 6.65285062789917\n",
      "idx: 300, loss: 0.20600944757461548 time take: 6.675922870635986\n",
      "epoch 45 time taken: 26.28723931312561s\n",
      "Training epoch: 46\n",
      "idx: 0, loss: 0.23136195540428162 time take: 0.24895524978637695\n",
      "idx: 100, loss: 0.18971608579158783 time take: 6.626577615737915\n",
      "idx: 200, loss: 0.3861982822418213 time take: 6.646604299545288\n",
      "idx: 300, loss: 0.26776695251464844 time take: 6.617311239242554\n",
      "epoch 46 time taken: 26.208499670028687s\n",
      "Training epoch: 47\n",
      "idx: 0, loss: 0.244558647274971 time take: 0.2429492473602295\n",
      "idx: 100, loss: 0.20656168460845947 time take: 6.621935129165649\n",
      "idx: 200, loss: 0.52567058801651 time take: 6.613205432891846\n",
      "idx: 300, loss: 0.2636171579360962 time take: 6.666454553604126\n",
      "epoch 47 time taken: 26.161191940307617s\n",
      "Training epoch: 48\n",
      "idx: 0, loss: 0.24156738817691803 time take: 0.24706768989562988\n",
      "idx: 100, loss: 0.1893640160560608 time take: 6.625141859054565\n",
      "idx: 200, loss: 0.3143514394760132 time take: 6.610278129577637\n"
     ]
    }
   ],
   "source": [
    "config_cifar_adam_softplus_odin = {\n",
    "    \"batch_size\": 128,\n",
    "    \"n_classes\": 10,\n",
    "    \"dataset_name\": \"cifar\",\n",
    "    \"epochs\": 100,\n",
    "    \"version\": time.time(),\n",
    "    \"lr\": 0.01,\n",
    "    \"momentum\": 0.9,\n",
    "    \"weight_decay\": 0.0005,\n",
    "    \"optimizer_type\": \"Adam\",\n",
    "    \"activation_function_type\": \"softplus\",\n",
    "    \"network\": \"resnet50\",\n",
    "    \"postprocessor_type\": \"odin\",\n",
    "    \"trials\": 3,\n",
    "    \"dataset_type\": \"cifar\",\n",
    "    \"results_dir\": \"cifar10-study\",\n",
    "    \"pretrained\": False\n",
    "}\n",
    "config_cifar_adam_softplus_odin[\"data_loaders\"] = get_data_loaders(config_cifar_adam_softplus_odin)\n",
    "run_full_oodn_pipeline(config_cifar_adam_softplus_odin)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "machine_shape": "hm",
   "provenance": []
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
